@ROUT damcases.idx samcases.idx
#
# In this file, any line beginning with a '#' is ignored, but the # must be in
# column 0.  All multiple whitespace is reduced to one space (i.e. used only
# to distinguish where words begin/end).  Lines may be extended by putting '\'
# as the *last* character of line.
#
# This file indexes the user-supplied matmul kernels, and has the 
# following format:
# ROUT='routine name' AUTH='author names' COMP='compiler name' CFLAGS='flags'
# ID=<id> NU=<nu> MU=<mu> KU=<ku> KBMAX=<kbmax> KBMIN=<kbmin>
# SSE=[0,1,2,3] X87=[0,1] BMABC=<0/1> BMAB=<0/1> JKMAB=<0/1> JKMABC=<0/1>
# AOUTER=<0/1> BETAN1=<0/1> KRUNTIME=<0/1> LDCTOP=<0/1> X87=<0/1>
# ASM=[asmlist], eg., asmlist is "GAS_x8664,GAS_x8632" or "GAS_SPARC"
# ASM defaults to no assembly dialect required.
# If NU/MU is negative, then the routine can only handle multiples of NU/MU.
#
@ROUT damcases.idx
ID=1 MU=4 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm2x4x1_sse2.S' \
     SSE=3 VLEN=2 KRUNTIME=1 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=2 MU=4 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm2x4x256_sse2.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=3 MU=6 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm3x3x256_sse2.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
#ID=4 MU=4 NU=1 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_dammm_nb4_sse2.S' \
#     SSE=3 KBMIN=4 KBMAX=4 ASM=GAS_x8664 KUISKB=1 \
#     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
ID=5 MU=2 NU=12 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm2x12x2_sse2.S' \
     SSE=3 VLEN=2 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=6 MU=2 NU=12 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm2x12x256_sse2.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=7 MU=12 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm12x3x256_avx.S' \
     SSE=3 VLEN=4 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=8 MU=6 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm6x3x256_sse3.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=9 MU=6 NU=3 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_damm6x3x4_sse3.S' \
     SSE=3 VLEN=2 KBMIN=4 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=10 MU=2 NU=12 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm2x12x2_sse2.S' \
     SSE=3 VLEN=2 KRUNTIME=1 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
ID=11 MU=12 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm12x3x1_avx.S' \
     SSE=3 VLEN=2 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=12 MU=4 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm4x4x2rp_arm.S' \
     ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=13 MU=12 NU=3 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm12x3x2_avx.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=1 KBMIN=6 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=14 MU=16 NU=2 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_damm16x2_kb4_avx.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=0 KBMIN=4 KBMAX=4 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=15 MU=5 NU=5 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm5x5x2_arm.S' \
     KBMIN=2 ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=16 MU=6 NU=1 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_amm6x1x1_x87.S' \
     ASM=GAS_x8664,GAS_x8632 KRUNTIME=1 x87=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=17 MU=24 NU=1 KU=8 AUTH='R. Clint Whaley' ROUT='ATL_damm24x1x8_sse2.S' \
     SSE=3 VLEN=2 KRUNTIME=1 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=18 MU=24 NU=1 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm24x1x1_sse2.S' \
     SSE=3 VLEN=2 KRUNTIME=1 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=19 MU=5 NU=5 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm5x5x2_armpf.S' \
     KBMIN=2 ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=20 MU=5 NU=5 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm5x5x1_armpf.S' \
     KBMIN=2 ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=21 MU=12 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm12x4x1_fma3.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx -mfma'
ID=22 MU=3 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm3x4x1_armpf.S' \
     KBMIN=2 ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3-fp16'
ID=23 MU=4 NU=2 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_amm4x2x4_kb4.c' \
     KRUNTIME=0 KBMIN=4 KBMAX=4 
ID=24 MU=6 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm6x4x1_fma3.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx -mfma'
ID=25 MU=6 NU=3 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm6x3x2_sse3.S' \
     SSE=3 VLEN=2 KBMIN=4 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=26 MU=4 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm4x4x256_sse3.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=27 MU=24 NU=1 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm24x1x256_sse3.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=28 MU=6 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm6x4x256_fma3.S' \
     SSE=5 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3 -mfma'
ID=29 MU=12 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm12x4x256_fma3.S' \
     SSE=5 VLEN=4 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3 -mfma'
ID=30 MU=12 NU=4 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm12x4x2_fma3.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx -mfma'
ID=31 MU=6 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm6x3r2x256_sse3.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=32 MU=14 NU=1 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_dkmmm14x1x256_sse3.S' \
     SSE=3 VLEN=2 KMAJ=2 ASM=GAS_x8664 KBMIN=2 KBMAX=256 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=33 MU=14 NU=1 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_dkmmm14x1x2_sse3.S' \
     SSE=3 VLEN=2 KMAJ=2 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=34 MU=24 NU=8 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm24x8x1_avxz.S' \
      ASM=GAS_x8664 VLEN=8 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=35 MU=32 NU=4 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm32x4x2rp_avxz.S' \
      ASM=GAS_x8664 VLEN=8 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
#ID=36 MU=32 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm32x4x256_avxz.S' \
#      ASM=GAS_x8664 KBMAX=320 COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=37 MU=32 NU=6 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm32x6x1_avxz.S' \
      ASM=GAS_x8664 VLEN=8 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=38 MU=16 NU=8 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_damm16x8x4_avxz.S' \
      ASM=GAS_x8664 VLEN=8 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=40 MU=24 NU=8 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm24x8x2_avxz.S' \
      ASM=GAS_x8664 VLEN = 8 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=41 MU=8 NU=8 KU=8 AUTH='R. Clint Whaley' ROUT='ATL_amm8x8x8_avxz.S' \
      VLEN=8 KRUNTIME=0 KBMAX=8 KBMIN=8 ASM=GAS_x8664 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=42 MU=5 NU=5 KU=2 AUTH="Whaley & Nuechterlein" \
      ROUT='ATL_damm5x5x2_aarch64.S' \
      KBMIN=2 ASM=GAS_ARM64 KRUNTIME=1 \
      COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=43 MU=4 NU=3 KU=6 AUTH='R. Clint Whaley' ROUT='ATL_dammm4x3x6_arm64.S' \
      KRUNTIME=1 KBMIN=12 ASM=GAS_ARM64 \
      COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=44 MU=4 NU=2 KU=2 AUTH="Whaley & Voronenko" ROUT='ATL_kmmm4x2x256_sse3.S' \
     KMAJ=2 KVEC=1 SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=45 MU=8 NU=1 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_kmmm8x1x256_L1pf.S' \
     KMAJ=2 KVEC=1 SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=46 MU=8 NU=6 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm8x6x2_fma3.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=1 LDCTOP=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx -mfma'
ID=47 MU=12 NU=6 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_dammm12x6x2_vsx.S' \
     VLEN=2 ASM=GAS_PPC KRUNTIME=1 LDCTOP=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mcpu=power8 -mvsx'
ID=48 MU=12 NU=4 KU=6 AUTH="Rakib Hasan" ROUT='ATL_damm12x4x6_aarch64-A57.S' \
     KBMIN=6 ASM=GAS_ARM64 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=49 MU=12 NU=4 KU=1 AUTH="Rakib Hasan" ROUT='ATL_damm12x4x1_aarch64-A53.S' \
     KBMIN=1 ASM=GAS_ARM64 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=50 MU=24 NU=8 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm24x8x1_avxz.S' \
      ASM=GAS_x8664 VLEN=8 KRUNTIME=1 
ID=51 MU=32 NU=4 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm32x4x2rp_avxz.S' \
      ASM=GAS_x8664 VLEN=8 KRUNTIME=1 
ID=52 MU=32 NU=6 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm32x6x1_avxz.S' \
      ASM=GAS_x8664 VLEN=8 KRUNTIME=1
@ROUT samcases.idx
@ROUT samcases.idx
ID=1 MU=16 NU=4 VLEN=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_samm16x4x1_av.c' \
     KRUNTIME=1 COMP='gcc' CFLAGS='-Os -maltivec -mabi=altivec -mcpu=970 -mtune=970 -mvrsave -fschedule-insns2 -fno-schedule-insns'
ID=2 MU=4 NU=6 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_samm4x6x2_arm.S' \
     ASM=GAS_ARM KRUNTIME=1 KBMIN=4 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=3 MU=4 NU=6 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_samm4x6x1_arm.S' \
     ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=7 MU=24 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_samm24x3x256_avx.S' \
     SSE=3 VLEN=8 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=8 MU=8 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_sammm8x4x256_sse2.S' \
     SSE=2 VLEN=4 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
ID=11 MU=24 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm12x3x1_avx.S' \
     SSE=3 VLEN=8 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=13 MU=24 NU=3 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm12x3x2_avx.S' \
     SSE=3 VLEN=8 ASM=GAS_x8664 KRUNTIME=1 KBMIN=6 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=16 MU=6 NU=1 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_amm6x1x1_x87.S' \
     ASM=GAS_x8664,GAS_x8632 KRUNTIME=1 x87=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=23 MU=4 NU=2 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_amm4x2x4_kb4.c' \
     KRUNTIME=0 KBMIN=4 KBMAX=4 
ID=24 MU=24 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_sammm24x4x256_fma3.S' \
     SSE=5 VLEN=8 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3 -mfma'
ID=25 MU=24 NU=4 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_samm24x4x2_fma3.S' \
     SSE=5 VLEN=8 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx -mfma'
ID=26 MU=12 NU=1 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_skmmm12x1x4_sse3.S' \
     SSE=3 VLEN=4 KVEC=1 KMAJ=4 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
ID=27 MU=12 NU=1 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_skmmm12x1x256_sse3.S' \
     SSE=3 KVEC=1 KMAJ=4 VLEN=4 ASM=GAS_x8664 KRUNTIME=0 KBMIN=4 KBMAX=256 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
#ID=26 MU=12 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_sammm12x3d2x256_sse3.S' \
#     SSE=3 DUPB=2 KBMAX=256 ASM=GAS_x8664 \
#     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
ID=34 MU=48 NU=8 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm24x8x1_avxz.S' \
      VLEN=16 ASM=GAS_x8664 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=35 MU=64 NU=4 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm32x4x2rp_avxz.S' \
      VLEN=16 ASM=GAS_x8664 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
#ID=36 MU=64 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm32x4x256_avxz.S' \
#      ASM=GAS_x8664 KBMAX=320 COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=37 MU=64 NU=6 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm32x6x1_avxz.S' \
      VLEN=16 ASM=GAS_x8664 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=38 MU=32 NU=8 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_damm16x8x4_avxz.S' \
      VLEN=16 ASM=GAS_x8664 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=40 MU=48 NU=8 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm24x8x2_avxz.S' \
      VLEN=16 ASM=GAS_x8664 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=42 MU=4 NU=6 KU=2 AUTH="Nuechterlein & Whaley" \
      ROUT='ATL_samm4x6x2b_aarch64.S' \
      ASM=GAS_ARM64 KRUNTIME=1 KBMIN=4 \
      COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=43 MU=8 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_sammm8x4x256_sdup.S' \
      SSE=3 VLEN=4 KBMAX=256 ASM=GAS_x8664 \
      COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=44 MU=4 NU=2 KU=4 AUTH="Whaley & Voronenko" ROUT='ATL_kmmm4x2x256_sse3.S' \
      KMAJ=4 KVEC=1 VLEN=4 SSE=3 KBMAX=256 ASM=GAS_x8664 \
      COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=45 MU=8 NU=1 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_kmmm8x1x256_L1pf.S' \
     KMAJ=4 KVEC=1 VLEN=4 SSE=3 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=48 MU=24 NU=4 KU=6 AUTH="Rakib Hasan" ROUT='ATL_damm12x4x6_aarch64-A57.S' \
     KBMIN=6 ASM=GAS_ARM64 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=49 MU=24 NU=4 KU=1 AUTH="Rakib Hasan" ROUT='ATL_damm12x4x1_aarch64-A53.S' \
     KBMIN=1 ASM=GAS_ARM64 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=50 MU=48 NU=8 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm24x8x1_avxz.S' \
      ASM=GAS_x8664 VLEN=16 KRUNTIME=1 
ID=51 MU=64 NU=4 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm32x4x2rp_avxz.S' \
      ASM=GAS_x8664 VLEN=16 KRUNTIME=1 
ID=52 MU=64 NU=6 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm32x6x1_avxz.S' \
      ASM=GAS_x8664 VLEN=16 KRUNTIME=1
@ROUT samcases.idx
@ROUT atlas_gnuvec.h
#ifndef ATLAS_GNUVEC
   #define ATLAS_GNUVEC 1
   #ifndef TYPE
      #if defined(SREAL) || defined(SCPLX)
         #define TYPE float
      #else
         #define TYPE double
      #endif
   #endif
   #ifdef ATL_VSX
      #define ATL_NVREG 64
      #ifndef ATL_VLEN
         #define ATL_VLENb 16
         #if defined(SREAL) || defined (SCPLX)
            #define ATL_VLEN 4
         #else
            #define ATL_VLEN 2
         #endif
      #endif
   #elif defined(ATL_AltiVec)
      #define ATL_NVREG 32
      #ifndef ATL_VLEN
         #define ATL_VLENb 16
         #if defined(SREAL) || defined (SCPLX)
            #define ATL_VLEN 4
         #else
            #define ATL_VLEN 2
         #endif
      #endif
   #elif defined(ATL_AVXZ)
      #include "immintrin.h"
      #define ATL_NVREG 32
      #define ATL_VLENb 64
      #if defined(SREAL) || defined (SCPLX)
          #define ATL_VLEN 16
      #else
          #define ATL_VLEN 8
      #endif
      #if defined(SREAL) || defined (SCPLX)
         #define ATL_gvbcast(ptr_, v_) \
            v_ = _mm512_extload_ps((void*)(ptr_), _MM_UPCONV_PS_NONE, \
                                   _MM_BROADCAST_1X16, 0)
      #else
         #define ATL_gvbcast(ptr_, v_) \
            v_ = _mm512_extload_pd((void*)(ptr_), _MM_UPCONV_PD_NONE, \
                                   _MM_BROADCAST_1X8, 0)
      #endif
   #elif defined(ATL_AVXMAC) || defined(ATL_AVXFMA4) || defined(ATL_AVX)
      #ifdef ATL_GAS_x8664
         #define ATL_NVREG 16
      #else
         #define ATL_NVREG 8
      #endif
      #ifndef ATL_VLEN
         #define ATL_VLENb 32
         #if defined(SREAL) || defined (SCPLX)
            #define ATL_VLEN 8
         #else
            #define ATL_VLEN 4
         #endif
      #endif
      #if ATL_VLENb == 32
         #define ATL_gvbcast(ptr_, v_) \
            (v_) = __builtin_ia32_vbroadcastsd256((void*)(ptr_));
      #elif ATL_VLENb == 16 && defined(ATL_SSE3)
         #include "immintrin.h"
         #define ATL_gvbcast(ptr_, v_) \
            (v_) = _mm_loaddup_pd(ptr_);
@skip            (v_) = __builtin_ia32_movddup(ptr_);
      #endif
   #elif defined(ATL_SSE3) || defined(ATL_SSE2)
      #ifdef ATL_GAS_x8664
         #define ATL_NVREG 16
      #else
         #define ATL_NVREG 8
      #endif
      #ifndef ATL_VLEN
         #define ATL_VLENb 16
         #if defined(SREAL) || defined (SCPLX)
            #define ATL_VLEN 4
         #else
            #define ATL_VLEN 2
         #endif
      #endif
      #if defined(DREAL) || defined(DCPLX)
         #if defined(ATL_SSE3) && ATL_VLEN == 2
         #include "immintrin.h"
            #define ATL_gvbcast(ptr_, v_) \
            (v_) = _mm_loaddup_pd(ptr_);
@skip               (v_) = __builtin_ia32_movddup(ptr_);
         #endif
      #endif
   #elif defined(SREAL) || defined(SCPLX)   /* single-only stuff */
      #ifdef ATL_AltiVec
         #define ATL_NVREG 32
         #ifndef ATL_VLEN
            #define ATL_VLENb 16
            #define ATL_VLEN 4
         #endif
      #elif defined(ATL_SSE1)
         #ifdef ATL_GAS_x8664
            #define ATL_NVREG 16
         #else
            #define ATL_NVREG 8
         #endif
         #ifndef ATL_VLEN
            #define ATL_VLENb 16
            #define ATL_VLEN 4
         #endif
      #elif defined(ATL_NONIEEE) && ATL_NONIEEE != 0
         #ifdef ATL_NEON
            #define ATL_NVREG 16
            #ifndef ATL_VLEN
               #define ATL_VLENb 8
               #define ATL_VLEN 2
            #endif
         #elif defined(ATL_3DNow)
            #define ATL_NVREG 8
            #ifndef ATL_VLEN
               #define ATL_VLENb 16
               #define ATL_VLEN 4
            #endif
         #endif
      #endif
   #endif
   #if defined(ATL_VLEN) && !defined(ATL_VLENb)
      #if defined(SREAL) || defined (SCPLX)
         @iexp i 0 2 +
         @iwhile i < 32
            @iexp j @(i) 4 *
         #if ATL_VLEN == @(i)
            #define ATL_VLENb @(j)
         #endif
            @iexp i @(i) 2 *
         @endiwhile
      #else
         @iexp i 0 2 +
         @iwhile i < 64
            @iexp j @(i) 8 *
         #if ATL_VLEN == @(i)
            #define ATL_VLENb @(j)
         #endif
            @iexp i @(i) 2 *
         @endiwhile
      #endif
   #endif
   #ifndef ATL_VLENb
      #define ATL_VLEN 1
      #if defined(SREAL) || defined (SCPLX)
         #define ATL_VLENb 4
      #else
         #define ATL_VLENb 8
      #endif
      #if defined(ATL_GAS_x8664) || defined(ATL_GAS_x8632)
         #define ATL_NVREG 8
      #else
         #define ATL_NVREG 32
      #endif
   #endif
   #ifndef ATL_vec_t
      #if ATL_VLEN > 1
         typedef TYPE ATL_vec_t  __attribute__ ((vector_size (ATL_VLENb)));
      #else
         #define ATL_vec_t TYPE
      #endif
   #endif
/*
 * Setup macros to multiply and divide by VLEN using shifts
 */
   #if ATL_VLEN == 1
      #define ATL_DivByVLEN(i_) (i_)
      #define ATL_MulByVLEN(i_) (i_)
@iexp s 1 0 +
@iexp i 2 0 +
@iwhile i < 64
   #elif ATL_VLEN == @(i)
      #define ATL_DivByVLEN(i_) ((i_)>>@(s))
      #define ATL_MulByVLEN(i_) ((i_)<<@(s))
   @iexp s @(s) 1 +
   @iexp i @(i) 2 *
@endiwhile
   #else
      #define ATL_DivByVLEN(i_) ((i_)/ATL_VLEN)
      #define ATL_MulByVLEN(i_) ((i_)*ATL_VLEN)
   #endif
   #ifndef ATL_gvbcast
      #if ATL_VLEN == 1
         #define ATL_gvbcast(ptr_, v_) \
            { ATL_vec_t z={*(ptr_)}; v_ = z; }
      #elif ATL_VLEN == 2
         #define ATL_gvbcast(ptr_, v_) \
            { ATL_vec_t z={*(ptr_),*(ptr_)}; v_ = z; }
      #elif ATL_VLEN == 4
         #define ATL_gvbcast(ptr_, v_) \
            { ATL_vec_t z={*(ptr_),*(ptr_),*(ptr_),*(ptr_)}; v_ = z; }
      #elif ATL_VLEN == 8
         #define ATL_gvbcast(ptr_, v_) \
            v_ = {*(ptr_), *(ptr_), *(ptr_), *(ptr_), \
                  *(ptr_), *(ptr_), *(ptr_), *(ptr_)}
      #elif ATL_VLEN == 16
         #define ATL_gvbcast(ptr_, v_) \
         { \
            ATL_vec_t z_ = {*(ptr_), *(ptr_), *(ptr_), *(ptr_), \
                  *(ptr_), *(ptr_), *(ptr_), *(ptr_), \
                  *(ptr_), *(ptr_), *(ptr_), *(ptr_), \
                  *(ptr_), *(ptr_), *(ptr_), *(ptr_), \
                 }; \
            v_ = z_; \
         }
      #else
         #error "Cannot create gvbcast"
      #endif
   #endif
   
#endif
@ROUT atlas_amm.h
#ifndef ATLAS_AMM_H
   #define ATLAS_AMM_H

#ifndef ATL_MaxMalloc
   #include "atlas_maxmalloc.h"
#endif
#ifndef ATL_MaxMalloc
   #define ATL_MaxMalloc 268435456UL
#endif
#include "atlas_misc.h"

#define ATL_AMK_NBIT 5
#define ATL_AMK_KVEC  1
#define ATL_AMK_KRUN  2
#define ATL_AMK_KMIN  4
#define ATL_AMK_KMAX  8
#define ATL_AMK_KALL 16

@beginskip
#if ATL_PSIZE >= ATL_DSIZE
   #define ATL_cparr_t ATL_iptr_t
   #define ATL_cpflt_t double
#elif ATL_PSIZE >= ATL_FSIZE
   #define ATL_cparr_t ATL_iptr_t
   #define ATL_cpflt_t float
#elif ATL_ISIZE >= ATL_FSIZE
   #define ATL_cparr_t unsigned int
   #define ATL_cpflt_t float
#elif ATL_LSIZE >= ATL_FSIZE
   #define ATL_cparr_t unsigned long
   #define ATL_cpflt_t float
#else
   #error "No integral type >= to float in size!"
#endif

@endskip
#ifdef TREAL
   typedef void (*cm2am_t)(const size_t, const size_t, const SCALAR,
                           const TYPE*, const size_t, TYPE*);
   typedef void (*tcm2am_t)(const size_t, const SCALAR, const TYPE*, 
                           const size_t, TYPE*);
   typedef void (*am2cm_t)(const size_t, const size_t, const SCALAR,
                           const TYPE*, TYPE*, const size_t);
   typedef void (*ablk2cmat_t)(const size_t, const size_t, const SCALAR,
                               const TYPE*, const SCALAR, TYPE *, const size_t);
   typedef void (*cmat2ablk_t)(const size_t, const size_t, const SCALAR,
                               const TYPE*, const size_t, const SCALAR,TYPE*);
   typedef void (*ammswp_t)(ATL_CINT, TYPE*,ATL_CSZT,TYPE*);
#else
   typedef void (*cm2am_t)(const size_t, const size_t, const SCALAR,
                           const TYPE*, const size_t, TYPE*, TYPE*);
   typedef void (*tcm2am_t)(const size_t, const SCALAR, const TYPE*, 
                           const size_t, TYPE*, TYPE*);
   typedef void (*am2cm_t)(const size_t, const size_t, const SCALAR,
                           const TYPE*, const TYPE*, TYPE*, const size_t);
   typedef void (*ablk2cmat_t)(const size_t, const size_t, const SCALAR,
                               const TYPE*, const TYPE*, const SCALAR, 
                               TYPE *, const size_t);
   typedef void (*cmat2ablk_t)(const size_t, const size_t, const SCALAR,
                               const TYPE*, const size_t, const SCALAR,
                               TYPE*,TYPE*);
   typedef void (*ammswp_t)(ATL_CINT, TYPE*,ATL_CSZT,TYPE*,TYPE*);
#endif
typedef void (*ammkern_t)(ATL_CSZT,ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,
                          TYPE*, const TYPE*, const TYPE*, const TYPE*);
#define ushort unsigned short
#define uint unsigned int
#define uchar unsigned char

typedef struct sminfo sminfo_t;  /* struct for trsm microkernel */
struct sminfo
{
   void *utrsm;                  /* function pointer to trsm microkernel */
   cm2am_t a2blk, b2blk;         /* A/B copy funcs */
   ammkern_t amm_b0, amm_b1;     /* func ptrs for beta=0,1 gemm */
   #ifdef TCPLX
      ammkern_t amm_bn;          /* func ptr for beta=-1 gemm */
   #endif
   size_t incA;                  /* (1|lda)SHIFT */
   ushort mmflg;                 /* flag bitvec from amm master list */
   ushort kb, rb;                /* triangular & RHS blocking */
   uchar mu, nu, ku;             /* unrollings of underlying amm */
   uchar bv;/*0:Right?, 1:Upper?, 2:TransA?, 3:Conj?, 4:NonUnit? 5: ALLT? */
};
typedef struct tminfo tminfo_t;  /* struct for trmm microkernel */
struct tminfo
{
   ushort flg;                   /* 0:same kernel as gemm? */
   tcm2am_t t2blk;               /* copy routine for triangular matrix */
   cm2am_t r2blk;                /* copy routines for regular matrix */
   ablk2cmat_t blk2c;            /* cpy from acc-maj blk to col-maj C */
   ammkern_t amm_b0, amm_b1;     /* func ptrs for beta=0,1 trmm */
   #ifdef TCPLX
      ammkern_t amm_bn;          /* func ptr for beta=-1 trmm */
   #endif
   size_t incA;                  /* (1|lda) */
   ushort kb;                    /* triangular blocking */
   ushort mu, nu, ku;            /* unrollings of underlying amm */
   ushort vlen;                  /* vector len for the kernels */
   /*ushort kvec;*/              /* is kvec kernel */
};

typedef struct amminfo amminfo_t;
struct amminfo
{
   cm2am_t a2blk, b2blk;
   ablk2cmat_t Cblk2cm, Cblk2cm_b1;
   cmat2ablk_t cm2Cblk;
   ammkern_t amm_b0, amm_b1, amm_bn, amm_k1_b0, amm_k1_b1, amm_k1_bn;
   ushort IDX, mb, nb, kb, kbmin, kbmax;
   uchar flag, mu, nu, ku, vlen;
};

typedef struct ipinfo ipinfo_t;  /* struct for inner-product based gemm */
struct ipinfo
{
   ammkern_t ammK1_b0, ammK1_b1; /* amm safe to use for KB0 calc */
   ammkern_t amm_b0, amm_b1;     /* amm to use after first K peel */
   cm2am_t a2blk, b2blk;         /* A/B copy funcs */
   ablk2cmat_t blk2c, blk2c_b1;  /* cpy from acc-maj blk to col-maj C */
   #ifdef TCPLX
      ammkern_t ammK1_bn;
      ammkern_t amm_bn;
      const TYPE *alpA, *alpB, *alpC, *ONE;
   #endif
   size_t nfnblks, npnblks; /* # of of full and partial blks along N */
   size_t nfmblks, npmblks; /* # of of full and partial blks along M */
   size_t nfkblks;          /* # of full kblks = (K-kb0)/kb */
   size_t incAk, incBk;     /* block-kb increment for A/B ptrs */
   size_t pincAm, incAm;    /* partial & full mb-block increment */
   size_t pincBn, incBn;    /* partial & full nb-block increment */
   size_t lda, ldb, ldc;    /* leading dim for all 3 matrices */
   #ifndef TCPLX
      TYPE alpA, alpB, alpC;
   #endif
   uint szC;                /* size of real portion of C workspace */
   uint pszA, szA;          /* size of real portion of part & full blks of A */
   uint pszB, szB;          /* size of real portion of part & full blks of B */
   ushort exsz;             /* extra bytes to alloc past end */
   ushort mF, nF;           /* size of final part of mat before copy */
   ushort mb, pmb, nb, pnb; /* full & partial blk factors for M & N */
   ushort kb;               /* sz of all K blks except first */
   ushort kb0;              /* K%kb or if zero, kb */
   ushort KB0;              /* if amm k-vec, ((kb0+ku-1)/ku)*ku, else kb0 */
   ushort nmu, nnu;         /* # of unrollings along each dim */
   ushort pnmu, pnnu;       /* # of unrollings in partial blocks */
   ushort nmuF, nnuF;       /* # of unrolling for final (remainder) block */
   uchar mu, nu, ku;        /* unrolling for each dim used by amm */
   uchar vlen;              /* vector length (needed for KVEC kerns) */
};

typedef struct opinfo opinfo_t;
struct opinfo
{
   cm2am_t a2blk, b2blk;    /* A/B copy routs */
   ablk2cmat_t blk2C;       /* cpy from acc-maj blk to col-maj C */
   ammkern_t amm_b0;        /* beta=0 amm kern */
   #ifdef TCPLX
      ammkern_t amm_b1;     /* beta=1 amm kern (needed for complex) */
      ammkern_t amm_bn;     /* beta=n amm kern (needed for complex) */
      const TYPE *alpA, *alpB, *beta, *ONE;
   #endif
   size_t nfnblks, npnblks; /* # of of full and partial blks along N */
   size_t nfmblks, npmblks; /* # of of full and partial blks along M */
   size_t pincAm, incAm;    /* partial & full mb-block increment */
   size_t pincBn, incBn;    /* partial & full nb-block increment */
   size_t lda, ldb, ldc;    /* stride between row elts for each mat */
   #ifndef TCPLX
      TYPE alpA, alpB, beta;
   #endif
   uint szC;                /* size of real C blk in workspace */
   uint pszA, szA;          /* size of real portion of part & full blks of A */
   uint pszB, szB;          /* size of real portion of part & full blks of B */
   ushort exsz;             /* extra bytes to alloc past end */
   ushort idx;              /* kern array index */
   ushort mF, nF;           /* size of final part of mat before copy */
   ushort mb, pmb, nb, pnb; /* full & partial blk factors for M & N */
   ushort kb;               /* K from original problem */
   ushort KB;               /* ((kb+ku-1)/vl)*vl if kvec, else kb */
   ushort nmuF, nnuF;       /* # of unrollings in final M/N blocks */
   ushort nmu, nnu;         /* # of unrollings along each dim */
   ushort pnmu, pnnu;       /* # of unrollings in partial blocks */
   uchar mu, nu, ku;        /* unrolling for each dim used by amm */
   uchar vlen;              /* vector length (needed for KVEC kerns) */
};
#undef ushort
#undef uchar
#undef uint

enum ATL_AMMALG {ATL_amm1b, ATL_ammrkK, ATL_NMK};

void Mjoin(PATL,opinfo) /* populate opinfo_t using atlas_opgen_view K-3 idx */
   (opinfo_t *out, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta);

void Mjoin(PATL,iptrsmInfo)
   (ipinfo_t *ip, enum ATLAS_SIDE SD, enum ATLAS_UPLO Uplo, enum ATLAS_TRANS TA,
    size_t N, size_t K, size_t lda, size_t ldb, const SCALAR alpha);
void Mjoin(PATL,ipgenInfo)
   (ipinfo_t *ip, int flg, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta);
void Mjoin(PATL,ipmenInfo)
   (ipinfo_t *ip, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta);
void Mjoin(PATL,ipmenUMInfo)
   (ipinfo_t *ip, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta);
void Mjoin(PATL,ipmekInfo)
   (ipinfo_t *ip, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta);
void Mjoin(PATL,ipnekInfo)
   (ipinfo_t *ip, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta);
double Mjoin(PATL,ipsyrkInfo) /* returns predicted time */
   (ipinfo_t*, int, enum ATLAS_TRANS,size_t,size_t,size_t,size_t, 
    const SCALAR alpha, const SCALAR beta);
int Mjoin(PATL,opsyrkInfo)
   (opinfo_t *out, int flag, enum ATLAS_TRANS TA, ATL_CSZT N, ATL_CSZT K, 
    ATL_CSZT lda, ATL_CSZT ldc, const SCALAR alpha, const SCALAR beta);
ablk2cmat_t Mjoin(PATL,opsyr2kInfo)
   (opinfo_t *out, int flag, enum ATLAS_TRANS TA, ATL_CSZT N, ATL_CSZT K, 
    ATL_CSZT lda, ATL_CSZT ldb, ATL_CSZT ldc, 
    const SCALAR alpha, const SCALAR beta);
@whiledef vw ipgen ipmen ipmek ipnek
void Mjoin(PATL,@(vw)InfoPop)
   (ipinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta, 
    size_t nfmblks, size_t npmblks, ATL_UINT mb, ATL_UINT pmb,
    size_t nfnblks, size_t npnblks, ATL_UINT nb, ATL_UINT pnb);

@endwhile
static int Mjoin(PATL,geGetAmmmIndx)(size_t M, size_t N, size_t K)
{
   ATL_assert(0);
}
@BEGINSKIP
static void Mjoin(PATL,geFillInIPInfo)
   (ipinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta, 
    size_t nfmblks, size_t npmblks, ATL_UINT mb, ATL_UINT pmb,
    size_t nfnblks, size_t npnblks, ATL_UINT nb, ATL_UINT pnb)
{
   ATL_assert(0);
}
static void Mjoin(PATL,sqFillInIPInfo)
   (ipinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta, ATL_UINT nb)
{
   ATL_assert(0);
}
static int Mjoin(PATL,tGetParCIndx)(ipinfo_t *ip, int P, size_t M, size_t N, size_t K)
{
   ATL_assert(0);
}
static int Mjoin(PATL,tGetParTriCIndx)(int P, int flg, size_t N, size_t K, int *NB)
{
   ATL_assert(0);
}
@ENDSKIP

static int Mjoin(PATL,tGetIPInfo_tMN)
   (ipinfo_t *ip, int P, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, 
    size_t M, size_t N, size_t K, const SCALAR alpha, size_t lda, size_t ldb,
    const SCALAR beta, size_t ldc)
{
   ATL_assert(0);
}
@whiledef sh ge sq
static void Mjoin(PATL,@(sh)ComputeIPInfo)
   (ipinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, 
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc, 
    const SCALAR alpha, const SCALAR beta)
{
   ATL_assert(0);
}
@endwhile
@multidef rt iploopsMNK iploopsMNK
@whiledef rt iploopsNK iploopsMK iploopsK iploopsNMK iploopsNMK
void Mjoin(PATL,@(rt))
   (ipinfo_t *ip, size_t i, size_t j, const TYPE *A, const TYPE *B, TYPE *C, 
    const int MVS, TYPE *a, TYPE *b, TYPE *rC, TYPE *iC, 
    const SCALAR beta, const ablk2cmat_t blk2c);
@endwhile
@whiledef rt ge sq rk
static int Mjoin(PATL,@(rt)GetAmmInfoInt)(char wh, int idx)
{
   ATL_assert(0);
}
static void *Mjoin(PATL,@(rt)GetAmmInfoPtr)(int idx, int what, int alp, int bet)
{
   ATL_assert(0);
}
@endwhile
@whiledef sf _tNK _tK
static int Mjoin(PATL,tGetRKInfo@(sf))
   (opinfo_t*a0, int a1, enum ATLAS_TRANS a2, enum ATLAS_TRANS a3,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta)
{
   ATL_assert(0);
}
@endwhile
@whiledef vw oprk opsq opmk opnk 1b_oprk 1b_opsq 1b_opmk 1b_opnk
int Mjoin(PATL,GetInfo_@(vw))
   (opinfo_t*, enum ATLAS_TRANS, enum ATLAS_TRANS, ATL_CSZT M, ATL_CSZT N, 
    ATL_CSZT K, ATL_CSZT lda, ATL_CSZT ldb, ATL_CSZT ldc,
    const SCALAR alpha, const SCALAR beta);
@endwhile
static void Mjoin(PATL,GetRKInfo)
   (opinfo_t*a0, int a1, enum ATLAS_TRANS a2, enum ATLAS_TRANS a3,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta)
{
   ATL_assert(0);
}
int Mjoin(PATL,GetSyrkIdx)(unsigned int flg, ATL_CSZT N, ATL_CSZT K, double);
double Mjoin(PATL,sSyrkTimeEst)
   (int id, unsigned int flg, size_t N, size_t K, double symul);
int Mjoin(PATL,GetSyrkInfo)
   (amminfo_t*,int, enum ATLAS_TRANS,ATL_CSZT,ATL_CSZT,int);
void Mjoin(PATL,GetSyrkOP)
   (opinfo_t *out, int flag, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    ATL_CSZT N, ATL_CSZT K, size_t lda, size_t ldc, 
    const SCALAR alpha, const SCALAR beta);
@whiledef info GetAmmmInfo GetRankKInfo
int Mjoin(PATL,@(info))
   (amminfo_t *out, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, ATL_CSZT M, 
    ATL_CSZT N, ATL_CSZT K, const SCALAR alpha, const SCALAR beta);
@endwhile
#ifdef TREAL
int Mjoin(PATL,GetTrsmInfo)
   (amminfo_t *out, int ialp, enum ATLAS_TRANS TA, ATL_CSZT M, ATL_CSZT N, 
    const SCALAR beta);
#endif
int Mjoin(PATL,tGetAmmmInfo)
   (amminfo_t *out, const unsigned int P, enum ATLAS_TRANS TA, 
    enum ATLAS_TRANS TB, ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, 
    const SCALAR alpha, const SCALAR beta);
ablk2cmat_t Mjoin(PATL,tGetSyammInfo)
   (amminfo_t *out, const int P, enum ATLAS_TRANS TA, ATL_CSZT N, ATL_CSZT K,
    const SCALAR alpha, const SCALAR beta);
ablk2cmat_t Mjoin(PATL,tGetSyammInfo_K)
   (amminfo_t *out, const int P, enum ATLAS_TRANS TA, ATL_CSZT N, ATL_CSZT K);

void Mjoin(PATL,oploopsM)
   (opinfo_t *rkinf, size_t i, size_t j, const TYPE *A, const TYPE *B, TYPE *C,
    int MV, TYPE *a, TYPE *b, TYPE *rC, TYPE *iC);
void Mjoin(PATL,oploopsN)
   (opinfo_t *rkinf, size_t i, size_t j, const TYPE *A, const TYPE *B, TYPE *C,
    int MV, TYPE *a, TYPE *b, TYPE *rC, TYPE *iC);
void Mjoin(PATL,opblk)
   (opinfo_t *op, size_t i, size_t j, const TYPE *A, const TYPE *B, TYPE *C,
    TYPE *pA, TYPE *pAn, TYPE *pB, TYPE *pBn, TYPE *rC, TYPE *iC);
@beginskip
void Mjoin(PATL,ammmM)
   (opinfo_t *rkinf, int N, int nb, int nnu, TYPE *a, int INCA,
    const TYPE *b, TYPE *c, const TYPE *A, TYPE *C, const SCALAR beta);
void Mjoin(PATL,ammmN)
   (opinfo_t *rkinf, int M, int mb, int nmu, const TYPE *a, TYPE *b, int INCB,
    TYPE *c, const TYPE *B, TYPE *C, const SCALAR beta);
@endskip

void Mjoin(PATL,ammmK)
   (amminfo_t*, const int mb, const int nmu, const int nb, const int nnu, 
    ATL_CINT nfkblks, const int kb, const int kb0, const int KB0, const TYPE *A,
    const size_t lda, const size_t incAk, const TYPE*B, const size_t ldb, 
    const size_t incBk, const ablk2cmat_t blkc2c, TYPE*, const size_t ldc, 
    TYPE *a, ATL_CINT inca, TYPE *b, ATL_CINT incb, TYPE *rC, TYPE *iC, 
    const SCALAR alpA, const SCALAR alpB, const SCALAR alpC, const SCALAR beta);

void Mjoin(PATL,gemm)
   (const enum ATLAS_TRANS,const enum ATLAS_TRANS,ATL_CSZT,ATL_CSZT,ATL_CSZT, 
    const SCALAR, const TYPE*,ATL_CSZT,const TYPE*,ATL_CSZT,const SCALAR,
    TYPE*,ATL_CSZT);
void Mjoin(PATL,ammm)
   (enum ATLAS_TRANS,enum ATLAS_TRANS,ATL_CSZT,ATL_CSZT,ATL_CSZT, const SCALAR,
    const TYPE*,ATL_CSZT,const TYPE*,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT);
#ifdef TREAL
int Mjoin(PATL,rk4n4)(enum ATLAS_TRANS,ATL_CSZT,const SCALAR,const TYPE*,
                      ATL_CSZT,const TYPE*,ATL_CSZT,TYPE*,ATL_CSZT);
#endif
int Mjoin(PATL,ammm_rk2)
   (enum ATLAS_TRANS,enum ATLAS_TRANS,ATL_CSZT,ATL_CSZT, const SCALAR,
    const TYPE*,ATL_CSZT,const TYPE*,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT);
@multidef rt ammmNKM ammmKNMK ammmKMNK
@whiledef rt ammm_1b ammm_rkK ammm_IP ammm_tN ammm_aliased_rkK ammmMNK ammmREC
int Mjoin(PATL,@(rt))
   (enum ATLAS_TRANS,enum ATLAS_TRANS,ATL_CSZT,ATL_CSZT,ATL_CSZT, const SCALAR,
    const TYPE*,ATL_CSZT,const TYPE*,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT);
@endwhile
int Mjoin(PATL,ammmNMK)
   (enum ATLAS_TRANS,enum ATLAS_TRANS,ATL_CSZT,ATL_CSZT,ATL_CSZT, 
    const SCALAR,const TYPE*,ATL_CSZT,const TYPE*,ATL_CSZT,const SCALAR,
    TYPE*,ATL_CSZT);
@beginskip
void Mjoin(PATL,ipsyrk)
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const SCALAR, const TYPE*, ATL_CSZT, const SCALAR, TYPE*,ATL_CSZT);
#ifdef TCPLX
void Mjoin(PATL,ipherk)
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const TYPE, const TYPE*, ATL_CSZT, const TYPE, TYPE*,ATL_CSZT);
#endif
@endskip
@whiledef rt op ip
int Mjoin(PATL,@(rt)syr2k)
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const SCALAR, const TYPE*, ATL_CSZT, const TYPE*, ATL_CSZT, 
    const SCALAR, TYPE*,ATL_CSZT);
#ifdef TCPLX
int Mjoin(PATL,@(rt)her2k)
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const SCALAR, const TYPE*, ATL_CSZT, const TYPE*, ATL_CSZT,
    const TYPE, TYPE*,ATL_CSZT);
#endif
@endwhile
@SKIP Prototypes for SYRK and HERK [op, ip, amm]
@multidef rtsy syrk_amm opsyrk ipsyrk 
@multidef rthk herk_amm opherk ipherk 
@whiledef rtp int int void
@(rtp) Mjoin(PATL,@(rtsy))
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const SCALAR, const TYPE*, ATL_CSZT, const SCALAR, TYPE*,ATL_CSZT);
#ifdef TCPLX
@(rtp) Mjoin(PATL,@(rthk))
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const TYPE, const TYPE*, ATL_CSZT, const TYPE, TYPE*,ATL_CSZT);
#endif
   @undef rtsy
   @undef rthk
@endwhile
@SKIP prototypes for sq/um syrk
@whiledef rt sq um
int Mjoin(PATL,@(rt)syrk)
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const SCALAR, const TYPE*, ATL_CSZT, const SCALAR, TYPE*,ATL_CSZT);
#ifdef TCPLX
int Mjoin(PATL,@(rt)herk)
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const TYPE, const TYPE*, ATL_CSZT, const TYPE, TYPE*,ATL_CSZT);
#endif
@endwhile
/*
 * Functions for testing Info return flag
 */
#define ATL_AMMFLG_KRUNTIME(flg_) ((flg_) & 1)
#define ATL_AMMFLG_KMAJOR(flg_) ((flg_) & 2)
/*
 * Helper functions we'd like to inline
 */
#ifdef ATL_GLOBIDX
static TYPE INLINE *IdxAw_rkK(opinfo_t *op, TYPE *A, size_t i)
{  /* index A workspace for ith block for rank-K (only 1 kb) */
   size_t m;

   m = op->nfmblks;
   m = Mmin(m, i);
   i -= m;
   A += (m * op->szA + i * op->pszA)SHIFT;
   return(A);
}

static TYPE INLINE *IdxAw_ip(ipinfo_t *ip, TYPE *A, size_t i, size_t k)
{  /* index A workspace for inner-product gemm */
   const size_t nfmblks = ip->nfmblks, szA = (i < nfmblks) ? ip->szA:ip->pszA;
   size_t m;

   m = Mmin(nfmblks, i);
   i -= m;
   m = (m * ip->szA + i * szA) * (ip->nfkblks+1);  /* offset to kpan */
   m = (m+k*szA)SHIFT;
   return(A+m);
}

static TYPE INLINE *IdxBw_ip(ipinfo_t *ip, TYPE *B, size_t k, size_t j)
{  /* index B workspace for inner-product gemm */
   const size_t nfnblks = ip->nfnblks, szB = (j < nfnblks) ? ip->szB:ip->pszB;
   size_t n;

   n = Mmin(nfnblks, j);
   j -= n;
   n = (n * ip->szB + j * szB) * (ip->nfkblks+1);  /* offset to kpan */
   n = (n+k*szB)SHIFT;
   return(B+n);
}

static const TYPE INLINE *IdxA_ip
   (ipinfo_t *ip, const TYPE *A, size_t i, size_t k)
{  /* index global A base-pointer to find (i,k) block for inner-product gemm */
   size_t m;

   m = ip->nfmblks;
   m = Mmin(m, i);
   i -= m;
   A += m * ip->incAm + i * ip->pincAm;
   A += k * ip->incAk;
   return(A);
}

static const INLINE TYPE *IdxB_ip
   (ipinfo_t *ip, const TYPE *B, size_t k, size_t j)
{  /* index global A base-pointer to find (i,k) block for inner-product gemm */
   size_t n;

   n = ip->nfnblks;
   n = Mmin(n, j);
   j -= n;
   B += ip->incBn * n + ip->pincBn * j;
   B += k * ip->incBk;
   return(B);
}
static INLINE TYPE *IdxC_ip(ipinfo_t *ip, TYPE *C, size_t i, size_t j)
{
   size_t n;

   n = ip->nfmblks;
   n = Mmin(n, i);
   i -= n;
   C += (ip->mb * n + ip->pmb * i)SHIFT;
   n = ip->nfnblks;
   n = Mmin(n, j);
   j -= n;
   C += (ip->nb * n + ip->pnb * j)*((ip->ldc) SHIFT);
   return(C);
}
#endif

#endif  /* end include file guard */
@ROUT emit_uamm
@extract -b @(topd)/cw.inc lang=C -def cwdate 2012 -def cwdate 2013  -def cwdate 2014 
#include "atlas_misc.h"
#include "atlas_mmparse.h"
#include "atlas_sys.h"
   static int UID=0, UIL=1;
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
   fprintf(stderr, "   -d <outdir>: directory to dump files to\n");
   fprintf(stderr, "   -i <infile> : can be repeated for multiple files\n");
   fprintf(stderr, "   -k <unique K cleanup index file> : \n");
   fprintf(stderr, "   -K <K cleanup by NB file> \n");
   fprintf(stderr, "   -r <rank-K kernel file> \n");
   fprintf(stderr, "   -s <square-case kernel file>\n");

   fprintf(stderr,
      "   -I <ID> : unique non-negative ID for header/kern files\n");
   exit(ierr ? ierr : -1);
}

ATL_mmnode_t *GetFlags(int nargs, char **args, char *PRE, char **DOUT,
                       char **UKIN, char **KCIN, char **RKIN, char **SQIN)
{
   int i, j=0, n, k;
   char pre='d';
   *SQIN = *RKIN = *UKIN = *KCIN = *DOUT = NULL;
   ATL_mmnode_t *mmb=NULL, *mmp, *mp;

   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        break;
      case 's':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *SQIN = DupString(args[i]);
        break;
      case 'k':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *UKIN = DupString(args[i]);
        break;
      case 'K':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *KCIN = DupString(args[i]);
        break;
      case 'I':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        UID = atol(args[i]);
        for (k=10; k <= UID; k *= 10)
           UIL++;
        break;
      case 'd':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *DOUT = DupString(args[i]);
        break;
      case 'i':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        mmp = ReadMMFile(args[i]);
        if (mmb)
        {
           ATL_mmnode_t *mp;
           for (mp=mmb; mp->next; mp = mp->next);
           mp->next = mmp;
        }
        else
           mmb = mmp;
        break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   *PRE = pre;
   if (!(*DOUT))
   {
      *DOUT = DupString("dMake_amm");
      (*DOUT)[0] = pre;
   }
   return(mmb);
}

char *GetVecStr(char pre, int vlen)
{
   if (vlen == 1)
      return("scalar");
   #ifdef ATL_AVX
      if (pre == 'd' || pre == 'z')
      {
         if (vlen == 4)
            return("avx");
         else if (vlen == 2)
            return("sse");
      }
      else if (pre == 's' || pre == 'c')
      {
         if (vlen == 8)
            return("avx");
         else if (vlen == 4)
            return("sse");
      }
   #elif defined(ATL_SSE1)
      #ifdef ATL_SSE2
         if ((pre == 'd' || pre == 'z') && vlen == 2)
               return("sse");
      #endif
      if ((pre == 's' || pre == 'c') && vlen == 4)
         return("sse");
   #endif
/*
 * Any vector length > 1 that isn't one of our known cases uses gnuvec
 */
   return("gvec");
}

void PrintBegBlock(char pre, ATL_mmnode_t *mmb, char *nam, FILE *fp)
{
   ATL_mmnode_t *mp;
   char PRE = toupper(pre);
   int i;

   if (nam)
   {
      fprintf(fp, "#ifndef ATLAS_%cUAMM_%s_H\n   #define ATLAS_%cUAMM_%s_H\n\n",
              PRE, nam, PRE, nam);
      fprintf(fp, "#include \"atlas_amm.h\"\n");
   }
   else
      fprintf(fp, "#ifndef ATLAS_%cUAMM_H\n   #define ATLAS_%cUAMM_H\n\n",
              PRE, PRE);
/*
 * Count mmb, and print def of NCASES
 */
   if (!nam || strstr(nam, "RANKK") == NULL)
   {
      for (mp=mmb,i=0; mp; i++, mp = mp->next);

      fprintf(fp, "#ifdef ATL_UAMM_NCASES\n");
      fprintf(fp, "   #if ATL_UAMM_NCASES != %d\n", i);
      fprintf(fp, "      #error \"NCASES MISMATCH!\"\n");
      fprintf(fp, "   #endif\n");
      fprintf(fp, "#else\n");
      fprintf(fp, "   #define ATL_UAMM_NCASES %d\n", i);
      fprintf(fp, "#endif\n");
   }
}

char *GetHName(char pre, char *outd, char *bnam)
{
   int i, NOBASE=0;
   char *fnam;
   if (!bnam)
   {
      NOBASE = 1;
      bnam = "";
   }
   i = strlen(outd) + strlen(bnam) + 16+UIL;

   fnam = malloc(i*sizeof(char));
   assert(fnam);
   if (NOBASE)
      sprintf(fnam, "%s/atlas_%cu%damm.h", outd, pre, UID);
   else
      sprintf(fnam, "%s/atlas_%cu%damm_%s.h", outd, pre, UID, bnam);
   return(fnam);
}

FILE *StandHStart(char pre, ATL_mmnode_t *mmb, char *outd, char *bnam)
{
   char *fnam;
   FILE *fp;
   int i;

   assert(outd);
   fnam = GetHName(pre, outd, bnam);
   fp = fopen(fnam, "w");
   assert(fp);
   if (bnam)
   {
      for (i=0; bnam[i]; i++)
         fnam[i] = toupper(bnam[i]);
      fnam[i] = '\0';
      PrintBegBlock(pre, mmb, fnam, fp);
   }
   else
      PrintBegBlock(pre, mmb, NULL, fp);
   free(fnam);
   return(fp);
}

static int Mylcm(const int M, const int N)
/*
 * Returns least common multiple (LCM) of two positive integers M & N by
 * computing greatest common divisor (GCD) and using the property that
 * M*N = GCD*LCM.
 */
{
   register int tmp, max, min, gcd=0;

   if (M != N)
   {
      if (M > N) { max = M; min = N; }
      else { max = N; min = M; }
      if (min > 0)  /* undefined for negative numbers */
      {
         do  /* while (min) */
         {
            if ( !(min & 1) ) /* min is even */
            {
               if ( !(max & 1) ) /* max is also even */
               {
                  do
                  {
                     min >>= 1;
                     max >>= 1;
                     gcd++;
                     if (min & 1) goto MinIsOdd;
                  }
                  while ( !(max & 1) );
               }
               do min >>=1 ; while ( !(min & 1) );
            }
/*
 *          Once min is odd, halve max until it too is odd.  Then, use
 *          property that gcd(max, min) = gcd(max, (max-min)/2)
 *          for odd max & min
 */
MinIsOdd:
            if (min != 1)
            {
               do  /* while (max >= min */
               {
                  max -= (max & 1) ? min : 0;
                  max >>= 1;
               }
               while (max >= min);
            }
            else return( (M*N) / (1<<gcd) );
            tmp = max;
            max = min;
            min = tmp;
         }
         while(tmp);
      }
      return( (M*N) / (max<<gcd) );
   }
   else return(M);
}

void GenAmmSum(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *rkb, char *outd)
{
   ATL_mmnode_t *mp, *p66;
   char *fnam;
   FILE *fp;
   char *type = "unsigned short";
   int i, n, maxb, maxNB, maxMB, maxKB, maxkmaj;
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};
   double mfB;

   fp = StandHStart(pre, mmb, outd, "sum");
   maxkmaj = maxNB = maxKB = maxMB = 0;
   mfB = 0.0;
   for (n=0,mp=mmb; mp; n++, mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         maxkmaj = Mmax(maxkmaj, mp->vlen);
      maxMB = Mmax(maxMB, mp->mbB);
      maxNB = Mmax(maxNB, mp->nbB);
      maxKB = Mmax(maxKB, mp->kbB);
      mfB = Mmax(mfB, mp->mflop[0]);
   }
   if (maxkmaj == 1)
      maxkmaj = 0;
   maxb = Mmax(maxMB, maxNB);
   maxb = Mmax(maxb, maxKB);
   fprintf(fp, "\n#define ATL_UAMM_MAXMB %d\n", maxMB);
   fprintf(fp, "#define ATL_UAMM_MAXNB %d\n", maxNB);
   fprintf(fp, "#define ATL_UAMM_MAXKB %d\n", maxKB);
   fprintf(fp, "#define ATL_UAMM_MAXKMAJ %d\n\n", maxkmaj);

   for (mp=mmb; mp && mp->next; mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_AMM_LMU %d\n", mp->mu);
   fprintf(fp, "#define ATL_AMM_LNU %d\n", mp->nu);
   fprintf(fp, "#define ATL_AMM_LKU %d\n", mp->ku);
   fprintf(fp, "#define ATL_AMM_LLCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_LLCMU %d\n\n",
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
/*
 * Find smallest case achieving 2/3 of maximal performance
 */
   for (i=0,mp=mmb; mp && mp->mflop[0]*1.5 < mfB; i++, mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_UAMM_66IDX %d\n", i);
   fprintf(fp, "#define ATL_UAMM_66MB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_UAMM_66NB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_UAMM_66KB %d\n", mp->kbB);
   fprintf(fp, "#define ATL_AMM_66LCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_66LCMU %d\n\n",
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   fprintf(fp, "#define ATL_UAMM_66RATIO %1.4lf\n\n", mp->mflop[0]/mfB);
/*
 * Find smallest case achieving 98% of maximal performance
 */
   for (i=0,mp=mmb; mp && mp->mflop[0] < 0.98*mfB; i++, mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_UAMM_98IDX %d\n", i);
   fprintf(fp, "#define ATL_UAMM_98MB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_UAMM_98NB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_UAMM_98KB %d\n", mp->kbB);
   fprintf(fp, "#define ATL_AMM_98LCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_98LCMU %d\n\n",
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   fprintf(fp, "#define ATL_UAMM_98RATIO %1.4lf\n\n", mp->mflop[0]/mfB);
   assert(rkb == NULL);

   fprintf(fp, "#define ATL_AMMFLG_KRUNTIME(flg_) ((flg_) & 1)\n");
   fprintf(fp, "#define ATL_AMMFLG_KMAJOR(flg_) ((flg_) & 2)\n");

   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenPerfFile(char pre, ATL_mmnode_t *mmb, char *outd, char *nm)
{
   ATL_mmnode_t *mp;
   #define NTHRSH 11
   int THRSH[NTHRSH] = {25, 33, 50, 66, 75, 80, 85, 90, 95, 98, 99};
   int idxT[NTHRSH];
   ATL_mmnode_t *mpT[NTHRSH];
   char *fnam;
   FILE *fp;
   char *type = "float";
   double mfMax=0.0;
   int i, j, n, maxb, maxNB, maxMB, maxKB, maxkmaj, idxMax=0;
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};

   for (i=0; i < NTHRSH; i++)
      mpT[i] = NULL;
   fp = StandHStart(pre, mmb, outd, nm);
   for (n=0,mp=mmb; mp; n++, mp = mp->next)
   {
      if (mp->mflop[0] > mfMax)
      {
         mfMax = mp->mflop[0];
         idxMax = n;
      }
   }
   fprintf(fp, "#define ATL_UAMM_MAXMFLOP %le /* (%.2f)*/ \n",
           mfMax, mfMax);
   fprintf(fp, "#define ATL_UAMM_MAXMFLOPIDX %d\n\n", idxMax);
   for (n=0,mp=mmb; mp; mp = mp->next, n++)
   {
      double mf = mp->mflop[0] / mfMax;
      for (i=0; i < NTHRSH; i++)
      {
         if (!mpT[i] && THRSH[i]*0.01*mfMax < mp->mflop[0])
         {
            mpT[i] = mp;
            idxT[i] = n;
         }
      }
   }
   for (i=0; i < NTHRSH; i++)
   {
      mp = mpT[i];
      fprintf(fp, "#define ATL_UAMM_%dLCMU %d\n", THRSH[i],
              Mylcm(Mylcm(mp->mu,mp->nu),mp->ku));
      fprintf(fp, "#define ATL_UAMM_%dLCMMN %d\n", THRSH[i],
              Mylcm(mp->mu,mp->nu));
      fprintf(fp, "#define ATL_UAMM_%dKB %d\n", THRSH[i],
              mp->kbB);
      fprintf(fp, "#define ATL_UAMM_%dNB %d\n", THRSH[i],
              mp->nbB);
      fprintf(fp, "#define ATL_UAMM_%dMB %d\n", THRSH[i],
              mp->mbB);
      fprintf(fp, "#define ATL_UAMM_%dIDX %d\n", THRSH[i],
              idxT[i]);
   }
   fprintf(fp, "\n");

   fprintf(fp, "static const float ATL_UAMM_PERF[%d] =", n);
   fprintf(fp, "   /* %% of performance of best kernel */\n{\n");
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d */\n", mp->mflop[0]/mfMax,
              (mp->next)?',':' ', j, mp->kbB);
   fprintf(fp, "};\n\n");

   fprintf(fp, "static const float ATL_UAMM_SPDUPNXT[%d] =", n);
   fprintf(fp, "   /* speedup of next higher NB */\n{\n");
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      double mf = (mp->next) ? mp->next->mflop[0] : mp->mflop[0];
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d vs. %d */\n", mf/mp->mflop[0],
              (mp->next)?',':' ', j, mp->kbB, mp->next?mp->next->kbB:mp->kbB);
   }
   fprintf(fp, "};\n\n");

   fprintf(fp, "#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenBlockingFile(char pre, ATL_mmnode_t *mmb, char *outd, char *nm)
{
   ATL_mmnode_t *mp;
   char *fnam;
   FILE *fp;
   char *type = "unsigned short";
   int i, n, maxb, maxNB, maxMB, maxKB, maxkmaj;
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};

   fp = StandHStart(pre, mmb, outd, nm);
   maxkmaj = maxNB = maxKB = maxMB = 0;
   for (n=0,mp=mmb; mp; n++, mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         maxkmaj = Mmax(maxkmaj, mp->vlen);
      maxMB = Mmax(maxMB, mp->mbB);
      maxNB = Mmax(maxNB, mp->nbB);
      maxKB = Mmax(maxKB, mp->kbB);
   }
   if (maxkmaj == 1)
      maxkmaj = 0;
   maxb = Mmax(maxMB, maxNB);
   maxb = Mmax(maxb, maxKB);
   fprintf(fp, "#define ATL_UAMM_MAXMB %d\n", maxMB);
   fprintf(fp, "#define ATL_UAMM_MAXNB %d\n", maxNB);
   fprintf(fp, "#define ATL_UAMM_MAXKB %d\n", maxKB);
   fprintf(fp, "#define ATL_UAMM_MAXKMAJ %d\n", maxkmaj);
   fprintf(fp, "\n");

   if (maxb <= 255)
      type = "unsigned char";
   for (i=0; i < 3; i++)
   {
      int j;
      fprintf(fp, "static const %s ATL_UAMM_%cBs[%d] =\n{\n",
              type, bc[i], n);
      for (j=0,mp=mmb; mp; j++,mp = mp->next)
      {
         int b;
         if (bc[i] == 'M')
            b = mp->mbB;
         else if (bc[i] == 'N')
            b = mp->nbB;
         else if (bc[i] == 'K')
            b = mp->kbB;
         if (mp->next)
            fprintf(fp, "%8d,  /* index %d */\n", b, j);
         else
            fprintf(fp, "%8d   /* index %d */\n", b, j);
      }
      fprintf(fp, "};\n\n");
   }
   for (i=0; i < 3; i++)
   {
      int j;
      fprintf(fp, "static const %s ATL_UAMM_%cUs[%d] =\n{\n",
              type, bc[i], n);
      for (j=0,mp=mmb; mp; j++,mp = mp->next)
      {
         int b;
         if (bc[i] == 'M')
            b = mp->mu;
         else if (bc[i] == 'N')
            b = mp->nu;
         else if (bc[i] == 'K')
         {
            if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
               b = mp->ku;
            else
               b = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->ku : mp->kbB;
         }
         if (mp->next)
            fprintf(fp, "%8d,  /* index %d */\n", b, j);
         else
            fprintf(fp, "%8d   /* index %d */\n", b, j);
      }
      fprintf(fp, "};\n\n");
   }
   fprintf(fp, "static const %s ATL_UAMM_KBMINs[%d] =\n{\n", type, n);
   for (i=0,mp=mmb; mp; i++,mp = mp->next)
   {
      if (mp->next)
         fprintf(fp, "%8d,  /* index %d */\n", mp->kbmin, i);
      else
         fprintf(fp, "%8d   /* index %d */\n", mp->kbmin, i);
   }
   fprintf(fp, "};\n\n");
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenFlagH(char pre, ATL_mmnode_t *mmb, char *outd, char *nm)
{
   FILE *fp;
   int j, n;
   ATL_mmnode_t *mp;

   fp = StandHStart(pre, mmb, outd, nm);

   for (n=0,mp=mmb; mp; n++,mp = mp->next);

   fprintf(fp, "static const unsigned char ATL_UAMM_KFLAG[%d] =\n{\n", n);
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      unsigned char flag=FLAG_IS_SET(mp->flag, MMF_KRUNTIME) ? 1 : 0;
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         flag |= 2;
      if (mp->next)
         fprintf(fp, "%6d,  /* index %d */\n", flag, j);
      else
         fprintf(fp, "%6d   /* index %d */\n", flag, j);
   }
   fprintf(fp, "};\n\n");
   fprintf(fp, "#define ATL_AMM_KRUNTIME(idx_) (ATL_AMM_KFLAG[idx_] & 1)\n");
   fprintf(fp, "#define ATL_AMM_KMAJOR(idx_) (ATL_AMM_KFLAG[idx_] & 2)\n");
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void SpewForthC2MProto(char pre, FILE *fp0, FILE *fp1, int mu, int nu)
{
   char ac[3] = {'1', 'n', 'X'};
   char bc[4] = {'0', '1', 'n', 'X'};
   int ia, ib;
   for (ia=0; ia < 3; ia ++)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp0, "void ATL_%cu%dablk2cmat_%dx%d_a%c_b%c\n",
                 pre, UID, mu, nu, ac[ia], bc[ib]);
         if (pre == 'z' || pre == 'c')
            fprintf(fp0, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         else
            fprintf(fp0, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         fprintf(fp1, "void ATL_%cu%dcmat2ablk_%dx%d_a%c_b%c\n",
                 pre, UID, mu, nu, ac[ia], bc[ib]);
         if (pre == 'z' || pre == 'c')
            fprintf(fp1, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,const SCALAR,TYPE*,TYPE*);\n");
         else
            fprintf(fp1, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,const SCALAR,TYPE*);\n");
      }
   }
}

void SpewForthC2BDecl(char pre, ATL_mmnode_t *mmb, FILE *fp, char *rt,
                      char alp, char bet)
{
   ATL_mmnode_t *mp;
   int j;

   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      fprintf(fp, "   ATL_%cu%d%s_%dx%d_a%c_b%c",
              pre, UID, rt, mp->mu,mp->nu, alp, bet);
      if (mp->next)
         fprintf(fp, ",  /* index %d */\n", j);
      else
         fprintf(fp, "   /* index %d */\n", j);
      }
      fprintf(fp, "};\n\n");
}

void GenC2BLK(char pre, ATL_mmnode_t *mmb, char *outd, char *suff)
{
   FILE *fp0, *fp1;
   ATL_mmnode_t *mp;
   int ia, ib;
   char ac[3] = {'1', 'n', 'X'};
   char bc[4] = {'0', '1', 'n', 'X'};
   char *fnam;

   if (!suff)
   {
      fp0 = StandHStart(pre, mmb, outd, "ablk2cmat");
      fp1 = StandHStart(pre, mmb, outd, "cmat2ablk");
   }
   else
   {
      fnam = malloc(sizeof(char)*(strlen(suff) + 10));
      assert(fnam);
      strncpy(fnam, "ablk2cmat", 9);
      strcpy(fnam+9, suff);
      fp0 = StandHStart(pre, mmb, outd, fnam);
      strncpy(fnam, "cmat2ablk", 9);
      fp1 = StandHStart(pre, mmb, outd, fnam);
   }
   fprintf(fp0, "\n");
   fprintf(fp1, "\n");
/*
 * Crank out prototypes
 */
   SpewForthC2MProto(pre, fp0, fp1, mmb->mu, mmb->nu);
   for (mp=mmb->next; mp; mp = mp->next)
   {
      ATL_mmnode_t *p;
      const int mu=mp->mu, nu=mp->nu;
      for (p=mmb; p->mu != mu || p->nu != nu; p = p->next);
      if (p == mp)  /* first occurance of this mu,nu pair */
         SpewForthC2MProto(pre, fp0, fp1, mp->mu, mp->nu);
   }
   fprintf(fp0, "\n");
   fprintf(fp1, "\n");
/*
 * Now, crank out funcptr arrays
 */
   for (ia=0; ia < 3; ia ++)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp0,
            "static const ablk2cmat_t ATL_UAMM_BLK2C_a%c_b%c[ATL_UAMM_NCASES] =\n{\n",
                 ac[ia], bc[ib]);
         SpewForthC2BDecl(pre, mmb, fp0, "ablk2cmat", ac[ia], bc[ib]);
         fprintf(fp1,
            "static const cmat2ablk_t ATL_UAMM_C2BLK_a%c_b%c[ATL_UAMM_NCASES] =\n{\n",
                 ac[ia], bc[ib]);
         SpewForthC2BDecl(pre, mmb, fp1, "cmat2ablk", ac[ia], bc[ib]);
      }
   }
   fprintf(fp0, "\n#endif  /* end include file guard */\n");
   fclose(fp0);
   fprintf(fp1, "\n#endif  /* end include file guard */\n");
   fclose(fp1);
}

void SpewForthRevCpProto(char pre, FILE *fp, char alp, int u, int kmaj)
{
   const int G = (pre == 'c' || pre == 'z') ? 2 : 1;
   const char *cst[2] = {"", "C"};
   int g;

   for (g=0; g < G; g++)
   {
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cu%dam2cm_a%c_%dx%d%s\n",
                 pre, UID, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cu%dam2cm_a%c_%d%s\n",pre, UID, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*,const TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*);\n");
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cu%dam2rm_a%c_%dx%d%s\n",
                 pre, UID, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cu%dam2rm_a%c_%d%s\n",pre, UID, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*,const TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*);\n");
   }
}

void SpewForthCpProto(char pre, FILE *fp, char alp, int u, int kmaj)
{
   const int G = (pre == 'c' || pre == 'z') ? 2 : 1;
   const char *cst[2] = {"", "C"};
   int g;

   for (g=0; g < G; g++)
   {
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cu%dcm2am_a%c_%dx%d%s\n",
                 pre, UID, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cu%dcm2am_a%c_%d%s\n",pre, UID, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp,
    "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*);\n");
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cu%drm2am_a%c_%dx%d%s\n",
                 pre, UID, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cu%drm2am_a%c_%d%s\n",pre, UID, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp,
     "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*);\n");
   }
}

void SpewForthCpConjDecl(char pre, int REVERSE, ATL_mmnode_t *mmb, FILE *fp,
                         char *arr, char *rt, char alp, int u)
{
   ATL_mmnode_t *mp;
   int j;

   fprintf(fp, "static const %s_t %s_a%c[%d] =\n{\n",
           REVERSE?"am2cm":"cm2am", arr, alp,  ATL_CountNumberOfMMNodes(mmb));
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (kmaj > 1)
         fprintf(fp, "   ATL_%cu%d%s_a%c_%dx%dC", pre, UID, rt, alp, kmaj,
                 u?mp->mu:mp->nu);
      else
         fprintf(fp, "   ATL_%cu%d%s_a%c_%dC", pre, UID, rt, alp,
                 u?mp->mu:mp->nu);
      if (mp->next)
         fprintf(fp, ",");
      else
         fprintf(fp, " ");
      fprintf(fp, "  /* index %d */\n", j);
   }
   fprintf(fp, "};\n\n");
}

void SpewForthCpDecl(char pre, int REVERSE, ATL_mmnode_t *mmb, FILE *fp,
                     char *arr, char *rt, char alp, int u)
{
   ATL_mmnode_t *mp;
   int j;

   fprintf(fp, "static const %s_t %s_a%c[%d] =\n{\n",
           REVERSE?"am2cm":"cm2am", arr, alp, ATL_CountNumberOfMMNodes(mmb));
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (kmaj > 1)
         fprintf(fp, "   ATL_%cu%d%s_a%c_%dx%d", pre, UID, rt, alp, kmaj,
                 u?mp->mu:mp->nu);
      else
         fprintf(fp, "   ATL_%cu%d%s_a%c_%d", pre, UID, rt, alp,
                 u?mp->mu:mp->nu);
      if (mp->next)
         fprintf(fp, ",");
      else
         fprintf(fp, " ");
      fprintf(fp, "  /* index %d */\n", j);
   }
   fprintf(fp, "};\n\n");
}


void GenAMAJ2CMAJ(char pre, ATL_mmnode_t *mmb, char *outd, char *suff)
/*
 * 3. atlas_<pre>amm_am2cm_a[1,X,n]:
 *    defines: ATL_AMM_NCASES
 *    prototypes all am2rm & am2cm routines
 *    1 indexible array giving which to use for each block factor
 */
{
   char ac[3] = {'1', 'n', 'X'};
   int ia, j;
   char *fnam, *sp, *np;
   ATL_mmnode_t *mp;

   if (!suff)
      suff = "";
   ia = strlen(outd) + strlen(suff) + 24+UIL;
   fnam = malloc(ia*sizeof(char));
   assert(fnam);
   sprintf(fnam, "%s/atlas_%cu%damm%s_am2cm_a1.h", outd, pre, UID, suff);
   np = fnam+ia-23+12;
   assert(*np == 'a' && np[1] == 'm');
   sp = fnam+ia-4;
   assert(*sp == '1');

   for (ia=0; ia < 3; ia++)
   {
      char *rt[2] = {"am2cm", "am2rm"};
      FILE *fp;
      int kmaj = FLAG_IS_SET(mmb->flag, MMF_KVEC) ? mmb->vlen:0;

      if (kmaj == 1)
         kmaj = 0;
      *sp = ac[ia];
      fp = fopen(fnam, "w");
      assert(fp);
      sp[1] = '\0';
      PrintBegBlock(pre, mmb, np, fp);
      sp[1] = '.';
      fprintf(fp, "/*\n * mat2blk prototypes\n */\n");
      SpewForthRevCpProto(pre, fp, ac[ia], mmb->mu, kmaj);
      if (mmb->nu != mmb->mu || kmaj > 1)
         SpewForthRevCpProto(pre, fp, ac[ia], mmb->nu, kmaj);
      for (mp=mmb->next; mp; mp = mp->next)
      {
         ATL_mmnode_t *p;
         int mu = mp->mu, nu = mp->nu;
         int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
         for (p=mmb; p != mp; p = p->next)
         {
            const int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if (mu == p->mu && km == kmaj)
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthRevCpProto(pre, fp, ac[ia], mu, kmaj);
         for (p=mmb; p != mp; p = p->next)
         {
            const int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if ((p->nu == nu && km == kmaj) ||
                (km == kmaj && p->mu == nu))
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthRevCpProto(pre, fp, ac[ia], nu, kmaj);
      }
      fprintf(fp, "\n");
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_UAMM_BLK2A", "am2cm", ac[ia], 1);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_UAMM_BLK2AT", "am2rm", ac[ia], 1);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_UAMM_BLK2B", "am2cm", ac[ia], 0);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_UAMM_BLK2BT", "am2rm", ac[ia], 0);
      if (pre == 'c' || pre == 'z')
      {
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_UAMM_BLKC2A",
                             "am2cm", ac[ia], 1);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_UAMM_BLKH2A",
                             "am2rm", ac[ia], 1);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_UAMM_BLKC2B",
                             "am2cm", ac[ia], 0);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_UAMM_BLKH2B",
                             "am2rm", ac[ia], 0);
      }
      fprintf(fp, "\n#endif  /* end include file guard */\n");
      fclose(fp);
   }
   free(fnam);
}
void GenCMAJ2AMAJ(char pre, ATL_mmnode_t *mmb, char *outd, char *suff)
/*
 * 3. atlas_<pre>amm_cm2am_a[1,X,n]:
 *    defines: ATL_AMM_NCASES
 *    prototypes all rm2am & cm2am routines
 *    1 indexible array giving which to use for each block factor
 */
{
   char ac[3] = {'1', 'n', 'X'};
   int ia, j;
   char *fnam, *sp, *np;
   ATL_mmnode_t *mp;

GenAMAJ2CMAJ(pre, mmb, outd, suff);
   if (!suff)
      suff = "";
   ia = strlen(outd) + strlen(suff) + 24+UIL;
   fnam = malloc(ia*sizeof(char));
   assert(fnam);
   sprintf(fnam, "%s/atlas_%cu%damm%s_cm2am_a1.h", outd, pre, UID, suff);
   np = fnam+ia-23+12;
   assert(*np == 'c' && np[1] == 'm');
   sp = fnam+ia-4;
   assert(*sp == '1');

   for (ia=0; ia < 3; ia++)
   {
      char *rt[2] = {"cm2am", "rm2am"};
      FILE *fp;
      int kmaj = FLAG_IS_SET(mmb->flag, MMF_KVEC) ? mmb->vlen:0;

      if (kmaj == 1)
         kmaj = 0;
      *sp = ac[ia];
      fp = fopen(fnam, "w");
      assert(fp);
      sp[1] = '\0';
      PrintBegBlock(pre, mmb, np, fp);
      sp[1] = '.';
      fprintf(fp, "/*\n * mat2blk prototypes\n */\n");
      SpewForthCpProto(pre, fp, ac[ia], mmb->mu, kmaj);
      if (mmb->nu != mmb->mu || kmaj > 1)
         SpewForthCpProto(pre, fp, ac[ia], mmb->nu, kmaj);
      for (mp=mmb->next; mp; mp = mp->next)
      {
         ATL_mmnode_t *p;
         int mu = mp->mu, nu = mp->nu;
         int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if (mu == p->mu && km == kmaj)
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthCpProto(pre, fp, ac[ia], mu, kmaj);
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if ((p->nu == nu && km == kmaj) ||
                (km == kmaj && p->mu == nu))
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthCpProto(pre, fp, ac[ia], nu, kmaj);
      }
      fprintf(fp, "\n");
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_UAMM_AN2BLK", "cm2am", ac[ia], 1);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_UAMM_AT2BLK", "rm2am", ac[ia], 1);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_UAMM_BN2BLK", "cm2am", ac[ia], 0);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_UAMM_BT2BLK", "rm2am", ac[ia], 0);
      if (pre == 'c' || pre == 'z')
      {
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_UAMM_AC2BLK",
                             "cm2am", ac[ia], 1);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_UAMM_AH2BLK",
                             "rm2am", ac[ia], 1);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_UAMM_BC2BLK",
                             "cm2am", ac[ia], 0);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_UAMM_BH2BLK",
                             "rm2am", ac[ia], 0);
      }
      fprintf(fp, "\n#endif  /* end include file guard */\n");
      fclose(fp);
   }
   free(fnam);
}

int KernelIsExactSame(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same including KB, 0 otherwise
 */
{
/*
 * Kernels aren't the same if one is being compiled with specific KB,
 * and the other has runtime
 */
   if (FLAG_IS_SET(p0->flag, MMF_KRUNTIME) !=
       FLAG_IS_SET(p1->flag, MMF_KRUNTIME))
      return(0);
   if (!FLAG_IS_SET(p0->flag, MMF_KRUNTIME) && (p0->kbB != p1->kbB))
      return(0);
/*
 * Kernels aren't same if they use different veclen
 */
   if (p0->vlen != p1->vlen)
      return(0);
/*
 * Kernels aren't same if the -DATL_MOVE bits don't match
 */
   if (ATL_MMF_MVGET(p0->flag) != ATL_MMF_MVGET(p1->flag))
      return(0);
/*
 * Genned kerns should match on flag,VLEN,mu,nu,ku.  Already checked vlen.
 * NOTE: if we make generator handle extra params, MUST UPDATE HERE!!!
 */
   if (p0->ID == 0 && p1->ID == 0) &&
      return(p0->mu == p1->mu && p0->nu == p1->nu && 
             p0->ku == p1->ku && p0->flag == p1->flag);
/*
 * If both are user kernels, then they may be repeats.  For user kernels,
 * they are the same if both ID and flag match, else they are not.
 */
   else if (p0->ID > 0 && p1->ID > 0)
      return(p0->ID == p1->ID && p0->flag == p1->flag);
   return(0);  /* Can't be the same if above criteria fails */
}

/*
 * RETURNS: flags that necessitate recompilation, not including KRUNTIME,
 * which is encoded in kb
 */
int GetCompTimeFlags(ATL_mmnode_t *mp)
{
   int iflg;
   iflg = ATL_MMF_MVGET(mp->flag);  /* MVbits change kern at comp time */
   iflg |=  (((mp->flag) & 1)<<3);  /* LDTOP/BOT could be compile-time dec */
   if (FLAG_IS_SET(mp->flag, MMF_KVEC))
      iflg |= 1<<4;
   return(iflg);
}
int ExactKernelInList(ATL_mmnode_t *mmb, ATL_mmnode_t *p)
/*
 * RETURNS: 1 if p is duplicated in mmb, else 0
 */
{
   ATL_mmnode_t *mp;
   if (!p || !mmb)
      return(0);
   for (mp=mmb; mp; mp = mp->next)
      if (KernelIsExactSame(mp, p))
         return(1);
    return(0);
}

void SpewForthKernProto(FILE *fp, char pre, ATL_mmnode_t *p, char bc)
{
   fprintf(fp, "void ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c\n", pre, UID, p->ID,
           FLAG_IS_SET(p->flag, MMF_KRUNTIME)?0:p->kbB, GetCompTimeFlags(p),
           p->mu, p->nu, p->ku,bc);
   fprintf(fp,
      "   (ATL_CSZT,ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,TYPE*,\n");
   fprintf(fp,
      "    const TYPE*,const TYPE*,const TYPE*);\n");
}

void SpewForthKernProtos(FILE *fp, char pre, ATL_mmnode_t *mmb, int nbet)
{
   ATL_mmnode_t *mp;
   for (mp=mmb; mp; mp = mp->next)
   {
      if (!ExactKernelInList(mp->next, mp))
      {
         char bc[3] = {'0', '1', 'n'};  /* 0 must come first */
         int ib;
         for (ib=0; ib < nbet; ib++)
            SpewForthKernProto(fp, pre, mp, bc[ib]);
      }
   }
}

void SpewForthKernArray(FILE *fp, char pre, ATL_mmnode_t *mmb,
                        char *vnam, char cbet)
{
   ATL_mmnode_t *mp;
   int n;

   for (n=0,mp=mmb; mp; n++, mp = mp->next);
   fprintf(fp, "static const ammkern_t ATL_UAMM_%s[%d] =\n", vnam, n);
   fprintf(fp, "{\n");
   for (mp=mmb; mp; mp = mp->next)
   {
      fprintf(fp, "   ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c", pre, UID, mp->ID,
              FLAG_IS_SET(mp->flag, MMF_KRUNTIME)?0:mp->kbB,
              GetCompTimeFlags(mp), mp->mu, mp->nu, mp->ku, cbet);
      if (mp->next)
         fprintf(fp, ",\n");
   }
   fprintf(fp, "\n};\n\n");
}

/*
 * RETURNS: possibly updated list of all unique mu/nu comboes
 */
typedef struct mnur mnur_t;
struct mnur {int mu; int nu; int kmaj; mnur_t *next;};
mnur_t *GetUniqueMNUnrolls(ATL_mmnode_t *mmb, mnur_t *urb)
{
   ATL_mmnode_t *mp;
   mnur_t *up;
/*
 * For each node in mmb, add to urb if mu/nu combo not already there
 * kmaj only affects A/B copy, and this is for C put, so ignore kmaj
 */
   for (mp = mmb; mp; mp = mp->next)
   {
      for (up=urb; up; up = up->next)
         if (mp->mu == up->mu && mp->nu == up->nu)
            break;
      if (!up)
      {
         up = malloc(sizeof(mnur_t));
         assert(up);
         up->mu = mp->mu;
         up->nu = mp->nu;
         up->kmaj = 0;
         up->next = urb;
         urb = up;
      }
   }
   return(urb);
}

/*
 * RETURNS: list of just unique MUs from mnb not already in mub
 */
mnur_t *GetUniqueMUnrolls(ATL_mmnode_t *mnb, mnur_t *mub)
{
   mnur_t *mup;
   ATL_mmnode_t *mnp;
   if (!mnb)
      return(mub);
   for (mnp=mnb; mnp; mnp = mnp->next)
   {
      const int kmaj = FLAG_IS_SET(mnp->flag, MMF_KVEC) ? mnp->vlen?0;
      for (mup=mub; mup; mup = mup->next)
         if (mup->mu == mnp->mu && mup->kmaj == kmaj)
            break;
      if (!mup)  /* a new mu */
      {
         mup = malloc(sizeof(mnur_t));
         assert(mup);
         mup->nu = mup->mu = mnp->mu;
         mup->next = mub;
         mup->kmaj = kmaj;
         mub = mup;
      }
   }
   return(mub);
}
/*
 * RETURNS: list of just unique NUs from mnb not already in mub
 */
mnur_t *GetUniqueNUnrolls(ATL_mmnode_t *mnb, mnur_t *mub)
{
   mnur_t *mup;
   ATL_mmnode_t *mnp;
   if (!mnb)
      return(mub);
   for (mnp=mnb; mnp; mnp = mnp->next)
   {
      const int kmaj = FLAG_IS_SET(mnp->flag, MMF_KVEC) ? mnp->vlen:0;
      for (mup=mub; mup; mup = mup->next)
         if (mup->mu == mnp->nu && kmaj == mup->kmaj)
            break;
      if (!mup)  /* a new nu */
      {
         mup = malloc(sizeof(mnur_t));
         assert(mup);
         mup->nu = mup->mu = mnp->nu;
         mup->next = mub;
         mup->kmaj = kmaj;
         mub = mup;
      }
   }
   return(mub);
}

void KillUnrollList(mnur_t *b)
{
   mnur_t *p;
   while (b)
   {
      p = b->next;
      free(b);
      b = p;
   }
}
void PrintSwapProto(FILE *fp, char pre, int mu, int nu)
{
   fprintf(fp, "void Mjoin(PATL,ammswp%dx%d)", mu, nu);
   if (pre == 'd' || pre == 's')
      fprintf(fp, "(ATL_CINT nnu, TYPE *A, ATL_CSZT lda, TYPE *b);\n");
   else
      fprintf(fp, "(ATL_CINT nnu, TYPE *A, ATL_CSZT lda, TYPE *r, TYPE *i);\n");
}


void zGenAmmSwp(char pre, FILE *fp, int mu, int nu)
{
}

void GenAmmSwp(char pre, FILE *fp, int mu, int nu)
{
   const int munu=mu*nu;
   int i, j, ib;

   if (pre == 'z' || pre == 'c')
   {
      zGenAmmSwp(pre, fp, mu, nu);
      return;
   }

   fprintf(fp, "#include \"atlas_misc.h\"\n");
   fprintf(fp, "void Mjoin(PATL,ammswp%dx%d)\n", mu, nu);
   fprintf(fp, "(\n");
   fprintf(fp, "   ATL_CINT nnu,   /* CEIL(rowlen / nu) */\n");
   fprintf(fp, "   TYPE *A,        /* col-maj matrix to swap wt b */\n");
   fprintf(fp, "   ATL_CSZT lda1,  /* stride between row elts in A */\n");
   fprintf(fp,
           "   TYPE *b         /* %dx%d C-format row ptr to be swapped */\n",
           mu, nu);
   fprintf(fp, ")\n{\n");

   fprintf(fp, "   register unsigned int j;\n");
   if (nu > 1)
   {
      fprintf(fp, "   const size_t lda2=lda1+lda1");
      for (i=3; i <= nu; i++)
         fprintf(fp, ", lda%d=lda1+lda%d", i, i-1);
      fprintf(fp, ";\n");
   }

   fprintf(fp, "   for (j=nnu; j; j--)\n   {\n");

   fprintf(fp, "      register TYPE a0");
   for (i=1; i < nu; i++)
      fprintf(fp, ", a%d", i);
   fprintf(fp, ";\n");

   fprintf(fp, "      a0 = *A;\n");
   for (i=1; i < nu; i++)
      fprintf(fp, "      a%d = A[lda%d];\n", i, i);
   fprintf(fp, "      *A = *b;\n");
   for (i=1; i < nu; i++)
      fprintf(fp, "      A[lda%d] = b[%d];\n", i, i*mu);
   fprintf(fp, "      *b = a0;\n");
   for (i=1; i < nu; i++)
      fprintf(fp, "      b[%d] = a%d;\n", i*mu, i);
   fprintf(fp, "      b += %d;\n", mu*nu);
   fprintf(fp, "      A += lda%d;\n", nu);

   fprintf(fp, "   }\n");

   fprintf(fp, "}\n");
}

void GenAmmSwapFiles(char pre, ATL_mmnode_t *mmb, char *outd)
{
   mnur_t *ub, *up;
   char *fnam;
   int ia;

   if (pre == 's')
      GenAmmSwapFiles('c', mmb, outd);
   else if (pre == 'd')
      GenAmmSwapFiles('z', mmb, outd);
   ia = strlen(outd) + 24+UIL;
   fnam = malloc(ia);
   assert(fnam);
   ub = GetUniqueMNUnrolls(mmb, NULL);
   for (up=ub; up; up = up->next)
   {
      FILE *fp;
      assert(up->mu < 100 && up->nu < 100);
      sprintf(fnam, "%s/ATL_%cammswp%dx%d.c", outd, pre, up->mu, up->nu);
      fp = fopen(fnam, "w");
      assert(fp);
      GenAmmSwp(pre, fp, up->mu, up->nu);
      fclose(fp);
   }
   KillUnrollList(ub);
   free(fnam);
}
void GenAmmSwapH(char pre, ATL_mmnode_t *mmb, char *outd)
{
   mnur_t *ub, *up;
   ATL_mmnode_t *mp;
   FILE *fp;
   int i;

   fp = StandHStart(pre, mmb, outd, "swp");

   fprintf(fp, "\n");
   ub = GetUniqueMNUnrolls(mmb, NULL);
   for (up=ub; up; up = up->next)
      PrintSwapProto(fp, pre, up->mu, up->nu);
   KillUnrollList(ub);
   fprintf(fp, "\n");

   fprintf(fp, "static const ammswp_t ATL_UAMM_SWP[ATL_UAMM_NCASES] =\n{\n");
   for (i=0, mp=mmb; mp; mp = mp->next, i++)
      if (mp->next)
         fprintf(fp, "   ATL_%cammswp%dx%d,  /* index %d */\n",
                 pre, mp->mu, mp->nu, i);
     else
         fprintf(fp, "   ATL_%cammswp%dx%d   /* index %d */\n",
                 pre, mp->mu, mp->nu, i);

   fprintf(fp, "};\n\n");
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

int KernelIsSame(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same except for blocking, 0 otherwise
 */
{
/*
 * Kernels aren't the same if one is being compiled with specific KB,
 * and the other has runtime
 */
   if (FLAG_IS_SET(p0->flag, MMF_KRUNTIME) !=
       FLAG_IS_SET(p1->flag, MMF_KRUNTIME))
      return(0);
/*
 * Two generated kernels are the same if mu,nu,ku,VLEN,flag are the same.
 * NOTE: if we make generator handle muladd, etc, MUST UPDATE HERE!!!
 */
   if (p0->ID == 0 && p1->ID == 0)
      return(p0->mu == p1->mu && p0->nu == p1->nu && p0->ku == p1->ku &&
             p0->vlen == p1->vlen && p0->flag == p1->flag);
/*
 * If both are user kernels, then they may be repeats.  For user kernels,
 * they are the same if both ID and flag match, else they are not.
 */
   else if (p0->ID > 0 && p1->ID > 0)
      return(p0->ID == p1->ID && p0->flag == p1->flag);
   return(0);  /* Can't be the same if above criteria fails */
}


void GenRankKH
(
   char pre,
   ATL_mmnode_t *sqb,  /* baseptr  of square-case AMMM kernels */
   ATL_mmnode_t *rkb,  /* rank-K kernels, one for each supported K */
   char *outd
)
{
   FILE *fp;
   mnur_t *putb, *cpyb, *up;
   ATL_mmnode_t *mp;
   int m, n, k;
   int ia, ib;
   char PRE = pre;
   char ac[3] =  {'1', 'n', 'X'};
   char bc[4] = {'1', 'n', '0', 'X'};
   if (pre == 'c')
      pre = 's';
   else  if (pre == 'z')
      pre = 'd';

   assert(sqb && rkb);
   fp = StandHStart(PRE, rkb, outd, "rankK");
   fprintf(fp, "\n");

   for (mp=sqb; mp->next; mp = mp->next);
   fprintf(fp, "#define ATL_rkAMM_LASTMB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_rkAMM_LASTNB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_rkAMM_LASTKB %d\n\n", mp->kbB);
/*
 * Prototype needed copy routines
 */
   putb = GetUniqueMNUnrolls(rkb, NULL);
   fprintf(fp, "/*\n * cblk2mat put function prototypes\n */\n");
   for (up=putb; up; up = up->next)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp, "void ATL_%cablk2cmat_%dx%d_a1_b%c\n",
                 PRE, up->mu, up->nu, bc[ib]);
         if (PRE == 'c' || PRE == 'z')
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         else
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
      }
   }
   KillUnrollList(putb);
   fprintf(fp,
      "/*\n * Column-major to access-major copy function prototypes\n */\n");
   cpyb = GetUniqueMUnrolls(rkb, NULL);
   cpyb = GetUniqueNUnrolls(rkb, cpyb);
   for (up=cpyb; up; up = up->next)
   {
      for (ia=0; ia < 3; ia++)
         SpewForthCpProto(PRE, fp, ac[ia], up->mu, up->kmaj);
   }
   KillUnrollList(cpyb);
/*
 * Prototype the rank-K functions
 */
   fprintf(fp, "/*\n * rank-K AMMM kernel prototypes\n */\n");
   for (mp=rkb; mp; mp = mp->next)
   {
/*
 *    For runtime kernels, only prototype 1st time they are seen in list
 */
      if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
      {
         ATL_mmnode_t *p;
         if (mp->ID > 0)
         {
            for (p=rkb; p != mp; p = p->next)
               if (p->ID == mp->ID)
                  break;
         }
         else
         {
            for (p=rkb; p != mp; p = p->next)
               if (KernelIsSame(mp, p))
                  break;
         }
         if (mp == p)
         {
            SpewForthKernProto(fp, pre, mp, '0');
            SpewForthKernProto(fp, pre, mp, '1');
            SpewForthKernProto(fp, pre, mp, 'n');
         }
      }
/*
 *    compile-time-K kernels get prototyped for each invocation
 */
      else
      {
         SpewForthKernProto(fp, pre, mp, '0');
         SpewForthKernProto(fp, pre, mp, '1');
         SpewForthKernProto(fp, pre, mp, 'n');
      }
   }
/*
 * Now, crank out funcptr arrays
 */
   for (ib=0; ib < 4; ib++)
   {
      fprintf(fp,
         "\nstatic const ablk2cmat_t ATL_AMM_BLK2C_a1_b%c[%d] =\n{\n",
              bc[ib], ATL_CountNumberOfMMNodes(rkb));
      SpewForthC2BDecl(PRE, rkb, fp, "ablk2cmat", '1', bc[ib]);
   }
   for (ia=0; ia < 3; ia++)
   {
      fprintf(fp, "\n");
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_AN2BLK", "cm2am", ac[ia], 1);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_AT2BLK", "rm2am", ac[ia], 1);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_BN2BLK", "cm2am", ac[ia], 0);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_BT2BLK", "rm2am", ac[ia], 0);
      if (PRE == 'z' || PRE == 'c')
      {
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_AC2BLK", "cm2am",ac[ia],1);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_AH2BLK", "rm2am",ac[ia],1);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_BC2BLK", "cm2am",ac[ia],0);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_BH2BLK", "rm2am",ac[ia],0);
      }
   }
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK", '0');
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK_b1", '1');
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK_bn", 'n');
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenSquareKH(char pre, ATL_mmnode_t *mmb, char *outd)
/*
 * 5. atlas_<pre>amm_kerns.h
 *    defines: ATL_AMM_NCASES
 *    prototypes all kernels, including K-cleanup
 *    1 indexible array gives kernel to use for each case as func ptr
 *    1 indexible array gives K-clean kernel
 */
{
   FILE *fp;
/*
 * Dump out standard header start and kernel prototypes
 */
   fp = StandHStart(pre, mmb, outd, "sqkern");
   fprintf(fp, "\n");
   SpewForthKernProtos(fp, pre, mmb, 3);
   fprintf(fp, "\n");
/*
 * Dump out kernel ptr arrays
 */
   SpewForthKernArray(fp, pre, mmb, "SQKERN_b0", '0');
   SpewForthKernArray(fp, pre, mmb, "SQKERN_b1", '1');
   SpewForthKernArray(fp, pre, mmb, "SQKERN_bn", 'n');

   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenKernH(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *ukb,
              ATL_mmnode_t *kcb, char *outd)
/*
 * 5. atlas_<pre>amm_kerns.h
 *    defines: ATL_AMM_NCASES
 *    prototypes all kernels, including K-cleanup
 *    1 indexible array gives kernel to use for each case as func ptr
 *    1 indexible array gives K-clean kernel
 */
{
   FILE *fp;
/*
 * Dump out standard header start and kernel prototypes
 */
   fp = StandHStart(pre, mmb, outd, "kern");
   fprintf(fp, "\n");
   SpewForthKernProtos(fp, pre, mmb, 3);
   if (ukb)
      SpewForthKernProtos(fp, pre, ukb, 3);
   fprintf(fp, "\n");
/*
 * Dump out kernel ptr arrays
 */
   SpewForthKernArray(fp, pre, mmb, "KERN_b0", '0');
   SpewForthKernArray(fp, pre, mmb, "KERN_b1", '1');
   SpewForthKernArray(fp, pre, mmb, "KERN_bn", 'n');
   if (kcb)
   {
      SpewForthKernArray(fp, pre, kcb, "KERN_K1", '0');
      SpewForthKernArray(fp, pre, kcb, "KERN_K1_b1", '1');
      SpewForthKernArray(fp, pre, kcb, "KERN_K1_bn", 'n');
   }

   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenCmplxHeaders(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *rkb, char *outd)
{
   GenCMAJ2AMAJ(pre, mmb, outd, NULL);
   GenC2BLK(pre, mmb, outd, NULL);
   if (rkb)
   {
      GenCMAJ2AMAJ(pre, rkb, outd, "rkk");
      GenC2BLK(pre, rkb, outd, "_rkk");
      GenRankKH(pre, mmb, rkb, outd);
   }
}

void GenHeaderFiles(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *ukb,
                    ATL_mmnode_t *kcb, ATL_mmnode_t *rkb, ATL_mmnode_t *urb,
                    ATL_mmnode_t *sqb, ATL_mmnode_t *usb, char *outd)
/*
 * Header files required to build full gemm (no timing):
 *X1. atlas_<pre>amm_blk.h :
 *X   defines: ATL_AMM_NCASES, ATL_AMM_MAX[M,N,K]B
 *X   3 arrays indexed by case give blocking
 *X2  atlas_<pre>amm_flag.h
 *X   defines: ATL_AMM_NCASES
 *X   1 indexible array giving KRUNTIME for now
 *X3. atlas_<pre>amm_cm2am_a[1,X,n]:
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all rm2am & cm2am routines
 *X   1 indexible array giving which to use for each block factor
 *X4. atlas_<pre>amm_ablk2cmat.h
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all ablk2cmat routines
 *X   1 indexible array for each alpha,beta combination
 *X   -> 3*4 = 12 indexible arrays total
 *X5. atlas_<pre>amm_kerns.h
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all kernels, including K-cleanup
 *X   1 indexible array gives kernel to use for each case as func ptr
 *X   1 indexible array gives K-clean kernel
 *X6. atlas_<pre>amm_cmat2ablk.h (I don't need, Rakib does)
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all cmat2ablk routines
 *X   1 indexible array for each alpha,beta combination
 *X   -> 3*4 = 12 indexible arrays total
 */
{
   if (rkb)
      GenAmmSum(pre, mmb, rkb, outd);
   GenAmmSwapH(pre, mmb, outd);
   GenBlockingFile(pre, mmb, outd, "blk");
   GenPerfFile(pre, mmb, outd, "perf");
   GenFlagH(pre, mmb, outd, "flag");
   GenCMAJ2AMAJ(pre, mmb, outd, NULL);
   GenC2BLK(pre, mmb, outd, NULL);
   GenKernH(pre, mmb, ukb, kcb, outd);
   if (rkb)
   {
      GenBlockingFile(pre, rkb, outd, "rkkblk");
      GenFlagH(pre, rkb, outd, "rkkflag");
      GenCMAJ2AMAJ(pre, rkb, outd, "rkk");
      GenC2BLK(pre, rkb, outd, "_rkk");
      GenRankKH(pre, mmb, rkb, outd);
   }
   if (sqb)
   {
      GenBlockingFile(pre, rkb, outd, "sqblk");
      GenFlagH(pre, rkb, outd, "sqflag");
      GenCMAJ2AMAJ(pre, rkb, outd, "sq");
      GenC2BLK(pre, rkb, outd, "_sq");
      GenSquareKH(pre, sqb, outd);
   }
}

/*
 * Splits rkb into two lists: (1) Routines with runtime K (RUNB),
 * (2) Routines with fixed-KB (returned)
 * NOTE: original list rkb is unchanged
 */
ATL_mmnode_t *SplitRankK(ATL_mmnode_t *rkb, ATL_mmnode_t **RUNB)
{
   ATL_mmnode_t *runb=NULL, *fixb=NULL, *p, *np;
   for (p=rkb; p; p = p->next)
   {
      np = CloneMMNode(p);
      if (FLAG_IS_SET(np->flag, MMF_KRUNTIME))
      {
         np->next = runb;
         runb = np;
      }
      else
      {
         np->next = fixb;
         fixb = np;
      }
   }
   *RUNB = runb;
   return(fixb);
}

char *GetKernComp(ATL_mmnode_t *mmp, char *dcomp, char *dflags, char **flgs)
{
   char *comp = dcomp;
   if (mmp->comp)
   {
      comp = (mmp->comp[0] == 'g' && mmp->comp[1] == 'c' &&
              mmp->comp[2] == 'c' &&
             (mmp->comp[3] == '\0' || mmp->comp[3] == ' '))
             ? "$(GOODGCC)" : mmp->comp;
      *flgs = mmp->cflags;
   }
   else
      *flgs = dflags;
   return(comp);
}
void PrintKernComp
(
   FILE *fp,            /* file to print to */
   char pre,
   ATL_mmnode_t *mmp,   /* kernel compile rule is for */
   int UID,             /* user-ID for user-determined kerns */
   char *comp,          /* compiler to use */
   char *cflags,        /* compiler flags to use */
   char *styp,          /* string defining type (eg. "-DSREAL") */
   char cbet,           /* character with beta name ('1', '0', 'n') */
   char *sbet           /* string wt full beta name ("1", "N1", "0") */
)
{
   const int kb = FLAG_IS_SET(mmp->flag, MMF_KRUNTIME)?0:mmp->kbB;
   const int flg = GetCompTimeFlags(mmp);
   if (pre == 'z')
      styp = "-DDREAL=1";
   else if (pre == 'c')
      styp = "-DSREAL=1";
   fprintf(fp, "ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c.o : %s\n", pre,
           UID, mmp->ID, kb, flg, mmp->mu, mmp->nu, mmp->ku, cbet, mmp->rout);
   fprintf(fp, "\t%s $(CDEFS2) %s -DBETA%s=1", comp, styp, sbet);
   if (!FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      fprintf(fp, " -DMB=%d -DNB=%d, -DKB=%d", mmp->mbB, mmp->nbB, mmp->kbB);
   if (FLAG_IS_SET(mmp->flag, MMF_MVA))
      fprintf(fp, " -DATL_MOVEA");
   if (FLAG_IS_SET(mmp->flag, MMF_MVB))
      fprintf(fp, " -DATL_MOVEB");
   if (FLAG_IS_SET(mmp->flag, MMF_MVC))
      fprintf(fp, " -DATL_MOVEC");
         fprintf(fp,
         " -DATL_USERMM=ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c -DATL_UAMMID=%d",
                 pre, UID, mmp->ID, kb, flg, mmp->mu, mmp->nu, mmp->ku, cbet,
                 UID);
         fprintf(fp, " %s -o ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c.o -c %s\n",
                 cflags, pre, UID, mmp->ID, kb, flg, mmp->mu, mmp->nu,
                 mmp->ku, cbet, mmp->rout);
}
void GenMakefile
(
   char pre,            /* type/precision prefix : s,d,c,z */
   ATL_mmnode_t *mmb,   /* main kernels for GEMM */
   ATL_mmnode_t *ukb,   /* unique kernels for doing K cleanup of kerns in mmb */
   ATL_mmnode_t *rkb,   /* list of kernels to doing rank-K update */
   ATL_mmnode_t *urb,   /* rank-K update kerns not existing in other lists */
   ATL_mmnode_t *usb,   /* square kernels not existing in other lists */
   char *outd
)
{
   ATL_mmnode_t *mmp, *p, *fixb, *runb;
   mnur_t *mnurb=NULL, *allub, *up;
   FILE *fp;
   char *comp, *cflags;
   char *ln;
   int i;
   char pres[2];
   char be[3] = {'1', 'n', '0'};
   char *bes[3] = {"1", "N1", "0"};
   char al[3] = {'1', 'n', 'X'};
   char dcomp[8] = {'$', '(', 'D', 'M', 'C', ')', '\0'};
   char dflags[12] = {'$', '(', 'D', 'M', 'C', 'F', 'L', 'A', 'G', 'S',
                     ')', '\0'};
   char *styps[2] = {"-DDREAL", "-DDCPLX"};
   char *styp = (pre == 'd' || pre == 'z') ? "-DDREAL" : "-DSREAL";

   pres[0] = pre;
   if (pre == 's' || pre == 'c')
   {
      styps[0] = "-DSREAL";
      styps[1] = "-DSCPLX";
      pres[1] = 'c';
   }
   else
      pres[1] = 'z';

   ln = malloc((strlen(outd)+11)*sizeof(char));
   assert(ln);
   sprintf(ln, "%s/%cMake_amm", outd, pre);
   fp = fopen(ln, "w");
   assert(fp);
   free(ln);
   fprintf(fp, "include ../Make.inc\n");
   fprintf(fp, "CDEFS2=$(CDEFS)\n\n");
   if (pre == 'c')
   {
      fprintf(fp, "CMC=$(SMC)\n");
      fprintf(fp, "CKCFLAGS=$(SKCFLAGS)\n");
      fprintf(fp, "CMCFLAGS=$(SMCFLAGS)\n");
   }
   else if (pre == 'z')
   {
      fprintf(fp, "ZMC=$(DMC)\n");
      fprintf(fp, "ZKCFLAGS=$(DKCFLAGS)\n");
      fprintf(fp, "ZMCFLAGS=$(DMCFLAGS)\n");
   }
/*
 * Build list of all unique MU/NU combos for copy routines
 * Square cases built from mmb, so they are all represented in mmb
 */
   mnurb = GetUniqueMNUnrolls(mmb, NULL);
   mnurb = GetUniqueMNUnrolls(urb, mnurb);
   allub = GetUniqueMUnrolls(mmb, NULL);
   allub = GetUniqueMUnrolls(urb, allub);
   allub = GetUniqueNUnrolls(mmb, allub);
   allub = GetUniqueNUnrolls(urb, allub);
/*
 * Spew out all filenames that must be compiled
 */
   fprintf(fp, "objs =");
/*
 * Routines to copy from MU/NU-major to column major output array
 */
   for (up=mnurb; up; up = up->next)
   {
      int j;
      const int mu=up->mu, nu=up->nu;

      for (j=0; j < 3; j++)
      {
         int k;
         char *rtn[2] = {"ablk2cmat", "cmat2ablk"};
         for (k=0; k < 2; k++)
         {
            int h;
            for (h=0; h < 2; h++)
            {
               if (pre != pres[h])
                  continue;
               if (j == 0)
                  fprintf(fp, " \\\n       ATL_%cammswp%dx%d.o", pre, mu, nu);
               fprintf(fp, " \\\n       ATL_%cu%d%s_%dx%d_a%c_b1.o",
                       pre, UID, rtn[k], mu, nu, al[j]);
               fprintf(fp, " ATL_%cu%d%s_%dx%d_a%c_bX.o",
                       pre, UID, rtn[k], mu, nu, al[j]);
               fprintf(fp, " \\\n       ATL_%cu%d%s_%dx%d_a%c_b0.o",
                       pre, UID, rtn[k], mu, nu, al[j]);
               fprintf(fp, " ATL_%cu%d%s_%dx%d_a%c_bn.o",
                       pre, UID, rtn[k], mu, nu, al[j]);
            }
         }
      }
   }
/*
 * Routines to copy back and forth from A and B
 */
   for (up=allub; up; up = up->next)
   {
      int h;
      for (h=0; h < 2; h++)
      {
        if (pre != pres[h]) continue;
         int j;
         const int u = up->mu;
         for (j=0; j < 3; j++)
         {
            if (up->kmaj > 1)
            {
               fprintf(fp,
 " \\\n       ATL_%cu%drm2am_a%c_%dx%d.o ATL_%cu%dcm2am_a%c_%dx%d.o",
              pre, UID, al[j], up->kmaj, u, pre, UID, al[j], up->kmaj, u);
               fprintf(fp,
 " \\\n       ATL_%cu%dam2rm_a%c_%dx%d.o ATL_%cu%dam2cm_a%c_%dx%d.o",
              pre, UID, al[j], up->kmaj, u, pre, UID, al[j], up->kmaj, u);
            }
            else
            {
               fprintf(fp,
                  " \\\n       ATL_%cu%drm2am_a%c_%d.o ATL_%cu%dcm2am_a%c_%d.o",
                       pre, UID, al[j], u, pre, UID, al[j], u);
               fprintf(fp,
                  " \\\n       ATL_%cu%dam2rm_a%c_%d.o ATL_%cu%dam2cm_a%c_%d.o",
                       pre, UID, al[j], u, pre, UID, al[j], u);
            }
            if (pre == 'c' || pre == 'z')
            {
               if (up->kmaj > 1)
               {
                  fprintf(fp,
 " \\\n       ATL_%cu%drm2am_a%c_%dx%dC.o ATL_%cu%dcm2am_a%c_%dx%dC.o",
                  pre, UID, al[j], up->kmaj, u, pre, UID, al[j], up->kmaj, u);
                  fprintf(fp,
 " \\\n       ATL_%cu%dam2rm_a%c_%dx%dC.o ATL_%cu%dam2cm_a%c_%dx%dC.o",
                  pre, UID, al[j], up->kmaj, u, pre, UID, al[j], up->kmaj, u);
               }
               else
               {
                  fprintf(fp,
               " \\\n       ATL_%cu%drm2am_a%c_%dC.o ATL_%cu%dcm2am_a%c_%dC.o",
                          pre, UID, al[j], u, pre, UID, al[j], u);
                  fprintf(fp,
               " \\\n       ATL_%cu%dam2rm_a%c_%dC.o ATL_%cu%dam2cm_a%c_%dC.o",
                          pre, UID, al[j], u, pre, UID, al[j], u);
               }
            }
         }
      }
   }
/*
 * AMM kernel routines
 */
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      int kb = mmp->kbB;
/*
 *    Kernels that take runtime K are only compiled once, so don't repeat them
 *    for every KB.  Only generate a statement if this is the first one.
 */
      if (FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      {
         const int id = mmp->ID;
         for (p=mmb; p != mmp; p = p->next)
            if (p->ID == id && FLAG_IS_SET(p->flag, MMF_KRUNTIME))
               break;
         if (p != mmp)
            continue;
         kb = 0;
      }
/*
 *    ATL_<pre>UAMMM_<ID>_<kb>_<flg>_<mu>x<nu>x<ku>_b<X>
 */
      for (i=0; i < 3; i++)
         fprintf(fp, " \\\n       ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c.o",
                 pre, UID, mmp->ID, kb, GetCompTimeFlags(mmp),
                 mmp->mu, mmp->nu, mmp->ku, be[i]);
   }
/*
 * AMM K-cleanup kernel routines are all unique, so no checking for repeats
 *    ATL_<pre>UAMMM_<ID>_<kb>_<flg>_<mu>x<nu>x<ku>_b0
 */
   for (mmp=ukb; mmp; mmp = mmp->next)
      for (i=0; i < 3; i++)
         fprintf(fp, " \\\n       ATL_%cu%dAMMM_%d_0_%x_%dx%dx%d_b%c.o", pre,
                 UID, mmp->ID, GetCompTimeFlags(mmp), mmp->mu, mmp->nu,
                 mmp->ku, be[i]);
/*
 * library make targets
 */
   fprintf(fp, "\n\nlib : %clib.grd\nall : %clib.grd\n%clib : %clib.grd\n",
           pre, pre, pre, pre);
   fprintf(fp, "%clib.grd : $(objs)\n", pre);
   fprintf(fp, "\t$(ARCHIVER) $(ARFLAGS) $(UAMMlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(UAMMlib)\n");
   fprintf(fp, "\t touch %clib.grd\n", pre);
   fprintf(fp, "clean : %cclean\n", pre);
   fprintf(fp, "%cclean:\n\t- rm -f $(objs)\n", pre);
   fprintf(fp, "killall : %ckillall\n", pre);
   fprintf(fp, "%ckillall : %cclean\n", pre, pre);
   fprintf(fp, "\t- $(ARCHIVER) d $(UAMMlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(UAMMlib)\n");
   fprintf(fp, "\t- rm -f ATL_%c*.[S,c]\n", pre);

/*
 * Print out the individual rules for each needed copy function
 */
   dcomp[2] = dflags[2] = toupper(pre);
   dflags[3] = dcomp[3] = 'K';
   fprintf(fp, "\ntsth.o : tsth.c\n");
   fprintf(fp, "\t%s %s $(CDEFS) %s -c tsth.c\n\n", dcomp, dflags, styp);
   fprintf(fp, "#\n# Data copy rules\n#\n");
/*
 * Print out 2-D ablk2Cmat, cmat2ablk and ammswp targets
 */
   for (up=mnurb; up; up = up->next)
   {
      const int mu=up->mu, nu = up->nu;
      char cbe[4] = {'0', '1', 'n', 'X'};
      int ibe[4] =  {0,    1,  -1,  2};
      int i, j;

      for (i=0; i < 4; i++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            if (pre != pres[h])
               continue;
            if (i == 0)
            {
               fprintf(fp, "ATL_%cammswp%dx%d.o : ATL_%cammswp%dx%d.c\n",
                       pre, mu, nu, pre, mu, nu);
               fprintf(fp, "\t%s %s %s $(CDEFS) -c ATL_%cammswp%dx%d.c\n",
                       dcomp, dflags, styp, pre, mu, nu);
            }
            char pre=pres[h];
            char *styp=styps[h];
            for (j=0; j < 3; j++)
            {
               int k;
               char *rtn[2] = {"ablk2cmat", "cmat2ablk"};
               for (k=0; k < 2; k++)
               {
                  char rn[64];
                  sprintf(rn, "ATL_%cu%d%s_%dx%d_a%c_b%c",
                          pre, UID, rtn[k], mu, nu, al[j], cbe[i]);
                  fprintf(fp, "%s.o : %s.c\n", rn, rn);
                  fprintf(fp, "\t%s %s $(CDEFS) %s -c -DATL_%c%s=%s \\\n",
                          dcomp, dflags, styp, rn[4], rn+6+UIL, rn);
                  fprintf(fp, "          -c %s.c\n", rn);
               }
            }
         }
      }
   }
   KillUnrollList(mnurb);
/*
 * Print out 1-D copy-in routine rules
 */
   for (up=allub; up; up = up->next)
   {
      const int u = up->mu, kmaj=up->kmaj;
      int j;
      for (j=0; j < 3; j++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            if (pre != pres[h]) continue;
            char *styp=styps[h];
            char *cst[2] = {"", "C"};
            char *cdef[2] = {"", "-DConj_=1 "};
            int g;
            const int G = (pre == 'c' || pre == 'z') ? 2:1;
            for (g=0; g < G; g++)
            {
               int kk;
               int nmI, nmI0=5;
               char *sp;
               char rout[32], rt0[32];
               if (kmaj > 1)
               {
                  sprintf(rout, "ATL_%cu%drm2am_a%c_%dx%d",
                          pre, UID, al[j], kmaj, u);
                  sprintf(rt0, "ATL_%crm2am_a%c_%dx%d", pre, al[j], kmaj, u);
               }
               else
               {
                  sprintf(rout, "ATL_%cu%drm2am_a%c_%d", pre, UID, al[j], u);
                  sprintf(rt0, "ATL_%crm2am_a%c_%d", pre, al[j], u);
               }
               sp = strstr(rout, "rm2am");
               nmI = sp - rout;
               for (kk=0; kk < 4; kk++)
               {
                  if (kk == 1)
                     rt0[5] = rout[6+UIL] = 'c';
                  else if (kk == 2)
                  {
                     rt0[5] = rout[6+UIL] = 'a';
                     rt0[8] = rout[9+UIL] = 'r';
                  }
                  else if (kk == 3)
                      rt0[8] = rout[9+UIL] = 'c';

                  fprintf(fp, "%s%s.o : %s.c\n", rout, cst[g], rout);
               fprintf(fp,
                       "\t%s %s $(CDEFS) %s%s -D%s%s=%s%s -o %s%s.o -c %s.c\n",
                       dcomp, dflags, cdef[g], styp, rt0, cst[g], rout, cst[g],
                       rout, cst[g], rout);
               }
            }
         }
      }
   }
   KillUnrollList(allub);
/*
 * Print out the individual rules for each kernel compile
 */
   dflags[3] = dcomp[3] = 'M';
   fprintf(fp, "#\n#  AMM kernel rules\n#\n");
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
/*
 *    Kernels that take runtime K are only compiled once, so print rules on
 *    only the first encounter of that ID
 */
      if (FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      {
         const int id = mmp->ID;
         for (p=mmb; p != mmp; p = p->next)
            if (p->ID == id && FLAG_IS_SET(p->flag, MMF_KRUNTIME))
               break;
         if (p != mmp)
            continue;
      }
      comp = GetKernComp(mmp, dcomp, dflags, &cflags);
/*
 *    ATL_<pre>UAMMM_<ID>_<kb>_<flg>_<mu>x<nu>x<ku>_b<X>,
 *    kerns in all 3 beta cases
 */
      for (i=0; i < 3; i++)
         PrintKernComp(fp, pre, mmp, UID, comp, cflags, styp, be[i], bes[i]);
   }
/*
 * K-cleanup needs only the kernel compile rule
 */
   fprintf(fp, "#\n#  K-cleanup rules\n#\n");
   for (mmp=ukb; mmp; mmp = mmp->next)
   {
      comp = GetKernComp(mmp, dcomp, dflags, &cflags);
      for (i=0; i < 3; i++)
         PrintKernComp(fp, pre, mmp, UID, comp, cflags, styp, be[i], bes[i]);
   }
   fclose(fp);
}

void GenKerns(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *ukb, ATL_mmnode_t *urb,
              char *outd)
/*
 * Creates/copies all required matmul kernels into outd using specified names
 */
{
   ATL_mmnode_t *mmp, *p;
   mnur_t *mnurb=NULL, *allub, *up;
   char *ln=NULL;
   int lnlen=0, dlen;
   char al[3] = {'1', 'n', 'X'};
   int ial[3] = {1,   -1,   2};
   char pres[2];
   pres[0] = pre;
   pres[1] = (pre == 's') ? 'c' : 'z';

   GenAmmSwapFiles(pre, mmb, outd);
/*
 * Build list of all unique MU/NU combos for copy routines
 */
   mnurb = GetUniqueMNUnrolls(mmb, NULL);
   mnurb = GetUniqueMNUnrolls(urb, mnurb);
   allub = GetUniqueMUnrolls(mmb, NULL);
   allub = GetUniqueMUnrolls(urb, allub);
   allub = GetUniqueNUnrolls(mmb, allub);
   allub = GetUniqueNUnrolls(urb, allub);
   dlen = strlen(outd);
/*
 * Extract every unique block-copy routine
 */
   for (up=mnurb; up; up = up->next)
   {
      const int mu=up->mu, nu=up->nu;
      char cbe[4] = {'0', '1', 'n', 'X'};
      int ibe[4] =  {0,    1,  -1,  2};
      int i, j;
      j = 64+8 + strlen(outd);
      j = (j > 128) ? j : 128;
      if (lnlen < j)
      {
         free(ln);
         lnlen = j;
         ln = malloc(j*sizeof(char));
         assert(ln);
      }
      for (i=0; i < 4; i++)
      {
         for (j=0; j < 3; j++)
         {
            char rn[64];
            int ierr;
            int k;
            for (k=0; k < 2; k++)
            {
               int h=0;
                  if (!k)
                     sprintf(rn, "ATL_%cablk2cmat_%dx%d_a%c_b%c.c",
                             pre, mu, nu, al[j], cbe[i]);
                  else
                     sprintf(rn, "ATL_%ccmat2ablk_%dx%d_a%c_b%c.c",
                             pre, mu, nu, al[j], cbe[i]);
                  sprintf(ln,
                     "make %s pre=%c mu=%d nu=%d al=%c be=%c alpha=%d beta=%d",
                          rn, pre, mu, nu, al[j], cbe[i], ial[j], ibe[i]);
                  ierr = system(ln);
                  if (ierr)
                  {
                     fprintf(stderr, "FAILED CMND='%s'\n", ln);
                     exit(ierr);
                  }
                  sprintf(ln, "mv %s %s/ATL_%cu%d%s", rn, outd, pre, UID, rn+5);
                  ierr = system(ln);
                  if (ierr)
                  {
                     fprintf(stderr, "FAILED CMND='%s'\n", ln);
                     exit(ierr);
                  }
            }
         }
      }
   }
   KillUnrollList(mnurb);

/*
 * Routines to copy back and forth from A and B
 */
   for (up=allub; up; up = up->next)
   {
      const int u = up->mu, kmaj=up->kmaj;
      int j;
      j = 16 * 40 + (strlen(outd)<<1);
      j = (j > 90) ? j : 90;
      if (lnlen < j)
      {
         free(ln);
         lnlen = j;
         ln = malloc(j*sizeof(char));
         assert(ln);
      }
      for (j=0; j < 3; j++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            int ierr;
            if (h)
               continue;
            sprintf(ln,
                    "make ATL_%crm2am_a%c_%d.c ATL_%ccm2am_a%c_%d.c "
                    "ATL_%cam2rm_a%c_%d.c ATL_%cam2cm_a%c_%d.c "
                    "pre=%c UR=%d alpha=%d al=%c kmaj=%d",
                    pre, al[j], u, pre, al[j], u,
                    pre, al[j], u, pre, al[j], u,
                    pre, u, ial[j], al[j], kmaj);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
            if (kmaj > 1)
               sprintf(ln,
                       "mv ATL_%crm2am_a%c_%d.c %s/ATL_%cu%drm2am_a%c_%dx%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], kmaj, u);
            else
               sprintf(ln,
                       "mv ATL_%crm2am_a%c_%d.c %s/ATL_%cu%drm2am_a%c_%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], u);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
            if (kmaj > 1)
               sprintf(ln,
                       "mv ATL_%ccm2am_a%c_%d.c %s/ATL_%cu%dcm2am_a%c_%dx%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], kmaj, u);
            else
               sprintf(ln,
                       "mv ATL_%ccm2am_a%c_%d.c %s/ATL_%cu%dcm2am_a%c_%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], u);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
            if (kmaj > 1)
               sprintf(ln,
                       "mv ATL_%cam2rm_a%c_%d.c %s/ATL_%cu%dam2rm_a%c_%dx%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], kmaj, u);
            else
               sprintf(ln,
                       "mv ATL_%cam2rm_a%c_%d.c %s/ATL_%cu%dam2rm_a%c_%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], u);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
            if (kmaj > 1)
               sprintf(ln,
                       "mv ATL_%cam2cm_a%c_%d.c %s/ATL_%cu%dam2cm_a%c_%dx%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], kmaj, u);
            else
               sprintf(ln,
                       "mv ATL_%cam2cm_a%c_%d.c %s/ATL_%cu%dam2cm_a%c_%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], u);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
         }
      }
   }
   KillUnrollList(allub);
/*
 * Copy/generate every unique file, but only once
 */
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      const int id=mmp->ID;
/*
 *    For generated files, just overwrite dups with same file, won't hurt
 */
      if (id == 0)
      {
         assert(mmp->genstr);
         assert(!system(mmp->genstr));
      }
      else  /* user-supplied files copied from AMMCASES directory */
      {
/*
 *       If this is the first time we've seen this ID, it must be copied
 */
         for (p=mmb; p != mmp && p->ID != id; p = p->next);
         if (p == mmp)
         {
            int i, ierr;
            i = strlen(mmp->rout) + dlen + 16;
            if (i > lnlen)
            {
               if (ln)
                  free(ln);
               ln = malloc(i*sizeof(char));
               assert(ln);
               lnlen = i;
            }
            sprintf(ln, "cp AMMCASES/%s %s/.", mmp->rout, outd);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
         }
      }
   }
/*
 * Copy/generate k-cleanup which is known to be unique
 */
   for (mmp=ukb; mmp; mmp = mmp->next)
   {
      const int id=mmp->ID;
/*
 *    For generated files, just generate it using genstr
 */
      if (id == 0)
      {
         assert(mmp->genstr);
         assert(!system(mmp->genstr));
      }
      else  /* user-supplied files copied from AMMCASES directory */
      {
         int i, ierr;
         i = strlen(mmp->rout) + dlen + 16;
         if (i > lnlen)
         {
            if (ln)
               free(ln);
            ln = malloc(i*sizeof(char));
            assert(ln);
            lnlen = i;
         }
         sprintf(ln, "cp AMMCASES/%s %s/.", mmp->rout, outd);
         ierr = system(ln);
         if (ierr)
         {
            fprintf(stderr, "FAILED CMND='%s'\n", ln);
            exit(ierr);
         }
      }
   }
   if (ln)
      free(ln);
}
void GenAllFiles(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *ukb,
                 ATL_mmnode_t *kcb, ATL_mmnode_t *rkb, ATL_mmnode_t *urb,
                 ATL_mmnode_t *sqb, ATL_mmnode_t *usb,
                 char *outd)
{
   GenHeaderFiles(pre, mmb, ukb, kcb, rkb, urb, sqb, usb, outd);
   GenMakefile(pre, mmb, ukb, rkb, urb, usb, outd);
   GenKerns(pre, mmb, ukb, urb, outd);
}


int KernelInList(ATL_mmnode_t *mmb, ATL_mmnode_t *p)
/*
 * RETURNS: 1 if p is duplicated in mmb, else 0
 */
{
   ATL_mmnode_t *mp;
   if (!p || !mmb)
      return(0);
   for (mp=mmb; mp; mp = mp->next)
      if (KernelIsSame(mp, p))
         return(1);
    return(0);
}

ATL_mmnode_t *StripNonUniqueKs(ATL_mmnode_t *ukb, ATL_mmnode_t *mmb)
/*
 * Deletes any ukb node that also appears in mmb,
 * RETURNS: possibly shortened ukb
 */
{
   ATL_mmnode_t *mp, *prev;
/*
 * Delete any repetitive nodes starting unique queue
 */
   while(ukb && KernelInList(mmb, ukb))
      ukb = KillMMNode(ukb);
   if (!ukb)
      return(ukb);
/*
 * Now, delete any internal non-unique K-cleanup
 */
   prev = ukb;
   mp = ukb->next;
   while (mp)
   {
      if (KernelInList(mmb, mp))
         mp = prev->next = KillMMNode(mp);
      else
      {
         prev = mp;
         mp = mp->next;
      }
   }
   return(ukb);
}
ATL_mmnode_t *StripExactMatchKs(ATL_mmnode_t *ukb, ATL_mmnode_t *mmb)
/*
 * Deletes any ukb node that also appears in mmb with same K-value,
 * RETURNS: possibly shortened ukb
 */
{
   ATL_mmnode_t *mp, *prev;
/*
 * Delete any repetitive nodes starting unique queue
 */
   while(ukb && ExactKernelInList(mmb, ukb))
      ukb = KillMMNode(ukb);
   if (!ukb)
      return(ukb);
/*
 * Now, delete any internal non-unique K-cleanup
 */
   prev = ukb;
   mp = ukb->next;
   while (mp)
   {
      if (ExactKernelInList(mmb, mp))
         mp = prev->next = KillMMNode(mp);
      else
      {
         prev = mp;
         mp = mp->next;
      }
   }
   return(ukb);
}
/*
 * RETURNS: mmb, with all repeated kernels removed
 */
ATL_mmnode_t *RemoveNonUniqueKernels(ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mp;
   if (!mmb || !mmb->next)
      return(mmb);
   for (mp=mmb; mp; mp = mp->next)
   {
      ATL_mmnode_t *p=mp->next, *prev=mp;
      while (p)
      {
         if (KernelIsSame(mp, p))
            prev->next = p = KillMMNode(p);
         else
         {
            prev = p;
            p = p->next;
         }
      }
   }
   return(mmb);
}

int main(int nargs, char **args)
{
   char pre='d';
   int verb=1;
   int *nbs;
   char *outd, *ukin, *kcin, *rkin, *sqin;
   ATL_mmnode_t *mmb, *mmp, *ukb=NULL, *kcb=NULL, *rkb=NULL, *urb=NULL,
                *sqb=NULL, *usb=NULL;

   mmb = GetFlags(nargs, args, &pre, &outd, &ukin, &kcin, &rkin, &sqin);
   assert(mmb);
   if (ukin)
   {
      ukb = ReadMMFile(ukin);
      free(ukin);
/*
 *    Now, strip off any ukb node that also appears in mmb, in order to
 *    make sure we don't repeat prototypes, generation, etc
 */
      ukb = StripNonUniqueKs(ukb, mmb);
   }
   if (kcin)
   {
      kcb = ReadMMFile(kcin);
      free(kcin);
   }
   if (rkin)
   {
      rkb = ReadMMFile(rkin);
      urb = CloneMMQueue(rkb);
      urb = RemoveNonUniqueKernels(urb);
      urb = StripExactMatchKs(urb, kcb);
      urb = StripExactMatchKs(urb, mmb);
      free(rkin);
   }
   if (sqin)
   {
      sqb = ReadMMFile(sqin);
      usb = CloneMMQueue(sqb);
      usb = RemoveNonUniqueKernels(usb);
      usb = StripExactMatchKs(usb, mmb);
      usb = StripExactMatchKs(usb, kcb);
      usb = StripExactMatchKs(usb, urb);
      free(sqin);
   }
   MMFillInGenStrings(pre, mmb, outd);
   MMFillInGenStrings(pre, ukb, outd);
   MMFillInGenStrings(pre, kcb, outd);
   MMFillInGenStrings(pre, rkb, outd);
   MMFillInGenStrings(pre, urb, outd);
   MMFillInGenStrings(pre, usb, outd);
   GenAllFiles(pre, mmb, ukb, kcb, rkb, urb, sqb, usb, outd);
   KillAllMMNodes(mmb);
   KillAllMMNodes(ukb);
   KillAllMMNodes(kcb);
   KillAllMMNodes(rkb);
   exit(0);
}
@ROUT emit_amm
@extract -b @(topd)/cw.inc lang=C -def cwdate 2012 -def cwdate 2013 -def cwdate 2015
#include "atlas_misc.h"
#include "atlas_mmparse.h"
#include "atlas_mmtesttime.h"
#include "atlas_sys.h"

ATL_mmnode_t *RemoveNonUniqueKernels(ATL_mmnode_t *mmb);

void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr, 
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
   fprintf(stderr, "   -d <outdir>: directory to dump files to\n");
   fprintf(stderr, "   -g <rect kern file> <geKCleanFile>\n");
   fprintf(stderr, "   -r <rank-K kernel file> \n");
   fprintf(stderr, "   -s <square-case kernel file> <sqKCleanFile>\n");
   fprintf(stderr, "   -t <trsm file> : should match -s\n");
   exit(ierr ? ierr : -1);
}

/*
 * RETURNS: precision prefix [s,d,c,z]
 */
char GetFlags(int nargs, char **args, char **DOUT, 
              ATL_mmnode_t **GEMM, ATL_mmnode_t **GEK1,
              ATL_mmnode_t **SQMM, ATL_mmnode_t **SQK1,
              ATL_mmnode_t **RKMM, ATL_mmnode_t **TRSM,
              ATL_mmnode_t **cGEMM, ATL_mmnode_t **cGEK1,
              ATL_mmnode_t **cSQMM, ATL_mmnode_t **cSQK1,
              ATL_mmnode_t **cRKMM, ATL_mmnode_t **cTRSM)
{
   int i, j=0, n, k;
   char pre='d', cpre;
   ATL_mmnode_t *gemm=NULL, *gek1=NULL, *sqmm=NULL, *sqk1=NULL, *rkmm=NULL;
   ATL_mmnode_t *trsm=NULL, *mmb=NULL, *mmp, *mp;

   *DOUT = NULL;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);
      
      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        break;
      case 'g':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        gemm = ReadMMFile(args[i]);
        assert(gemm);
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        gek1 = ReadMMFile(args[i]);
        assert(gek1);
        break;
      case 't':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        trsm = ReadMMFile(args[i]);
        assert(trsm);
      case 's':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        sqmm = ReadMMFile(args[i]);
        assert(sqmm);
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        sqk1 = ReadMMFile(args[i]);
        assert(sqk1);
        break;
      case 'r':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        rkmm = ReadMMFile(args[i]);
        break;
      case 'd':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *DOUT = DupString(args[i]);
        break;
      case 'i':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        mmp = ReadMMFile(args[i]);
        if (mmb)
        {
           ATL_mmnode_t *mp;
           for (mp=mmb; mp->next; mp = mp->next);
           mp->next = mmp;
        }
        else
           mmb = mmp;
        break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (!gemm)
   {
      assert(!gek1);
      gemm = ReadMMFileWithPath(pre, "res", "geAMMRES.sum");
      assert(gemm);
      gek1 = ReadMMFileWithPath(pre, "res", "geAMMKCLEAN.sum");
      assert(gek1);
   }
   if (!sqmm)
   {
      assert(!sqk1);
      sqmm = ReadMMFileWithPath(pre, "res", "sqAMMRES.sum");
      assert(sqmm);
      sqk1 = ReadMMFileWithPath(pre, "res", "sqAMMKCLEAN.sum");
      assert(sqk1);
   }
   if (!trsm)
   {
      trsm = ReadMMFileWithPath(pre, "res", "tsAMMRES.sum");
      assert(trsm);
   }
   if (!rkmm)
   {
      rkmm = ReadMMFileWithPath(pre, "res", "rkAMMRES.sum");
      assert(rkmm);
   }
   if (!(*DOUT))
      *DOUT = DupString("KERNEL");
   cpre = (pre == 'd') ? 'z' : 'c';
   *cGEMM = ReadMMFileWithPath(cpre, "res", "geAMMRES.sum");
   *cGEK1 = ReadMMFileWithPath(cpre, "res", "geAMMKCLEAN.sum");
   *cSQMM = ReadMMFileWithPath(cpre, "res", "sqAMMRES.sum");
   *cSQK1 = ReadMMFileWithPath(cpre, "res", "sqAMMKCLEAN.sum");
   *cRKMM = ReadMMFileWithPath(cpre, "res", "rkAMMRES.sum");
   *cTRSM = ReadMMFileWithPath(cpre, "res", "tsAMMRES.sum");
   *GEMM = gemm;
   *GEK1 = gek1;
   *SQMM = sqmm;
   *SQK1 = sqk1;
   *RKMM = rkmm;
   *TRSM = trsm;
   return(pre);
}

char *GetVecStr(char pre, int vlen)
{
   if (vlen == 1)
      return("scalar");
   #ifdef ATL_AVX
      if (pre == 'd' || pre == 'z')
      {
         if (vlen == 4)
            return("avx");
         else if (vlen == 2)
            return("sse");
      }
      else if (pre == 's' || pre == 'c')
      {
         if (vlen == 8)
            return("avx");
         else if (vlen == 4)
            return("sse");
      }
   #elif defined(ATL_SSE1)
      #ifdef ATL_SSE2
         if ((pre == 'd' || pre == 'z') && vlen == 2)
               return("sse");
      #endif
      if ((pre == 's' || pre == 'c') && vlen == 4)
         return("sse");
   #endif
/*
 * Any vector length > 1 that isn't one of our known cases uses gnuvec
 */
   return("gvec");
}

void PrintBegBlock(char pre, ATL_mmnode_t *mmb, char *pfx, char *nam, FILE *fp)
{
   ATL_mmnode_t *mp;
   char PRE = toupper(pre);
   int i;

   if (nam)
   {
      if (pfx)
         fprintf(fp,
         "#ifndef ATLAS_%c%sAMM_%s_H\n   #define ATLAS_%c%sAMM_%s_H\n\n",
                 PRE, pfx, nam, PRE, pfx, nam);
      else
         fprintf(fp,"#ifndef ATLAS_%cAMM_%s_H\n   #define ATLAS_%cAMM_%s_H\n\n",
                 PRE, nam, PRE, nam);
      fprintf(fp, "#include \"atlas_amm.h\"\n");
   }
   else
      fprintf(fp, "#ifndef ATLAS_%cAMM_H\n   #define ATLAS_%cAMM_H\n\n",
              PRE, PRE);
/*
 * Count mmb, and print def of NCASES
 */
   for (mp=mmb,i=0; mp; i++, mp = mp->next);
   if (pfx)
      fprintf(fp, "#define ATL_%c%sAMM_NCASES %d\n", pre, pfx, i);
   else if (!nam || strstr(nam, "RANKK") == NULL)
   {
      fprintf(fp, "#ifdef ATL_AMM_NCASES\n");
      fprintf(fp, "   #if ATL_AMM_NCASES != %d\n", i);
      fprintf(fp, "      #error \"NCASES MISMATCH!\"\n");
      fprintf(fp, "   #endif\n");
      fprintf(fp, "#else\n");
      fprintf(fp, "   #define ATL_AMM_NCASES %d\n", i);
      fprintf(fp, "#endif\n");
   }
}

char *GetHName(char pre, char *outd, char *pfx, char *bnam)
{
   int i, NOBASE=0;
   char *fnam;
   if (!bnam)
   {
      NOBASE = 1;
      bnam = "";
   }
   i = strlen(outd) + strlen(bnam) + strlen(pfx) + 16;

   fnam = malloc(i*sizeof(char));
   assert(fnam);
   if (NOBASE)
      sprintf(fnam, "%s/atlas_%c%samm.h", outd, pre, pfx);
   else
      sprintf(fnam, "%s/atlas_%c%samm_%s.h", outd, pre, pfx, bnam);
   return(fnam);
}

FILE *StandHStart(char pre, ATL_mmnode_t *mmb, char *pfx, 
                  char *outd,  char *bnam)
{
   char *fnam;
   FILE *fp;
   int i;

   assert(outd);
   fnam = GetHName(pre, outd, pfx, bnam);
   fp = fopen(fnam, "w");
   assert(fp);
   if (bnam)
   {
      for (i=0; bnam[i]; i++)
         fnam[i] = toupper(bnam[i]);
      fnam[i] = '\0';
      if (strstr(bnam, "perf"))
         PrintBegBlock(pre, mmb, pfx, fnam, fp);
      else
         PrintBegBlock(pre, mmb, NULL, fnam, fp);
   }
   else
      PrintBegBlock(pre, mmb, NULL, NULL, fp);
   free(fnam);
   return(fp);
}

@extract -b @(basd)/atlas.base rout=Mylcm

void GenAmmSum(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *rkb, 
               char *pfx, char *outd)
{
   ATL_mmnode_t *mp, *p66;
   char *fnam;
   FILE *fp;
   char *type = "unsigned short";
   int i, n, maxb, maxNB, maxMB, maxKB, maxkmaj;
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};
   double mfB;

   fp = StandHStart(pre, mmb, pfx, outd, "sum");
   maxkmaj = maxNB = maxKB = maxMB = 0;
   mfB = 0.0;
   for (n=0,mp=mmb; mp; n++, mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         maxkmaj = Mmax(maxkmaj, mp->vlen);
      maxMB = Mmax(maxMB, mp->mbB);
      maxNB = Mmax(maxNB, mp->nbB);
      maxKB = Mmax(maxKB, mp->kbB);
      mfB = Mmax(mfB, mp->mflop[0]);
   }
   if (maxkmaj == 1)
      maxkmaj = 0;
   maxb = Mmax(maxMB, maxNB);
   maxb = Mmax(maxb, maxKB);
   fprintf(fp, "\n#define ATL_AMM_MAXMB %d\n", maxMB);
   fprintf(fp, "#define ATL_AMM_MAXNB %d\n", maxNB);
   fprintf(fp, "#define ATL_AMM_MAXKB %d\n", maxKB);
   fprintf(fp, "#ifndef  ATL_geAMM_MAXKVEC\n", cn);
   fprintf(fp, "   #define ATL_geAMM_MAXKVEC %d\n\n", maxkmaj);
   fprintf(fp, "#endif\n");

   for (mp=mmb; mp && mp->next; mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_AMM_LMU %d\n", mp->mu);
   fprintf(fp, "#define ATL_AMM_LNU %d\n", mp->nu);
   fprintf(fp, "#define ATL_AMM_LKU %d\n", mp->ku);
   fprintf(fp, "#define ATL_AMM_LLCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_LLCMU %d\n\n", 
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
/*
 * Find smallest case achieving 2/3 of maximal performance
 */
   for (i=0,mp=mmb; mp && mp->mflop[0]*1.5 < mfB; i++, mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_AMM_66IDX %d\n", i);
   fprintf(fp, "#define ATL_AMM_66MB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_AMM_66NB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_AMM_66KB %d\n", mp->kbB);
   fprintf(fp, "#define ATL_AMM_66LCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_66LCMU %d\n\n", 
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   fprintf(fp, "#define ATL_AMM_66RATIO %1.4lf\n\n", mp->mflop[0]/mfB);
/*
 * Find smallest case achieving 98% of maximal performance
 */
   for (i=0,mp=mmb; mp && mp->mflop[0] < 0.98*mfB; i++, mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_AMM_98IDX %d\n", i);
   fprintf(fp, "#define ATL_AMM_98MB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_AMM_98NB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_AMM_98KB %d\n", mp->kbB);
   fprintf(fp, "#define ATL_AMM_98LCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_98LCMU %d\n\n", 
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   fprintf(fp, "#define ATL_AMM_98RATIO %1.4lf\n\n", mp->mflop[0]/mfB);
   if (rkb)
   {
      maxkmaj = maxNB = maxKB = maxMB = 0;
      mfB = 0.0;
      for (n=0,mp=rkb; mp; n++, mp = mp->next)
      {
         if (FLAG_IS_SET(mp->flag, MMF_KVEC))
            maxkmaj = Mmax(maxkmaj, mp->vlen);
         maxMB = Mmax(maxMB, mp->mbB);
         maxNB = Mmax(maxNB, mp->nbB);
         maxKB = Mmax(maxKB, mp->kbB);
         mfB = Mmax(mfB, mp->mflop[0]);
      }
      if (maxkmaj == 1)
         maxkmaj = 0;
      fprintf(fp, "#define ATL_rkAMM_LASTMB %d\n", maxMB);
      fprintf(fp, "#define ATL_rkAMM_LASTNB %d\n", maxNB);
      fprintf(fp, "#define ATL_rkAMM_LASTKB %d\n", maxKB);
      fprintf(fp, "#define ATL_MAXKMAJ_RKK %d\n\n", maxkmaj);
/*
 *    Find smallest case achieving 2/3 of maximal performance
 */
      for (i=0,mp=rkb; mp && mp->mflop[0]*1.5 < mfB; i++, mp = mp->next);
      assert(mp);
      fprintf(fp, "#define ATL_66IDX_RKK %d\n", i);
      fprintf(fp, "#define ATL_66NB_RKK %d\n", mp->mbB);
      fprintf(fp, "#define ATL_66MB_RKK %d\n", mp->nbB);
      fprintf(fp, "#define ATL_66KB_RKK %d\n", mp->kbB);
      fprintf(fp, "#define ATL_66RATIO_RKK %1.4lf\n\n", mp->mflop[0]/mfB);
   }
   fprintf(fp, "#define ATL_AMMFLG_KRUNTIME(flg_) ((flg_) & 1)\n");
   fprintf(fp, "#define ATL_AMMFLG_KMAJOR(flg_) ((flg_) & 2)\n");

   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenPerfFile(char pre, ATL_mmnode_t *mmb, char *pfx, char *outd, 
                 double mfMax)
{
   ATL_mmnode_t *mp;
   #define NTHRSH 11
   int THRSH[NTHRSH] = {25, 33, 50, 66, 75, 80, 85, 90, 95, 98, 99};
   int idxT[NTHRSH];
   ATL_mmnode_t *mpT[NTHRSH];
   char *fnam;
   FILE *fp;
   char *type = "float";
   int i, j, n, maxb, maxNB, maxMB, maxKB, idxMax=0;
   const int FNDMAX = (mfMax == 0.0);
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};

   fp = StandHStart(pre, mmb, pfx, outd, "perf");

   if (FNDMAX)
   {
      for (i=0; i < NTHRSH; i++)
         mpT[i] = NULL;
      for (n=0,mp=mmb; mp; n++, mp = mp->next)
      {
         if (mp->mflop[0] > mfMax)
         {
            mfMax = mp->mflop[0];
            idxMax = n;
         }
      }
   }
   else
   {
      for (n=0,mp=mmb; mp; n++, mp = mp->next);
      idxMax = -1;
   }
   fprintf(fp, "#define ATL_%sAMM_DENOM %le /* (%.2f)*/ \n", pfx,
           mfMax, mfMax);
   fprintf(fp, "#define ATL_%sAMM_MAXMFLOPIDX %d\n\n", pfx, idxMax);
   if (FNDMAX)
   {
      for (n=0,mp=mmb; mp; mp = mp->next, n++)
      {
         double mf = mp->mflop[0] / mfMax;
         for (i=0; i < NTHRSH; i++)
         {
            if (!mpT[i] && THRSH[i]*0.01*mfMax < mp->mflop[0])
            {
               mpT[i] = mp;
               idxT[i] = n;
            }
         }
      }
      for (i=0; i < NTHRSH; i++)
      {
         mp = mpT[i];
      @multidef fd
         idxT[i] mp->mbB mp->nbB mp->kbB Mylcm(mp->mu,mp->nu) 
         Mylcm(Mylcm(mp->mu,mp->nu),mp->ku)
      @endmultidef
      @whiledef nm IDX MB NB KB LCMMN LCMU
         fprintf(fp, "#define ATL_AMM_%d@(nm) %d\n", THRSH[i],
                 @(fd));
         @undef fd
      @endwhile
      }
      fprintf(fp, "\n");
   }

   fprintf(fp, "static const float ATL_%sAMM_PERF[%d] =", pfx, n);
   fprintf(fp, "   /* %% of performance of best kernel */\n{\n");
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d */\n", mp->mflop[0]/mfMax,
              (mp->next)?',':' ', j, mp->kbB);
   fprintf(fp, "};\n\n");

   fprintf(fp, "static const float ATL_%sAMM_TIME[%d] =", pfx, n);
   fprintf(fp, "   /* %% of performance of best kernel */\n{\n");
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
      fprintf(fp, "   %e%c  /* IDX=%d, KB=%d */\n", 
              2.0*mp->mbB*mp->nbB*mp->kbB / (mp->mflop[0]*1.0e6),
              (mp->next)?',':' ', j, mp->kbB);
   fprintf(fp, "};\n\n");

   #if 0   /* found no use for this yet, so don't waste mem wt it */
   fprintf(fp, "static const float ATL_AMM_SPDUPNXT[%d] =", n);
   fprintf(fp, "   /* speedup of next higher NB */\n{\n");
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      double mf = (mp->next) ? mp->next->mflop[0] : mp->mflop[0];
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d vs. %d */\n", mf/mp->mflop[0],
              (mp->next)?',':' ', j, mp->kbB, mp->next?mp->next->kbB:mp->kbB);
   }
   fprintf(fp, "};\n\n");
   #endif

   fprintf(fp, "#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenBlockingFile(char pre, ATL_mmnode_t *mmb, char *pfx, char *outd)
{
   ATL_mmnode_t *mp;
   char *fnam;
   FILE *fp;
   char *type = "unsigned short";
   int i, n, maxb, maxNB, maxMB, maxKB, maxkmaj;
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};

   fp = StandHStart(pre, mmb, pfx, outd, "blk");
   maxkmaj = maxNB = maxKB = maxMB = 0;
   for (n=0,mp=mmb; mp; n++, mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         maxkmaj = Mmax(maxkmaj, mp->vlen);
      maxMB = Mmax(maxMB, mp->mbB);
      maxNB = Mmax(maxNB, mp->nbB);
      maxKB = Mmax(maxKB, mp->kbB);
   }
   if (maxkmaj == 1)
      maxkmaj = 0;
   maxb = Mmax(maxMB, maxNB);
   maxb = Mmax(maxb, maxKB);
   fprintf(fp, "#define ATL_AMM_MAXMB %d\n", maxMB);
   fprintf(fp, "#define ATL_AMM_MAXNB %d\n", maxNB);
   fprintf(fp, "#define ATL_AMM_MAXKB %d\n", maxKB);
   fprintf(fp, "#ifndef  ATL_AMM_MAXKVEC\n", cn);
   fprintf(fp, "   #define ATL_AMM_MAXKVEC %d\n", maxkmaj);
   fprintf(fp, "#endif\n");
   fprintf(fp, "\n");

   if (maxb <= 255)
      type = "unsigned char";
   for (i=0; i < 3; i++)
   {
      int j;
      fprintf(fp, "static const %s ATL_AMM_%cBs[%d] =\n{\n", 
              type, bc[i], n);
      for (j=0,mp=mmb; mp; j++,mp = mp->next)
      {
         int b;
         if (bc[i] == 'M')
            b = mp->mbB;
         else if (bc[i] == 'N')
            b = mp->nbB;
         else if (bc[i] == 'K')
            b = mp->kbB;
         if (mp->next)
            fprintf(fp, "%8d,  /* index %d */\n", b, j);
         else
            fprintf(fp, "%8d   /* index %d */\n", b, j);
      }
      fprintf(fp, "};\n\n");
   }
   for (i=0; i < 3; i++)
   {
      int j;
      fprintf(fp, "static const %s ATL_AMM_%cUs[%d] =\n{\n", 
              type, bc[i], n);
      for (j=0,mp=mmb; mp; j++,mp = mp->next)
      {
         int b;
         if (bc[i] == 'M')
            b = mp->mu;
         else if (bc[i] == 'N')
            b = mp->nu;
         else if (bc[i] == 'K')
         {
            if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
               b = mp->ku;
            else
               b = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->ku : mp->kbB;
         }
         if (mp->next)
            fprintf(fp, "%8d,  /* index %d */\n", b, j);
         else
            fprintf(fp, "%8d   /* index %d */\n", b, j);
      }
      fprintf(fp, "};\n\n");
   }
   fprintf(fp, "static const %s ATL_AMM_KBMINs[%d] =\n{\n", type, n);
   for (i=0,mp=mmb; mp; i++,mp = mp->next)
   {
      if (mp->next)
         fprintf(fp, "%8d,  /* index %d */\n", mp->kbmin, i);
      else
         fprintf(fp, "%8d   /* index %d */\n", mp->kbmin, i);
   }
   fprintf(fp, "};\n\n");
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenFlagH(char pre, ATL_mmnode_t *mmb, char *pfx, char *outd)
{
   FILE *fp;
   int j, n;
   ATL_mmnode_t *mp;

   fp = StandHStart(pre, mmb, pfx, outd, "flag");

   for (n=0,mp=mmb; mp; n++,mp = mp->next);

   fprintf(fp, "static const unsigned char ATL_AMM_KFLAG[%d] =\n{\n", n);
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      unsigned char flag=FLAG_IS_SET(mp->flag, MMF_KRUNTIME) ? 1 : 0;
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         flag |= 2;
      if (mp->next)
         fprintf(fp, "%6d,  /* index %d */\n", flag, j);
      else
         fprintf(fp, "%6d   /* index %d */\n", flag, j);
   }
   fprintf(fp, "};\n\n");
   fprintf(fp, "#define ATL_AMM_KRUNTIME(idx_) (ATL_AMM_KFLAG[idx_] & 1)\n");
   fprintf(fp, "#define ATL_AMM_KMAJOR(idx_) (ATL_AMM_KFLAG[idx_] & 2)\n");
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void SpewForthC2MProto(char pre, FILE *fp0, FILE *fp1, int mu, int nu)
{
   char ac[3] = {'1', 'n', 'X'};
   char bc[4] = {'0', '1', 'n', 'X'};
   int ia, ib;
   for (ia=0; ia < 3; ia ++)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp0, "void ATL_%cablk2cmat_%dx%d_a%c_b%c\n", 
                 pre, mu, nu, ac[ia], bc[ib]);
         if (pre == 'z' || pre == 'c')
            fprintf(fp0, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         else
            fprintf(fp0, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         fprintf(fp1, "void ATL_%ccmat2ablk_%dx%d_a%c_b%c\n", 
                 pre, mu, nu, ac[ia], bc[ib]);
         if (pre == 'z' || pre == 'c')
            fprintf(fp1, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,const SCALAR,TYPE*,TYPE*);\n");
         else
            fprintf(fp1, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,const SCALAR,TYPE*);\n");
      }
   }
}

void SpewForthC2BDecl(char pre, ATL_mmnode_t *mmb, FILE *fp, char *rt, 
                      char alp, char bet)
{
   ATL_mmnode_t *mp;
   int j;

   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      fprintf(fp, "   ATL_%c%s_%dx%d_a%c_b%c", 
              pre, rt, mp->mu,mp->nu, alp, bet);
      if (mp->next)
         fprintf(fp, ",  /* index %d */\n", j);
      else
         fprintf(fp, "   /* index %d */\n", j);
      }
      fprintf(fp, "};\n\n");
}

void GenC2BLK(char pre, ATL_mmnode_t *mmb, char *pfx, char *outd)
{
   FILE *fp0, *fp1;
   ATL_mmnode_t *mp;
   int ia, ib;
   char ac[3] = {'1', 'n', 'X'};
   char bc[4] = {'0', '1', 'n', 'X'};
   char *fnam;

   fp0 = StandHStart(pre, mmb, pfx, outd, "ablk2cmat");
   fp1 = StandHStart(pre, mmb, pfx, outd, "cmat2ablk");
   fprintf(fp0, "\n");
   fprintf(fp1, "\n");
/*
 * Crank out prototypes
 */
   SpewForthC2MProto(pre, fp0, fp1, mmb->mu, mmb->nu);
   for (mp=mmb->next; mp; mp = mp->next)
   {
      ATL_mmnode_t *p;
      const int mu=mp->mu, nu=mp->nu;
      for (p=mmb; p->mu != mu || p->nu != nu; p = p->next);
      if (p == mp)  /* first occurance of this mu,nu pair */
         SpewForthC2MProto(pre, fp0, fp1, mp->mu, mp->nu);
   }
   fprintf(fp0, "\n");
   fprintf(fp1, "\n");
/*
 * Now, crank out funcptr arrays
 */
   for (ia=0; ia < 3; ia ++)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp0, 
            "static const ablk2cmat_t ATL_AMM_BLK2C_a%c_b%c[ATL_AMM_NCASES] =\n{\n",
                 ac[ia], bc[ib]);
         SpewForthC2BDecl(pre, mmb, fp0, "ablk2cmat", ac[ia], bc[ib]);
         fprintf(fp1, 
            "static const cmat2ablk_t ATL_AMM_C2BLK_a%c_b%c[ATL_AMM_NCASES] =\n{\n",
                 ac[ia], bc[ib]);
         SpewForthC2BDecl(pre, mmb, fp1, "cmat2ablk", ac[ia], bc[ib]);
      }
   }
   fprintf(fp0, "\n#endif  /* end include file guard */\n");
   fclose(fp0);
   fprintf(fp1, "\n#endif  /* end include file guard */\n");
   fclose(fp1);
}

void SpewForthRevCpProto(char pre, FILE *fp, char alp, int u, int kmaj)
{
   const int G = (pre == 'c' || pre == 'z') ? 2 : 1;
   const char *cst[2] = {"", "C"};
   int g;

   for (g=0; g < G; g++)
   {
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cam2cm_a%c_%dx%d%s\n",
                 pre, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cam2cm_a%c_%d%s\n",pre, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*,const TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*);\n");
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cam2rm_a%c_%dx%d%s\n",
                 pre, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cam2rm_a%c_%d%s\n",pre, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*,const TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*);\n");
   }
}

void SpewForthCpProto(char pre, FILE *fp, char alp, int u, int kmaj)
{
   const int G = (pre == 'c' || pre == 'z') ? 2 : 1;
   const char *cst[2] = {"", "C"};
   int g;

   for (g=0; g < G; g++)
   {
      if (kmaj > 1)
         fprintf(fp, "void ATL_%ccm2am_a%c_%dx%d%s\n", 
                 pre, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%ccm2am_a%c_%d%s\n", pre, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp,
    "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*);\n");
      if (kmaj > 1)
         fprintf(fp, "void ATL_%crm2am_a%c_%dx%d%s\n", 
                 pre, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%crm2am_a%c_%d%s\n", pre, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp,
     "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*);\n");
   }
}

void SpewForthCpConjDecl(char pre, int REVERSE, ATL_mmnode_t *mmb, FILE *fp, 
                         char *arr, char *rt, char alp, int u)
{
   ATL_mmnode_t *mp;
   int j;

   fprintf(fp, "static const %s_t %s_a%c[%d] =\n{\n",
           REVERSE?"am2cm":"cm2am", arr, alp,  ATL_CountNumberOfMMNodes(mmb));
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (kmaj > 1)
         fprintf(fp, "   ATL_%c%s_a%c_%dx%dC", pre, rt, alp, kmaj, 
                 u?mp->mu:mp->nu);
      else
         fprintf(fp, "   ATL_%c%s_a%c_%dC", pre, rt, alp, u?mp->mu:mp->nu);
      if (mp->next)
         fprintf(fp, ",");
      else
         fprintf(fp, " ");
      fprintf(fp, "  /* index %d */\n", j);
   }
   fprintf(fp, "};\n\n");
}

void SpewForthCpDecl(char pre, int REVERSE, ATL_mmnode_t *mmb, FILE *fp, 
                     char *arr, char *rt, char alp, int u)
{
   ATL_mmnode_t *mp;
   int j;

   fprintf(fp, "static const %s_t %s_a%c[%d] =\n{\n", 
           REVERSE?"am2cm":"cm2am", arr, alp, ATL_CountNumberOfMMNodes(mmb));
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (kmaj > 1)
         fprintf(fp, "   ATL_%c%s_a%c_%dx%d", pre, rt, alp, kmaj, 
                 u?mp->mu:mp->nu);
      else
         fprintf(fp, "   ATL_%c%s_a%c_%d", pre, rt, alp, u?mp->mu:mp->nu);
      if (mp->next)
         fprintf(fp, ",");
      else
         fprintf(fp, " ");
      fprintf(fp, "  /* index %d */\n", j);
   }
   fprintf(fp, "};\n\n");
}


@define len @23@
void GenAMAJ2CMAJ(char pre, ATL_mmnode_t *mmb, char *suff, char *outd)
/*
 * 3. atlas_<pre>amm_am2cm_a[1,X,n]: 
 *    defines: ATL_AMM_NCASES
 *    prototypes all am2rm & am2cm routines
 *    1 indexible array giving which to use for each block factor
 */
{
   char ac[3] = {'1', 'n', 'X'};
   int ia, j;
   char *fnam, *sp, *np;
   ATL_mmnode_t *mp;

   if (!suff)
      suff = "";
   ia = strlen(outd) + strlen(suff) + @(len);
   fnam = malloc(ia*sizeof(char));
   assert(fnam);
   sprintf(fnam, "%s/atlas_%c%samm_am2cm_a1.h", outd, pre, suff);
   np = fnam+ia-23+12;
   assert(*np == 'a' && np[1] == 'm');
   sp = fnam+ia-4;
   assert(*sp == '1');

   for (ia=0; ia < 3; ia++)
   {
      char *rt[2] = {"am2cm", "am2rm"};
      FILE *fp;
      int kmaj = FLAG_IS_SET(mmb->flag, MMF_KVEC) ? mmb->vlen:0;

      if (kmaj == 1)
         kmaj = 0;
      *sp = ac[ia];
      fp = fopen(fnam, "w");
      assert(fp);
      sp[1] = '\0';
      PrintBegBlock(pre, mmb, NULL, np, fp);
      sp[1] = '.';
      fprintf(fp, "/*\n * mat2blk prototypes\n */\n");
      SpewForthRevCpProto(pre, fp, ac[ia], mmb->mu, kmaj);
      if (mmb->nu != mmb->mu || kmaj > 1)
         SpewForthRevCpProto(pre, fp, ac[ia], mmb->nu, kmaj);
      for (mp=mmb->next; mp; mp = mp->next)
      {
         ATL_mmnode_t *p;
         int mu = mp->mu, nu = mp->nu;
         int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if (mu == p->mu && km == kmaj)
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthRevCpProto(pre, fp, ac[ia], mu, kmaj);
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if ((p->nu == nu && km == kmaj) || 
                (km == kmaj && p->mu == nu))
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthRevCpProto(pre, fp, ac[ia], nu, kmaj);
      }
      fprintf(fp, "\n");
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_AMM_BLK2A", "am2cm", ac[ia], 1);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_AMM_BLK2AT", "am2rm", ac[ia], 1);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_AMM_BLK2B", "am2cm", ac[ia], 0);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_AMM_BLK2BT", "am2rm", ac[ia], 0);
      if (pre == 'c' || pre == 'z')
      {
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_AMM_BLKC2A", 
                             "am2cm", ac[ia], 1);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_AMM_BLKH2A", 
                             "am2rm", ac[ia], 1);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_AMM_BLKC2B", 
                             "am2cm", ac[ia], 0);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_AMM_BLKH2B", 
                             "am2rm", ac[ia], 0);
      }
      fprintf(fp, "\n#endif  /* end include file guard */\n");
      fclose(fp);
   }
   free(fnam);
}
void GenCMAJ2AMAJ(char pre, ATL_mmnode_t *mmb, char *pfx, char *outd)
/*
 * 3. atlas_<pre>amm_cm2am_a[1,X,n]: 
 *    defines: ATL_AMM_NCASES
 *    prototypes all rm2am & cm2am routines
 *    1 indexible array giving which to use for each block factor
 */
{
   char ac[3] = {'1', 'n', 'X'};
   int ia, j;
   char *fnam, *sp, *np;
   ATL_mmnode_t *mp;

   ia = strlen(outd) + strlen(pfx) + @(len);
   fnam = malloc(ia*sizeof(char));
   assert(fnam);
   sprintf(fnam, "%s/atlas_%c%samm_cm2am_a1.h", outd, pre, pfx);
   np = fnam+ia-23+12;
   assert(*np == 'c' && np[1] == 'm');
   sp = fnam+ia-4;
   assert(*sp == '1');

   for (ia=0; ia < 3; ia++)
   {
      char *rt[2] = {"cm2am", "rm2am"};
      FILE *fp;
      int kmaj = FLAG_IS_SET(mmb->flag, MMF_KVEC) ? mmb->vlen:0;

      if (kmaj == 1)
         kmaj = 0;
      *sp = ac[ia];
      fp = fopen(fnam, "w");
      assert(fp);
      sp[1] = '\0';
      PrintBegBlock(pre, mmb, NULL, np, fp);
      sp[1] = '.';
      fprintf(fp, "/*\n * mat2blk prototypes\n */\n");
      SpewForthCpProto(pre, fp, ac[ia], mmb->mu, kmaj);
      if (mmb->nu != mmb->mu || kmaj > 1)
         SpewForthCpProto(pre, fp, ac[ia], mmb->nu, kmaj);
      for (mp=mmb->next; mp; mp = mp->next)
      {
         ATL_mmnode_t *p;
         int mu = mp->mu, nu = mp->nu;
         int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if (mu == p->mu && km == kmaj)
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthCpProto(pre, fp, ac[ia], mu, kmaj);
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if ((p->nu == nu && km == kmaj) || 
                (km == kmaj && p->mu == nu))
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthCpProto(pre, fp, ac[ia], nu, kmaj);
      }
      fprintf(fp, "\n");
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_AMM_AN2BLK", "cm2am", ac[ia], 1);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_AMM_AT2BLK", "rm2am", ac[ia], 1);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_AMM_BN2BLK", "cm2am", ac[ia], 0);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_AMM_BT2BLK", "rm2am", ac[ia], 0);
      if (pre == 'c' || pre == 'z')
      {
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_AMM_AC2BLK", 
                             "cm2am", ac[ia], 1);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_AMM_AH2BLK", 
                             "rm2am", ac[ia], 1);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_AMM_BC2BLK", 
                             "cm2am", ac[ia], 0);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_AMM_BH2BLK", 
                             "rm2am", ac[ia], 0);
      }
      fprintf(fp, "\n#endif  /* end include file guard */\n");
      fclose(fp);
   }
   free(fnam);
}

int KernelIsExactSame(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same including KB, 0 otherwise
 */
{
/*
 * Kernels aren't the same if one is being compiled with specific KB,
 * and the other has runtime
 */
   if (FLAG_IS_SET(p0->flag, MMF_KRUNTIME) != 
       FLAG_IS_SET(p1->flag, MMF_KRUNTIME))
      return(0);
   if (!FLAG_IS_SET(p0->flag, MMF_KRUNTIME) && (p0->kbB != p1->kbB))
      return(0);
/*
 * Kernels aren't same if their vectorization strategy is different
 */
   if (FLAG_IS_SET(p0->flag, MMF_KVEC) != FLAG_IS_SET(p1->flag, MMF_KVEC))
      return(0);
   if (p0->vlen != p1->vlen)
      return(0);
/*
 * Kernels aren't same if the -DATL_MOVE bits don't match
 */
   if (ATL_MMF_MVGET(p0->flag) != ATL_MMF_MVGET(p1->flag))
      return(0);
/*
 * Two generated kernels are the same if mu,nu,kmaj,ku,VLEN,flag are the same.
 * NOTE: if we make generator handle muladd, etc, MUST UPDATE HERE!!!
 */
   if (p0->ID == 0 && p1->ID == 0)
      return(p0->mu == p1->mu && p0->nu == p1->nu && p0->ku == p1->ku && 
             p0->vlen == p1->vlen && p0->flag == p1->flag);
/*
 * If both are user kernels, then they may be repeats.  For user kernels,
 * they are the same if both ID and flag match, else they are not.
 */
   else if (p0->ID > 0 && p1->ID > 0)
      return(p0->ID == p1->ID && p0->flag == p1->flag);
   return(0);  /* Can't be the same if above criteria fails */
}

/*
 * RETURNS: flags that necessitate recompilation, not including KRUNTIME,
 * which is encoded in kb
 */
int GetCompTimeFlags(ATL_mmnode_t *mp)
{
   int iflg;
   iflg = ATL_MMF_MVGET(mp->flag);  /* MVbits change kern at comp time */
   iflg |=  (((mp->flag) & 1)<<3);  /* LDTOP/BOT could be compile-time dec */
   if (FLAG_IS_SET(mp->flag, MMF_KVEC))
      iflg |= 1<<4;
   return(iflg);
}

void FillInGenStrings
(
   char pre,
   ATL_mmnode_t *mmb,  /* queue to look through */
   char *dir           /* output directory to generate into */
)
/*
 * Creates GenString for any ID=0 in mmb
 */
{
   ATL_mmnode_t *mp;

   if (pre == 'z')
      pre = 'd';
   else if (pre == 'c')
      pre = 's';

   for (mp=mmb; mp; mp = mp->next)
   {
      if (mp->ID == 0)  /* is generated file */
      {
         int lr, ld;
         char *sp, *sp0=mp->rout;

         assert(sp0);  /* should have been filled in by search */
         lr = strlen(sp0);
         ld = strlen(dir);
         sp = malloc(ld+ld+2);
         assert(sp);
         strncpy(sp, dir, ld);
         sp[ld] = '/';
         strcpy(sp+ld+1, sp0);
         mp->rout = sp;
         mp->genstr = MMGetGenString(pre, mp);
         mp->rout = sp0;
         free(sp);
      }
   }
}

int ExactKernelInList(ATL_mmnode_t *mmb, ATL_mmnode_t *p)
/*
 * RETURNS: 1 if p is duplicated in mmb, else 0
 */
{
   ATL_mmnode_t *mp;
   if (!p || !mmb)
      return(0);
   for (mp=mmb; mp; mp = mp->next)
      if (KernelIsExactSame(mp, p))
         return(1);
    return(0);
}

void SpewForthKernProto(FILE *fp, char pre, char *nm, ATL_mmnode_t *p, char bc)
{
   fprintf(fp, "void ATL_%c%s_%d_%d_%x_%dx%dx%d_b%c\n", pre, nm, p->ID, 
           FLAG_IS_SET(p->flag, MMF_KRUNTIME)?0:p->kbB, GetCompTimeFlags(p),
           p->mu, p->nu, p->ku,bc);
   fprintf(fp, 
      "   (ATL_CSZT,ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,TYPE*,\n");
   fprintf(fp, 
      "    const TYPE*,const TYPE*,const TYPE*);\n");
}

void SpewForthKernProtos(FILE *fp, char pre, char *nm, ATL_mmnode_t *mmb, 
                         int nbet)
{
   ATL_mmnode_t *mp;
   for (mp=mmb; mp; mp = mp->next)
   {
      char bc[3] = {'0', '1', 'n'};  /* 0 must come first */
      int ib;
      for (ib=0; ib < nbet; ib++)
         SpewForthKernProto(fp, pre, nm, mp, bc[ib]);
   }
}

void SpewForthKernArray(FILE *fp, char pre, ATL_mmnode_t *mmb, 
                        char *vnam, char cbet)
{
   ATL_mmnode_t *mp;
   int n;
   char *nm = (vnam[5] == 'R' && vnam[6] == 'K') ? "AMRK":"AMMM";

   for (n=0,mp=mmb; mp; n++, mp = mp->next);
   fprintf(fp, "static const ammkern_t ATL_AMM_%s[%d] =\n", vnam, n);
   fprintf(fp, "{\n");
   for (mp=mmb; mp; mp = mp->next)
   {
      fprintf(fp, "   ATL_%c%s_%d_%d_%x_%dx%dx%d_b%c", pre, nm, mp->ID, 
              FLAG_IS_SET(mp->flag, MMF_KRUNTIME)?0:mp->kbB, 
              GetCompTimeFlags(mp), mp->mu, mp->nu, mp->ku, cbet);
      if (mp->next)
         fprintf(fp, ",\n");
   }
   fprintf(fp, "\n};\n\n");
}

/*
 * RETURNS: new list of K-cleanup kernels for mmb taken from mmk; 
 * mmb & mmk not changed
 */
ATL_mmnode_t *GetUniqueK1Kerns
(
   char pre,            /* z,c,d,s */
   ATL_mmnode_t *mmb,   /* list of kernels requiring K-cleanup */
   ATL_mmnode_t *mmk,   /* list of K-cleanup kernels */
   char *outd
)
{
   ATL_mmnode_t *kcb=NULL, *prev, *mp;
   for (mp=mmb; mp; mp = mp->next)
   {
      ATL_mmnode_t *kc;
      int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      for (kc=mmk; kc; kc = kc->next) /* search for matching cleanup routine */
      {
         int km = FLAG_IS_SET(kc->flag, MMF_KVEC) ? kc->vlen:0;
         if (kc->mu == mp->mu && kc->nu == mp->nu && km == kmaj)
            break;
      }
      if (!kc)  /* cleanup routine must be in original list! */
      {
         if (mp->ku == 1 && FLAG_IS_SET(mp->flag, MMF_KRUNTIME) &&
             (!mp->kbmin || mp->kbmin == 1))
            kc = mp;
         else
         {
            for (kc=mmb; kc; kc = kc->next)
            {
               int km = FLAG_IS_SET(kc->flag, MMF_KVEC) ? kc->vlen:0;
               if (kc->mu == mp->mu && kc->nu == mp->nu && km == kmaj
                   && kc->ku == 1 && FLAG_IS_SET(kc->flag, MMF_KRUNTIME) &&
                   (!kc->kbmin || kc->kbmin == 1) && 
                   (!kc->kbmax || kc->kbmax >= mp->kbB))
                  break;
            }
            assert(kc);
         }
      }
      assert(kc);
      kc = CloneMMNode(kc);
      kc->mbB = mp->mbB;
      kc->nbB = mp->nbB;
      kc->kbB = mp->kbB;
      if (kcb)
      {
         prev->next = kc;
         prev = prev->next;
      }
      else
         prev = kcb = kc;
      
   }
   FillInGenStrings(pre, kcb, outd);
   return(kcb);
}

/*
 * RETURNS: possibly updated list of all unique mu/nu comboes
 */
typedef struct mnur mnur_t;
struct mnur {int mu; int nu; int kmaj; mnur_t *next;};
mnur_t *GetUniqueMNUnrolls(ATL_mmnode_t *mmb, mnur_t *urb)
{
   ATL_mmnode_t *mp;
   mnur_t *up;
/*
 * For each node in mmb, add to urb if mu/nu combo not already there
 * kmaj only affects A/B copy, and this is for C put, so ignore kmaj
 */
   for (mp = mmb; mp; mp = mp->next)
   {
      for (up=urb; up; up = up->next)
         if (mp->mu == up->mu && mp->nu == up->nu)
            break;
      if (!up)
      {
         up = malloc(sizeof(mnur_t));
         assert(up);
         up->mu = mp->mu;
         up->nu = mp->nu;
         up->kmaj = 0;
         up->next = urb;
         urb = up;
      }
   }
   return(urb);
}

/*
 * RETURNS: list of just unique MUs from mnb not already in mub
 */
mnur_t *GetUniqueMUnrolls(ATL_mmnode_t *mnb, mnur_t *mub)
{
   mnur_t *mup;
   ATL_mmnode_t *mnp;
   if (!mnb)
      return(mub);
   for (mnp=mnb; mnp; mnp = mnp->next)
   {
      const int kmaj = FLAG_IS_SET(mnp->flag, MMF_KVEC) ? mnp->vlen:0;
      for (mup=mub; mup; mup = mup->next)
         if (mup->mu == mnp->mu && mup->kmaj == kmaj)
            break;
      if (!mup)  /* a new mu */
      {
         mup = malloc(sizeof(mnur_t));
         assert(mup);
         mup->nu = mup->mu = mnp->mu;
         mup->next = mub;
         mup->kmaj = kmaj;
         mub = mup;
      }
   }
   return(mub);
}
/*
 * RETURNS: list of just unique NUs from mnb not already in mub
 */
mnur_t *GetUniqueNUnrolls(ATL_mmnode_t *mnb, mnur_t *mub)
{
   mnur_t *mup;
   ATL_mmnode_t *mnp;
   if (!mnb)
      return(mub);
   for (mnp=mnb; mnp; mnp = mnp->next)
   {
      const int kmaj = FLAG_IS_SET(mnp->flag, MMF_KVEC) ? mnp->vlen:0;
      for (mup=mub; mup; mup = mup->next)
         if (mup->mu == mnp->nu && kmaj == mup->kmaj)
            break;
      if (!mup)  /* a new nu */
      {
         mup = malloc(sizeof(mnur_t));
         assert(mup);
         mup->nu = mup->mu = mnp->nu;
         mup->next = mub;
         mup->kmaj = kmaj;
         mub = mup;
      }
   }
   return(mub);
}

void KillUnrollList(mnur_t *b)
{
   mnur_t *p;
   while (b)
   {
      p = b->next;
      free(b);
      b = p;
   }
}

int MMKernsSame1(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same except for blocking, 0 otherwise
 */
{
/*
 * Kernels aren't the same if one is being compiled with specific KB,
 * and the other has runtime
 */
   if (FLAG_IS_SET(p0->flag, MMF_KRUNTIME) != 
       FLAG_IS_SET(p1->flag, MMF_KRUNTIME))
      return(0);
/*
 * Two generated kernels are the same if mu,nu,ku,VLEN,flag are the same.
 * NOTE: if we make generator handle muladd, etc, MUST UPDATE HERE!!!
 */
   if (p0->ID == 0 && p1->ID == 0)
      return(p0->mu == p1->mu && p0->nu == p1->nu && p0->ku == p1->ku &&
             p0->vlen == p1->vlen && p0->flag == p1->flag);
/*
 * If both are user kernels, then they may be repeats.  For user kernels,
 * they are the same if both ID and flag match, else they are not.
 */
   else if (p0->ID > 0 && p1->ID > 0)
      return(p0->ID == p1->ID && p0->flag == p1->flag);
   return(0);  /* Can't be the same if above criteria fails */
}

@beginskip
/*
 * This routine spits out the timing estimate for doing a muXnuXku portion
 * of the computation.  It is a wild estimate, in that assumes you are
 * using mbBxnbBxkbB blocking used during timings, but it's better than nothing.
 * Note we have a MFLOP measure, and mf = 2*M*N*K / (1e6*time)
 * so time = 2*M*N*K / (1e6*mf), which is time for full GEMM, so
 * time / M*N*K is time for 1 K iteration, or t1 = 2 / (1.e6*mf), which we
 * then multiply by mu*nu*ku to get t2 = 2*mu*nu*ku /1.e6*mf, which is the
 * time to do one unrolled iteration of the ku loop (the building block of
 * all usage of this kernel).  For k-major storage, total time can be
 * estimated at:
 *   T = CEIL(M/mu)*CEIL(N/nu)*CEIL(K/ku)*t3
 * For M-major storage it would instead be:
 *   T = CEIL(M/mu) * CEIL(N/nu) * (FLOOR(K/ku)*t3 + K%ku*t3_K1)
 * where t3_K1 is the t3 mentioned above for the KU=1 K-cleanup kernel.
 */
void SpewTimeEst
(
   ATL_mmnode_t *mmb,  /* baseptr  of AMMM kernel queue */
   char *arrnam,       /* name of array to create */
   FILE *fpout,        /* open file stream to print array to */
   int imf             /* which mflop elt to use for timing */
)
{
}
@endskip

void GenRankKH
(
   char pre, 
   ATL_mmnode_t *geb,  /* baseptr  of gemm kernels */
   ATL_mmnode_t *rkb,  /* rank-K kernels, one for each supported K */
   char *outd
)
{
   FILE *fp;
   mnur_t *putb, *cpyb, *up;
   ATL_mmnode_t *mp;
   int m, n, k;
   int ia, ib;
   char PRE = pre;
   char ac[3] =  {'1', 'n', 'X'};
   char bc[4] = {'1', 'n', '0', 'X'};
   if (pre == 'c')
      pre = 's';
   else  if (pre == 'z')
      pre = 'd';

   assert(geb && rkb);
   fp = StandHStart(PRE, rkb, "rk", outd, "kern");
   fprintf(fp, "\n");

   for (mp=geb; mp->next; mp = mp->next);
   fprintf(fp, "#define ATL_rkAMM_LASTMB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_rkAMM_LASTNB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_rkAMM_LASTKB %d\n\n", mp->kbB);
/*
 * Prototype needed copy routines
 */
   putb = GetUniqueMNUnrolls(rkb, NULL);
   fprintf(fp, "/*\n * cblk2mat put function prototypes\n */\n");
   for (up=putb; up; up = up->next)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp, "void ATL_%cablk2cmat_%dx%d_a1_b%c\n", 
                 PRE, up->mu, up->nu, bc[ib]);
         if (PRE == 'c' || PRE == 'z')
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         else
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
      }
   }
   KillUnrollList(putb);
   fprintf(fp, 
      "/*\n * Column-major to access-major copy function prototypes\n */\n");
   cpyb = GetUniqueMUnrolls(rkb, NULL);
   cpyb = GetUniqueNUnrolls(rkb, cpyb);
   for (up=cpyb; up; up = up->next)
   {
      for (ia=0; ia < 3; ia++)
         SpewForthCpProto(PRE, fp, ac[ia], up->mu, up->kmaj);
   }
   KillUnrollList(cpyb);
/*
 * Prototype the rank-K functions
 */
   fprintf(fp, "/*\n * rank-K AMMM kernel prototypes\n */\n");
   for (mp=rkb; mp; mp = mp->next)
   {
/*
 *    For runtime-K kernels, only prototype 1st time they are seen in list
 */
      if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
      {
         ATL_mmnode_t *p;
         if (mp->ID > 0)
         {
            for (p=rkb; p != mp; p = p->next)
               if (p->ID == mp->ID)
                  break;
         }
         else
         {
            for (p=rkb; p != mp; p = p->next)
               if (MMKernsSame(mp, p))
                  break;
         }
         if (mp == p)
         {
            SpewForthKernProto(fp, pre, "AMRK", mp, '0');
            SpewForthKernProto(fp, pre, "AMRK", mp, '1');
            SpewForthKernProto(fp, pre, "AMRK", mp, 'n');
         }
      }
/*
 *    compile-time-K kernels get prototyped for each invocation
 */
      else
      {
         SpewForthKernProto(fp, pre, "AMRK", mp, '0');
         SpewForthKernProto(fp, pre, "AMRK", mp, '1');
         SpewForthKernProto(fp, pre, "AMRK", mp, 'n');
      }
   }
/*
 * Now, crank out funcptr arrays
 */
   for (ib=0; ib < 4; ib++)
   {
      fprintf(fp,
         "\nstatic const ablk2cmat_t ATL_AMM_BLK2C_a1_b%c[%d] =\n{\n",
              bc[ib], ATL_CountNumberOfMMNodes(rkb));
      SpewForthC2BDecl(PRE, rkb, fp, "ablk2cmat", '1', bc[ib]);
   }
   for (ia=0; ia < 3; ia++)
   {
      fprintf(fp, "\n");
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_AN2BLK", "cm2am", ac[ia], 1);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_AT2BLK", "rm2am", ac[ia], 1);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_BN2BLK", "cm2am", ac[ia], 0);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_BT2BLK", "rm2am", ac[ia], 0);
      if (PRE == 'z' || PRE == 'c')
      {
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_AC2BLK", "cm2am",ac[ia],1);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_AH2BLK", "rm2am",ac[ia],1);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_BC2BLK", "cm2am",ac[ia],0);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_BH2BLK", "rm2am",ac[ia],0);
      }
   }
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK", '0');
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK_b1", '1');
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK_bn", 'n');
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenKernH
(
   char pre, 
   char *outd, 
   char *pfx, 
   ATL_mmnode_t *mmb,  /* full kerns */
   ATL_mmnode_t *k1b   /* K cleanup kerns */
)
/*
 * 5. atlas_<pre>_<pfx>kern.h
 *    defines: ATL_AMM_NCASES
 *    prototypes all kernels, including K-cleanup
 *    1 indexible array gives kernel to use for each case as func ptr
 *    1 indexible array gives K-clean kernel
 */
{
   FILE *fp;
   ATL_mmnode_t *ukb;
   const char upr = (pre == 'z' || pre == 'd') ? 'd' : 's';

   fp = StandHStart(pre, mmb, pfx, outd, "kern");
   fprintf(fp, "\n");
/*
 * For prototyping, create a list of all full and cleanup kerns, and get
 * rid of duplicates
 */
   ukb = AddUniqueMMKernCompList(NULL, mmb);
   ukb = AddUniqueMMKernCompList(ukb, k1b);
   SpewForthKernProtos(fp, upr, "AMMM", ukb, 3);
   fprintf(fp, "\n");
   KillAllMMNodes(ukb);
/*
 * Dump out kernel ptr arrays
 */
   SpewForthKernArray(fp, upr, mmb, "KERN_b0", '0');
   SpewForthKernArray(fp, upr, mmb, "KERN_b1", '1');
   SpewForthKernArray(fp, upr, mmb, "KERN_bn", 'n');
   if (k1b)
   {
      SpewForthKernArray(fp, upr, k1b, "KERN_K1", '0');
      SpewForthKernArray(fp, upr, k1b, "KERN_K1_b1", '1');
      SpewForthKernArray(fp, upr, k1b, "KERN_K1_bn", 'n');
   }

   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenCmplxHeaders(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *rkb, 
                     char *pfx, char *outd)
{
@skip   GenAMAJ2CMAJ(pre, mmb, pfx, outd);
   GenCMAJ2AMAJ(pre, mmb, pfx, outd);
   GenC2BLK(pre, mmb, pfx, outd);
   if (rkb)
   {
@skip      GenAMAJ2CMAJ(pre, mmb, pfx, outd);
      GenCMAJ2AMAJ(pre, rkb, "rk", outd);
      GenC2BLK(pre, rkb, "rk", outd);
      GenRankKH(pre, mmb, rkb, outd);
   }
}

void GenHeaderFiles(char pre, char *outd, 
                    ATL_mmnode_t *geb, ATL_mmnode_t *gek1b,
                    ATL_mmnode_t *sqb, ATL_mmnode_t *sqk1b,
                    ATL_mmnode_t *rkb, ATL_mmnode_t *trsmb)
/*
 * Header files required to build full gemm (no timing):
 *X1. atlas_<pre>amm_blk.h : 
 *X   defines: ATL_AMM_NCASES, ATL_AMM_MAX[M,N,K]B
 *X   3 arrays indexed by case give blocking
 *X2  atlas_<pre>amm_flag.h
 *X   defines: ATL_AMM_NCASES
 *X   1 indexible array giving KRUNTIME for now
 *X3. atlas_<pre>amm_cm2am_a[1,X,n]: 
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all rm2am & cm2am routines
 *X   1 indexible array giving which to use for each block factor
 *X4. atlas_<pre>amm_ablk2cmat.h
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all ablk2cmat routines
 *X   1 indexible array for each alpha,beta combination
 *X   -> 3*4 = 12 indexible arrays total
 *X5. atlas_<pre>amm_kerns.h
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all kernels, including K-cleanup
 *X   1 indexible array gives kernel to use for each case as func ptr
 *X   1 indexible array gives K-clean kernel
 *X6. atlas_<pre>amm_cmat2ablk.h (I don't need, Rakib does)
 *X   defines: ATL_AMM_NCASES 
 *X   prototypes all cmat2ablk routines
 *X   1 indexible array for each alpha,beta combination
 *X   -> 3*4 = 12 indexible arrays total
 */
{
   ATL_mmnode_t *mp;
   char *pfx;

   pfx = "ge";
   GenAmmSum(pre, geb, rkb, pfx, outd);
   GenBlockingFile(pre, geb, pfx, outd);
   GenPerfFile(pre, geb, pfx, outd, 0.0);
   GenFlagH(pre, geb, pfx, outd);
   GenCMAJ2AMAJ(pre, geb, pfx, outd);
   GenC2BLK(pre, geb, pfx, outd);
   GenKernH(pre, outd, pfx, geb, gek1b);
@skip   GenCmplxHeaders(pre=='s'?'c':'z', geb, rkb, pfx, outd);

   pfx = "sq";
   GenAmmSum(pre, sqb, rkb, pfx, outd);
   GenBlockingFile(pre, sqb, pfx, outd);
   GenPerfFile(pre, sqb, pfx, outd, 0.0);
   GenFlagH(pre, sqb, pfx, outd);
   GenAMAJ2CMAJ(pre, sqb, pfx, outd);
   GenCMAJ2AMAJ(pre, sqb, pfx, outd);
   GenC2BLK(pre, sqb, pfx, outd);
   GenKernH(pre, outd, pfx, sqb, sqk1b);
@skip   GenCmplxHeaders(pre=='s'?'c':'z', sqb, rkb, pfx, outd);

   if (trsmb)
   {
      double maxMF=0.0;
      for (mp=sqb; mp; mp = mp->next)
         if (mp->mflop[0] > maxMF)
             maxMF = mp->mflop[0];
      GenPerfFile(pre, trsmb, "ts", outd, maxMF);
   }
   if (rkb)
   {
      pfx = "rk";
      GenBlockingFile(pre, rkb, pfx, outd);
      GenPerfFile(pre, rkb, pfx, outd, 0.0);
      GenFlagH(pre, rkb, pfx, outd);
      GenCMAJ2AMAJ(pre, rkb, pfx, outd);
      GenC2BLK(pre, rkb, pfx, outd);
      GenRankKH(pre, geb, rkb, outd);
   }
}

/*
 * Splits rkb into two lists: (1) Routines with runtime K (RUNB),
 * (2) Routines with fixed-KB (returned)
 * NOTE: original list rkb is unchanged
 */
ATL_mmnode_t *SplitRankK(ATL_mmnode_t *rkb, ATL_mmnode_t **RUNB)
{
   ATL_mmnode_t *runb=NULL, *fixb=NULL, *p, *np;
   for (p=rkb; p; p = p->next)
   {
      np = CloneMMNode(p);
      if (FLAG_IS_SET(np->flag, MMF_KRUNTIME))
      {
         np->next = runb;
         runb = np;
      }
      else
      {
         np->next = fixb;
         fixb = np;
      }
   }
   *RUNB = runb;
   return(fixb);
}

char *GetKernComp(ATL_mmnode_t *mmp, char *dcomp, char *dflags, char **flgs)
{
   char *comp = dcomp;
   if (mmp->comp)
   {
      comp = (mmp->comp[0] == 'g' && mmp->comp[1] == 'c' &&
              mmp->comp[2] == 'c' && 
             (mmp->comp[3] == '\0' || mmp->comp[3] == ' '))
             ? "$(GOODGCC)" : mmp->comp;
      *flgs = mmp->cflags;
   }
   else
      *flgs = dflags;
   return(comp);
}
void PrintKernComp
(
   FILE *fp,            /* file to print to */
   char pre, 
   ATL_mmnode_t *mmp,   /* kernel compile rule is for */
   int UID,             /* user-ID for user-determined kerns */
   char *nam,           /* base name ("AMMM" or "AMRK") */
   char *comp,          /* compiler to use */
   char *cflags,        /* compiler flags to use */
   char *styp,          /* string defining type (eg. "-DSREAL") */
   char cbet,           /* character with beta name ('1', '0', 'n') */
   char *sbet           /* string wt full beta name ("1", "N1", "0") */
)
{
   const int kb = FLAG_IS_SET(mmp->flag, MMF_KRUNTIME)?0:mmp->kbB;
   const int flg = GetCompTimeFlags(mmp);
   fprintf(fp, "ATL_%c%s_%d_%d_%x_%dx%dx%d_b%c.o : %s\n", pre, nam,
           mmp->ID, kb, flg, mmp->mu, mmp->nu, mmp->ku, cbet, mmp->rout);
   fprintf(fp, "\t%s $(CDEFS2) %s -DBETA%s=1", comp, styp, sbet);
   if (!FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      fprintf(fp, " -DMB=%d -DNB=%d, -DKB=%d", mmp->mbB, mmp->nbB, mmp->kbB);
   if (FLAG_IS_SET(mmp->flag, MMF_MVA))
      fprintf(fp, " -DATL_MOVEA");
   if (FLAG_IS_SET(mmp->flag, MMF_MVB))
      fprintf(fp, " -DATL_MOVEB");
   if (FLAG_IS_SET(mmp->flag, MMF_MVC))
      fprintf(fp, " -DATL_MOVEC");
         fprintf(fp, " -DATL_USERMM=ATL_%c%s_%d_%d_%x_%dx%dx%d_b%c", pre, nam,
                 mmp->ID, kb, flg, mmp->mu, mmp->nu, mmp->ku, cbet);
         fprintf(fp, " %s -o ATL_%c%s_%d_%d_%x_%dx%dx%d_b%c.o -c %s\n", 
                 cflags, pre, nam, mmp->ID, kb, flg, mmp->mu, mmp->nu, mmp->ku, 
                 cbet, mmp->rout);
}
@define uid @-1@
@define lib @ATLAS@
void GenMakefile
(
   char pre,            /* type/precision prefix : s,d,c,z */
   char *outd,          /* directory to generate Makefile in */
   ATL_mmnode_t *geb,   /* main kernels for GEMM */
   ATL_mmnode_t *gek1b, /* K-cleanup for gemm kerns */
   ATL_mmnode_t *sqb,   /* kernels where MB=NB=KB */
   ATL_mmnode_t *sqk1b, /* K-cleanup for square kerns */
   ATL_mmnode_t *rkb    /* list of kernels to doing rank-K update */
)
{
   ATL_mmnode_t *mmb, *mmp, *p, *fixb, *runb;
   mnur_t *mnurb=NULL, *allub, *up;
   FILE *fp;
   char *comp, *cflags;
   char *ln;
   int i;
   char pres[2];
   char be[3] = {'1', 'n', '0'};
   char *bes[3] = {"1", "N1", "0"};
   char al[3] = {'1', 'n', 'X'};
   char dcomp[8] = {'$', '(', 'D', 'M', 'C', ')', '\0'};
   char dflags[12] = {'$', '(', 'D', 'M', 'C', 'F', 'L', 'A', 'G', 'S', 
                     ')', '\0'};
   char *styps[2] = {"-DDREAL", "-DDCPLX"};
   char *styp = (pre == 'd' || pre == 'z') ? "-DDREAL" : "-DSREAL";
/*
 * Square & rect kernels handled same way: going to be compiled once for
 * each compile-time K, and once if runtime, so combine them into one big
 * queue for Make generation, w/o repeating same compile-time kernel
 */
   mmb = AddUniqueMMKernCompList(NULL, geb);
   mmb = AddUniqueMMKernCompList(mmb, gek1b);
   mmb = AddUniqueMMKernCompList(mmb, sqk1b);
   mmb = AddUniqueMMKernCompList(mmb, sqb);

   pres[0] = pre;
   if (pre == 's' || pre == 'c')
   {
      styps[0] = "-DSREAL";
      styps[1] = "-DSCPLX";
      pres[1] = 'c';
   }
   else
      pres[1] = 'z';

   ln = malloc((strlen(outd)+11)*sizeof(char));
   assert(ln);
   sprintf(ln, "%s/%cMake_amm", outd, pre);
   fp = fopen(ln, "w");
   assert(fp);
   free(ln);
   fprintf(fp, "include ../Make.inc\n");
   fprintf(fp, "CDEFS2=$(CDEFS)\n\n");
   if (pre == 'c')
   {
      fprintf(fp, "CMC=$(SMC)\n");
      fprintf(fp, "CKCFLAGS=$(SKCFLAGS)\n");
      fprintf(fp, "CMCFLAGS=$(SMCFLAGS)\n");
   }
   else if (pre == 'z')
   {
      fprintf(fp, "ZMC=$(DMC)\n");
      fprintf(fp, "ZKCFLAGS=$(DKCFLAGS)\n");
      fprintf(fp, "ZMCFLAGS=$(DMCFLAGS)\n");
   }
/*
 * Build list of all unique MU/NU combos for copy routines
 */
   mnurb = GetUniqueMNUnrolls(mmb, NULL);
   mnurb = GetUniqueMNUnrolls(rkb, mnurb);
   allub = GetUniqueMUnrolls(mmb, NULL);
   allub = GetUniqueMUnrolls(rkb, allub);
   allub = GetUniqueNUnrolls(mmb, allub);
   allub = GetUniqueNUnrolls(rkb, allub);
/*
 * Spew out all filenames that must be compiled
 */
   fprintf(fp, "objs =");
/*
 * Routines to copy from MU/NU-major to column major output array
 */
   for (up=mnurb; up; up = up->next)
   {
      int j;
      const int mu=up->mu, nu=up->nu;

      for (j=0; j < 3; j++)
      {
         int k;
         char *rtn[2] = {"ablk2cmat", "cmat2ablk"};
         for (k=0; k < 2; k++)
         {
            int h;
            for (h=0; h < 2; h++)
            {
               char pre = pres[h];
               fprintf(fp, " \\\n       ATL_%c%s_%dx%d_a%c_b1.o",
                       pre, rtn[k], mu, nu, al[j]);
               fprintf(fp, " ATL_%c%s_%dx%d_a%c_bX.o",
                       pre, rtn[k], mu, nu, al[j]);
               fprintf(fp, " \\\n       ATL_%c%s_%dx%d_a%c_b0.o",
                       pre, rtn[k], mu, nu, al[j]);
               fprintf(fp, " ATL_%c%s_%dx%d_a%c_bn.o",
                       pre, rtn[k], mu, nu, al[j]);
            }
         }
      }
   }
/*
 * Routines to copy back and forth from A and B
 */
   for (up=allub; up; up = up->next)
   {
      int h;
      for (h=0; h < 2; h++)
      {
         char pre=pres[h];
         int j;
         const int u = up->mu;
         for (j=0; j < 3; j++)
         {
            if (up->kmaj > 1)
            {
               fprintf(fp, 
 " \\\n       ATL_%crm2am_a%c_%dx%d.o ATL_%ccm2am_a%c_%dx%d.o",
                       pre, al[j], up->kmaj, u, pre, al[j], up->kmaj, u);
               fprintf(fp, 
 " \\\n       ATL_%cam2rm_a%c_%dx%d.o ATL_%cam2cm_a%c_%dx%d.o",
                       pre, al[j], up->kmaj, u, pre, al[j], up->kmaj, u);
            }
            else
            {
               fprintf(fp, 
                       " \\\n       ATL_%crm2am_a%c_%d.o ATL_%ccm2am_a%c_%d.o",
                       pre, al[j], u, pre, al[j], u);
               fprintf(fp, 
                       " \\\n       ATL_%cam2rm_a%c_%d.o ATL_%cam2cm_a%c_%d.o",
                       pre, al[j], u, pre, al[j], u);
            }
            if (pre == 'c' || pre == 'z')
            {
               if (up->kmaj > 1)
               {
                  fprintf(fp, 
 " \\\n       ATL_%crm2am_a%c_%dx%dC.o ATL_%ccm2am_a%c_%dx%dC.o",
                          pre, al[j], up->kmaj, u, pre, al[j], up->kmaj, u);
                  fprintf(fp, 
 " \\\n       ATL_%cam2rm_a%c_%dx%dC.o ATL_%cam2cm_a%c_%dx%dC.o",
                          pre, al[j], up->kmaj, u, pre, al[j], up->kmaj, u);
               }
               else
               {
                  fprintf(fp, 
                     " \\\n       ATL_%crm2am_a%c_%dC.o ATL_%ccm2am_a%c_%dC.o",
                          pre, al[j], u, pre, al[j], u);
                  fprintf(fp, 
                     " \\\n       ATL_%cam2rm_a%c_%dC.o ATL_%cam2cm_a%c_%dC.o",
                          pre, al[j], u, pre, al[j], u);
               }
            }
         }
      }
   }
/*
 * AMM kernel routines
 */
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      int kb = mmp->kbB;
/*
 *    Kernels that take runtime K are only compiled once, so don't repeat them
 *    for every KB.  Only generate a statement if this is the first one.
 */
      if (FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      {
         const int id = mmp->ID;
         for (p=mmb; p != mmp; p = p->next)
            if (MMKernsSame(mmp, p))
               break;
         if (p != mmp)
            continue;
         kb = 0;
      }
/* 
 *    ATL_<pre>AMMM_<ID>_<kb>_<flg>_<mu>x<nu>x<ku>_b<X>
 */
      for (i=0; i < 3; i++)
         fprintf(fp, " \\\n       ATL_%cAMMM_%d_%d_%x_%dx%dx%d_b%c.o", 
                 pre, mmp->ID, kb, GetCompTimeFlags(mmp), mmp->mu, mmp->nu, 
                 mmp->ku, be[i]);
   }
/*
 * rank-K AMM routines where KB is runtime variable
 */
   fixb = SplitRankK(rkb, &runb);
   runb = RemoveNonUniqueKernels(runb);
   for (mmp=runb; mmp; mmp = mmp->next)
      for (i=0; i < 3; i++)
         fprintf(fp, " \\\n       ATL_%cAMRK_%d_0_%x_%dx%dx%d_b%c.o", pre, 
                 mmp->ID, GetCompTimeFlags(mmp),mmp->mu,mmp->nu,mmp->ku,be[i]);
/*
 * rank-K AMM routines where KB is compile-time, need obj for each unique kbB
 */
   for (mmp=fixb; mmp; mmp = mmp->next)
   {
      for (i=0; i < 3; i++)
         fprintf(fp, " \\\n       ATL_%cAMRK_%d_%d_%x_%dx%dx%d_b%c.o", 
                 pre, mmp->ID, mmp->kbB, GetCompTimeFlags(mmp), 
                 mmp->mu, mmp->nu, mmp->ku, be[i]);
   }
/*
 * library make targets
 */
   fprintf(fp, "\n\nlib : %clib.grd\nall : %clib.grd\n%clib : %clib.grd\n", 
           pre, pre, pre, pre);
   fprintf(fp, "%clib.grd : $(objs)\n", pre);
   fprintf(fp, "\t$(ARCHIVER) $(ARFLAGS) $(@(lib)lib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(@(lib)lib)\n");
   fprintf(fp, "\t touch %clib.grd\n", pre);
   fprintf(fp, "clean : %cclean\n", pre);
   fprintf(fp, "%cclean:\n\t- rm -f $(objs)\n", pre);
   fprintf(fp, "killall : %ckillall\n", pre);
   fprintf(fp, "%ckillall : %cclean\n", pre, pre);
   fprintf(fp, "\t- $(ARCHIVER) d $(@(lib)lib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(@(lib)lib)\n");
   fprintf(fp, "\t- rm -f ATL_%c*.[S,c]\n", pre);

/*
 * Print out the individual rules for each needed copy function
 */
   dcomp[2] = dflags[2] = toupper(pre);
   dflags[3] = dcomp[3] = 'K';
   fprintf(fp, "\ntsth.o : tsth.c\n");
   fprintf(fp, "\t%s %s $(CDEFS) %s -c tsth.c\n\n", dcomp, dflags, styp);
   fprintf(fp, "#\n# Data copy rules\n#\n");
/*
 * Print out 2-D ablk2Cmat, cmat2ablk and ammswp targets
 */
   for (up=mnurb; up; up = up->next)
   {
      const int mu=up->mu, nu = up->nu;
      char cbe[4] = {'0', '1', 'n', 'X'};
      int ibe[4] =  {0,    1,  -1,  2};
      int i, j;

      for (i=0; i < 4; i++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            char pre=pres[h];
            char *styp=styps[h];
            for (j=0; j < 3; j++)
            {
               int k;
               char *rtn[2] = {"ablk2cmat", "cmat2ablk"};
               for (k=0; k < 2; k++)
               {
                  char rn[64];
                  sprintf(rn, "ATL_%c%s_%dx%d_a%c_b%c",
                          pre, rtn[k], mu, nu, al[j], cbe[i]);
                  fprintf(fp, "%s.o : %s.c\n", rn, rn);
                  fprintf(fp, "\t%s %s $(CDEFS) %s -c %s.c\n", 
                          dcomp, dflags, styp, rn);
               }
            }
         }
      }
   }
   KillUnrollList(mnurb);
/*
 * Print out 1-D copy-in routine rules
 */
   for (up=allub; up; up = up->next)
   {
      const int u = up->mu, kmaj=up->kmaj;
      int j;
      for (j=0; j < 3; j++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            char pre=pres[h];
            char *styp=styps[h];
            char *cst[2] = {"", "C"};
            char *cdef[2] = {"", "-DConj_=1 "};
            int g;
            const int G = (pre == 'c' || pre == 'z') ? 2:1;
            for (g=0; g < G; g++)
            {
               int kk, r;
               const int nmI = 5;
               char rout[32];
               char *routs[4] = {"rm2am", "cm2am", "am2rm", "am2cm"};
               for (r=0; r < 4; r++)
               {
                  if (kmaj > 1)
                     sprintf(rout, "ATL_%c%s_a%c_%dx%d", 
                             pre, routs[r], al[j], kmaj, u);
                  else
                     sprintf(rout, "ATL_%c%s_a%c_%d", pre, routs[r], al[j], u);
                  fprintf(fp, "%s%s.o : %s.c\n", rout, cst[g], rout);
                  fprintf(fp, "\t%s %s $(CDEFS) %s%s -o %s%s.o -c %s.c\n", 
                          dcomp, dflags, cdef[g], styp, rout, cst[g], rout);
               }
            }
         }
      }
   }
   KillUnrollList(allub);
/*
 * Print out the individual rules for each kernel compile
 */
   dflags[3] = dcomp[3] = 'M';
   fprintf(fp, "#\n#  AMM kernel rules\n#\n");
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
/*
 *    Kernels that take runtime K are only compiled once, so print rules on
 *    only the first encounter of that ID
 */
      if (FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      {
         const int id = mmp->ID;
         for (p=mmb; p != mmp; p = p->next)
            if (MMKernsSame(mmp, p))
               break;
         if (p != mmp)
            continue;
      }
      comp = GetKernComp(mmp, dcomp, dflags, &cflags);
/* 
 *    ATL_<pre>AMMM_<ID>_<kb>_<flg>_<mu>x<nu>x<ku>_b<X>, 
 *    kerns in all 3 beta cases
 */
      for (i=0; i < 3; i++)
         PrintKernComp(fp, pre, mmp, @(uid), "AMMM", comp, cflags, styp, 
                       be[i], bes[i]);
   }
/*
 * runtime-KB rank-K needs only one kernel compile rule
 */
   if (runb)
      fprintf(fp, "#\n#  rank-K kernels with run-time K\n#\n");
   for (mmp=runb; mmp; mmp = mmp->next)
   {
      comp = GetKernComp(mmp, dcomp, dflags, &cflags);
      for (i=0; i < 3; i++)
         PrintKernComp(fp, pre, mmp, @(uid), "AMRK", comp, cflags, styp, 
                       be[i], bes[i]);
   }
   
/*
 * Compile-time rank-K must be recompiled for each kbB
 */
   if (fixb)
      fprintf(fp, "#\n#  rank-K kernels with compile-time KB\n#\n");
   for (mmp=fixb; mmp; mmp = mmp->next)
   {
      const int kmaj = FLAG_IS_SET(mmp->flag, MMF_KVEC) ? mmp->vlen:0;
      comp = GetKernComp(mmp, dcomp, dflags, &cflags);
      for (i=0; i < 3; i++)
      {
         int kbG = mmp->kbB;
         if (kmaj)
            kbG = ((mmp->kbB + kmaj-1)/kmaj)*kmaj;
         fprintf(fp, "ATL_%cAMRK_%d_%d_%x_%dx%dx%d_b%c.o : %s\n", pre, mmp->ID, 
                 mmp->kbB, GetCompTimeFlags(mmp), mmp->mu, mmp->nu, mmp->ku,
                 be[i], mmp->rout);
         fprintf(fp, "\t%s $(CDEFS2) %s -DBETA%s=1", comp, styp, bes[i]);
         fprintf(fp, " -DKB=%d -DATL_USERMM=ATL_%cAMRK_%d_%d_%x_%dx%dx%d_b%c", 
                 kbG, pre, mmp->ID, mmp->kbB, GetCompTimeFlags(mmp), mmp->mu,
                 mmp->nu, mmp->ku, be[i]);
         fprintf(fp, " -DATL_MOVEA -DATL_MOVEC");
         fprintf(fp, " %s -o ATL_%cAMRK_%d_%d_%x_%dx%dx%d_b%c.o -c %s\n", 
                 cflags, pre, mmp->ID, mmp->kbB, GetCompTimeFlags(mmp), 
                 mmp->mu, mmp->nu, mmp->ku, be[i], mmp->rout);
      }
   }
   KillAllMMNodes(fixb);
   KillAllMMNodes(runb);
   KillAllMMNodes(mmb);
   fclose(fp);
}

void GenKerns(char pre, char *outd, ATL_mmnode_t *geb, ATL_mmnode_t *gek1b, 
              ATL_mmnode_t *sqb, ATL_mmnode_t *sqk1b, ATL_mmnode_t *rkb)
/*
 * Creates/copies all required matmul kernels into outd using specified names
 */
{
   ATL_mmnode_t *mmb, *mmp, *p;
   mnur_t *mnurb=NULL, *allub, *up;
   char *ln=NULL;
   int lnlen=0, dlen;
   char al[3] = {'1', 'n', 'X'};
   int ial[3] = {1,   -1,   2};
   char pres[2];
   pres[0] = pre;
   pres[1] = (pre == 's') ? 'c' : 'z';
/*
 * All non-rkK kerns are generated the same way, so combine them all into one
 * gigantic queue.  We then eliminate all the guys who aren't different
 * once we have compiled them, which still leaves duplicates that differ
 * only in their compilation options.  We'll go ahead and just generate
 * them multiple times (overwriting the file with the same file), so that
 * we don't have to write & support a stricter RemoveNonUnique
 */
   mmb = CloneMMQueue(geb);
   ATL_LastMMNode(mmb)->next = CloneMMQueue(sqb);
   ATL_LastMMNode(mmb)->next = CloneMMQueue(gek1b);
   ATL_LastMMNode(mmb)->next = CloneMMQueue(sqk1b);
   ATL_LastMMNode(mmb)->next = CloneMMQueue(rkb);
   mmb = RemoveNonUniqueKernels(mmb);
/*
 * Build list of all unique MU/NU combos for copy routines
 */
   mnurb = GetUniqueMNUnrolls(mmb, NULL);
   allub = GetUniqueMUnrolls(mmb, NULL);
   allub = GetUniqueNUnrolls(mmb, allub);
   dlen = strlen(outd);
/*
 * Extract every unique block-copy routine
 */
   for (up=mnurb; up; up = up->next)
   {
      const int mu=up->mu, nu=up->nu;
      char cbe[4] = {'0', '1', 'n', 'X'};
      int ibe[4] =  {0,    1,  -1,  2};
      int i, j;
      j = 64+8 + strlen(outd);
      j = (j > 128) ? j : 128;
      if (lnlen < j)
      {
         free(ln);
         lnlen = j;
         ln = malloc(j*sizeof(char));
         assert(ln);
      }
      for (i=0; i < 4; i++)
      {
         for (j=0; j < 3; j++)
         {
            char rn[64];
            int ierr;
            int k;
            for (k=0; k < 2; k++)
            {
               int h;
               for (h=0; h < 2; h++)
               {
                  char pre = pres[h];
                  if (!k)
                     sprintf(rn, "ATL_%cablk2cmat_%dx%d_a%c_b%c.c",
                             pre, mu, nu, al[j], cbe[i]);
                  else
                     sprintf(rn, "ATL_%ccmat2ablk_%dx%d_a%c_b%c.c",
                             pre, mu, nu, al[j], cbe[i]);
                  sprintf(ln, 
                     "make %s pre=%c mu=%d nu=%d al=%c be=%c alpha=%d beta=%d", 
                          rn, pre, mu, nu, al[j], cbe[i], ial[j], ibe[i]);
                  ierr = system(ln);
                  if (ierr)
                  {
                     fprintf(stderr, "FAILED CMND='%s'\n", ln);
                     exit(ierr);
                  }
                  sprintf(ln, "mv %s %s/.", rn, outd);
                  ierr = system(ln);
                  if (ierr)
                  {
                     fprintf(stderr, "FAILED CMND='%s'\n", ln);
                     exit(ierr);
                  }
               }
            }
         }
      }
   }
   KillUnrollList(mnurb);

/*
 * Routines to copy back and forth from A and B
 */
   for (up=allub; up; up = up->next)
   {
      const int u = up->mu, kmaj=up->kmaj;
      int j;
      j = 16 * 40 + (strlen(outd)<<1);
      j = (j > 90) ? j : 90;
      if (lnlen < j)
      {
         free(ln);
         lnlen = j;
         ln = malloc(j*sizeof(char));
         assert(ln);
      }
      for (j=0; j < 3; j++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            int ierr;
            char pre = pres[h];
            sprintf(ln, "make ATL_%crm2am_a%c_%d.c ATL_%ccm2am_a%c_%d.c "
                    "pre=%c UR=%d alpha=%d al=%c kmaj=%d",
                    pre, al[j], u, pre, al[j], u, pre, u, ial[j], al[j], kmaj);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
            sprintf(ln, "make ATL_%cam2rm_a%c_%d.c ATL_%cam2cm_a%c_%d.c "
                    "pre=%c UR=%d alpha=%d al=%c kmaj=%d",
                    pre, al[j], u, pre, al[j], u, pre, u, ial[j], al[j], kmaj);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
   @whiledef rt cm2am rm2am am2cm am2rm
            if (kmaj > 1)
               sprintf(ln, 
                       "mv ATL_%c@(rt)_a%c_%d.c %s/ATL_%c@(rt)_a%c_%dx%d.c",
                       pre, al[j], u, outd, pre, al[j], kmaj, u);
            else
               sprintf(ln, 
                       "mv ATL_%c@(rt)_a%c_%d.c %s/ATL_%c@(rt)_a%c_%d.c",
                       pre, al[j], u, outd, pre, al[j], u);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
   @endwhile
         }
      }
   }
   KillUnrollList(allub);
/*
 * Copy/generate every unique file, but only once
 */
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      const int id=mmp->ID;
/*
 *    For generated files, just overwrite dups with same file, won't hurt
 */
      if (id == 0)
      {
         assert(mmp->genstr);
         assert(!system(mmp->genstr));
      }
      else  /* user-supplied files copied from AMMCASES directory */
      {
/*
 *       If this is the first time we've seen this ID, it must be copied
 */
         for (p=mmb; p != mmp && p->ID != id; p = p->next);
         if (p == mmp)
         {
            int i, ierr;
            i = strlen(mmp->rout) + dlen + 16;
            if (i > lnlen)
            {
               if (ln)
                  free(ln);
               ln = malloc(i*sizeof(char));
               assert(ln);
               lnlen = i;
            }
            sprintf(ln, "cp AMMCASES/%s %s/.", mmp->rout, outd);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
         }
      }
   }
/*
 * Copy/generate rank-K kerns
 */
   for (mmp=rkb; mmp; mmp = mmp->next)
   {
      const int id=mmp->ID;
/*
 *    For generated files, just generate it using genstr
 */
      if (id == 0)
      {
         assert(mmp->genstr);
         assert(!system(mmp->genstr));
      }
      else  /* user-supplied files copied from AMMCASES directory */
      {
         int i, ierr;
         i = strlen(mmp->rout) + dlen + 16;
         if (i > lnlen)
         {
            if (ln)
               free(ln);
            ln = malloc(i*sizeof(char));
            assert(ln);
            lnlen = i;
         }
         sprintf(ln, "cp AMMCASES/%s %s/.", mmp->rout, outd);
         ierr = system(ln);
         if (ierr)
         {
            fprintf(stderr, "FAILED CMND='%s'\n", ln);
            exit(ierr);
         }
      }
   }
   KillAllMMNodes(mmb);
   if (ln)
      free(ln);
}

int KernelInList(ATL_mmnode_t *mmb, ATL_mmnode_t *p)
/*
 * RETURNS: 1 if p is duplicated in mmb, else 0
 */
{
   ATL_mmnode_t *mp;
   if (!p || !mmb)
      return(0);
   for (mp=mmb; mp; mp = mp->next)
      if (MMKernsSame1(mp, p))
         return(1);
    return(0);
}

ATL_mmnode_t *StripNonUniqueKs(ATL_mmnode_t *ukb, ATL_mmnode_t *mmb) 
/*
 * Deletes any ukb node that also appears in mmb,
 * RETURNS: possibly shortened ukb
 */
{
   ATL_mmnode_t *mp, *prev;
/*
 * Delete any repetitive nodes starting unique queue
 */
   while(ukb && KernelInList(mmb, ukb))
      ukb = KillMMNode(ukb);
   if (!ukb)
      return(ukb);
/*
 * Now, delete any internal non-unique K-cleanup
 */
   prev = ukb;
   mp = ukb->next;
   while (mp)
   {
      if (KernelInList(mmb, mp))
         mp = prev->next = KillMMNode(mp);
      else
      {
         prev = mp;
         mp = mp->next;
      }
   }
   return(ukb);
}
ATL_mmnode_t *StripExactMatchKs(ATL_mmnode_t *ukb, ATL_mmnode_t *mmb) 
/*
 * Deletes any ukb node that also appears in mmb with same K-value,
 * RETURNS: possibly shortened ukb
 */
{
   ATL_mmnode_t *mp, *prev;
/*
 * Delete any repetitive nodes starting unique queue
 */
   while(ukb && ExactKernelInList(mmb, ukb))
      ukb = KillMMNode(ukb);
   if (!ukb)
      return(ukb);
/*
 * Now, delete any internal non-unique K-cleanup
 */
   prev = ukb;
   mp = ukb->next;
   while (mp)
   {
      if (ExactKernelInList(mmb, mp))
         mp = prev->next = KillMMNode(mp);
      else
      {
         prev = mp;
         mp = mp->next;
      }
   }
   return(ukb);
}
/*
 * RETURNS: mmb, with all repeated kernels removed
 */
ATL_mmnode_t *RemoveNonUniqueKernels(ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mp;
   if (!mmb || !mmb->next)
      return(mmb);
   for (mp=mmb; mp; mp = mp->next)
   {
      ATL_mmnode_t *p=mp->next, *prev=mp;
      while (p)
      {
@skip    if (MMKernsSame(mp, p) && (FLAG_IS_SET(p->flag, MMF_KRUNTIME) ||
@skip        p->kbB == mp->kbB))
         if (MMKernsSame1(mp, p))
            prev->next = p = KillMMNode(p);
         else
         {
            prev = p;
            p = p->next;
         }
      }
   }
   return(mmb);
}

void GenAllFiles(char pre, char *outd, ATL_mmnode_t *geb, ATL_mmnode_t *gek1b, 
                 ATL_mmnode_t *sqb, ATL_mmnode_t *sqk1b, ATL_mmnode_t *rkb,
                 ATL_mmnode_t *trsmb, ATL_mmnode_t *cgeb, ATL_mmnode_t *cgek1b,
                 ATL_mmnode_t *csqb, ATL_mmnode_t *csqk1b, ATL_mmnode_t *crkb,
                 ATL_mmnode_t *ctrsmb)
{
   ATL_mmnode_t *uge, *usq, *urk;  /* lists w/o object repeats */
   ATL_mmnode_t *mp;
   const char cpr = (pre == 'd') ? 'z' : 'c';

   if (!ctrsmb)
      ctrsmb = trsmb;
   GenHeaderFiles(pre, outd, geb, gek1b, sqb, sqk1b, rkb, trsmb);
   GenHeaderFiles(cpr, outd, cgeb, cgek1b, csqb, csqk1b, crkb, ctrsmb);
/*
 * Link complex and real together: real/cplx don't matter for generation
 * or compiling
 */
   ATL_LastMMNode(geb)->next = cgeb;
   ATL_LastMMNode(gek1b)->next = cgek1b;
   ATL_LastMMNode(sqb)->next = csqb;
   ATL_LastMMNode(sqk1b)->next = csqk1b;
   mp = AddUniqueMMKernCompList(NULL, rkb);
   KillAllMMNodes(rkb);
   rkb = AddUniqueMMKernCompList(mp, crkb);
   KillAllMMNodes(crkb);

   GenMakefile(pre, outd, geb, gek1b, sqb, sqk1b, rkb);
   GenKerns(pre, outd, geb, gek1b, sqb, sqk1b, rkb);
   KillAllMMNodes(geb);
   KillAllMMNodes(gek1b);
   KillAllMMNodes(sqb);
   KillAllMMNodes(sqk1b);
   KillAllMMNodes(rkb);
   KillAllMMNodes(trsmb);
}

void Cplx2RealMM(char pre, ATL_mmnode_t *mmb, char *outd)
{
   ATL_mmnode_t *mp;
   const int mask = ~(1<<MMF_COMPLEX);
   char pfx[8];
   const char cpr = (pre == 'd') ? 'z' : 'c';
   pfx[0] = 'A'; pfx[1] = 'T'; pfx[2] = 'L'; pfx[3] = '_';
   pfx[4] = cpr; pfx[5] = 0;
   for (mp=mmb; mp; mp = mp->next)
   {
      char *sp;
      mp->flag &= mask;
      if (mp->rout)
      {
         sp = strstr(mp->rout, pfx);
         if (sp)
            sp[4] = pre;
      }
   }
   FillInGenStrings(pre, mmb, outd);
}

int main(int nargs, char **args)
{
   char pre='d';
   int verb=1;
   int *nbs;
   char *outd, *ukin, *kcin, *rkin, *sqin;
   ATL_mmnode_t *geb, *gek1b, *sqb, *sqk1b, *rkb, *trsm;
   ATL_mmnode_t *cgeb, *cgek1b, *csqb, *csqk1b, *crkb, *ctrsm;
/*
 * We expect to get a list of rectangular blocking factor kernels for gemm,
 * K-cleanup kernels for gemm, and square kernels for building amm-based L3BLAS,
 * and their K-cleanup kernels, and finally a list of kernels for rank-K
 */
   pre = GetFlags(nargs, args, &outd, &geb, &gek1b, &sqb, &sqk1b, &rkb, &trsm,
                  &cgeb, &cgek1b, &csqb, &csqk1b, &crkb, &ctrsm);
   assert(geb && gek1b);
   assert(sqb && sqk1b);
   assert(rkb);
/*
 * Complex actually handled by real
 */
   if (pre == 'c')
      pre = 's';
   else if (pre == 'z')
      pre = 'd';
/*
 * Fill in correct generator strings for all lists
 */
   FillInGenStrings(pre, geb, outd);
   FillInGenStrings(pre, gek1b, outd);
   FillInGenStrings(pre, sqb, outd);
   FillInGenStrings(pre, sqk1b, outd);
   FillInGenStrings(pre, rkb, outd);
   Cplx2RealMM(pre, cgeb, outd);
   Cplx2RealMM(pre, cgek1b, outd);
   Cplx2RealMM(pre, csqb, outd);
   Cplx2RealMM(pre, csqk1b, outd);
   Cplx2RealMM(pre, crkb, outd);

   GenAllFiles(pre, outd, geb, gek1b, sqb, sqk1b, rkb, trsm, 
               cgeb, cgek1b, csqb, csqk1b, crkb, ctrsm);

   return(0);
}
@ROUT gmmsearch
@extract -b @(topd)/cw.inc lang=C -def cwdate 2015 -def cwdate 2016
#include "atlas_cache.h"
#include "atlas_misc.h"
#include "atlas_mmtesttime.h"
/*
 * Flag for iFKO (must be power of 2).
 */
 #define FKO_FLAG 262144 
@extract -b @(basd)/atlas.base rout=Mylcm
@ROUT ammsearch uammsearch
@extract -b @(topd)/cw.inc lang=C -def cwdate 2012 -def cwdate 2013 -def cwdate 2015
#include "atlas_misc.h"
@skip #include "atlas_gnuvec.h"
#include "atlas_mmtesttime.h"

static int VLEN=0;
@beginskip
#define NVECS 4
static enum VECTYPE {VTAVXZ=0, VTAVX=1, VTSSE=2, VTGV=3, VTSC=4} VECi=VTSC;
static int VLEN[5] = {8, 4, 2, 2, 1};  /* assume double, fix later if nec */
static char *VECs[5] = {"avxz", "avx", "sse", "gvec", "scalar"};
@endskip
static int TSIZE=8;
@skip static char *MOVES=NULL;
static int IMVS=3;     /* move ptrs in timing encoded in last 3 bits: CBA */
#define KRUNMUL 1.02   /* KRUNTIME speedup increase over K-compile time */

@extract -b @(basd)/atlas.base rout=Mylcm

ATL_mmnode_t *GetGenCases(char pre)
{
   ATL_mmnode_t *mb, *mp;
   mb = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   if (!mb)
   {
      char ln[32];
      sprintf(ln, "make res/%cgAMMRES.sum", pre);
      assert(!system(ln));
      mb = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   }
   assert(mb);
   MMFillInGenStrings(pre, mb);
   return(mb);
}

@ROUT ammsearch uammsearch gmmsearch
double TimeMMKernel_KB
(
   int verb,                    /* 0: no output, 1 min output, 2: full output */
   int FORCETIME,               /* 1: ignore any prior output file */
   ATL_mmnode_t *mmp,           /* ptr to mmkern struct */
   char pre,                    /* type/prec prefix: z,c,d,s */
   int mb, int nb, int kb,      /* dimensions to time */
   int beta,                    /* beta to time */
   int mflop,                   /* >0: force mflop MFLOPs in each time interv */
   int cflush                   /* >=0: size of cache flush, else ignored */
)
/*
 * If kernel has property KRUNTIME, try timing it with compile- and run-time K,
 * and if compile-time is more than 2% faster, turn off KRUNTIME
 */
{
   double mf;
   const int kb0 = mmp->kbB;
   if (mmp->ID && mmp->kbmax && kb > mmp->kbmax)  /* genned codes can adapt */
      return(0.0);
   mmp->mbB = mb;
   mmp->nbB = nb;
   mmp->kbB = kb;
/*
 * If it's a generated kernel, regen in case we need KB to match KU, and
 * to specialize it to KB (assuming compile-time is faster)
 */
   if (!mmp->ID)
   {
      if (mmp->genstr)
         free(mmp->genstr);
      if (mmp->rout)
         free(mmp->rout);
      if (FLAG_IS_SET(mmp->flag, MMF_KUISKB))
         mmp->kbmax = mmp->kbmin = mmp->ku = kb;
      mmp->rout = DupString("ATL_tmp.c");
      mmp->genstr = MMGetGenString(pre, mmp);
   }
   mf = TimeMMKernel(verb, FORCETIME, mmp, pre, mb, nb, kb, beta, mflop,cflush);
   if (FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
   {
      double mfC;
      mmp->flag &= ~(1<<MMF_KRUNTIME);
      mfC = TimeMMKernel(verb, FORCETIME, mmp, pre, mb, nb, kb, beta, 
                         mflop, cflush);
      if (mfC <= 1.02*mf)
         mmp->flag |= (1<<MMF_KRUNTIME);
      else
      {
         if (verb)
            printf("      Forcing K compile-time, mfC=%.2f, mfR=%.2f\n", 
                   mfC, mf);
         mf = mfC;
      }
   }
   return(mf);
}
@ROUT ammsearch uammsearch
/*
 * Finds best blocking factors for kernel mmp trying all legal values
 * between [b0, bN]
 */
ATL_mmnode_t *BestBlocking_BFI
(
   int verb, 
   char pre, 
   ATL_mmnode_t *mmp, 
   int b0,
   int bN,
   int minInc,  /* minimum increment to use */
   int FORCE
)
/*
 * Times all legal block factors in all dims between [b0,bN].
 * RETURNS: ptr to best performing kernel, NULL if no legal block factors
 */
{
   ATL_mmnode_t *mp;
   int mbB=0, nbB=0, kbB=0;
   int mbS=0, nbS=0, kbS=0;
   int mu = mmp->mu, nu = mmp->nu, ku = mmp->ku;
   int k0, kn, m0, mn, n0, nn, m, n, k;
   double mfB=0.0, mfS=0.0;

   if (!mmp)
      return(NULL);
   if (minInc > mu)
      mu = ((minInc+mu-1)/mu)*mu;
   if (minInc > nu)
      nu = ((minInc+nu-1)/nu)*nu;
   if (minInc > ku)
      ku = ((minInc+ku-1)/ku)*ku;
   m0 = ((b0+mu-1)/mu)*mu;
   n0 = ((b0+nu-1)/nu)*nu;
   k0 = ((b0+ku-1)/ku)*ku;
   mn = ((bN+mu-1)/mu)*mu;
   nn = ((bN+nu-1)/nu)*nu;
   kn = ((bN+ku-1)/ku)*ku;
   mp = CloneMMNode(mmp);
   if (mp->kbmax && mp->kbmax < kn)
      kn = mp->kbmax;
   if (mp->kbmin && mp->kbmin > k0)
      k0 = mp->kbmin;


   printf("SEARCH BLKING [%d - %d] for %d.%s:\n\n", b0, bN, mp->ID, mp->rout);
   printf("  MB    NB    KB        MFLOP    mbB  nbB  kbB      mflopB\n");
   printf("====  ====  ====  ===========   ==== ==== ==== ===========\n");
   for (m=m0; m <= mn; m += mu)
   {
      for (n=m0; n <= nn; n += nu)
      {
         for (k=k0; k <= kn; k += ku)
         {
            double mf;
            mf = TimeMMKernel(verb, FORCE, mp, pre, m, n, k, 1, 0, -1);
            printf("%4d %5d %5d %11.1f %4d %4d %4d %11.1f\n", 
                   m, n, k, mf, mbB, nbB, kbB, mfB);
            if (mf > mfB)
            {
               mfB = mf;
               mbB = m;
               nbB = n;
               kbB = k;
            }
            if (m == n && m == k)
            {
               if (mf > mfS)
               {
                  mfS = mf;
                  mbS = m;
                  nbS = n;
                  kbS = k;
               }
            }
         }
      }
   }
   if (mfB == 0)
   {
      printf("NO KERNEL POSSIBLE FOR RANGE=[%d,%d]\n", b0, bN);
      KillMMNode(mp);
      return(NULL);
   }
   mp->mbB = mbB;
   mp->nbB = nbB;
   mp->kbB = kbB;
   mp->mflop[0] = mfB;
   printf("FOR %d.'%s': MB=%d, NB=%d, KB=%d, MFLOPS=%.1f\n",
          mp->ID, mp->rout, mbB, nbB, kbB, mfB);
   k = MMKernelFailsTest(pre, mbB, nbB, kbB, 0, mp);
   if (!k)
      k = MMKernelFailsTest(pre, mbB, nbB, kbB, 1, mp);
   if (!k)
      k = MMKernelFailsTest(pre, mbB, nbB, kbB, -1, mp);
   if (k)
   {
      printf("KERNEL FAILS TESTER FOR [M,N,K]B=%d,%d,%d\n", mbB, nbB, kbB);
      exit(k);
   }
   if (mbS == 0)
      mp->next = NULL;
   else
   {
      k = MMKernelFailsTest(pre, mbS, nbS, kbS, 0, mp);
      if (!k)
         k = MMKernelFailsTest(pre, mbS, nbS, kbS, 1, mp);
      if (!k)
         k = MMKernelFailsTest(pre, mbS, nbS, kbS, -1, mp);
      if (k)
         mp->next = NULL;
      else
      {
         mp->next = CloneMMNode(mp);
         mp->next->mbB = mbS;
         mp->next->nbB = nbS;
         mp->next->kbB = kbS;
         mp->next->mflop[0] = mfS;
      }
   }
   WriteRefreshedMMFileWithPath(pre, "res", "AMMEXBLKS.sum", mp);
   return(mp);
}

ATL_mmnode_t *TimeExtraBlockings(char pre, int verb)
{
   ATL_mmnode_t *eb;
   eb = ReadMMFileWithPath(pre, "res", "AMMEXBLKS.sum");
   if (!eb)
      return(eb);
   if (eb->mflop[0] < 0)
   {
      ATL_mmnode_t *mp;
      printf("EXTRA BLOCKING FACTOR TIMINGS:\n\n");
      if (verb)
      {
         printf("  MB    NB    KB        MFLOP\n");
         printf("====  ====  ====  ===========\n");
      }
      for (mp=eb; mp; mp = mp->next)
      {
         mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB,
                                     mp->kbB, 1, 0, -1);
         if (verb)
            printf("%4d %5d %5d %11.1f\n", 
                   mp->mbB, mp->nbB, mp->kbB, mp->mflop[0]);
      }
      WriteRefreshedMMFileWithPath(pre, "res", "AMMEXBLKS.sum", eb);
   }
   return(eb);
}

ATL_mmnode_t *GetGenKernForNB(char pre, int nb)
{
   static ATL_mmnode_t *mmb=NULL;
   ATL_mmnode_t *mp=NULL, *pM=NULL, *pK=NULL;
   char upr = pre;

   if (upr == 'z')
      upr = 'd';
   if (upr == 'c')
      upr = 's';

   if (!nb)
   {
      if (mmb)
         KillAllMMNodes(mmb);
      return(NULL);
   }
   if (!mmb)
   {
      mmb = ReadMMFileWithPath(upr, "res", "gAMMRES.sum");
      assert(mmb);
      for (mp=mmb; mp; mp = mp->next)
      {
         if (mp->genstr)
            free(mp->genstr);
         if (mp->rout)
            free(mp->rout);
         mp->genstr = mp->rout=NULL;
      }
   }
/*
 * See if any existing kernel can handle this case, modulo ku/kb
 */
   for (mp=mmb; mp; mp = mp->next)
   {
      if ((nb%(mp->mu) == 0) && (nb%(mp->nu) == 0))
      {
         if (!FLAG_IS_SET(mp->flag, MMF_KVEC))
         {
            if (!pM)
               pM = mp;
         }
         else if (!pK && (nb%mp->vlen == 0))  /* K-vec must match on vlen too */
            pK = mp;
      }
      if (pK && pM)
         break;
   }
/*
 * If we've got either pM or pK, all we need to do is possibly adjust kb/ku
 * With same vector length, we'll just take the first one that works.
 */
   if (pM || pK)
   {
      if (pM)
         mp = CloneMMNode(pM);
      else
         mp = CloneMMNode(pK);
      if (FLAG_IS_SET(mp->flag,MMF_KUISKB))
         mp->kbmax = mp->kbmin = mp->ku = mp->kbB = nb;
      else if (nb%(mp->ku))
         mp->ku = (pM) ? 1 : mp->vlen;
      mp->mbB = mp->nbB = mp->kbB = nb;
      mp->rout = MMGetGenName(pre, nb, mp);
      mp->genstr = MMGetGenString(pre, mp);
      return(mp);
   }
/*
 * If changing K info isn't enough, we'll have to make a new kernel that
 * changes possibly a bunch of stuff, including vlen
 *
 * Try to find both a M- & K-vec kernel as a candidate.  Since no kernel
 * working tends to happen more with small NB, prioritize end of queue.
 */
   for (mp=mmb; mp; mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         pK = mp;
      else
         pM = mp;
   }

/*
 * Find a legal M-vec (or unvectorized) kernel based on best M kernel
 */
   if (pM)
   {
      int vl=pM->vlen, u;
      mp = CloneMMNode(pM);
/*
 *    Find a vlen compatible with this MB; may become 1 -> unvectorized
 */
      while (vl > 1 && nb % vl)  /* make vlen evenly divide nb */
         vl >>= 1;
      mp->vlen = vl;
      mp->mu = (pM->mu / pM->vlen) * vl;  /* use same # of regs */
/*
 *    Make mu evenly divide MB (vl already does)
 */
      for (u=mp->mu; u > vl && nb%u; u -= vl);
      assert(nb%u == 0);
      mp->mu = u;
/*
 *    Make nu evenly divide NB
 */
      for (u=mp->nu; nb%u; u--);
      if (FLAG_IS_SET(mp->flag, MMF_NOBCAST))
      {
         if (u > vl)
            u = (u/vl)*vl;
         else
            mp->flag &= (1<<MMF_NOBCAST);
      }
      mp->nu = u;
/*
 *    Make ku evenly divide KB
 */
      if (nb%(mp->ku) != 0)
         mp->ku = 1;
@skip      for (u=mp->ku; nb%u; u--);
@skip      mp->ku = u;
      pM = mp;
   }
/*
 * Find a legal K-vec kernel if possible
 */
   if (pK)
   {
      int mu=0, nu=0, vl;
      mp = NULL;
/*
 *    Make vlen evenly divide KB
 */
      for(vl=pK->vlen; vl > 1 && nb%vl; vl >>= 1);
      if (vl > 1)
      {
         int i, j;
         float minrat=0.0;
/*
 *       Find mu & nu such that mu*nu % vl == 0
 */
         for (i=pK->mu; i > 0; i--)
         {
            for (j=pK->nu; j > 0; j--)
            {
               if ((i*j)%vl == 0 && i%nb == 0 && j%nb == 0)
               {
                  float ratio = (i+j)/(i*j);
                  if (minrat == 0.0 || ratio < minrat)
                  {
                     minrat = ratio;
                     mu = i;
                     nu = j;
                  }
               }
            }
         }
/*
 *       Do we have a legal k-vectorized kernel?
 */
         if (vl > 1 & mu > 1 && nu > 1)
         {
/*
 *          Make ku divide KB & vl
 */
            i = pK->ku;
            if (i%vl)
            {
               if (i > vl)
                  i = (i/vl)*vl;
               else
                  i = vl;
            }
            for (; i > vl && nb%i; i -= vl);
            if (nb%i)
            {
               mp = pK = CloneMMNode(pK);
               pK->vlen = vl;
               pK->mu = mu;
               pK->nu = nu;
               pK->ku = i;
            }
         }
      }
      pK = mp;
   }
/*
 * If we've found no legal kernel, create a scalar kernel that will work
 */
   if (!pM && !pK)
   {
      mp = pM = GetMMNode();
      mp->mu = (nb&3) ? 1 : 4;
      if (nb%6 == 0)
         mp->mu = 6;
      else if ((nb & 3) == 0)
         mp->mu = 4;
      if ((nb & 1) == 0)
         mp->mu = 2;
      else
         mp->mu = 1;
      mp->nu = mp->ku = mp->vlen = 1;
   }
/*
 * put best kernel in pM, free other
 */
   if (pM && pK)  /* wt both K & M, guess best */
   {
      if (pK->vlen > pM->vlen)
      {
         KillMMNode(pM);
         pM = pK;
      }
      else if (pM->vlen > pK->vlen)
         KillMMNode(pK);
      else /* vlen same, break tie on relative speed & load/use ratio */
      {
         double krat, mrat;
         krat = (pK->mu + pK->nu);
         krat /= (pK->mu * pK->nu);
         mrat = pK->mu / pK->vlen;
         mrat = (mrat+pK->nu) / (mrat*pK->nu);
         if (pM->mflop[0] != 0.0 && pK->mflop[0] != 0)
            krat *= pM->mflop[0] / pK->mflop[0];
         if (krat < 0.0)
            krat = -krat;
         if (krat < mrat)
         {
            KillMMNode(pM);
            pM = pK;
         }
         else
            KillMMNode(pK);
      }
   }
   else if (!pM)
      pM = pK;
   assert(pM);
   if (!FLAG_IS_SET(pM->flag,MMF_KRUNTIME))
      pM->kbB = nb;
   pM->rout = MMGetGenName(pre, nb, pM);
   pM->genstr = MMGetGenString(pre, pM);
   pM->mbB = pM->nbB = pM->kbB = nb;
   return(pM);
}
@beginskip
ATL_mmnode_t *GetGenKernForNB(char pre, int nb)
{
   static ATL_mmnode_t *mmM=NULL, *mmK=NULL;
   ATL_mmnode_t *mp=NULL, *kp=NULL;
   char upr = pre;

   if (upr == 'z')
      upr = 'd';
   if (upr == 'c')
      upr = 's';

   if (!nb)
   {
      if (mmM)
         KillAllMMNodes(mmM);
      if (mmK)
         KillAllMMNodes(mmK);
      return(NULL);
   }
   if (!mmM)
   {
      mmM = ReadMMFileWithPath(upr, "res", "gmvAMMUR.sum");
      if (mmM)
      {
         if (mmM->next)
         {
            KillAllMMNodes(mmM->next);
            mmM->next = NULL;
         }
         if (mmM->genstr)
            free(mmM->genstr);
         if (mmM->rout)
            free(mmM->rout);
         mmM->genstr = mmM->rout=NULL;
      }
   }
   if (!mmK)
   {
      mmK = ReadMMFileWithPath(upr, "res", "gkvAMMUR.sum");
      if (mmK)
      {
         if (mmK->next)
         {
            KillAllMMNodes(mmK->next);
            mmK->next = NULL;
         }
         if (mmK->genstr)
            free(mmK->genstr);
         if (mmK->rout)
            free(mmK->rout);
         mmK->genstr = mmK->rout=NULL;
      }
   }
   assert(mmM || mmK);
/*
 * Find a legal M-vec (or unvectorized) kernel based on best M kernel
 */
   if (mmM)
   {
      int vl=mmM->vlen, u;
      mp = CloneMMNode(mmM);
/*
 *    Find a vlen compatible with this MB; may become 1 -> unvectorized
 */
      while (vl > 1 && nb % vl)  /* make vlen evenly divide nb */
         vl >>= 1;
      mp->vlen = vl;
      mp->mu = (mmM->mu / mmM->vlen) * vl;  /* use same # of regs */
/*
 *    Make mu evenly divide MB (vl already does)
 */
      for (u=mp->mu; u > vl && nb%u; u -= vl);
      mp->mu = u;
/*
 *    Make nu evenly divide NB
 */
      for (u=mp->nu; nb%u; u--);
      if (FLAG_IS_SET(mp->flag, MMF_NOBCAST))
      {
         if (u > vl)
            u = (u/vl)*vl;
         else
            mp->flag &= (1<<MMF_NOBCAST);
      }
      mp->nu = u;
/*
 *    Make ku evenly divide KB
 */
      for (u=mp->ku; nb%u; u--);
      mp->ku = u;
   }
/*
 * Find a legal K-vec kernel if possible
 */
   if (mmK)
   {
      int mu=0, nu=0, vl;
/*
 *    Make vlen evenly divide KB
 */
      for(vl=mmK->vlen; vl > 1 && nb%vl; vl >>= 1);
      if (vl > 1)
      {
         int i, j;
         float minrat=0.0;
/*
 *       Find mu & nu such that mu*nu % vl == 0
 */
         for (i=mmK->mu; i > 0; i--)
         {
            for (j=mmK->nu; j > 0; j--)
            {
               if ((i*j)%vl == 0 && i%nb == 0 && j%nb == 0)
               {
                  float ratio = (i+j)/(i*j);
                  if (minrat == 0.0 || ratio < minrat)
                  {
                     minrat = ratio;
                     mu = i;
                     nu = j;
                  }
               }
            }
         }
/*
 *       Do we have a legal k-vectorized kernel?
 */
         if (vl > 1 & mu > 1 && nu > 1)
         {
/*
 *          Make ku divide KB & vl
 */
            i = mmK->ku;
            if (i%vl)
            {
               if (i > vl)
                  i = (i/vl)*vl;
               else
                  i = vl;
            }
            for (; i > vl && nb%i; i -= vl);
            if (nb%i)
            {
               kp = CloneMMNode(mmK);
               kp->vlen = vl;
               kp->mu = mu;
               kp->nu = nu;
               kp->ku = i;
            }
         }
      }
   }
/*
 * put best kernel in mp, free other
 */
   if (mp && kp)  /* wt both K & M, guess best */
   {
      if (kp->vlen > mp->vlen)
      {
         KillMMNode(mp);
         mp = kp;
      }
      else if (mp->vlen > kp->vlen)
         KillMMNode(kp);
      else /* vlen same, break tie on relative speed & load/use ratio */
      {
         double krat, mrat;
         krat = (kp->mu + kp->nu);
         krat /= (kp->mu * kp->nu);
         mrat = kp->mu / kp->vlen;
         mrat = (mrat+kp->nu) / (mrat*kp->nu);
         if (mmM->mflop[0] != 0.0 && mmK->mflop[0] != 0)
            krat *= mmM->mflop[0] / mmK->mflop[0];
         if (krat < 0.0)
            krat = -krat;
         if (krat < mrat)
         {
            KillMMNode(mp);
            mp = kp;
         }
         else
            KillMMNode(kp);
      }
   }
   else if (!mp)
      mp = kp;
   assert(mp);
   mp->rout = MMGetGenName(pre, nb, mp);
   mp->genstr = MMGetGenString(pre, mp);
   return(mp);
}
@endskip

void PrintGen0(FILE *fp, ATL_mmnode_t *mp, int mb, int nb, int kb)
{
   fprintf(fp, "B=(%d,%d,%d), U=(%d,%d,%d), pf=(%x,%d), flg=%x",
           mb?mb:mp->mbB, nb?nb:mp->nbB, kb?kb:mp->kbB, mp->mu, mp->nu,
           FLAG_IS_SET(mp->flag, MMF_KUISKB) ? -1:mp->ku, 
           mp->pref, mp->pfLS, mp->flag);
}

void PrintGen(FILE *fp, ATL_mmnode_t *mp, int mb, int nb, int kb, double mf)
/*
 * Prints single line description of mp to fp
 */
{
   fprintf(fp, "   0.");
   PrintGen0(fp, mp, mb, nb, kb);
   fprintf(fp, ": MFLOP=%.0f\n", mf);
}

ATL_mmnode_t *BestForThisNB
(
   int verb, 
   char pre, 
   ATL_mmnode_t *mmb, 
   int nb, 
   int pnb,  /* previous nb */
   int nnb   /* next nb */
)
/*
 * Times all kernels in mmb
 * RETURNS: ptr to best performing kernel, empty gen node if no user case wrks
 */
{
   ATL_mmnode_t *mmp, *mmB=NULL;
   double mf, mf0, mfB=0.0;

   printf("SCOPING FOR BEST PERFORMING KERNEL FOR NB=%d\n", nb);
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      const int kb0 = mmp->kbB, ku0 = mmp->ku;
      char *gs0=mmp->genstr;
      int kb, kbOK;
/*
 *    Choose kb, if forced only kb will do, so skip if kernel can't do it
 *    Genned kerns can be adapted, so are checked differently frm user kerns.
 */
      if (!mmp->ID)  /* kvec OK wt any mul of vlen, mvec OK wt any K */
         kbOK = FLAG_IS_SET(mmp->flag, MMF_KVEC) ? (nb%mmp->vlen == 0):1;
      else
      {
         kbOK = (mmp->kbmin) ? (nb >= mmp->kbmin) : 1;
         if (kbOK && mmp->kbmax)
            kbOK = nb <= mmp->kbmax;
      }
      if (!kbOK || ((nb/mmp->mu)*mmp->mu != nb) || ((nb/mmp->nu)*mmp->nu != nb)
          || ((nb/mmp->ku)*mmp->ku != nb) || (nb == pnb) || (nb == nnb))
      {
         
         printf("   %d. %s: SKIPPED, bad NB\n", mmp->ID, mmp->rout);
         continue;
      }
/*
 *    Generated files may need to get genstr and related info corrected
 */
      if (mmp->ID == 0)
      {
         if (FLAG_IS_SET(mmp->flag, MMF_KUISKB))
             mmp->kbmax = mmp->kbmin = mmp->ku = mmp->kbB = nb;
         if (!FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
             mmp->kbB = nb;
         mmp->genstr = MMGetGenString(pre, mmp);
      }
      mf0 = TimeMMKernel(verb, 0, mmp, pre, nb, nb, nb, 1, 0, -1);
      if (mmp->ID == 0)  /* put original info back in queue */
      {
         free(mmp->genstr);
         mmp->genstr = gs0;
         mmp->kbB = kb0;
         mmp->ku = ku0;
      }
/*
 *    Give bonus to K-runtime variable over K-compile time; K-runtime kernels
 *    can be used for some K-cleanup, and they can be used for any required KB
 *    as well as being typically much smaller instruction load, so they are
 *    strongly preferred
 */
      mf = FLAG_IS_SET(mmp->flag, MMF_KRUNTIME) ? mf0*KRUNMUL : mf0;
      if (mf > mfB)
      {
         mfB = mf;
         mmB = mmp;
         mmB->mbB = mmB->nbB = mmB->kbB = nb;
      }
      if (mmp->ID)
         printf("   %d. %s: kb=%d, flg=%x, MFLOP=%.2f\n", 
                mmp->ID, mmp->rout, nb, mmp->flag, mf0);
      else
         PrintGen(stdout, mmp, nb, nb, nb, mf0);
   }
   if (mmB)
   {
      mmB = CloneMMNode(mmB);
      mmB->mflop[0] = mfB;
      if (!mmB->ID)  /* specialize generated code for this KB */
      {
         if (mmB->genstr)
            free(mmB->genstr);
         if (mmB->rout)
            free(mmB->rout);
         mmB->mbB = mmB->nbB = mmB->kbB = nb;
         if (FLAG_IS_SET(mmB->flag, MMF_KUISKB))
             mmB->kbmin = mmB->kbmax = mmB->ku = nb;
         mmB->rout = MMGetGenName(pre, nb, mmB);
         mmB->genstr = MMGetGenString(pre, mmB);
      }
   }
   else
   {
      mmB = GetGenKernForNB(pre, nb);
      assert(mmB);
   }
   if (MMKernelFailsAnyBeta(pre, nb, nb, nb, mmB))
   {
      printf("BEST KERNEL FAILS TESTER FOR NB=%d\n", nb);
      exit(1);
   }
   mmB->mflop[0] = TimeMMKernel(verb, 0, mmB, pre, nb, nb, nb, 1, 0, -1);
   printf("BEST KERNEL FOUND FOR NB=%d: ID#%d '%s' %.2f MFLOPS\n\n", 
          nb, mmB->ID, mmB->rout, mmB->mflop[0]);
   return(mmB);
}

int DeleteBadBigNBs(ATL_mmnode_t *mmb, int *nbs)
{
   ATL_mmnode_t *best=NULL, *mmp;
   double mfB=0.0;
   int n=0;
/*
 * Find the best-performing kernel
 */
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      double mf;
      mf = mmp->mflop[0];
      if (mf > mfB)
      {
         mfB = mf;
         best = mmp;
      }
   }
/*
 * Delete all NBs larger than best
 */
   while (best->next)
   {
      best->next = KillMMNode(best->next);
      n++;
   }
   if (n)
   {
      int N = *nbs;
      N = (N >= 0) ? N : -N;
      printf("Deleted %d large, slow kernels starting at NB=%d\n", 
             n, nbs[N-n+1]);
   }
   return(n);
}

@ROUT uammsearch
ATL_mmnode_t *FindBestForEachNB(int verb, char pre, ATL_mmnode_t *mmb, int *nbs)
{
   int i, n, FORCE=0;
   ATL_mmnode_t *best, *bp;
/*
 * If # of nbs is negative, then each nb is required and that exact size
 * will be used, or no NB of that size if no kernel works.  The normal behavior
 * is the exact size of forced for all nb <= 16, and inexact for larger
 */
   n = nbs[0];
   if (n < 0)  /* negative # of nbs says force exact NB or nothing */
   {
      n = -n;
      FORCE = 1;
   }
   bp = best = BestForThisNB(verb, pre, mmb, nbs[1], 0, (n == 1)?nbs[1]:0,
                             FORCE);
   for (i=2; i <= n; i++)
   {
      int pnb = nbs[i-1], nnb = (i < n) ? nbs[i+1]:0;
      bp->next = BestForThisNB(verb, pre, mmb, nbs[i], pnb, nnb, FORCE);
      bp = bp->next;
   }
   if (!FORCE)
      i = DeleteBadBigNBs(best, nbs);
   return(best);
}

@ROUT ammsearch
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr, 
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
@skip    fprintf(stderr, "   -o <outfile>: output file (res/<pre>uAMMRES.sum)\n");
   fprintf(stderr, "   -n # nb1 ... nb# : NBs to try for\n");
   fprintf(stderr, "   -N # nb1 ... nb# : force exact NBs in search\n");
   fprintf(stderr, "   -r <nreg> : set max # of registers to try\n");
   fprintf(stderr, "   -b <nb>   : set initial block factor to try\n");
   fprintf(stderr, "   -v <verb> : set verbosity (1)\n");
   exit(ierr ? ierr : -1);
}

void GetFlags(int nargs, char **args, char *PRE, int *verb, int *NREG, 
              int *NB, int *CS)
{
   ATL_mmnode_t *mmb=NULL, *mp;
   int B0, BN;
   int i, j=0, n, k;
   char pre='d';
   int *nbs=NULL;
   *NREG = *NB = 0;
   *verb = 1;
   *CS = 0;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);
      
      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        break;
      case 'r':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *NREG = atoi(args[i]);
         break;
      case 'v':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *verb = atoi(args[i]);
         break;
      case 'b':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *NB = atoi(args[i]);
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   *PRE = pre;
/*
 * NREG has been stored by search in ivar.  Read it, and then zero ivar so
 * it won't propogate, making .sum files confusing
 */
   if (*NREG == 0)
   {
      ATL_mmnode_t *mp;
      char upr=pre;
      if (pre == 'z')
         upr = 'd';
      else if (pre == 'c')
         upr = 's';
      mp = ReadMMFileWithPath(upr, "res", "gmvAMMUR.sum");
      if (mp)
      {
         *NREG = mp->ivar;
         KillAllMMNodes(mp);
      }
   }
   if (*CS == 0)
      *CS = GetL1CacheElts(pre);
}
@ROUT ammsearch uammsearch
static void ApplyMoves2Flag
(
   ATL_mmnode_t *mmp,  /* kernel to set MMF_MV[A,B,C] flag bits */
   int mvBits          /* last 3 bits: MOVE_[CBA] */
)
{
   int flag = mmp->flag & (~MMF_MVSET);         /* zero existing move bits */
   mmp->flag = flag | ((mvBits & 7)<<MMF_MVA); /* put new move bits in */
}
static void ApplyMoves2Flags
(
   ATL_mmnode_t *mmb,  /* kernel to set MMF_MV[A,B,C] flag bits */
   int mvBits          /* last 3 bits: MOVE_[CBA] */
)
{
   const unsigned int mvMSK = ~MMF_MVSET, mvSET = (mvBits&7)<<MMF_MVA;
   ATL_mmnode_t *mmp;
   for (mmp=mmb; mmp; mmp = mmp->next)
      mmp->flag = ((mmp->flag) & mvMSK) | mvSET;
}

ATL_mmnode_t *GetNewKCleanGenNode
(
   char pre, 
   ATL_mmnode_t *kp,  /* kernel we are generating K-cleanup for */
   int mb, 
   int nb, 
   int kb
)
{
   ATL_mmnode_t *p;
   const int mu=kp->mu, nu=kp->nu;
   int kvec=0, ku=1, vl, vmu;
   int kmaj = FLAG_IS_SET(kp->flag, MMF_KVEC) ? kp->vlen:0;

   if (kmaj > 1)
   {
      kvec = 1;
      ku = vl = kmaj;
@skip      assert((mu*nu)%vl == 0);  /* impossible for legal code */
   }
   else
   {
      if (kp->vlen)
      {
         vl = kp->vlen;
         if (mu%vl)
         {
            fprintf(stderr, "kern=%d '%s', mu=%d, vlen=%d\n", kp->ID,
                    kp->rout?kp->rout:"NULL", kp->mu, kp->vlen);
         }
         assert(mu%vl == 0);
      }
      else
         vl = 1;
   }
   printf("  TRY: mu=%d, nu=%d, ku=%d, vl=%d, kvec=%d\n", mu, nu, ku, vl, kvec);
   p = MMGetNodeGEN(pre, 0, 0, mu, nu, ku, vl, kvec, 0, 0, NULL);
   p->mbB = mb;
   p->nbB = nb;
   p->kbB = kb;
   return(p);
} 

ATL_mmnode_t *FindDefMUNU(int verb, char pre, int nreg, int lat, int nb, int ku,
                          int *MU, int *NU)
{
   ATL_mmnode_t *mmp;
   double mf, mfB=0.0;
   int n, i, j, kb, muB=1, nuB=1, VL, chkVL=0;

/*   mmp = ReadMMFileWithPath(pre, "res", "gAMMMUNU.sum"); */
   mmp = NULL;
   if (mmp)
   {
      MMFillInGenStrings(pre, mmp);
      nb = mmp->kbB;
      if (mmp->mflop[0] < 0.0)
         mmp->mflop[0] = TimeMMKernel(verb, 1, mmp, pre, nb, nb, nb, 1, 0, -1);
      printf("READ IN BEST GENNED MU=%d, NU=%d, MFLOP=%.2f\n\n", 
             mmp->mu, mmp->nu, mmp->mflop[0]);
#if 0
/*
 *    See if there is a mismatch between vector settings
 */
      if (mmp->vlen != VLEN[VECi])
      {
         printf("\n\n!!! WARNING: TURNING OFF VECTORIZATION DUE TO MISMATCHED VLEN IN 'res/%cAMMMUNU.sum!!!!\n\n", pre);
         VECi = VTSC;
      }
      *MU = mmp->mu / VLEN[VECi];
      assert(*MU);
      *NU = mmp->nu;
@skip      KillMMNode(mmp);
#endif
      return (mmp);
   }
   VL = GetNativeVLEN(pre);
   if (!VL)
      chkVL = VL = (pre == 's' || pre == 'c') ? 4 : 2;  /* temp kludge */
   mmp = MMGetNodeGEN(pre, 0, nb, 1, 1, ku, 1, 0, 0, 0, 
                      DupString("ATL_Xamm_munu.c"));
   if (pre == 'z')
      mmp->rout[4] = 'd';
   else if (pre == 'c')
      mmp->rout[4] = 's';
   else
      mmp->rout[4] = pre;
   mmp->mbB = mmp->nbB = mmp->kbB = nb;
   mmp->vlen = VL;
/*
 * Try all near-square register blocking cases
 */
   printf("Finding best MUxNU case for nb=%d\n", nb);
   for (n=4; n < nreg; n++)
   {
      int mbu, nbu, mu, nu;
      for (j=1; j*j < n; j++);
      i = n / j;
      if (nb%i || nb%j)
         continue;
      mu = mmp->mu = i * VL;
      nu = mmp->nu = j;
      if (mmp->genstr)
        free(mmp->genstr);
      mbu = (nb >= mu) ? (nb/mu)*mu : mu;
      nbu = (nb >= nu) ? (nb/nu)*nu : nu;
      mmp->genstr = MMGetGenString(pre, mmp);
      mf = TimeMMKernel(verb, 1, mmp, pre, mbu, nbu, nb, 1, 0, -1);
      printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
      if (mf > mfB)
      {
         muB = i;
         nuB = j;
         mfB = mf;
      }
   }
/*
 * For non-AVX x86, try 1-D cases since they are 2-operand assemblies
 */
   #if (defined(ATL_GAS_x8664) || defined(ATL_GAS_x8632)) && !defined(ATL_AVX)
      printf("BEST NEAR-SQUARE CASE IS MU=%d, NU=%d, MFLOP=%.2f\n\n", 
             muB, nuB, mfB);
      printf("Finding best 1-D outer loop unrolling for nb=%d\n", nb);
      for (n=2; n < nreg; n++)
      {
         int mbu, nbu, mu, nu;
         i = 1; j = n;
         if (nb % n)
            continue;
         mu = mmp->mu = i*VL;
         nu = mmp->nu = j;
         if (mmp->genstr)
           free(mmp->genstr);
         mmp->genstr = MMGetGenString(pre, mmp);
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         mf = TimeMMKernel(verb, 1, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (mf > mfB)
         {
            muB = i;
            nuB = j;
            mfB = mf;
         }
         i = n; j = 1;
         mu = mmp->mu = i * VL;
         nu = mmp->nu = j;
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         if (mmp->genstr)
           free(mmp->genstr);
         mmp->genstr = MMGetGenString(pre, mmp);
         mf = TimeMMKernel(verb, 1, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (mf > mfB)
         {
            muB = i;
            nuB = j;
            mfB = mf;
         }
      }
   #endif

   i = FLAG_IS_SET(mmp->flag, MMF_KVEC);
   KillMMNode(mmp);
   mmp = MMGetNodeGEN(pre, 0, nb, (i)?muB:muB*VL, nuB, ku, VL, i, 0, 0, NULL);
   WriteRefreshedMMFileWithPath(pre, "res", "gAMMMUNU.sum", mmp);
@skip   KillMMNode(mmp);
   printf("BEST CASE IS MU=%d, NU=%d, MFLOP=%.2f (%.2f)\n\n", 
          muB, nuB, mf, mfB);
   *MU = muB;
   *NU = nuB;
   return(mmp);
}

#if 0
void GetMUNUbyNB(int nb, int nreg, int *MU, int *NU)
{
   int mu=(*MU), nu=(*NU), vmu=mu*VLEN;

   assert(mu && nu && !(nb%VLEN[VECi]));
   if (!(nb%vmu) && !(nb%nu))
      return;
   if (nu == 1) /* handle MUx1 by decreasing by VLEN */
   {
      int u = vmu, vlen = VLEN[VECi];
      while (u+u+1 <= nreg && nb%u)
         u += vlen;
      if (u+u+1 > nreg)
         u -= vlen;
      while (nb%u)
         u -= vlen;
      assert(u);
      *MU = u / vlen;
      return;
   }
   if (mu == 1 || nu == 1) /* handle 1-D cases by just inc/dec U */
   {
      int u = (mu == 1) ? nu : mu;
      while (u+u+1 <= nreg && nb%u)
         u++;
      if (u+u+1 > nreg)
         u--;
      while (nb%u)
         u--;
      if (mu == 1)
         *NU = u;
      else
         *MU = u;
      return;
   }
   if (nb%vmu)  /* mu can't handle NB */
   {
      int i;
/* 
 *    try increasing mu until we run out of registers
 */
      for (i=mu+1; i*nu+i+nu <= nreg; i++)
         if (!(nb%(i*VLEN[VECi])))
            break;
/*
 *    Try decreasing mu until it divides
 */
      if (nb%(i*VLEN[VECi]) || i*nu+i+nu > nreg)
      {
         for (mu--; mu; mu--)
            if (!(nb%(mu*VLEN[VECi])))
               break;
      }
      else
         mu = i;
   }
   if (nb%nu)  /* nu can't handle NB */
   {
      int i;
/* 
 *    try increasing nu until we run out of registers
 */
      for (i=nu+1; i*mu+i+mu <= nreg; i++)
         if (!(nb%i))
            break;
/*
 *    Try decreasing nu until it divides
 */
      if (nb%i || i*mu+i+mu > nreg)
      {
         for (nu--; nu; nu--)
            if (!(nb%nu))
               break;
      }
      else
         nu = i;
   }
   *MU = mu;
   *NU = nu;
}
#endif

int FindNBInArray(int nb, int *nbs)
/*
 * RETURNS: location+1, or 0 if not found
 */
{
   int i, n = (nbs[0] > 0) ? nbs[0] : -nbs[0];
   for (i=1; i <= n; i++)
       if (nbs[i] == nb)
          return(i);
   return(0);
}
#if 0
ATL_mmnode_t *CreateGenCasesFromNBs
(
   ATL_mmnode_t *mmb,   /* best user-contributed kernels */
   char pre,            /* precision: s/d */
   int *nbs,            /* list of desired NBs */
   int nreg,            /* upper bound on register use */
   int MU, int NU,      /* default M/N unrolling */
   int KU               /* -1 for fully unrolled, else unrolling factor */
)
/*
 * Generate a list of generated kernels, with the union of nb's in nbs
 * and mmb, and return the generated nodes for timing.
 * HERE HERE HERE: this code is crap, needs to merge both lists, not user
 * list twice.
 */
{
   ATL_mmnode_t *mp, *umb=NULL, *ap;
   int i, n = (nbs[0] > 0) ? nbs[0] : -nbs[0], ne=0, *enbs;

/*
 * Create new queue with an entry for all NBs; both lists (mmb & nbs) are
 * sorted in increasing size
 */
   if (!n && !mmb)
      return(NULL);
   n++;
   ap = mmb;  /* add ptr */
   i = 1;     /* ptr to normal block under consideration */
   do
   {
      int nb, mu=MU, nu=NU, ku;
      ATL_mmnode_t *p=NULL;
      if (ap && i < n)  /* must choose amongst blocks */
      {
         nb = ap->kbB;
         nb = Mmin(nb, nbs[i]);
         if (nb == ap->kbB)
            ap = ap->next;
         if (nb == nbs[i])
            i++;
      }
      else if (ap)
      {
         nb = ap->kbB;
         ap = ap->next;
      }
      else
         nb = nbs[i++];
      ku = (KU == -1) ? nb : KU;
   
/*
 *    If NB is not a multiple of VLEN, drop down to shorter ops
 */
      if (nb%VLEN[VECi])
      {
         int vl=VECi;
/*
 *       For AVX, see if dropping to SSE will fix problem
 */
         if (VECi == VTAVX && !(nb%VLEN[VTSSE]))  /* AVX can drop to SSE */
         {
            VECi = VTSSE;
            GetMUNUbyNB(nb, nreg, &mu, &nu);
            p = GetNewGenNode(pre, nb, 0, mu, nu, ku, 0);
         }
         if (!p)
         {
            VECi = VTSC;
            GetMUNUbyNB(nb, nreg, &mu, &nu);
            p = GetNewGenNode(pre, nb, 0, mu, nu, ku, 0);
         }
         VECi = vl;
      }
      else
      {
         GetMUNUbyNB(nb, nreg, &mu, &nu);
         p = GetNewGenNode(pre, nb, 0, mu, nu, ku, 0);
      }
      if (umb)
      {
         mp->next = p;
         mp = p;
      }
      else
         umb = mp = p;
   }
   while (i < n || ap);
   return(umb);
}
void SetGenVec(int verb, char pre)
/*
 * This routine uses a simple timing to be sure if vectorization helps or not
 */
{
   ATL_mmnode_t *mp;
/*
 * If vector operations are being used, make sure they work; compiler and
 * flag changes can mess them up, and in this case we'll fall back to
 * scalar generation.  Try to see if we can successfully test simplist
 * possible vector kernel, and fall back to scalar kernel if we can't
 */
   if (VLEN[VECi] < 2)
      return;
   mp = GetNewGenNode(pre, 32, 0, 1, 1, 1, 0);
   if (MMKernelFailsTest(pre, 32, 32, 32, 1, mp))
   {
      printf("ERROR: VEC='%s' FAILED, genstr='%s'!\n",VECs[VECi],mp->genstr);
      KillMMNode(mp);
/*
 *    For AVX, try falling back to SSE
 */
      if (VECi == VTAVX)
      {
         VECi = VTSSE;
         KillMMNode(mp);
         mp = GetNewGenNode(pre, 32, 0, 1, 1, 1, 0);
         if (MMKernelFailsTest(pre, 32, 32, 32, 1, mp))
            VECi = VTSC;
      }
      else
         VECi = VTSC;
   }
   KillMMNode(mp);
/*
 * For AVX, switch to SSE if AVX doesn't offer a performance advantage
 * (as on AMD Dozer), since SSE smaller code size and requires less cleanup 
 */
   if (VECi == VTAVX)
   {
      double mfA, mfS, mf;
      char *sp; 
      int vl;
      mp = GetNewGenNode(pre, 128, 0, 1, 4, 1, 0);
      mfA = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      KillMMNode(mp);
      mp = GetNewGenNode(pre, 128, 0, 2, 2, 1, 0);
      mf = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      KillMMNode(mp);
      if (mf > mfA)
         mfA = mf;
      vl = VECi;
      VECi = VTSSE;
      mp = GetNewGenNode(pre, 128, 0, 1, 4, 1, 0);
      mfS = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      KillMMNode(mp);
      mp = GetNewGenNode(pre, 128, 0, 2, 2, 1, 0);
      mf = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      if (mf > mfA)
         mfA = mf;
      KillMMNode(mp);
      if (mfA < 1.03*mfS)
         printf("USING SSE INSTEAD OF AVX, AVX=%.2f, SSE=%.2f\n", mfA, mfS);
      else
      {
         printf("AVX GOOD, AVX=%.2f, SSE=%.2f\n", mfA, mfS);
         VECi = vl;
      }
   }
/*
 * For any system, don't use vector instructions if they aren't faster than
 * scalar. 
 */
   if (VLEN[VECi] > 1)
   {
      double mfV, mfS;
      char *sp; 
      int vl;
      mp = GetNewGenNode(pre, 128, 0, 1, 4, 1, 0);
      mfV = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      KillMMNode(mp);
      vl = VECi;
      VECi = VTSC;
      mp = GetNewGenNode(pre, 128, 0, 1, 4, 1, 0);
      mfS = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      KillMMNode(mp);
      if (mfV < 1.05*mfS)
         printf("USING SCALAR INSTEAD OF VECTOR, VEC=%.2f, SCALAR=%.2f\n", 
                mfV, mfS);
      else
      {
         printf("VEC GOOD, VEC=%.2f, SCALAR=%.2f\n", mfV, mfS);
         VECi = vl;
      }
   }
   printf("GENERATING WITH VEC='%s', VLEN=%d\n\n", VECs[VECi], VLEN[VECi]);
}
#endif

@beginskip
ATL_mmnode_t *FindBestGenCases(int verb, char pre, int nreg, 
                               int *nbs, ATL_mmnode_t *ummb)
{
   ATL_mmnode_t *mp, *gmmU, *gmmb;
   int MU, NU;

   gmmb = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   if (gmmb)
   {
      printf("Reading in generated cases for all NBs:\n");
      MMFillInGenStrings(pre, gmmb);
      for (mp=gmmb; mp; mp = mp->next)
      {
         const int mu = (mp->vlen) ? mp->mu / mp->vlen : mp->mu;
         int kb = mp->kbB, mb = Mmax(mp->mu,kb), nb=Mmax(mp->nu,kb);
         if (mp->mflop[0] < 0.0)
            mp->mflop[0] = TimeMMKernel(verb, 1, mp, pre, mb, nb, kb, 1, 0, -1);
         printf("  NB=%d, MU=%d, NU=%d, vlen=%d, MFLOP=%.2f\n", 
                nb, mu, mp->nu, mp->vlen, mp->mflop[0]);
      }
      WriteMMFileWithPath(pre, "res", "gAMMRES.sum", gmmb);
      printf("Done.\n\n");
      return(gmmb);
   }
   SetGenVec(verb, pre);
/*
 * Find the best mu/nu for NB=120; we don't care if we overflow cache for
 * this timing, and 120 = LCM(2,3,4,5,6,8,12).  Use ku=1 so that large
 * problems don't have large K-driven advantage.
 */
   KillMMNode(FindDefMUNU(verb, pre, nreg, 0, 120, 1, &MU, &NU));
   gmmb = CreateGenCasesFromNBs(ummb, pre, nbs, nreg, MU, NU, 1);
   if (verb > 1)
   {
      printf("\n");
      PrintMMNodes(stdout, gmmb);
      printf("\n");
   }
   printf("Finding generated cases for all NBs:\n");
   for (mp=gmmb; mp; mp = mp->next)
   {
      int mu;
      mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB, mp->kbB, 
                                  1, 0, -1);
      mu = (mp->vlen) ? mp->mu / mp->vlen : mp->mu;
      printf("   NB=%d, mu=%d, nu=%d, vlen=%d, MFLOPS=%.2f\n", 
             mp->kbB, mu, mp->nu, mp->vlen, mp->mflop[0]);
   }
   printf("Done.\n\n");
   WriteMMFileWithPath(pre, "res", "gAMMRES.sum", gmmb);
   return(gmmb);
}
@endskip


@ROUT uammsearch
ATL_mmnode_t *FindBestUserCases(int verb, char pre, int *nbs, ATL_mmnode_t *mmb)
/*
 * NOTE: frees mmb after search!!
 * RETURNS: list of the best user case for each supplied NB; if no user case
 *          works, special "generated" node is returned for later filling out.
 */
{
   ATL_mmnode_t *mmp, *mp;
   mp = ReadMMFileWithPath(pre, "res", "uAMMRES.sum");
/*
 * If final output file exists, then we need to rerun timings at worst
 */
   if (mp)
   {
      KillAllMMNodes(mmb);
      for (mmp=mp; mmp; mmp = mmp->next)
      {
         if (mmp->ID > 0 && mmp->mflop[0] < 0.0)
            mmp->mflop[0] = TimeMMKernel(verb, 0, mmp, pre, mmp->mbB, mmp->nbB,
                                         mmp->kbB, 1, 0, -1);
         if (mmp->ID > 0)
            printf("USER KERNEL AT NB=%d gets MFLOP=%.2f\n",
                   mmp->kbB, mmp->mflop[0]);
         else
            printf("NO USER KERNEL FOR NB=%d\n", mmp->kbB);
      }
      printf("\n");
      return(mp);
   }
   mmp = FindBestForEachNB(verb, pre, mmb, nbs);
   KillAllMMNodes(mmb);
   WriteMMFileWithPath(pre, "res", "uAMMRES.sum", mmp);
   return(mmp);
}

@ROUT ammsearch uammsearch gmmsearch
ATL_mmnode_t *MergeCases
(
   int imf,
   ATL_mmnode_t *bs0, /* queue of cases */
   ATL_mmnode_t *bs1  /* queue of cases */
)
/*
 * Merges two queues of matmul kern cases.  Cases are not winnowed, but
 * duplicates are not allowed, so if two entries have the same kbB, then
 * we take the one with best mflop[imf].  If imf < 0, then we do indeed
 * allow duplicates of kbB.
 * NOTE: does not change bs0 or bs1.
 * ASSUMES: both bs0 & bs1 are in kb-increasing order.
 * RETURNS: base ptr to merged queue
 */
{
   ATL_mmnode_t *mb=NULL, *mp;
   while (bs0 || bs1)
   {
      ATL_mmnode_t *p;
      if (bs0 && bs1)
      {
         if (bs0->kbB < bs1->kbB)
         {
            p = CloneMMNode(bs0);
            bs0 = bs0->next;
         }
         else if (bs0->kbB > bs1->kbB)
         {
            p = CloneMMNode(bs1);
            bs1 = bs1->next;
         }
         else /* they are equal, must take best performer, or both */
         {
/*
 *          If we are taking both, special case can't use general completion
 */
            if (imf < 0)
            {
               p = CloneMMNode(bs0);
               bs0 = bs0->next;
               p->next = CloneMMNode(bs1);
               bs1 = bs1->next;
               if (mb)
                  mp->next = p;
               else
                  mb = p;
               mp = p->next;
               continue;
            }
/*
 *          Taking only the best performer, but moving both base ptrs
 */
            else
            {
/*
 *             If they are equal, take the KRUN=1 case if it exists, else
 *             take the most flexible one or one requiring the least cleanup
 */
               if (bs0->mflop[imf] == bs1->mflop[imf])
               {
                  if (FLAG_IS_SET(bs0->flag, MMF_KRUNTIME))
                     p = bs0;
                  else if (FLAG_IS_SET(bs1->flag, MMF_KRUNTIME))
                     p = bs1;
                  else if (bs0->ku < bs1->ku)
                     p = bs0;
                  else if (bs1->ku < bs0->ku)
                     p = bs1;
                  else
                  {
                     const int u0=Mmax(bs0->mu, bs0->nu), 
                               u1=Mmax(bs1->mu, bs1->nu);
                     p = (u0 <= u1) ? bs0 : bs1;
                  }
               }
               else
                  p = (bs0->mflop[imf] > bs1->mflop[imf]) ? bs0 : bs1;
               p = CloneMMNode(p);
               bs0 = bs0->next;
               bs1 = bs1->next;
            }
         }
      }
      else if (bs0)
      {
         p = CloneMMNode(bs0);
         bs0 = bs0->next;
      }
      else /* if (bs1) */
      {
         p = CloneMMNode(bs1);
         bs1 = bs1->next;
      }
      if (mb)
      {
         mp->next = p;
         mp = p;
      }
      else
        mp = mb = p;
   }
   return(mb);
}
@ROUT ammsearch uammsearch

#define HUGE_NB 180
ATL_mmnode_t *WinnowHugeNB
(
   int imf,
   ATL_mmnode_t *mb  /* queue of cases */
)
/*
 * Removes any NB >= HUGE_NB that aren't at least 2% faster than smaller cases
 */
{
   ATL_mmnode_t *mp, *p, *prev=mb;
   double mfB;

   if (!mb || !mb->next)
      return(mb);
   mp = mb->next;
/*
 * Find best-performing kernel below HUGE_NB
 */
   mfB = mp->mflop[imf];
   for (mp=mb->next; mp; mp = mp->next)
   {
      if (mp->mbB < HUGE_NB && mp->nbB < HUGE_NB && mp->kbB < HUGE_NB)
         mfB = Mmax(mfB, mp->mflop[imf]);
      else
         break;
      prev = mp;
   }
/*
 * If no kernels above threshold, return original queue
 */
   if (!mp)
      return(mb);
/* 
 * mp points to first NB above threshold, but there is no point in deleting
 * small NB if we leave large NB, so delete only from the end of queue
 */
  do
  {
     for (p=mp; p->next; p = p->next);
     if (p->mflop[imf] <= 1.02*mfB)
        mp = RemoveMMNodeFromQ(mp, p);
     else  /* stop removing stuff */
        break;
  }
  while (mp);
  prev->next = mp;
  return(mb);
}

@ROUT ammsearch uammsearch gmmsearch
ATL_mmnode_t *WinnowCases
(
   int imf,
   ATL_mmnode_t *mb  /* queue of cases */
)
/*
 * Removes any case that runs slower than a smaller case
 * RETURNS: mb with queue bad kernels deleted
 * NOTE: mb can never change, since by def nothing smaller than 1st case
 */
{
   ATL_mmnode_t *prev = mb, *mp;

   if (!mb)
      return(NULL);
@skip   mb = WinnowHugeNB(imf, mb);
   mp = mb->next;
   while (mp)
   {
      if (mp->mflop[imf] <= prev->mflop[imf])  /* kill slow KB */
         mp = prev->next = KillMMNode(mp);
      else
      {
         prev = mp;
         mp = mp->next;
      }
   }
   return(mb);
}
@ROUT ammsearch uammsearch

ATL_mmnode_t *MergeAndWinnowCases
(
   int verb, 
   char pre, 
   ATL_mmnode_t *umb, /* queue of user cases */
   ATL_mmnode_t *gmb  /* genned cases, always include NBs of umb */
)
/*
 * Merges user and gmp cases, while getting rid of cases that get worse
 * performance than their smaller blocks; FREES umb and gmb
 * RETURNS: new merged and winnowed queue
 */
{
   ATL_mmnode_t *mmb=NULL, *mmp, *gmp, *ump=umb;
   for (gmp=gmb; gmp; gmp = gmp->next)
   {
      ATL_mmnode_t *p;
      if (ump)
      {
         if (ump->kbB == gmp->kbB)
         {
            if (gmp->mflop[0] >= ump->mflop[0])
               p = CloneMMNode(gmp);
            else
               p = CloneMMNode(ump);
            ump = ump->next;
         }
         else
            p = CloneMMNode(gmp);
      }
      else
         p = CloneMMNode(gmp);
      p->next = NULL;
      if (mmb)
      {
/*
 *       If larger NB isn't faster than smaller one, kill it for nb >= 16
 */
         if (p->kbB >= 16 && mmp->mflop[0] > p->mflop[0])
            KillMMNode(p);
         else
         {
            mmp->next = p;
            mmp = p;
         }
      }
      else
         mmp = mmb = p;
   }
   KillAllMMNodes(umb);
   KillAllMMNodes(gmb);
   mmb = WinnowCases(0, mmb);
@skip   mmb = WinnowHugeNB(0, mmb);
   return(mmb);
}


@beginskip
void ApplyMoves2Flags  /* overwrites MV bits according to string */
(
   ATL_mmnode_t *mmb,  /* queue of kernels to set MMF_MV[A,B,C] flag bits */
   char *mvs           /* string passed to timer wt moves */
)
{
   ATL_mmnode_t *mmp;
   const unsigned int NOMV = ~MMF_MVSET;
   unsigned int DOMV;
   if (!mvs)
      DOMV = ((1<<MMF_MVA) | (1<<MMF_MVB));
   else
   {
      DOMV = 0;
      if (strstr(mvs, "MoveA"))
         DOMV |= (1<<MMF_MVA);
      if (strstr(mvs, "MoveB"))
         DOMV |= (1<<MMF_MVB);
      if (strstr(mvs, "MoveC"))
         DOMV |= (1<<MMF_MVC);
   }
   for (mmp=mmb; mmp; mmp = mmp->next)
      mmp->flag = (((mmp->flag) & NOMV) | DOMV);
}
@endskip

int FailKCleanTests(char pre, int nb, ATL_mmnode_t *kp)
/*
 *  This routine tests if a kernel is suitable for use in K-cleanup by
 *  doing testing with ku=1, kb=0, and tries all K values between 1 and nb
 *  RETURNS: 0 if kernel passes all tests, else non-zero
 */
{
   int i, beg, end, inc, kmaj = FLAG_IS_SET(kp->flag, MMF_KVEC) ? kp->vlen:0;;

   if (!FLAG_IS_SET(kp->flag, MMF_KRUNTIME) || 
       (kp->ku != 1 && kp->ku != kmaj))
      return(-1);
   printf("TESTING ID=%d, rout='%s', nb=%d, mu=%d, nu=%d for K-cleanup:\n",
          kp->ID, kp->rout, nb, kp->mu, kp->nu);

   if (kmaj > 1)
   {
      inc = beg = kmaj;
      end = ((nb+inc-1)/inc)*inc;
   }
   else
   {
      beg = inc = 1;
      end = nb;
   }
   for (i=beg; i <= end; i += inc)
   {
      int ierr;
      ierr = MMKernelFailsTest(pre, nb, nb, i, 0, kp);
      if (ierr)
      {
         printf("  K=%d: FAILED!\n", i);
         return(ierr);
      }
      else
         printf("  K=%d: PASSED!\n", i);
   }
   printf("PASSED ALL K-tests!\n\n");
   return(0);
}
@ROUT ammsearch  `@define kpr @AMM@`
@ROUT uammsearch `@define kpr @UMM@`
ATL_mmnode_t *GetUniqueKClean(int verb, char pre, ATL_mmnode_t *mmb)
/*
 * OUTPUT: <pre>@(kpr)KCLEAN.sum: all unique kerns to be compiled
 */
{
   ATL_mmnode_t *mp, *gmmb, *ummb, *ub, *np, **dlmm;
   int nn=0, nd=0, n=0;  /* #needed & done, total, copy of done */
   int *dl, *nl;         /* done and needed lists */
   int i;
@ROUT ammsearch
   gmmb = ReadMMFileWithPath(pre, "res", "@(kpr)KCLEAN.sum");
   if (gmmb)
   {
      printf("READING IN UNIQUE K-CLEANUP:\n");
      MMFillInGenStrings(pre, gmmb);
      for (mp=gmmb; mp; mp = mp->next)
      {
         int mb = (mp->nbB > mp->mu) ? (mp->nbB/mp->mu)*mp->mu : mp->mu;
         int nb = (mp->nbB > mp->nu) ? (mp->nbB/mp->nu)*mp->nu : mp->nu;
         int kb = (nb > 8) ? (nb>>2) : nb, KB = kb;
         int ku = mp->ku, kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;;
         if (kmaj > 1)
            KB = ((kb+ku-1)/ku)*ku;
         if (mp->mflop[0] < 0.0)
         {
            mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mb, nb, KB, 0, 0, -1);
            mp->mflop[0] *= (double)kb / (double)KB;
         }
         printf("   nb=%d,  kb=%d, mu=%d, nu=%d, MFLOP=%.2f\n", 
                nb, kb, mp->mu, mp->nu, mp->mflop[0]);
      }
      printf("Done.\n");
      return(gmmb);
   }
@ROUT ammsearch uammsearch
/*
 * Find out how many total kernels, and how many already have their own
 * cleanup (nd, number done).  This nd may be bigger than it should, because
 * we can't guarantee they are unique
 */
   for (mp=mmb; mp; mp = mp->next, n++)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if ((mp->ku == 1 || (kmaj == mp->ku)) && 
          FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
        nd++;
   }
   dl = malloc(8*n*sizeof(int));
   assert(dl);
   if (nd)
   {
      dlmm = malloc(nd*sizeof(ATL_mmnode_t*));
      assert(dlmm);
   }
   else
      dlmm = NULL;

   nl = dl + (n<<2);
   nd = 0;
/*
 * First, go back through kernels, and add kernels that can serve as K-cleaners
 * to the done list
 */
   for (mp=mmb; mp; mp = mp->next, n++)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME) && 
          (mp->ku == 1 || kmaj == mp->ku))
      {
         const int nd4 = (nd<<2), mu=mp->mu, nu=mp->nu;
/*
 *       See if trip is already in done list if so, no new entry, just update kb
 *       and cleanup kernel entry
 */
         for (i=0; i < nd4; i += 4)
            if (mu == dl[i] && nu == dl[i+1] && kmaj == dl[i+2])
               break;
         if (i < nd4)
         {                      /* (larger NB always later) */
            dl[i+3] = mp->kbB;  /* take largest kbB that matches mu/nu */
            dlmm[i>>2] = mp;
            continue;           
         }
         else
         {
            dl[nd4] = mu;
            dl[nd4+1] = nu;
            dl[nd4+2] = kmaj;
            dl[nd4+3] = mp->kbB;
            dlmm[nd++] = mp;
         }
      }
   }
/*
 * Delete any kernels from dl that fail to actually work for K cleaning
 */
   for (i=0; i < nd; i++)
   {
      if (FailKCleanTests(pre, dlmm[i]->kbB, dlmm[i]))
      {
         const int i4=(i<<2), nc=nd-i-1;
         if (nc > 0)
         {
            memcpy(dl+i4, dl+i4+4, (nc<<2)*sizeof(int));
            memcpy(dlmm[i], dlmm[i+1], nc*sizeof(ATL_mmnode_t*));
         }
         nd--;
      }
   }

/*
 * Find all unique (mu,nu,kmaj) combos that still need to to be cleaned; 
 * there will be nn (# needed) of these, and we'll save (mu,nu,MAXNB) in
 * needed list (nl).
 * We use MAXNB for testing (large NB tests mosts cases of K).
 * Combos that are handled by the done list (dl) aren't added to needed list.
 */
   for (mp=mmb; mp; mp = mp->next, n++)
   {
      int mu=mp->mu, nu=mp->nu, nn4=(nn<<2), nd4=(nd<<2);
      int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
/*
 *    See if pair is already in done list or needed list, if so, no change
 */
      for (i=0; i < nd4; i += 4)
         if (mu == dl[i] && nu == dl[i+1] && kmaj == dl[i+2])
            break;
      if (i < nd4)    /* if it was found in the done list */
         continue;    /* this combo is already handled */
/*
 *    If we reach here, combo is not handled, must add to needed list 
 */
      for (i=0; i < nn4; i += 4)
         if (mu == nl[i] && nu == nl[i+1] && kmaj == nl[i+2])
            break;
      if (i < nn4)            /* If already in needed list */
      {
         nl[i+3] = mp->kbB;   /* just update kb so we get largest for testing */
         continue;
      }
/*
 *    If we haven't seen this pair before, add to needed list
 */
      else
      {
         nl[nn4] = mu;
         nl[nn4+1] = nu;
         nl[nn4+2] = kmaj;
         nl[nn4+3] = mp->kbB;
         nn++;
      }
   }
/*
 * Now, create a queue of generated kernels for each needed pair, and time
 * it's maxNB performance.
 */
   gmmb = NULL;
   printf("Timing Generated K-cleanup:\n");
   for (i=0; i < nn; i++)
   {
      ATL_mmnode_t *p;
      const int i4 = (i<<2), mu=nl[i4], nu=nl[i4+1], kmaj=nl[i4+2];
      int nb = Mmax(nl[i4+3],nu), mb = (nb > mu) ? (nb/mu)*mu : mu, ku;
      const int kb = (nb > 8) ? (nb>>2) : nb;
      int vl=VLEN, vmu, KK;
      double mf;
/*
 *    HERE HERE: Improve KMAJ when generator is extended!
 */
      if (kmaj > 1)
      {
         while ((mu*nu)%vl)
            vl >>= 1;
         vmu = mu;
         ku = vl;
      }
      else
      {
         while (mu%vl)
            vl >>= 1;
         ku = 1;
      }
/* HERE HERE */
      p = MMGetNodeGEN(pre, 0, 0, mu, nu, ku, vl, kmaj, 0, 0, NULL);
      p->mbB = mb;
      p->nbB = nb;
      p->kbB = kb;
      p->flag |= (1<<MMF_KRUNTIME);
      #if 1  /* by default don't waste time testing generated code */
         assert(!FailKCleanTests(pre, nb, p));
      #endif
      KK = (kmaj < 2) ? kb : ((kb+kmaj-1)/kmaj)*kmaj;
      p->mflop[0] = TimeMMKernel(verb, 0, p, pre, mb, nb, kb, 0, 0, -1);
      if (KK != kb)
         p->mflop[0] *= (double)kb / (double)KK;
      printf("   nb=%d, kb=%d,  mu=%d, nu=%d, MFLOP=%.2f\n", 
             nb, kb, mu, nu, p->mflop[0]);
      if (gmmb)
      {
         mp->next = p;
         mp = p;
      }
      else
         gmmb = mp = p;
   }
   printf("Done.\n");
/*
 * Now, add the done-list items to generated list
 */
   for (i=0; i < nd; i++)
   {
      const int i4=4*i, mu=dl[i4], nu=dl[i4+1], kmaj=dl[i4+2], nb=dl[i4+3];
      ATL_mmnode_t *prev=NULL;
/*
 *    Get a copy of done-list kern that can be added to genlist
 */
      np = CloneMMNode(dlmm[i]);
      np->next = gmmb;
      gmmb = np;
   }
   if (dlmm)
      free(dlmm);
/*
 * Now, search index file for suitable user-submitted kernels to compete
 * with existing solutions
 */
   ub = ReadMMFileWithPath(pre, "AMMCASES", "amcases.idx");
   ummb = NULL;  /* no suitable user cases to begin */
/*
 * Look through user-list for any routine with ku=1 and K-Runtime
 */
   for (mp=ub; mp; mp = mp->next)
   {
      int km = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME) && 
          (mp->ku == 1 || km == mp->ku))
      {
/*
 *       It matched our gross criteria, see if it is a required mu/nu
 */
         for (i=0; i < nn; i++)
         {
            const int i4=(i<<2), mu=nl[i4], nu=nl[i4+1], kmaj=nl[i4+2], 
                      nb=nl[i4+3];
            if (mp->mu == mu && mp->nu == nu && km == kmaj)
            {
               if (!FailKCleanTests(pre, nb, mp))
               {
                  ATL_mmnode_t *p;
                  p = CloneMMNode(mp);
                  p->next = NULL;
                  p->nbB = ((nb+nu-1)/nu)*nu;
                  p->mbB = ((nb+mu-1)/mu)*mu;
                  p->kbB = nb;
                  if (ummb)
                  {
                     np->next = p;
                     np = p;
                  }
                  else
                     np = ummb = p;
                  break;
               }
            }
         }
      }
   }
   KillAllMMNodes(ub);
/*
 * If we have both user and genned code, must compare timing to select best
 */
   if (ummb)
   {
/*
 *    Now, loop over user cases and time them for comparison with genned
 */
      printf("Timing User K-cleanup:\n");
      for (mp=ummb; mp; mp = mp->next)
      {
         const int nb = mp->nbB, kb = (nb > 8) ? (nb>>2) : nb;
         const int KK = FLAG_IS_SET(mp->flag,MMF_KVEC) ? 
                   kb:((kb+mp->vlen-1)/mp->vlen)*mp->vlen;
         mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mp->mbB, nb, KK, 0,0,-1);
         if (KK != kb)
            mp->mflop[0] *= (double)kb / (double)KK;
         printf("   ID=%d, nb=%d, kb=%d, mu=%d, nu=%d, MFLOP=%.2f\n", 
                mp->ID, nb, kb, mp->mu, mp->nu, mp->mflop[0]);
      }
      printf("Done timing, merging lists:\n");
/*
 *    Merge generated (gmmb) and user (ummb) kerns by selecting best performing.
 *    gmmb is a superset of ummb, so what we will do is look through gmmb
 *    for matching (mu,nu,dup), time them, and if ummb is faster, replace
 *    that entry in gmmb with ummb.
 */
      while (ummb)
      {
         ATL_mmnode_t *prev=NULL;
         int mu=ummb->mu, nu=ummb->nu;
         int kmaj = FLAG_IS_SET(ummb->flag, MMF_KVEC) ? ummb->vlen:0;

         for (mp=gmmb; mp; mp = mp->next)
         {
            int km = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
            if (mp->mu == mu && mp->nu == nu && km == kmaj)
               break;
            prev = mp;
         }
         assert(mp);  /* logic error if we haven't found it */
/*
 *       If user case gets better performance, replace genned case in queue
 */
         if (ummb->mflop[0] > gmmb->mflop[0])
         {
            printf("   Replacing genned case (%.2f) with user ID %d (%.2f)\n",
                   gmmb->mflop[0], ummb->ID, ummb->mflop[0]);
            if (prev)
            {
               prev->next = ummb;
               ummb = ummb->next;
               prev->next->next = KillMMNode(mp);
            }
            else /* replace gmmb, mp pts at gmmb */
            {
               ATL_mmnode_t *up=ummb;
               ummb = ummb->next;
               up->next = KillMMNode(gmmb);
               gmmb = up;
            }
         }
         else /* user case loser, just delete it */
         {
            printf("   Preferring genned case (%.2f) over user ID %d (%.2f)\n",
                   gmmb->mflop[0], ummb->ID, ummb->mflop[0]);
            ummb = KillMMNode(ummb);
         }
      }
      printf("DONE.\n\n");
   }
   else
      printf("NO VALID USER-SUBMITTED K-CLEANUP KERNELS\n\n");
   free(dl);
@skip   ApplyMoves2Flags(gmmb, MOVES);  /* gen must know operand movement pattern */
   WriteRefreshedMMFileWithPath(pre, "res", "@(kpr)KCLEAN.sum", gmmb);
   return(gmmb);
}

@beginskip
int MMKernsSame(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same except for blocking, 0 otherwise
 */
{
/*
 * Two generated kernels are the same if mu,nu,ku,VLEN,flag are the same.
 * NOTE: if we make generator handle muladd, etc, MUST UPDATE HERE!!!
 */
   if (p0->ID == 0 && p1->ID == 0)
      return(p0->mu == p1->mu && p0->nu == p1->nu && p0->ku == p1->ku &&
             p0->vlen == p1->vlen && p0->flag == p1->flag);
/*
 * If both are user kernels, then they may be repeats.  For user kernels,
 * they are the same if both ID and flag match, else they are not.
 */
   else if (p0->ID > 0 && p1->ID > 0)
      return(p0->ID == p1->ID && p0->flag == p1->flag);
   return(0);  /* Can't be the same if above criteria fails */
}

int MMKernCompsSame(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same except for blocking, 0 otherwise
 */
{
/*
 * Kernels are not the same if one has compile-time K and other runtime
 */
   if (FLAG_IS_SET(p0->flag, MMF_KRUNTIME) != 
       FLAG_IS_SET(p1->flag, MMF_KRUNTIME))
      return(0);
/*
 * Kernels not same if both compilet-time K with differing KB
 */
   if (!FLAG_IS_SET(p0->flag, MMF_KRUNTIME) && p0->kbB != p1->kbB)
      return(0);
   return(MMKernsSame(p0, p1));
}
@endskip

@ROUT ammsearch uammsearch gmmsearch
int KernelIsUnique(ATL_mmnode_t *mmb, ATL_mmnode_t *mmp)
/*
 * Determines if mmp is the first mention of a unique kernel in mmb, or not.
 * For user cases (ID > 0), (ID,flag) together make a unique kernel.
 * For user generated cases, if they match on : mu,nu,ku,VLEN,flag
 *
 * RETURNS: 0 if mmp appears in mmb before mmp, else 1
 */
{
   ATL_mmnode_t *mp;
   if (mmp == mmb)
      return(1);
   for (mp=mmb; mp && mp != mmp; mp = mp->next)
      if (MMKernsPerfSame(mmp, mp))
         return(0);
   return(1);  /* didn't find it, must be first time in list */
}
@ROUT ammsearch uammsearch

@beginskip
int MMKernCompIsPresent(ATL_mmnode_t *mmb, ATL_mmnode_t *mmp)
/*
 * RETURNS: 1 if kernel compilation matching mmp is in list mmb, 0 otherwise
 */
{
   ATL_mmnode_t *mp;
   for (mp=mmb; mp; mp = mp->next)
      if (mp != mmp && MMKernCompsSame(mmp, mp))
         return(1);
   return(0);
}
@endskip

/*
 * Returns a non-repetitive list of user kernels (ID>0) found in rb.  Note that
 * differing compilations of the same kernel are reduced to one entry.
 * rb is left unchanged.
 */
ATL_mmnode_t *GetUniqueUserKerns(ATL_mmnode_t *rb)
{
   ATL_mmnode_t *ub=NULL, *p;

   if (!rb)
      return(NULL);
   for (p=rb; p; p = p->next)
      if (p->ID > 0) 
         break;
   if (!p)
      return(NULL);
   ub = CloneMMNode(p);
   for (p=p->next; p; p = p->next)
   {
       if (p->ID > 0)
       {
          ATL_mmnode_t *np;
          int ID = p->ID;

          for (np=ub; np; np = np->next)
             if (np->ID == ID)
                break;
          if (!np)
          {
             np = CloneMMNode(p);
             np->next = ub;
             ub = np;
          }
       }
   }
   return(ub);
}

static int SelfKClean(ATL_mmnode_t *mp)
{
   if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
      {
         if (mp->ku == mp->vlen && mp->kbmin == mp->vlen)
            return(1);
      }
      else if (mp->ku == 1 && mp->kbmin < 2)
         return(1);
   }
   return(0);
}

ATL_mmnode_t *CanKClean(ATL_mmnode_t *krn, ATL_mmnode_t *cln)
/*
 * RETURNS: NULL if cln/krn cannot provide K-cleanup for krn, else ptr
 *          to krn if it can do its own K-cleanup, else ptr to cln
 */
{
/*
 * First, determine if kernel can perform its own cleaning
 */
   if (SelfKClean(krn))
      return(krn);
/*
 * Cleaner must share same mu/nu, have runtime K, and handle long enough K
 */
   if (krn->mu == cln->mu && krn->nu == cln->nu && 
       FLAG_IS_SET(cln->flag, MMF_KRUNTIME) &&
      (!cln->kbmax || cln->kbmax >= krn->kbB))
   {
      int kmaj = FLAG_IS_SET(krn->flag, MMF_KVEC) ? krn->vlen:0;
      int km = FLAG_IS_SET(cln->flag, MMF_KVEC) ? cln->vlen:0;
      if (kmaj > 1)
      {
         if (km == kmaj && cln->kbmin <= kmaj)
            return(cln);
      }
      else if (cln->ku == 1 && cln->kbmin < 2 && km < 2)
         return(cln);
   }
   return(NULL);
}

ATL_mmnode_t *FindKCleaner(ATL_mmnode_t *clnb, ATL_mmnode_t *kp)
/*
 * RETURNS: kp if kp provides its own K cleanup, 
 *          else NULL if no K-cleaner for kp is found in clnb, 
 *          else a ptr to the first such valid K-cleaner found in clnb
 */
{
   ATL_mmnode_t *mp, *cln;
   for (mp=clnb; mp; mp = mp->next)
   {
      ATL_mmnode_t *cln;
      cln = CanKClean(kp, mp);
      if (cln)
         return(cln);
   }
   return(NULL);
}

ATL_mmnode_t *FindAllKCleaners(ATL_mmnode_t *clnb, ATL_mmnode_t *kp)
/*
 * RETURNS: if kp provides its own K-cleaning, then kp is returned.
 *          otherwise a queue cloned nodes of all kernels in clnb that 
 *          could be used to clean kp is return.
 * Cloned nodes have their blocking values set to match kp
 */
{
   ATL_mmnode_t *gdb=NULL, *mp;

   gdb = FindKCleaner(clnb, kp);
   if (gdb == kp)
      return(kp);
   else if (gdb)
   {
      mp = gdb;
      gdb = CloneMMNode(gdb);
      gdb->mbB = kp->mbB;
      gdb->nbB = kp->nbB;
      gdb->kbB = kp->kbB;
      while ((mp = FindKCleaner(mp->next, kp)))
      {
         ATL_mmnode_t *p;
         p = CloneMMNode(mp);
         p->mbB = kp->mbB;
         p->nbB = kp->nbB;
         p->kbB = kp->kbB;
         p->next = gdb;
         gdb = p;
      }
      return(gdb);
   }
   return(NULL);
}

ATL_mmnode_t *FindAllUniqueKClean(int verb, char pre, ATL_mmnode_t *mmb)
/*
 * Finds a way to clean up all kernels in mmb
 * RETURNS: list of all unique kernels required to do K-cleanup
 */
{
   ATL_mmnode_t *clnb, *mkb, *kp;
   if (verb)
      printf("FINDING K CLEANERS FOR ALL KERNELS:\n");
   clnb = ReadMMFileWithPath(pre, "res", "k1AMM.sum");
   if (clnb)
   {
      MMFillInGenStrings(pre, clnb);
      TimeNegMMKernels(0, verb, 0, clnb, pre, 1, 0, -1);
      WriteRefreshedMMFileWithPath(pre, "res", "k1AMM.sum", clnb);
      return(clnb);
   }
/*
 * mkb is the list of all candidate cleanup codes
 */
   mkb = GetWorkingUserCases(verb, pre);
   for (kp=mmb; kp; kp = kp->next)
   {
      ATL_mmnode_t *cp;
      if (FindKCleaner(clnb, kp))  /* if we've already got a K-cleaner */
         continue;                 /* for this case, skip! */
      cp = FindAllKCleaners(mkb, kp);
      if (cp)
         printf("   %s --> %s!\n", kp->rout, cp->rout);
      else
         printf("   %s --> no Kclean!\n", kp->rout);
/*
 *    For kernels that serve as their own K-cleanup, just use them wt no need
 *    to time anything else
 */
      if (cp == kp)
      {
         cp = CloneMMNode(kp);
         cp->next = clnb;
         clnb = cp;
      }
/*
 *    For kernels that must be cleaned by other kernels, we must time all
 *    candidate kernels and use the best!
 */
      else
      {
         ATL_mmnode_t *mp;
         const int mb=kp->mbB, nb=kp->nbB, kb=kp->kbB;
         int ntim;
/*
 *       Add generated case to any user cases that work
 */
         mp = GetNewKCleanGenNode(pre, kp, mb, nb, kb);
         if (!CanKClean(kp, mp))
         {
            int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
            int km = FLAG_IS_SET(kp->flag, MMF_KVEC) ? kp->vlen:0;
            fprintf(stderr, "KU=(%d,%d,%d), KV=%d, MU=(%d,%d,%d), MV=%d\n",
                    kp->mu, kp->nu, kp->ku, km,
                    mp->mu, mp->nu, mp->ku, kmaj);
            assert(CanKClean(kp,mp));
         }
         mp->next = cp;
         cp = mp;
         ntim = ATL_CountNumberOfMMNodes(cp);
         if (ntim > 1)
         {
/*
 *          Now time all kernels, and choose the fastest for cleanup.
 *          We'll use kbB as kb, even though this is larger than the code
 *          will ever be used for.  However, it will allow us to directly
 *          compare kernel and cleanup performance.
 *          A better strategy would be to time many different K cases, but
 *          I don't want to spend that amount of install time tuning and timing
 *          low-order cleanup!
 */
            printf("   CHOOSING BETWEEN %d KB=%d K-CLEANERS WITH TIMINGS:\n", 
                   ntim, kb);
            for (mp=cp; mp; mp = mp->next)
            {
               double mf;
               if (mp->mbB != mb || mp->nbB != nb || mp->kbB != kb || 
                   mp->mflop[0] <= 0.0)
               {
                  mp->mbB = mb;
                  mp->nbB = nb;
                  mp->kbB = kb;
                  mf = TimeMMKernel(0, 1, mp, pre, mb, nb, kb, 0, 0, -1);
                  mp->mflop[0] = mf;
               }
               else
                  mf = mp->mflop[0];
               printf("      %d-%s: %.2f\n", mp->ID, mp->rout?mp->rout:"", mf);
            }
            mp = FindMaxMflopMMQ(cp, 0);
            printf("   USING %d-%s\n", mp->ID, mp->rout? mp->rout:"");
            cp = RemoveMMNodeFromQ(cp, mp);
            KillAllMMNodes(cp);
         }
         else
         {
            mp = cp;
            mp->mbB = mb;
            mp->nbB = nb;
            mp->kbB = kb;
         }
         mp->next = clnb;
         clnb = mp;
      }
   }
   KillAllMMNodes(mkb);
   if (verb)
      printf("DONE FINDING FULL LIST OF K-CLEANERS\n");
   WriteRefreshedMMFileWithPath(pre, "res", "k1AMM.sum", clnb);
   return(clnb);
}

ATL_mmnode_t *FindMUNU(ATL_mmnode_t *mb, int mu, int nu)
{
   ATL_mmnode_t *mp;
   for (mp=mb; mp; mp = mp->next)
      if (mp->mu == mu && mp->nu == nu)
         return(mp);
   return(NULL);
}

ATL_mmnode_t *KCleanByNB
(
   int verb, 
   char pre, 
   ATL_mmnode_t *mmb, /* final kernels giving final supported NBs */
   ATL_mmnode_t *mkb  /* All necessary routs ku=1 to clean all kerns in mmb */
)
/*
 * Replicates mkb so that it includes all NBs in mmb, times K-clean,
 * **FREES** mkb, and returns by-NB list
 *
 * OUTPUT:
 *   <pre>@(kpr)KCLEANBYNB.sum: non-unique K-clean for each NB in mmb
 *      mflop[1] contains estimated time for 1 K-it using K=MAX(kb/4,4)
 */
{
   ATL_mmnode_t *nkb=NULL, *mp, *np;
   int kb;
   double mf;

@ROUT ammsearch
   nkb = ReadMMFileWithPath(pre, "res", "@(kpr)KCLEANBYNB.sum");
   if (nkb)
   {
      KillAllMMNodes(mkb);
      printf("READING IN BY-NB K-CLEANUP:\n");
      MMFillInGenStrings(pre, nkb);
      for (mp=nkb; mp; mp = mp->next)
      {
         int mb=mp->mbB, nb=mp->nbB;
         kb = mp->kbB >> 2;
         kb = (kb >= 4) ? kb : 4;
         if (mp->mflop[0] < 0.0)
            mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mb, nb, kb, 0, 0, -1);
         mf = (2.0*nb)*nb;  /* flop count of gemm/kits (kb) */
         mp->mflop[1] = mf / mp->mflop[0]; /* time in microsecs for 1 k-it */
         printf("   nb=%d, kb=%d, mu=%d, nu=%d, mf=%.2f (%e Usec/Kit)\n", 
                nb, kb, mp->mu, mp->nu, mp->mflop[0], mp->mflop[1]);
      }
      printf("Done.\n");
      WriteRefreshedMMFileWithPath(pre, "res", "@(kpr)KCLEANBYNB.sum", nkb);
      return(nkb);
   }
@ROUT ammsearch uammsearch
   printf("TIMING K-CLEAN FOR ALL SUPPORTED NBs:\n");
   for (mp=mmb; mp; mp = mp->next)
   {
      ATL_mmnode_t *p;
      int mb = mp->mbB, nb = mp->nbB, kb;

      kb = mp->kbB >> 2;
      kb = (kb >= 4) ? kb : 4;
      if (FLAG_IS_SET(mp->flag,MMF_KVEC))
         kb = ((kb+mp->vlen-1)/mp->vlen)*mp->vlen;

      p = FindMUNU(mkb, mp->mu, mp->nu);
/*
 *    If no user cleanup exists, generate one
 */
      if (!p)
      {
         if (FLAG_IS_SET(mp->flag, MMF_KVEC))
            p = MMGetNodeGEN(pre, 0, 0, mp->mu, mp->nu, mp->vlen, mp->vlen, 
                             1, 0, 0, NULL);
         else
            p = MMGetNodeGEN(pre, 0, 0, mp->mu, mp->nu, 1, mp->vlen, 
                             0, 0, 0, NULL);
      }
      else
      {
         p = CloneMMNode(p);
         p->next = NULL;
      }
      p->nbB = nb; p->mbB = mb;  p->kbB = kb;
      p->mflop[0] = TimeMMKernel(verb, 0, p, pre, mb, nb, kb, 0, 0, -1);
      mf = mb*nb;
      p->mflop[1] = mf / p->mflop[0];   /* time in microseconds for 1 k it */
      printf("   mb=%d, nb=%d, kb=%d, mu=%d, nu=%d, mf=%.2f (%e Usec/Kit)\n", 
             mb, nb, kb, p->mu, p->nu, p->mflop[0], mf);
      if (nkb)
      {
         np->next = p;
         np = p;
      }
      else
         nkb = np = p;
   }
   printf("DONE.\n\n");
   KillAllMMNodes(mkb);
   WriteRefreshedMMFileWithPath(pre, "res", "@(kpr)KCLEANBYNB.sum", nkb);
   return(nkb);
}

void TimeKClean(int verb, char pre, ATL_mmnode_t *mp)
/*
 *   mp is the ku=1, KRUNTIME K-cleanup kernel for a support NB.
 *   This routine creates an output file for supported the NB, where we
 *   document the performance for all NB different KB values.  These
 *   timings can therefore precisely document how expensive K-cleanup
 *   will be for each NB.  
 *   OUTPUT:
 *   <pre>@(kpr)KCLEAN_<nb>.TIM: timing of K-clean for nb=<nb>; there are
 *   i=nb-1 timings, mflop[0] contains time to do NB-i K its.  Will use
 *   these times to get completely accurate estimate of total time for
 *   large problems (use estimated time in CLBYNB for small probs).
 */
{
   ATL_mmnode_t *mmb, *p, *np;
   char fn[32];
   int mb = mp->mbB, nb = mp->nbB, i;

   sprintf(fn, "@(kpr)KCLEAN_%d.TIM", mp->nbB);
   mmb = ReadMMFileWithPath(pre, "res", fn);
   if (mmb)
   {
      printf("READING IN K-CLEANUP TIMINGS FOR NB=%d:\n", nb);
      MMFillInGenStrings(pre, mmb);
      for (p=mmb; p; p = p->next)
      {
         int kb = p->kbB;
         assert(nb == p->nbB && mb == p->mbB);
         if (p->mflop < 0)
            p->mflop[0] = TimeMMKernel(verb, 0, p, pre, mb, nb, kb, 0, 0, -1);
         printf("   MB=%d, NB=%d, KB=%d, mu=%d, nu=%d, MFLOP=%.2f\n", 
                mb, nb, kb, p->mu, p->nu, p->mflop[0]);
      }
      printf("Done.\n\n");
      WriteRefreshedMMFileWithPath(pre, "res", fn, mmb);
      KillAllMMNodes(mmb);
      return;
   }
   
   printf("TIMING K-CLEANUP FOR MB=%d, NB=%d:\n", mb, nb);
   for (i=1; i <= nb; i++)  /* create queue of ascending KB */
   {
      p = CloneMMNode(mp);
      p->next = NULL;
      p->kbB = i;
      p->mflop[0] = TimeMMKernel(verb, 0, p, pre, mb, nb, i, 0, 0, -1);
      printf("   MB=%d, NB=%d, KB=%d, mu=%d, nu=%d, MFLOP=%.2f\n", mb, nb, i, 
             p->mu, p->nu, p->mflop[0]);
      if (mmb)
      {
         np->next = p;
         np = p;
      }
      else
         mmb = np = p;
   }
   WriteRefreshedMMFileWithPath(pre, "res", fn, mmb);
   KillAllMMNodes(mmb);
   printf("Done.\n");
}

/*
 * Specialize the K cleanup routs in mkb to the kernels in mmb by changing
 * their block factors, and timing them.
 */
ATL_mmnode_t *SpecializeKClean
   (int verb, char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *mkb)
{
   ATL_mmnode_t *mp, *b=NULL;
   for (mp=mmb; mp; mp = mp->next)
   {
      ATL_mmnode_t *kp;
      if (SelfKClean(mp))
      {
         kp = CloneMMNode(mp);
         kp->mflop[2] = 1.0;
      }
      else
      {
         const int mb=mp->mbB, nb=mp->nbB, kb=mp->kbB;
         kp = FindKCleaner(mkb, mp);
         if (!kp)
            fprintf(stderr, "UR(%d,%d,%d), %s: NO KCLEAN", 
                    mp->mu, mp->nu, mp->ku, mp->rout);
         assert(kp);
         kp = CloneMMNode(kp);
         if (kp->mbB != mb || kp->nbB != nb || kp->kbB != kb || 
             kp->mflop[0] <= 0.0)
         {
            kp->mbB = mb;
            kp->nbB = nb;
            kp->kbB = kb;
            kp->mflop[0] = TimeMMKernel(verb, 0, kp, pre, mb, nb, kb, 0, 0, -1);
            kp->mflop[2] = kp->mflop[0] / mp->mflop[0];
         }
      }
      printf("   KB=%d KCLEAN SPEEDUP: %.4f\n", kp->kbB, kp->mflop[2]);
      kp->next = b;
      b = kp;
   }
   return(b);
}
@ROUT uammsearch
void ComputeKClean(int verb, char pre, ATL_mmnode_t *mmb)
{
}
@ROUT ammsearch
void ComputeKClean(int verb, char pre)
/*
 * This kernel finds K-cleanup for all routines present in <pre>geAMMRES.sum
 * and <pre>sqAMMRES.sum.
 *
 * OUTPUT: <pre>@(kpr)KCLEAN.sum: all unique kerns to be compiled
 *         <pre>geAMMKCLEAN.sum:  MFLOP[2] = cleanup slowdown
 *         <pre>sqAMMKCLEAN.sum: MFLOP[2] = cleanup slowdown
@beginskip
 *   i=nb-1 timings, mflop[0] contains time to do NB-i K its.  Will use
 *   these times to get completely accurate estimate of total time for
 *   large problems (use estimated time in CLBYNB for small probs).
@endskip
 * 
 * NOTE: we will time K-cleanup kernels only in BETA=0 case, and peel
 *    the first K-block rather than the last.  This will minimize the C cost,
 *    which is more appreciable for short-K.  We will actually generate all
 *    beta cases, since sometimes you need other betas (in complex, or if
 *    you can't peel first partial for some reason).
 */
{
   ATL_mmnode_t *mkb, *mmGE=NULL, *mmSQ=NULL, *mp, *mmGEk=NULL, *mmSQk=NULL;
   ATL_mmnode_t *ipb, *ipk;
   mmGEk = TimeMMFileWithPath(pre, "res", "geAMMKCLEAN.sum", 
                              0, verb|1, 0, 0, 0, -1);
   mmSQk = TimeMMFileWithPath(pre, "res", "sqAMMKCLEAN.sum", 
                              0, verb|1, 0, 0, 0, -1);
   @beginskip
   if (mmGEk && mmSQk)
   {
      KillAllMMNodes(mmGEk);
      KillAllMMNodes(mmSQk);
      return;
   }
   if (mmGEk)
      KillAllMMNodes(mmGEk);
   if (mmSQk)
      KillAllMMNodes(mmSQk);
   mmGEk = mmSQk = NULL;
   @endskip
/*
 * Find all unique K-clean kernels
 */
   mkb = ReadMMFileWithPath(pre, "res", "k1AMM.sum");
   if (!mkb)
   {
/*
 *    Will use only one K-cleanup for any (mu,nu,kmaj) combo.  Decide between
 *    competing kernels based on timings, with larger KB more important, so we
 *    reverse the list order so that the larger block factors choose cleanup for
 *    smaller, rather than reverse.
 */
      mmGE = ReverseMMQ(ReadMMFileWithPath(pre, "res", "geAMMRES.sum"));
      mmSQ = ReverseMMQ(ReadMMFileWithPath(pre, "res", "sqAMMRES.sum"));
      assert(mmGE && mmSQ);
/*
 *    Now temporarily join rect & square lists into one, and get a list of
 *    all cleanup routines that are required.  Routines that provide their
 *    own cleanup will always be used regardless of what is in the list,
 *    and the first such kernel will appear in mkb
 */
      for (mp=mmGE; mp->next; mp = mp->next);
      mp->next = mmSQ;
      mkb = FindAllUniqueKClean(verb, pre, mmGE);
      mp->next = NULL;  /* go back to separate lists */
   }
/*
 * Use reversed lists to build lists of cleanup, which will be in correct
 * order due to the way we build them
 */
   if (!mmGEk)
   {
      if (verb)
         printf("SPECIALIZING K-CLEANERS FOR RECTANGULAR BLOCKINGS:\n");
      if (!mmGE)
         mmGE = ReverseMMQ(ReadMMFileWithPath(pre, "res", "geAMMRES.sum"));
      mmGEk = SpecializeKClean(verb, pre, mmGE, mkb);
      if (verb)
         printf("DONE SPECIALIZING K-CLEANERS FOR RECTANGULAR BLOCKINGS.\n");
      KillAllMMNodes(mmGE);
      WriteRefreshedMMFileWithPath(pre, "res", "geAMMKCLEAN.sum", mmGEk);
   }
   KillAllMMNodes(mmGEk);
/*
 * Now do same for square kernels
 */
   if (!mmSQk)
   {
      if (verb)
         printf("SPECIALIZING K-CLEANERS FOR SQUARE BLOCKINGS:\n");
      if (!mmSQ)
         mmSQ = ReverseMMQ(ReadMMFileWithPath(pre, "res", "sqAMMRES.sum"));
      mmSQk = SpecializeKClean(verb, pre, mmSQ, mkb);
      if (verb)
         printf("DONE SPECIALIZING K-CLEANERS FOR SQUARE BLOCKINGS.\n");
      KillAllMMNodes(mmSQ);
      WriteRefreshedMMFileWithPath(pre, "res", "sqAMMKCLEAN.sum", mmSQk);
   }
   KillAllMMNodes(mmSQk);
/*
 * Specialize cleaners to inner-product views.  We don't have to read this
 * for unique, since they come from geAMMRES exclusively
 */
   @whiledef fn mn m n
   ipk = TimeMMFileWithPath(pre, "res", "@(fn)AMMKCLEAN.sum",0,verb|1,0,0,0,-1);
   if (!ipk)
   {
      ipb = ReverseMMQ(ReadMMFileWithPath(pre, "res", "ip@(fn)PERF.sum"));
      assert(ipb);
      if (verb)
         printf("SPECIALIZING K-CLEANERS FOR IP DEGEN @up@(fn):\n");
      ipk = SpecializeKClean(verb, pre, ipb, mkb);
      if (verb)
         printf("DONE SPECIALIZING K-CLEANERS FOR IP DEGEN @up@(fn).\n");
      KillAllMMNodes(ipb);
      WriteRefreshedMMFileWithPath(pre, "res", "@(fn)AMMKCLEAN.sum", ipk);
   }
   KillAllMMNodes(ipk);
   @endwhile

   KillAllMMNodes(mkb);
   if (verb)
      printf("\nDONE FINDING K-CLEANUP FOR EACH KB.\n");
}
@ROUT ammsearch uammsearch

void FindBestKU1
(
   int verb, 
   char pre,   
   int K       /* K dim, should be small, probably like 23 or 17 */
)
/* 
 * Find the best possible kernel for use in low-rank update;  We only consider
 * kernels with runtime-K that handle all possible K (ku=1).  We will try
 * all legal blocking factors between 16 & 480 for this kernel, and choose
 * the one that performs best.  This kernel always used for any K not covered
 * by optimized kernels given in eAMMRES kbBs.  When we match a kbB, we
 * compare the perf of this kernel at its optimal nbB/mbB wt that of the
 * specialized kernel, and choose the best.
 *
 * OUTPUT: This routine outputs two files:
 * (1) AMMRANKK: best ku=1 kern wt best MB/NB, K=K
 * (2) AMMRANKKT: timing of this kern wt M=mbB, N=nbB, all K between 1 & maxNB
 */
{
}

@ROUT ammsearch uammsearch gmmsearch
double CacheRatio_all3pAB(size_t CS, size_t mb, size_t nb, size_t kb, 
                          size_t mu, size_t nu)
{ /* RETURNS: ratio of util cache A,B,C + next A & B */
   double dret = 2.0*kb*(mb+nb)+mb*nb;
   return(dret/CS);
}
double CacheRatio_all3pA(size_t CS, size_t mb, size_t nb, size_t kb, 
                         size_t mu, size_t nu)
{ /* RETURNS: ratio of utilized cache to keep all 3 mm ops + next A in CS */
   double dret = kb*(mb+mb+nb)+mb*nb;
   return(dret/CS);
}
double CacheRatio_all3pB(size_t CS, size_t mb, size_t nb, size_t kb, 
                         size_t mu, size_t nu)
{ /* RETURNS: ratio of utilized cache to keep all 3 mm ops + next A in CS */
   double dret = kb*(mb+nb+nb)+mb*nb;
   return(dret/CS);
}

double CacheRatio_all3(size_t CS, size_t mb, size_t nb, size_t kb, 
                       size_t mu, size_t nu)
{ /* RETURNS: ratio of utilized cache to keep all 3 mm ops in CS */
   double dret = 1.0*kb*(mb+nb)+mb*nb;
   return(dret/CS);
}

double CacheRatio_one(size_t CS, size_t mb, size_t nb, size_t kb, 
                      size_t mu, size_t nu)
{ /* RETURNS: ratio of util cache for B + working set of A/C */
   double dret = kb*nb + 2.0*(mu*kb + mu*nu);
   return(dret/CS);
}

double CacheRatio_ws(size_t CS, size_t mb, size_t nb, size_t kb, 
                     size_t mu, size_t nu)
{ /* RETURNS: ratio of working set of all matmul ops to CS */
   double dret = 2.0*(mu*nu + nu*kb) + mu*kb;
   return(dret/CS);
}

typedef void (*BudgetFunc_t)(double, size_t, size_t, size_t, size_t, 
                             size_t*, size_t*, size_t*);

#define MAXNB 360
void GetBlkFromBudget_allP(char extra, double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   double (*cacheRatio)(size_t,size_t,size_t,size_t,size_t,size_t);
   size_t mb=mu, nb=nu, kb=ku;
   int MGROW, NGROW, KGROW;

   if (extra == 'A')
      cacheRatio = CacheRatio_all3pA;
   else if (extra == 'B')
      cacheRatio = CacheRatio_all3pB;
   else if (extra == '2')
      cacheRatio = CacheRatio_all3pAB;
   else  /* nothing extra */
      cacheRatio = CacheRatio_all3;
   do
   {
      size_t mn=mb+mu, nn=nb+nu, kn=kb+ku;
      MGROW = mn < MAXNB && (cacheRatio(CS, mn, nb, kb, mu, nu) <= thresh);
      NGROW = nn < MAXNB && (cacheRatio(CS, mb, nn, kb, mu, nu) <= thresh);
      KGROW = kn < MAXNB && (cacheRatio(CS, mb, nb, kn, mu, nu) <= thresh);
      if (KGROW && ((!MGROW && !NGROW) || (kn <= nn && kn <= mn)))
         kb = kn;
      else if (MGROW && (!NGROW || mb < nb))
         mb = mn;
      else if (NGROW)
         nb = nn;
   }
   while (MGROW | NGROW | KGROW);
   *MB = mb;
   *NB = nb;
   *KB = kb;
}

void GetBlkFromBudget_all3pA(double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   GetBlkFromBudget_allP('A', thresh, CS, mu, nu, ku, MB, NB, KB);
}
void GetBlkFromBudget_all3pB(double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   GetBlkFromBudget_allP('B', thresh, CS, mu, nu, ku, MB, NB, KB);
}
void GetBlkFromBudget_all3pAB(double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   GetBlkFromBudget_allP('2', thresh, CS, mu, nu, ku, MB, NB, KB);
}
void GetBlkFromBudget_all3(double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   GetBlkFromBudget_allP('N', thresh, CS, mu, nu, ku, MB, NB, KB);
}

void GetBlkFromBudget_one(double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   size_t mb=mu, nb=nu, kb=ku;
   int NGROW, KGROW;
   do
   {
      size_t nn=nb+nu, mn=(nn/mu)*mu, mn1 = ((nn+mu-1)/mu)*mu, kn=kb+ku;
      if (mn1 - nn <= nn - mn || !mn)
         mn = mn1;
      NGROW = nn < MAXNB && (CacheRatio_one(CS, mn, nn, kb, mu, nu) <= thresh);
      KGROW = kn < MAXNB && (CacheRatio_one(CS, mb, nb, kn, mu, nu) <= thresh);
      if (NGROW && ((nn < kn && mn < kn) || !KGROW))
      {
         nb = nn;
         mb = mn;
      }
      else if (KGROW)
         kb = kn;
   }
   while (NGROW | KGROW);
   *MB = mb;
   *NB = nb;
   *KB = kb;
}

void GetBlkFromBudget_ws(double thresh, size_t CS, 
                          size_t mu, size_t nu, size_t ku,
                          size_t *MB, size_t *NB, size_t *KB)
{
   size_t mb=mu, nb=nu, kb=ku;
   int KGROW;
   do
   {
      size_t kn=kb+ku, mn=(kn > mu)?(kn/mu)*mu:mu, nn=(kn>nu)?(kn/nu)*nu:nu;
      KGROW = kn < MAXNB && (CacheRatio_ws(CS, mn, nn, kn, mu, nu) <= thresh);
      if (KGROW)
      {
         mb = mn;
         nb = mn;
         kb = kn;
      }
   }
   while (KGROW);
   *MB = mb;
   *NB = nb;
   *KB = kb;
}

int Blk2Case(size_t CS, int mb, int nb, int kb, int mu, int nu)
{
   size_t sz3 = mb*nb + kb*(mb+nb);
   if (CacheRatio_all3pAB(CS, mb, nb, kb, mu, nu) < 1.0)
      return(4);
   else if (CacheRatio_all3pA(CS, mb, nb, kb, mu, nu) < 1.0 &&
            CacheRatio_all3pB(CS, mb, nb, kb, mu, nu) < 1.0)
      return(3);
   else if (CacheRatio_all3(CS, mb, nb, kb, mu, nu) < 1.0)
      return(0);
   else if (CacheRatio_one(CS, mb, nb, kb, mu, nu) < 1.0)
      return(1);
   return(2);
}
ATL_mmnode_t *FindBestCacheBudgetCase
(
   int verb,
   char pre, 
   BudgetFunc_t GetBlocking,     /* func ptr to budget function */
   double thresh,                /* max ratio of cache to fill */
   size_t CS,                    /* size of cache we are optimizing for */
   int imf,                      /* entry in mflop[] to use */
   ATL_mmnode_t *mmb             /* list of cases to try */
)
/*
 * RETURNS: clone of best-peforming kernel in mmb for kb=kb, mb & nb 
 *          near-square and within budget
 */
{
   ATL_mmnode_t *mmB=NULL, *mp, *p;
   double mf, mfB=0.0;

   printf("Finding best case for cache budget case=%d, CS=%.0f elts\n",
          imf, CS*thresh);
   for (mp=mmb; mp; mp = mp->next)
   {
      size_t mb, nb, kb, ku=mp->ku;
      if (!mp->ID && FLAG_IS_SET(mp->flag, MMF_KUISKB))
         ku = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen : 1;

      GetBlocking(thresh, CS, mp->mu, mp->nu, ku, &mb, &nb, &kb);
      p = CloneMMNode(mp);  /* can't use mp, since may switch KRUNTIME */
      mf = TimeMMKernel_KB(verb, 0, p, pre, mb, nb, kb, 1, 0, -1);
@ROUT gmmsearch
      printf("   RT='%s' B=(%d,%d,%d), MFLOP=%.2f\n", p->rout,
             (int)mb, (int)nb, (int)kb, mf);
@ROUT ammsearch uammsearch
      printf("   ID=%d, mb=%d, nb=%d, kb=%d, RTK=%d, MFLOP=%.2f\n", p->ID,
             (int)mb, (int)nb, (int)kb, FLAG_IS_SET(p->flag, MMF_KRUNTIME), mf);
@ROUT ammsearch uammsearch gmmsearch
      if (mf > mfB)
      {
         if (mmB)
            KillMMNode(mmB);
         p->mbB = mb;
         p->nbB = nb;
         p->kbB = kb;
         mmB = p;
         mfB = mmB->mflop[imf] = mf;
      }
      else
         KillMMNode(p);
   }
   printf("BEST CASE %s: mb=%d, nb=%d, kb=%d, RTK=%d, MFLOP=%.2f\n\n",
          mmB->rout ? mmB->rout : "GENNED",
          mmB->mbB, mmB->nbB, mmB->kbB, FLAG_IS_SET(mmB->flag, MMF_KRUNTIME), 
          mmB->mflop[imf]);
   mmB->next = NULL;
   return(mmB);
}

ATL_mmnode_t *FindBestCacheBudgetCases
(
   int verb,
   char pre, 
   size_t CS,                    /* size of cache we are optimizing for */
   ATL_mmnode_t *mmb             /* list of cases to try */
)
/*
 * This case attempts to find the best kernel for 3-5 cases of interest:
 * (1) All 3 matrices fit in CS -- this case is designed for when we wish
 *     to reuse at least one of the matrices *across* mmkern calls.  It is
 *     particularly good for complex arithmetic, or when CS is large enough
 *     that A&B are reused so much internally to a mmkern call that it makes
 *     sense to retain C in cache for the next mmkern call in K-loop.
 * (2) All of B fits in CS, and so does the working set of A&C.  This one
 *     reuses all internal ops from L1, but won't allow any full op reuse
 *     across multiple GEMM calls.  Usually best for small-to-medium cache
 *     sizes.
 * (3) All of working set of A/B/C fit in cache.  This case provides maximal
 *     NB, where only the mu*KB panel of A is reused from the L1 internally
 *     to the algorthm.  It is essentially an L2-blocked algorithm internally,
 *     but can be useful on those archs where the best sustained bandwidth
 *     comes from one L1 load (A) and 1 L2 load (B).
 * If 3 blocks fit with smallest dim > 16, then also add:
 * (4) All 3 blocks fit in cache, with room for the next A or B.
 * If this fits in cache with smallest dim > 16, then add:
 * (5) All 3 blocks fit in cache, with room for the next A and B.
 */
{
   ATL_mmnode_t *mm3, *mm1, *mmw;
   mm3 = FindBestCacheBudgetCase(verb, pre, GetBlkFromBudget_all3, 1.0, 
                                 CS, 1, mmb);
   mm1 = FindBestCacheBudgetCase(verb, pre, GetBlkFromBudget_one, 1.0, 
                                 CS, 2, mmb);
   mmw = FindBestCacheBudgetCase(verb, pre, GetBlkFromBudget_ws, .90, 
                                 CS, 3, mmb);
   mm3->next = mm1;
   mm1->next = mmw;
   mmw->next = NULL;

/*
 * If cache large enough, try fitting 4 & 5 blocks in it
 */
   if (mm3->mbB > 16 && mm3->nbB > 16 && mm3->kbB > 16)
   {
      ATL_mmnode_t *mp;
      mp = FindBestCacheBudgetCase(verb, pre, (mm3->mbB > mm3->nbB) ?
              GetBlkFromBudget_all3pA:GetBlkFromBudget_all3pB,
              0.95, CS, 4, mmb);
      mmw->next = mp;
      if (mp->mbB > 16 && mp->nbB > 16 && mp->kbB > 16)
      {
         ATL_mmnode_t *mm5;
         mm5 = FindBestCacheBudgetCase(verb, pre, GetBlkFromBudget_all3pAB,
                                       0.95, CS, 5, mmb);
         mp->next = mm5;
      }
   }
   {
      int i;
      ATL_mmnode_t *mp;
      char *exp[5] = {"3BLKS", "1BLKS", "0BLKS", "4BLKS", "5BLKS"};

      for (i=0, mp=mm3; mp; i++, mp=mp->next)
@ROUT gmmsearch
         printf("%s: RT='%s' B=(%d,%d,%d), RK=%d MFLOP=%.2f\n", 
                exp[i], mp->rout, mp->mbB, mp->nbB, mp->kbB, 
                FLAG_IS_SET(mp->flag, MMF_KRUNTIME), mp->mflop[i+1]);
@ROUT ammsearch uammsearch
         printf("%s: ID=%d, RT='%s' B=(%d,%d,%d), RK=%d MFLOP=%.2f\n", 
                exp[i], mp->ID, mp->rout, mp->mbB, mp->nbB, mp->kbB, 
                FLAG_IS_SET(mp->flag, MMF_KRUNTIME), mp->mflop[i+1]);
@ROUT ammsearch uammsearch gmmsearch
      printf("\n");
   }
   return(mm3);
}
@ROUT ammsearch uammsearch
ATL_mmnode_t *TimeKBRegion
(
   int verb,
   char pre, 
   ATL_mmnode_t *mmk,            /* kernel to time throughout region */
   int kbmin,                    /* start of region */
   int kbend,                    /* largest kb in region */
   int kincD                     /* default stride between kernel timings */
)
/*
 * Returns list of timings of kernel mmk using near-square cases with KB
 * varying between kbmin - kbend.  All cases that are legal and incremented
 * by kinc are tried, as are all perfectly square cases
 */
{
   ATL_mmnode_t *mmb=NULL, *mp, *mpB=NULL;
   const int ku = mmk->ku, mu=mmk->mu, nu=mmk->nu;
   int kstart, kinc, kend, k, ksq, ksqinc;
   double mf, mfB=0.0;
/*
 * Get starting and ending point that is legal for this kernel.
 */
   kstart = Mmax(mmk->kbmin, kbmin);
   kstart = ((kstart+ku-1)/ku)*ku;
   kend = ((kbend+ku-1)/ku)*ku;
   if (mmk->kbmax)
      kend = Mmin(kend, mmk->kbmax);
   k = kstart;
/*
 * square inc always lcm(mu,nu,ku).  Normal increment is always at least
 * as big as the default stride, but must be a multiple of the kernel's ku
 */
   ksqinc = Mylcm(mu, nu);
   ksqinc = Mylcm(ksqinc, ku);
   for (kinc=ku; kinc < kincD; kinc += ku);
   if (kstart <= kend)
   {
      int kb = k;
      printf("TIMING %s mu=%d, mu=%d, For KB=[%d,%d]:\n", 
             mmk->rout ? mmk->rout : "Genkern", mu, nu, kstart, kend);
      ksq = ((kstart+ksqinc-1)/ksqinc)*ksqinc;
      do
      {
         ATL_mmnode_t *p;
         const int mb=((kb+mu-1)/mu)*mu, nb=((kb+nu-1)/nu)*nu;

         p = CloneMMNode(mmk);
         mf = TimeMMKernel_KB(verb, 0, p, pre, mb, nb, kb, 1, 0, -1);
         printf("   mb=%d, nb=%d, kb=%d, KRUN=%d, MFLOP=%.2f\n",
                mb, nb, kb, FLAG_IS_SET(p->flag, MMF_KRUNTIME), mf);
         p->mflop[0] = mf;
         if (mf > mfB)
         {
            mfB = mf;
            mpB = p;
         }
         if (mmb)
         {
            mp->next = p;
            mp = p;
         }
         else
            mmb = mp = p;
         if (kb == ksq)
            ksq += ksqinc;
         if (kb == k)
            k += kinc;
         kb = Mmin(k,ksq);
      }
      while(kb <= kend);
      printf("DONE, best case %s mb=%d, nb=%d, kb=%d, MFLOP=%.2f\n\n", 
             mmk->rout ? mmk->rout : "Genkern",
             mpB->mbB, mpB->nbB, mpB->kbB, mfB);
   }
   else
   {
      printf("KERNEL %s mu=%d, mu=%d, has no legal cases in KB=[%d,%d]!\n\n", 
             mmk->rout ? mmk->rout : "Genkern", mu, nu, kstart, kend);
   }
   return(mmb);
}

ATL_mmnode_t *TimeAllKBRegions
(
   int verb,
   char pre, 
   ATL_mmnode_t *mmk,            /* kernel to time throughout regions */
   int kb                        /* maxKB to ever try */
)
/*
 * Times mmk for KBs up to kb
 */
{
   const int ku = mmk->ku;
   ATL_mmnode_t *mmb, *mp;

   mmb = TimeKBRegion(verb, pre, mmk, 24, kb, 4);
   return(mmb);
}

ATL_mmnode_t *FindCacheBudgetCasesByKB
(
   int verb,
   char pre, 
   size_t CS,                    /* size of cache we are optimizing for */
   ATL_mmnode_t *mmb             /* list of cases to try */
)
/* 
 * This routine is responsible for:
 * (1) Find the best performing kernels out of mmb for our 3-5 cache budget
 *     cases
 * (2) Free mmb
 * (3) For each unique kernel, find perf of kernel for all supported KBs 
 *     in the budgetary regions
 * (4) Merge these lists, and winnow underperforming cases
 * (5) RETURN: queue of all supported KBs
 */
{
   ATL_mmnode_t *mm3b, *mp;
   const char upr = (pre == 'z' || pre == 'd') ? 'd' : 's';
/*
 * We want number of real elts, not # of cplx elts!
 */
   if (pre == 'c' || pre == 'z')
      CS += CS;
/*
 * See if we just need to rerun cases
 */
   mm3b = ReadMMFileWithPath(pre, "res", "bAMMRES.sum");
   if (mm3b)
   {
      int i=0, WRT=0;
      printf("READING IN LARGE KERNEL CASES FROM res/<pre>bAMMRES:\n");
      MMFillInGenStrings(pre, mm3b);
      for (mp=mm3b; mp; mp = mp->next)
      {
         if (mp->mflop[0] <= 0.0)
         {
            mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB, 
                                        mp->kbB, 1, 0, -1);
            WRT=1;
         }
         printf("   ID=%d, %s: MB=%d, NB=%d, KB=%d, KRUN=%d, MFLOP=%.2f\n",
                mp->ID, mp->rout ? mp->rout : "Gennedkern",
                mp->mbB, mp->nbB, mp->kbB, FLAG_IS_SET(mp->flag, MMF_KRUNTIME),
                mp->mflop[0]);
         i++;
      }
      if (WRT)
         WriteRefreshedMMFileWithPath(pre, "res", "bAMMRES.sum", mm3b);
      printf("DONE %d CASES.\n\n", i);
      return(mm3b);
   }
/*
 * Find best performing kernels for each of our 3-5 cache budgets
 */
@skip   mm3b = FindBestCacheBudgetCases(verb, pre, CS, mmb);
@skip   KillAllMMNodes(mmb);
   mm3b = mmb;
/*
 * Get list of performance of all-3-5 in-cache kernel in all 3-5 cache regions
 */
   mmb = TimeAllKBRegions(verb, pre, mm3b, mm3b->next->next->kbB);
   for (mp=mm3b->next; mp; mp = mp->next)
   {
      if (KernelIsUnique(mm3b, mp))
      {
         ATL_mmnode_t *p, *p2;
         p = TimeAllKBRegions(verb, pre, mp, mm3b->next->next->kbB);
         p2 = MergeCases(0, mmb, p);
         KillAllMMNodes(p);
         KillAllMMNodes(mmb);
         mmb = p2;
      }
   }
   KillAllMMNodes(mm3b);
/*
 * Now, get rid of any blocking factor that is slower than the preceeding one
 */
   mmb = WinnowCases(0, mmb);
   WriteRefreshedMMFileWithPath(pre, "res", "bAMMRES.sum", mmb);
   return(mmb);
}

@beginskip
ATL_mmnode_t *DecentGenCase(int verb, char pre, int nreg)
{
/*
 * Find out what vectorization, if any, to use in generating kernels
 */
   int mu, nu;
   SetGenVec(verb, pre);
/* 
 * 120 = LCM(2,3,4,5,6,8), and large enough to stress mu/nu
 */
   return(FindDefMUNU(verb, pre, nreg, 0, 120, 1, &mu, &nu));
@skip   return(ReadMMFileWithPath(pre, "res", "gAMMMUNU.sum"));
@skip   return(GetNewGenNode(pre, 0, 0, mu, nu, 1, 0));
}
@endskip

/*
 * This routine finds kernels to use in low-rank-K update. For 3 <= K <= 15,
 * it tries all kernels and chooses the best performing; In this search
 * we consider only compile-time K kernels, since runtime kernels will be
 * selected by general (K>15) search.
 * (K=1 and K=2 are handled by GER and GER2).
 * We consider only user-generated kernels; for any problem sizes that are
 * not supported, we will use the normal K or K-clean routines.  This list
 * is just to allow for hand-tuning small-K special cases.
 * This routine produces output file <pre>AMMLOWK.sum
 */
ATL_mmnode_t *GetLowRankKKernels
(
   int verb,            /* verbosity */
   char pre,            /* s,d */
   int MB,              /* default mb to time with */
   int NB,              /* default nb to time with */
   ATL_mmnode_t *inb    /* all working ukerns */
)
{
   int k, ik;
   ATL_mmnode_t *rkKb=NULL, *mp;
/*
 * Get rid of all K-runtime kernels from consideration
 */
   while (inb && FLAG_IS_SET(inb->flag, MMF_KRUNTIME))
      inb = KillMMNode(inb);
   if (inb)
   {
      ATL_mmnode_t *prev=inb;
      mp = inb->next;
      while (mp)
      {
         if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
         {
            mp = KillMMNode(mp);
            prev->next = mp;
         }
         else
         {
            prev = mp;
            mp = mp->next;
         }
      }
   }
   else
      return(NULL);
   for (ik=0; ik < 2; ik++)
   {
      int kbeg, kend, kinc;
      if (!ik)
      {
         kbeg = 96;
         kend = 16;
         kinc = 16;
      }
      else
      {
         kbeg = 15;
         kend = 3;
         kinc = 1;
      }
      for (k=kbeg; k >= kend; k -= kinc)
      {
         printf("FINDING BEST USER-PROVIDED KERNEL FOR K=%d:\n", k);
         ATL_mmnode_t *best=NULL;
         for (mp=inb; mp; mp = mp->next)
         {
            const int mu = mp->mu, nu = mp->nu, ku = mp->ku;
            const int mb = (MB/mu)*mu, nb = (NB/nu)*nu;
            const int KK = (!FLAG_IS_SET(mp->flag,MMF_KVEC)) ? 
                           k : ((k+ku-1)/ku)*ku;
            double mf;
   
            assert(mb && nb);
            if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME) || KK%ku)
            {
               printf("   skipping %d. %s, KRUN=%d, ku=%d\n", mp->ID, mp->rout,
                      FLAG_IS_SET(mp->flag, MMF_KRUNTIME), ku);
               continue;
            }
            if ((mp->kbmin && k < mp->kbmin) || (mp->kbmax && KK > mp->kbmax))
            {
               printf("   skipping %d. %s, kbmin,max=%d,%d, K=%d\n", 
                      mp->ID, mp->rout, mp->kbmin, mp->kbmax, KK);
               continue;
            }
            mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, KK, 0, 0, -1);
            if (KK != k)
               mf = (mf*k) / (double)KK;
            printf("   %d. %s: mb=%d, nb=%d, MFLOP=%.2f\n", mp->ID, mp->rout,
                   mb, nb, mf);
            if (!best)
            {
               best = mp;
               mp->mflop[0] = mf;
               mp->mbB = mb;
               mp->nbB = nb;
               mp->kbB = k;
            }
            else if (best->mflop[0] < mf)
            {
               best = mp;
               mp->mflop[0] = mf;
               mp->mbB = mb;
               mp->nbB = nb;
               mp->kbB = k;
            }
         }
         if (best)
         {
            best = CloneMMNode(best);
            best->next = rkKb;
            rkKb = best;
            printf("BEST FIXED-%d KERNEL: %d. %s MFLOP=%.2f\n\n", 
                   k, best->ID, best->rout, best->mflop[0]);
         }
         else
            printf("NO SPECIAL CASE for K=%d\n\n", k);
      }
   }
   KillAllMMNodes(inb);
   return(rkKb);
}

/*
 * Finds list of best run-time kernel, ranked by KU.  Higher KUs are not
 * retained unless they beat any lower-KU kernel that divides that KU evenly
 */
ATL_mmnode_t *GetRuntimeKKernels
(
   int verb,            /* verbosity */
   char pre,            /* s,d */
   int MB,              /* default mb to time with */
   int NB,              /* default nb to time with */
   ATL_mmnode_t *inb    /* all working ukerns */
)
{
   ATL_mmnode_t *mp;
   int KU;
/*
 * Get rid of all non-K-runtime kernels from consideration
 */
   while (inb && !FLAG_IS_SET(inb->flag, MMF_KRUNTIME))
      inb = KillMMNode(inb);
/* 
 * Got rid of any at base, now get rid of non-K-runtime from internal nodes
 */
   if (inb)
   {
      ATL_mmnode_t *prev=inb;
      mp = inb->next;
      while (mp)
      {
         if (!FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
         {
            mp = KillMMNode(mp);
            prev->next = mp;
         }
         else
         {
            prev = mp;
            mp = mp->next;
         }
      }
   }
   else
      return(NULL);
   KU = inb->ku;
   for (mp=inb->next; mp; mp = mp->next)
      KU = Mylcm(KU, mp->ku);
   if (KU > 32)
      KU = 32;
   else
      KU = ((16+KU-1)/KU)*KU;
   printf("TRYING ALL RUNTIMEK KERNS WITH MB=%d, NB=%d, KB=%d:\n", MB, NB, KU);
   for (mp=inb; mp; mp = mp->next)
   {
      int mu=mp->mu, nu=mp->nu, ku=mp->ku;
      int mb = (MB/mu)*mu, nb = (NB/nu)*nu, kb = (KU/ku)*ku;
      double mf;
      assert(mb && nb && kb);
      mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, kb, 0, 0, -1);
      printf("   %d. %s: mb=%d, nb=%d, MFLOP=%.2f\n", mp->ID, mp->rout,
             mb, nb, mf);
      mp->mflop[0] = mf;
      mp->mbB = mb;
      mp->nbB = nb;
      mp->kbB = kb;
   }
   printf("\n");
   inb = ATL_SortMMNodesByMflop(0, inb);
   if (inb->ku == 1)
   {
      KillAllMMNodes(inb->next);
      inb->next = NULL;
   }   
   else
   {
      ATL_mmnode_t *p;
/*
 *    Go thru sorted list, and kill all slower nodes that don't add new K
 */
      for (p=inb; p; p = p->next)
      {
         ATL_mmnode_t *prev=p;
         mp = p->next;
         while (mp)
         {
            if (mp->ku % p->ku == 0)
            {
               mp = KillMMNode(mp);
               prev->next = mp;
            }
            else
            {
               prev = mp;
               mp = mp->next;
            }
         }
      }
   }
   if (!inb)
      printf("NO RETAINED RUNTIME KERNELS.\n\n");
   else
   {
      printf("RETAINED RUNTIME KERNELS:\n");
      for (mp=inb; mp; mp = mp->next)
         printf("   %d. %s: ku=%d, MFLOP=%.2f\n", mp->ID, mp->rout, mp->ku,
                mp->mflop[0]);
      printf("DONE.\n");
   }
   return(inb);
}
/*
 * RETURNS: 1 if mmc is slower than any kernel in mmb
 */
int IsSlowerThanList
(
   int verb,            /* verbosity */
   char pre,            /* s,d */
   int MB,
   int NB,              /* default mb/nb to time with */
   ATL_mmnode_t *mmc,  /* candidate mmkern */
   ATL_mmnode_t *mmb   /* kernels to time candidate against */
)
{
   ATL_mmnode_t *mp;
   double mfc, mf;
   int mu, nu, ku;
   int mb, nb, kb, KB;

   if (!mmb)
      return(0);
   kb = mmc->kbB;
   mu = mmc->mu;
   nu = mmc->nu;
   mb = (MB/mu)*mu;
   nb = (NB/nu)*nu;
   assert(mb && nb && kb);
   KB = (!FLAG_IS_SET(mmc->flag,MMF_KVEC))?kb:((kb+mmc->ku-1)/mmc->ku)*mmc->ku;
   mfc = TimeMMKernel(verb, 0, mmc, pre, mb, nb, KB, 0, 0, -1);
   mfc = (kb*mfc)/(double)KB;
   mmc->mflop[1] = mfc;
   kb = mmc->kbB;
   for (mp=mmb; mp; mp = mp->next)
   {
      ku = mp->ku;
      if (mp->kbmin && kb < mp->kbmin)
         continue;
      if (mp->kbmax && kb > mp->kbmax)
         continue;
      if (kb%ku == 0 || FLAG_IS_SET(mp->flag,MMF_KVEC))
      {
         int KK = (FLAG_IS_SET(mp->flag,MMF_KVEC)) ? ((kb+ku-1)/ku)*ku : kb;
         mu = mp->mu;
         nu = mp->nu;
         mb = (MB/mu)*mu;
         nb = (NB/nu)*nu;
         assert(mb && nb);
         mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, KK, 0, 0, -1);
         mp->mflop[1] = (kb*mfc)/(double)KK;
         if (mf > mfc)
         {
@skip            printf("      %d. %s (%.2f) outcompeted by %d. %s (%.2f)\n",
@skip                   mmc->ID, mmc->rout, mfc, mp->ID, mp->rout, mf);
            return(1);
         }
      }
   }
   return(0);
}

/*
 * Finds best-performing square cases in list of pre-existing kernels, mmb.
 * Does not modify original mmb list, and will return only kernels that are
 * faster than smaller square cases.
 * RETURNS: new list of all square cases that got best performance from
 *          original mmb.
 */
@ROUT uammsearch
ATL_mmnode_t *FindBestSquareCases(char pre, int verb, ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mmp, *mmSQ=NULL, *prev=NULL;
   int maxNB=0, maxU=0, i;

   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      if (mmp->mu > maxU)
         maxU = mmp->mu;
      if (mmp->nu > maxU)
         maxU = mmp->nu;
      if (mmp->nbB > maxNB)
         maxNB = mmp->nbB;
      if (mmp->mbB > maxNB)
         maxNB = mmp->mbB;
      if (mmp->kbB > maxNB)
         maxNB = mmp->kbB;
   }
   maxNB = ((maxNB+maxU-1) / maxU)*maxU;

   for (i=4; i <= maxNB; i++)
   {
      mmp = BestForThisNB(verb, pre, mmb, i, i-1, i+1);
      if (mmSQ)
      {
         if (prev->mflop[0] >= mmp->mflop[0])
            KillMMNode(mmp);
         else
         {
            prev->next = mmp;
            prev = mmp;
         }
      }
      else
         mmSQ = prev = mmp;
   }
   return(mmSQ);
}
@ROUT ammsearch
/*
 * Sets all MV[A,B,C] bits in mmb to those provided in low 3 bits of bits
 */
void ResetMoveBitsInQ(ATL_mmnode_t *mmb, int bits)
{
   while (mmb)
   {
      ATL_MMF_MVPUT(mmb->flag, bits);
      mmb = mmb->next;
   }
}
ATL_mmnode_t *FindBestSquareCases(char pre, int verb, int nregs, int maxNB, 
                                  ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mp, *mmSQ=NULL, *mmGN, *prev=NULL, *mmS;
   int maxU=0, i, KM;
   int vlen;
   const char upr = (pre == 's' || pre == 'c') ? 's' : 'd';

   mmGN = GetGenCases(pre);
   assert(mmGN);
   vlen = mmGN->next->next->vlen;
@skip   vlen = GetNativeVLEN(pre);
   if (vlen < 1)
      vlen = 1;
   for (mp=mmb; mp; mp = mp->next)
   {
      if (mp->mu > maxU)
         maxU = mp->mu;
      if (mp->nu > maxU)
         maxU = mp->nu;
@beginskip
      if (mp->nbB > maxNB)
         maxNB = mp->nbB;
      if (mp->mbB > maxNB)
         maxNB = mp->mbB;
      if (mp->kbB > maxNB)
         maxNB = mp->kbB;
@endskip
   }
   maxNB = 1.2 * maxNB;
   maxNB = ((maxNB+maxU-1) / maxU)*maxU;
/*
 * For small problems, try full generated & user kerns, since square kerns
 * are very likely to use some odd kernel that got winnowed in original file
 */
   mmS = ReadMMFileWithPath(upr, "res", "WORKING.sum");
   ATL_LastMMNode(mmS)->next = CloneMMQueue(mmGN);
   ResetMoveBitsInQ(mmS, 5);  /* mmb already set to movA=movC=1, movB=0 */
/*
 * Find best NB=4 case to start queue
 */
   mmSQ = prev = BestForThisNB(verb, pre, mmS, 4, 4-1, 4+1);
/*
 * for nb < vlen, scope every multiple of 2
 */
   KM = Mmax(vlen,16);
   for (i=6; i <= KM; i += 2)
   {
      mp = BestForThisNB(verb, pre, mmS, i, i-1, i+1);
      if (prev->mflop[0] >= mp->mflop[0])
         KillMMNode(mp);
      else
      {
         prev->next = mp;
         prev = mp;
      }
   }
   KillAllMMNodes(mmS);  /* don't need small queue anymore */
/*
 * For larger problems, only use user kernels that won against generated.
 * We add back in all generated kerns in case we need an eliminated one for
 * cleanup.  Could do same for user (use mmS for all), but mmGN is at most
 * length 5, while mmb is of any length, which is why we don't want to time
 * all those kerns.
 */
   mmb = AddUniqueMMKernCompList(mmGN, mmb);
/*
 * For square cases > VLEN, try only multiples of VLEN: since we always 
 * vectorize along at least one dim, only these dims can be fully vectorized
 */
   for (i=((16+vlen)/vlen)*vlen; i <= maxNB; i += vlen)
   {
      mp = BestForThisNB(verb, pre, mmb, i, i-1, i+1);
      if (prev->mflop[0] >= mp->mflop[0])
         KillMMNode(mp);
      else
      {
         prev->next = mp;
         prev = mp;
      }
   }
   return(mmSQ);
}

ATL_mmnode_t *MergeRankKKernels
(
   int verb,            /* verbosity */
   char pre,            /* s,d */
   int MB,              /* default mb to time with */
   int NB,              /* default nb to time with */
   int maxKB,           /* largest KB to produce */
   ATL_mmnode_t *fixb,  /* rank-K fixed-K kerenls */
   ATL_mmnode_t *runb,  /* rank-K, runtime-K kernels */
   ATL_mmnode_t *sqrb   /* optimized near-square kernels */
)
{
   ATL_mmnode_t *rkb, *rkp;
   int k;
   rkp = rkb = GetMMNode();
   printf("CHOOSING BEST KERNEL FOR EACH RANK-K (3 <= K <= %d):\n", maxKB);
   for (k=3; k <= maxKB; k++)
   {
      ATL_mmnode_t *best=NULL, *p;
      double mfB=0.0, mf;
/*
 *    fixb & sqrb are in K-order, so we pop them off stack until we get to
 *    one big enough to solve the problem.  We also ignore all KRUNTIME kernels
 *    in sqrb, since they should appear in runb if they are competitive
 */
      while (fixb)
      {
         if (fixb->kbB < k || (fixb->kbmin && fixb->kbmin > k) ||
             (fixb->kbmax && fixb->kbmax < k))
            fixb = KillMMNode(fixb);
         else
            break;
      }
      while (sqrb)
      {
         if (sqrb->kbB < k || FLAG_IS_SET(sqrb->flag, MMF_KRUNTIME)
             || (sqrb->kbmin && sqrb->kbmin > k) || 
                (sqrb->kbmax && sqrb->kbmax < k))
            sqrb = KillMMNode(sqrb);
         else break;
      }
      if (fixb)
      {
         if (fixb->kbB == k)
         {
            int mu = fixb->mu, nu = fixb->nu, ku = fixb->ku;
            int mb = (NB/mu)*mu, nb = (NB/nu)*nu;
            int kb = (!FLAG_IS_SET(fixb->flag,MMF_KVEC)) ? k : ((k+ku-1)/ku)*ku;
            best = fixb;
            fixb = fixb->next;
            mfB = TimeMMKernel(verb, 0, best, pre, mb, nb, kb, 0,0, -1);
            mfB = (mfB*k)/(double)kb;
         }
      }
      if (sqrb)
      {
         if (sqrb->kbB == k)
         {
            int mu = sqrb->mu, nu = sqrb->nu, ku = sqrb->ku;
            int mb = (MB/mu)*mu, nb = (NB/nu)*nu;
            int kb = (!FLAG_IS_SET(sqrb->flag,MMF_KVEC)) ? k : ((k+ku-1)/ku)*ku;
            mf = TimeMMKernel(verb, 0, sqrb, pre, mb, nb, kb, 0, 0,-1);
            mf = (mf*k)/(double)kb;
            if (mf > mfB)
            {
               mfB = mf;
               if (best)
                  KillMMNode(best);
               best = sqrb;
               sqrb = sqrb->next;
            }
            else
               sqrb = KillMMNode(sqrb);
         }
      }
      for (p=runb; p; p = p->next)
         if ((k % p->ku == 0 || FLAG_IS_SET(p->flag,MMF_KVEC)) && 
             k > p->kbmax && (!p->kbmin || p->kbmin <= k))
            break;
      if (p)
      {
         int mu = p->mu, nu = p->nu, ku = p->ku;
         int mb = (NB/mu)*mu, nb = (NB/nu)*nu;
         int kb = (!FLAG_IS_SET(p->flag,MMF_KVEC)) ? k : ((k+ku-1)/ku)*ku;
         if (p->kbmax && p->kbmax < kb)
            mf = -1.0;
         else
            mf = TimeMMKernel(verb, 0, p, pre, mb, nb, kb, 0, 0, -1);
         mf = (mf*k)/(double)kb;
         if (mf > mfB)
         {
            mfB = mf;
            if (best)
               KillMMNode(best);
            best = CloneMMNode(p);
         }
      }
      assert(best);
      printf("   Best kernel K=%d: %d. %s (%.2f)\n",k,best->ID,best->rout,mfB);
      best->kbB = k;
      rkp->next = best;
      rkp = best;
   }
   if (sqrb)
      KillAllMMNodes(sqrb);
   if (fixb)
      KillAllMMNodes(fixb);
   rkp->next = NULL;
   printf("DONE.\n\n");
   return(KillMMNode(rkb));
}

/*
 * Complex types use the previously selected real kernels in order to
 * reduce library size (means we only have 2 precision GEMMS for 4
 * types/precisions).  The only thing that is different is we may
 * reduce max NB in order to keep complex ops in cache.
 * May want to write this as part of real tuning!
 */
int DoComplex(char pre, int verb)
{
   ATL_mmnode_t *mmb;
   char upr = (pre == 'z') ? 'd' : 's';
   exit(-1);
   mmb = ReadMMFileWithPath(pre, "res", "geAMMRES.sum");
   if (!mmb)
   {
      mmb = ReadMMFileWithPath(upr, "res", "geAMMRES.sum");
      assert(mmb);
      WriteMMFileWithPath(pre, "res", "geAMMRES.sum", mmb);
   }

}

/*
 * Creates two lists from original, which is left unchanged.
 * A list of all unique runtime kernels is RETURNED, 
 * while a list of all unique KB compile kernels is provided by CBAS
 */
ATL_mmnode_t *SplitRunCompKB(ATL_mmnode_t *orig, ATL_mmnode_t **CBAS)
{
   ATL_mmnode_t *comp=NULL, *run, *bp;
   for (bp=orig; bp; bp = bp->next)
   {
      if (FLAG_IS_SET(bp->flag, MMF_KRUNTIME))
      {
         if (!MMKernCompIsPresent(run, bp))
         {
            ATL_mmnode_t *tp;
            tp = CloneMMQueue(bp);
            tp->next = run;
            run = tp;
         }
      }
      else  /* candidate for compile-time K list */
      {
         if (!MMKernCompIsPresent(comp, bp))
         {
            ATL_mmnode_t *tp;
            tp = CloneMMQueue(bp);
            tp->next = comp;
            comp = tp;
         }
      }
   }
/*
 * Put them back in original order, they were produced backwards from orig
 */
   if (comp)
      comp = ReverseMMQ(comp);
   if (run)
      run = ReverseMMQ(run);

   *CBAS = comp;
   return(run);
}
/*
 * Deletes all kernels in mmb with kbB that are not a multiple of mu
 */
ATL_mmnode_t *KillIncompatible_MK(ATL_mmnode_t *mmb)
{
   while (mmb && (mmb->kbB/mmb->mu)*mmb->mu != mmb->kbB)
      mmb = KillMMNode(mmb);
   if (mmb)
   {
      ATL_mmnode_t *mp=mmb->next, *prev=mmb;

      while (mp)
      {
         if ((mp->kbB/mp->mu)*mp->mu != mp->kbB)
             mp = prev->next = KillMMNode(mp);
         else
         {
            prev = mp;
            mp = mp->next;
         }
      }
   }
   return(mmb);
}
/*
 * Given a list of kernels being already being used by GEMM, find best
 * performing cases with MB=KB, and NB allowed to vary.  These blockings
 * of already-existing kernels will be used to build triangular & symmetric
 * amm-based routines 
 */
ATL_mmnode_t *DoMKB_findNB(char pre, int verb, ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mmSQ, *run, *comp, *mp;
   mmSQ = ReadMMFileWithPath(pre, "res", "mkbAMMRES.sum");
   if (mmSQ)
   {
      MMFillInGenStrings(pre, mmSQ);
      if (mmSQ->mflop[0] < 0.0)
      {
         for (mp=mmSQ; mp; mp = mp->next)
         {
            int nb=mp->kbB;
            if (mp->mflop[0] < 0.0)
               mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, nb, nb, nb, 
                                           1, 0, -1);
         }
         WriteMMFileWithPath(pre, "res", "mkbAMMRES.sum", mmSQ);
      }
      return(mmSQ);
   }
   run = SplitRunCompKB(mmb, &comp);
   comp = KillIncompatible_MK(comp);
/*
 * Add all K-cleanup kernels to list of candidates
 */
   mp = ReadMMFileWithPath(pre, "res", "AMMKCLEAN.sum");
   if (mp)
   {
      ATL_mmnode_t *r, *c;
      r = SplitRunCompKB(mp, &c);
      KillAllMMNodes(mp);
      c = KillIncompatible_MK(c);
      mp = MergeCases(-1, run, r);
      KillAllMMNodes(run);
      KillAllMMNodes(r);
      run = mp;
      mp = MergeCases(-1, comp, c);
      KillAllMMNodes(comp);
      KillAllMMNodes(c);
      comp = mp;
   }
/*
 * HERE HERE HERE
 */
}
ATL_mmnode_t *DoSquare(char pre, int verb, int nregs, ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mmSQ;
   const char upr = (pre == 'z' || pre == 'd') ? 'd' : 's';

   mmSQ = TimeMMFileWithPath(pre, "res", "sqAMMRES.sum", 0,verb|1, 0, 1, 0, -1);
   if (mmSQ)
      return(mmSQ);
   else
   {
      int maxNB=0;
      ATL_mmnode_t *mp;

      for (mp=mmb; mp; mp = mp->next) /* find maximum NB */
      {
          if (mp->kbB > maxNB)
             maxNB = mp->kbB;
          if (mp->mbB > maxNB)
             maxNB = mp->mbB;
          if (mp->nbB > maxNB)
             maxNB = mp->nbB;
      }
      mmSQ = FindBestSquareCases(pre, verb, nregs, maxNB, mmb);
      WriteRefreshedMMFileWithPath(pre, "res", "sqAMMRES.sum", mmSQ);
   }
   return(mmSQ);
}

void DoTRSM(char pre, int verb)
/*
 * Later, may need to put trsm 'Right' timings in mflop[1]
 */
{
   ATL_mmnode_t *tb, *tp, *sb;
   if (pre == 'z' || pre == 'c')
      return;
   tb = ReadMMFileWithPath(pre, "res", "tsAMMRES.sum");
   if (tb)  /* already ran! */
   {
      for (tp=tb; tp; tp = tp->next)
      {
         if (tp->mflop[0] <= 0.0)
         {
            tp->mflop[0] = TimeTSKernel(verb, 0, pre, tp->mbB, tp->nbB, 0);
            if (verb)
               printf("   trsmKL %dx%d: %.2f\n", tp->mbB,tp->nbB, tp->mflop[0]);
         }
      }
      WriteRefreshedMMFileWithPath(pre, "res", "tsAMMRES.sum", tb);
      KillAllMMNodes(tb);
      return;
   }

   tb = ReadMMFileWithPath(pre, "res", "sqAMMRES.sum");
   printf("\nFINDING PERFORMANCE OF TRSM KERNELS FOR SQUARE AMM:\n");
   for (tp=tb; tp; tp = tp->next)
   {
      tp->mflop[0] = TimeTSKernel(verb, 0, pre, tp->mbB, tp->nbB, 0);
      if (verb)
         printf("   trsmKL %dx%d: %.2f\n", tp->mbB, tp->nbB, tp->mflop[0]);
   }
   WriteRefreshedMMFileWithPath(pre, "res", "tsAMMRES.sum", tb);
   printf("DONE TRSM TIMING.\n");
   KillAllMMNodes(tb);
}

ATL_mmnode_t *FindBestNK_M
   (char pre, int verb, ATL_mmnode_t *mmb, unsigned int mb)
/*
 * RETURNS: Clone of node that provides best perf for a problem with MB=mb.
 *          We try finding best nb&kb by using ones near any that are near
 *          those in list of mmb.  NULL if no kern can do MB=mb.
 */
{
   ATL_mmnode_t *mp, *mpMax=NULL;
   unsigned int kbB=0, nbB=0;
   double mf, mfMax=0.0;
/*
 * Try all candidate kernels for this mb
 */
   for (mp=mmb; mp; mp = mp->next)
   {
      int kb=mp->kbB, nb=mp->nbB;
      if (mb % mp->mu)
         continue;
      mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, kb, 1, 0, -1);
/*
 *    Try NB (and if allowed KB) from larger kerns to see if they improve
 *    small mb perf
 */
      if (mp->next)  /* larger KB/NB kerns exist */
      {
         ATL_mmnode_t *mpG; /* kerns of greater size */
         int KB, lastK=kb, lastN=nb;
         const int ku=mp->ku, nu=mp->nu; 
         const int CHGK=FLAG_IS_SET(mp->flag, MMF_KRUNTIME);

         for (mpG=mp->next; mpG; mpG = mpG->next)
         {
            int k = mpG->kbB, n=mpG->nbB;
            double mfG;

            if (nu <= 8)
               n = ((n+nu-1)/nu)*nu;
            else
               n = (n/nu)*nu;
            if (CHGK)
            {
               if (ku <= 8)
                  k = ((k+ku-1)/ku)*ku;
               else
                  k = (k/ku)*ku;
            }
            else 
               k = kb;
            if (n <= lastN || k <= lastK)
               continue;
            mfG = TimeMMKernel(verb, 0, mp, pre, mb, n, k, 1, 0, -1);
            if (mfG > mf)
            {
               mf = mfG;
               nb = n;
               kb = k;
            }
            lastN = n;
            lastK = k;
         }
      }
      if (mf > mfMax)
      {
         nbB = nb;
         kbB = kb;
         mfMax = mf;
         mpMax = mp;
      }
   }
   if (mpMax)
   {
      int i;
      for (i=0, mp=mmb; mp != mpMax; i++, mp = mp->next);
      mp = mpMax;
      mpMax = CloneMMNode(mpMax);
      mpMax->ivar = i + 1;
      mpMax->mflop[0] = mfMax;
      mpMax->mbB = mb;
      mpMax->nbB = nbB;
      mpMax->kbB = kbB;
   }
   return(mpMax);
}

ATL_mmnode_t *FindBestMK_N
   (char pre, int verb, ATL_mmnode_t *mmb, unsigned int nb)
/*
 * RETURNS: Clone of node that provides best perf for a problem with NB=nb.
 *          We try finding best mb&kb by using ones near any that are near
 *          those in list of mmb.  NULL if no kern can do NB=nb.
 */
{
   ATL_mmnode_t *mp, *mpMax=NULL;
   unsigned int kbB=0, mbB=0;
   double mf, mfMax=0.0;
/*
 * Try all candidate kernels for this nb
 */
   for (mp=mmb; mp; mp = mp->next)
   {
      int kb=mp->kbB, mb=mp->mbB;
      if (nb % mp->nu)
         continue;
      mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, kb, 1, 0, -1);
/*
 *    Try MB (and if allowed KB) from larger kerns to see if they improve
 *    small nb perf
 */
      if (mp->next)  /* larger KB/MB kerns exist */
      {
         ATL_mmnode_t *mpG; /* kerns of greater size */
         int KB, lastK=kb, lastM=mb;
         const int ku=mp->ku, mu=mp->mu; 
         const int CHGK=FLAG_IS_SET(mp->flag, MMF_KRUNTIME);

         for (mpG=mp->next; mpG; mpG = mpG->next)
         {
            int k = mpG->kbB, m=mpG->mbB;
            double mfG;

            if (mu <= 8)
               m = ((m+mu-1)/mu)*mu;
            else
               m = (m/mu)*mu;
            if (CHGK)
            {
               if (ku <= 8)
                  k = ((k+ku-1)/ku)*ku;
               else
                  k = (k/ku)*ku;
            }
            else 
               k = kb;
            if (m <= lastM || k <= lastK)
               continue;
            mfG = TimeMMKernel(verb, 0, mp, pre, m, nb, k, 1, 0, -1);
            if (mfG > mf)
            {
               mf = mfG;
               mb = m;
               kb = k;
            }
            lastM = m;
            lastK = k;
         }
      }
      if (mf > mfMax)
      {
         mbB = mb;
         kbB = kb;
         mfMax = mf;
         mpMax = mp;
      }
   }
   if (mpMax)
   {
      int i;
      for (i=0, mp=mmb; mp != mpMax; i++, mp = mp->next);
      mp = mpMax;
      mpMax = CloneMMNode(mpMax);
      mpMax->ivar = i + 1;
      mpMax->mflop[0] = mfMax;
      mpMax->nbB = nb;
      mpMax->mbB = mbB;
      mpMax->kbB = kbB;
   }
   return(mpMax);
}

ATL_mmnode_t *FindBestK_MN
   (char pre, int verb, ATL_mmnode_t *mmb, unsigned int nb)
/*
 * RETURNS: Clone of node that provides best perf for a problem with MB=NB=nb,
 *          and any KB in the list of mmb.  NULL if no kern can do MB=NB=nb.
 */
{
   ATL_mmnode_t *mp, *mpMax=NULL;
   unsigned int kbB=0;
   double mf, mfMax=0.0;
   for (mp=mmb; mp; mp = mp->next)
   {
      int kb=mp->kbB;
      if (nb % mp->mu || nb % mp->nu)
         continue;
      mf = TimeMMKernel(verb, 0, mp, pre, nb, nb, kb, 1, 0, -1);
/*
 *    If we can change KB, try larger ones before giving up on this kern
 */
      if (mp->next && FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
      {
         ATL_mmnode_t *mpK;
         int KB, lastK=kb;
         const int ku=mp->ku, kbmin=mp->kbmin, kbmax=mp->kbmax;

         for (mpK=mp->next; mpK; mpK = mpK->next)
         {
            int k = mpK->kbB;
            double mfK;

            if (k < kbmin)
               k = kbmin;
            else if (kbmax && k > kbmax)
               k = kbmax;
            else if (ku <= 8 || ku > k)
               k = ((k+ku-1)/ku)*ku;
            else
            {
               k = (k/ku)*ku;
               if (k <= lastK)
                  continue;
            }
            mfK = TimeMMKernel(verb, 0, mp, pre, nb, nb, k, 1, 0, -1);
            if (mfK > mf)
            {
               mf = mfK;
               kb = k;
            }
            lastK = k;
         }
      }
      if (mf > mfMax)
      {
         kbB = kb;
         mfMax = mf;
         mpMax = mp;
      }
   }
   if (mpMax)
   {
      int i;
      for (i=0, mp=mmb; mp != mpMax; i++, mp = mp->next);
      mpMax = CloneMMNode(mpMax);
      mpMax->ivar = i + 1;
      mpMax->mflop[0] = mfMax;
      mpMax->mbB = mpMax->nbB = nb;
      mpMax->kbB = kbB;
   }
   return(mpMax);
}

void GenAllIPViews(char pre, int verb)
/*
 * Generates performance views of geAMMRES.sum
 */
{
   ATL_mmnode_t *mmb, *mp, *mpL;
   mmb = ReadMMFileWithPath(pre, "res", "geAMMRES.sum");
   assert(mmb);
   mp = TimeMMFileWithPath(pre, "res", "ipmnPERF.sum", 0, verb|1, 0, 1, 0, -1);
   if (mp)
      KillAllMMNodes(mp);
   else /* generate inner-product MB=NB, KB free view */
   {
      int i, nb, NBMAX, k;
      ATL_mmnode_t *mb=NULL;
      double mfL=0.0;

      printf("   FINDING BEST CASE FOR DEGENERATE MB=NB\n");
      i = GetOffset(mmb, &(mmb->next));
      GetIntMaxMinAtOff(mmb, i, GetOffset(mmb, &(mmb->nbB)), &NBMAX, &nb);
      GetIntMaxMinAtOff(mmb, i, GetOffset(mmb, &(mmb->mbB)), &k, &i);
      NBMAX = Mmax(NBMAX,k);
      nb = Mmin(nb, i);
      for (mpL=mmb; mpL->next; mpL=mpL->next);
      while (nb <= NBMAX)
      {
         mp = FindBestK_MN(pre, verb, mmb, nb);
         if (mp && mp->mflop[0] >= mfL)
         {
            mfL = mp->mflop[0];
            printf("      BEST CASE NB=%d: %d-%s, KB=%d  mf=%.2f.\n", mp->nbB,
                   mp->ID, mp->rout ? mp->rout:"gen", mp->kbB, mfL);
            mp->next = mb;
            mb = mp;
         }
         nb++;
@skip         while (mb->kbB < nb && mb->next)
@skip            mb = mb->next;
      }
      mb = ReverseMMQ(mb);
@skip      MMPruneMflopTol(mb, 0, 1.0);
      WriteMMFileWithPath(pre, "res", "ipmnPERF.sum", mb);
      KillAllMMNodes(mb);
      printf("   DONE DEGENERATE MB/NB SEARCH.\n\n");
   }

   mp = TimeMMFileWithPath(pre, "res", "ipnPERF.sum", 0, verb|1, 0, 1, 0, -1);
   if (mp)
      KillAllMMNodes(mp);
   else /* generate inner-product NB < MAXNB, MB,KB free view */
   {
      int i, nb, NBMAX, k;
      ATL_mmnode_t *mb=NULL;
      double mfL=0.0;

      printf("   FINDING BEST CASE FOR DEGENERATE NB\n");
      i = GetOffset(mmb, &(mmb->next));
      GetIntMaxMinAtOff(mmb, i, GetOffset(mmb, &(mmb->nbB)), &NBMAX, &nb);
      while (nb <= NBMAX)
      {
         mp = FindBestMK_N(pre, verb, mmb, nb);
         if (mp && mp->mflop[0] >= mfL)
         {
            mfL = mp->mflop[0];
            printf("      BEST CASE NB=%d: %d-%s, MB=%d, KB=%d  mf=%.2f.\n", 
                   mp->nbB, mp->ID, mp->rout ? mp->rout:"gen", 
                   mp->mbB, mp->kbB, mfL);
            mp->next = mb;
            mb = mp;
         }
         nb++;
      }
      mb = ReverseMMQ(mb);
@skip      MMPruneMflopTol(mb, 0, 1.0);
      WriteMMFileWithPath(pre, "res", "ipnPERF.sum", mb);
      KillAllMMNodes(mb);
      printf("   DONE DEGENERATE NB SEARCH.\n\n");
   }

   mp = TimeMMFileWithPath(pre, "res", "ipmPERF.sum", 0, verb|1, 0, 1, 0, -1);
   if (mp)
      KillAllMMNodes(mp);
   else /* generate inner-product NB < MAXNB, MB,KB free view */
   {
      int i, nb, NBMAX, k;
      ATL_mmnode_t *mb=NULL;
      double mfL=0.0;

      printf("   FINDING BEST CASE FOR DEGENERATE MB\n");
      i = GetOffset(mmb, &(mmb->next));
      GetIntMaxMinAtOff(mmb, i, GetOffset(mmb, &(mmb->mbB)), &NBMAX, &nb);
      while (nb <= NBMAX)
      {
         mp = FindBestNK_M(pre, verb, mmb, nb);
         if (mp && mp->mflop[0] >= mfL)
         {
            mfL = mp->mflop[0];
            printf("      BEST CASE MB=%d: %d-%s, NB=%d, KB=%d  mf=%.2f.\n", 
                   mp->mbB, mp->ID, mp->rout ? mp->rout:"gen", 
                   mp->nbB, mp->kbB, mfL);
            mp->next = mb;
            mb = mp;
         }
         nb++;
      }
      mb = ReverseMMQ(mb);
@skip      MMPruneMflopTol(mb, 0, 1.0);
      WriteMMFileWithPath(pre, "res", "ipmPERF.sum", mb);
      KillAllMMNodes(mb);
      printf("   DONE DEGENERATE MB SEARCH.\n\n");
   }

   KillAllMMNodes(mmb);
}
/*
 * Finds main amm kernels
 */
ATL_mmnode_t *DoMainMM(char pre, int verb, int nregs, int CS)
{
   ATL_mmnode_t *mmb, *sqmmb, *mp, *mmGN;
   const char upr = (pre == 'z' || pre == 'd') ? 'd' : 's';
/* 
 * If we are quick returning, still must possibly retime subsearches
 */
   mmb = TimeMMFileWithPath(pre, "res", "geAMMRES.sum", 0, verb|1, 0, 1, 0, -1);
   if (mmb)
   {
      KillAllMMNodes(DoSquare(pre, verb, nregs, mmb));
      return(mmb);
   }
/*
 * Find the generated cases for each cache context
 */
   mmGN = GetGenCases(pre);
   assert(mmGN);
/*
 * Find which user-supplied kernels can compile on this platform
 */
   mmb = GetWorkingUserCases(verb, upr);
/*
 * Add gmmsearch-suggested kernels to those being considered.
 */
   mp = ATL_LastMMNode(mmGN);
   mp->next = mmb;
   mmb = mmGN;
/*
 * Find the best user-supplied cases for the three common cache blking cases
 */
   mmb = FindCacheBudgetCasesByKB(verb, pre, CS, mmb);
   #if 0  /* switching square case to rank-K */
/*
 *    Now find best square cases
 */
      sqmmb = DoSquare(pre, verb, nregs, mmb);
/*
 *     Now merge square & rect lists for best performing kernels, and write out
 */
      mp = MergeCases(0, mmb, sqmmb);
      KillAllMMNodes(sqmmb);
      KillAllMMNodes(mmb);
      mmb = WinnowCases(0, mp);
   #else
      mmb = WinnowCases(0, mmb);
   #endif
   WriteRefreshedMMFileWithPath(pre, "res", "geAMMRES.sum", mmb);
   return(mmb);
}
@beginskip
/*
 * Finds main amm kernels
 */
ATL_mmnode_t *DoMainMM(char pre, int verb, int nregs, int CS, int *nbs)
{
   ATL_mmnode_t *mmb, *smmb;
   mmb = ReadMMFileWithPath(pre, "res", "geAMMRES.sum");
   if (mmb)
   {
      MMFillInGenStrings(pre, mmb);
      if (mmb->mflop[0] < 0.0)
      {
         ATL_mmnode_t *mp;
         for (mp=mmb; mp; mp = mp->next)
            mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB,
                                        mp->kbB, 1, 0, -1);
         WriteMMFileWithPath(pre, "res", "geAMMRES.sum", mmb);
      }
      return(mmb);
   }
   if (verb)
   {
      int i;
      const int n = (nbs[0] >= 0) ? nbs[0]+1 : 1-nbs[0];
      printf("NBs = %3d", nbs[1]);
      for (i=2; i < n; i++)
         printf(", %3d", nbs[i]);
      printf("\n");
   }
/*
 * Find which kernels can compile on this platform
 */
   mmb = GetWorkingUserCases(verb, pre);
/*
 * For small cases (or user specified), try all kernels with all KB for
 * user generated.  Smmb now points to these KB values that are always
 * retained, and will simply be added to eventual list of large KB kernels
 * that we generate in the next step.
 */
   if (mmb)
   {
      ATL_mmnode_t *mmp;
      mmp = CloneMMQueue(mmb);
      smmb = FindBestUserCases(verb, pre, nbs, mmp);
      mmp = FindBestGenCases(verb, pre, nregs, nbs, smmb);
      if (nbs[0] >= 0)
         smmb = MergeAndWinnowCases(verb, pre, smmb, mmp);
      else  /* forced nbs are all kept, so just merge */
         smmb = MergeCases(0, smmb, mmp);
@skip         WriteMMFileWithPath(pre, "./", "win0.sum", smmb);
   }
   else
     smmb = FindBestGenCases(verb, pre, nregs, nbs, NULL);
/*
 * If nbs aren't being forced, then try larger ranges using cache budgets
 */
   if (nbs[0] >= 0)
   {
      ATL_mmnode_t *mp;
/*
 *    Find decent generator case and find correct vectorization settings, add
 *    this case to default list to be searched.
 */
      mp = DecentGenCase(verb, pre, nregs);
      mp->next = mmb;
      mmb = mp;
/*
 *    Find the best user-supplied cases for the three common cache blking cases
 */
      mmb = FindCacheBudgetCasesByKB(verb, pre, CS, mmb);
/*
 *    Now add small-case kernels back in, and write it out
 */
      mp = MergeCases(0, mmb, smmb);
      KillAllMMNodes(smmb);
      KillAllMMNodes(mmb);
      mmb = WinnowCases(0, mp);
   }
   else /* when we force nbs, we just blindly use the provided list */
      mmb = smmb;
   WriteMMFileWithPath(pre, "res", "geAMMRES.sum", mmb);
   return(mmb);
}
@endskip

int KernHandlesThisKB(ATL_mmnode_t *mp, int kb)
{
   if (!mp->ID)  /* genned kernel handles all K (kvec needs padding) */
      return(1);
   if (mp->kbmax && kb > mp->kbmax)
      return(0);
/*
 * KVEC kerns can always handle problems within vlen-1 less than their kb
 * due to padding in copy routines.
 */
   if (FLAG_IS_SET(mp->flag, MMF_KVEC))
   {
      int KB;
      const int ku = mp->ku;
      if (mp->kbmin)
      {
         KB = (mp->kbmin / mp->vlen)*mp->vlen;
         if (KB < mp->kbmin)
            return(0);
      }
      KB = ((kb+mp->vlen-1)/mp->vlen)*mp->vlen;
      if ((KB/ku)*ku != kb)
         return(0);
   }
   else
   {
      const int ku = mp->ku;
      if (kb < mp->kbmin)
         return(0);
      if ((kb/ku)*ku != kb)
      {
         if (mp->ID)
            return(0);
         else if (!FLAG_IS_SET(mp->flag, MMF_KUISKB))
            return(0);  /* genned codes can adjust fully-unrolled loop */
      }
   }
   return(1);
}

/*
 * This routine tries all kernels in mmb, with K=KB, M=CEIL(KB/MU)*MU,
 * N=CEIL(KB/NU)*NU.  Kernels that can't handle KB are rejected
 * RETURNS: new mmnode ptr for best case for this KB; cannot be NULL, because
 *          1st param of mmb must be a generated kernel that works for any KB
 */
ATL_mmnode_t *BestKernForKB(int verb, char pre, ATL_mmnode_t *mmb, int KB)
{
   ATL_mmnode_t *mp, *mpB=NULL;
   double mfB=0.0;
   assert(mmb);
   printf("   FINDING BEST NEAR-SQUARE KERNEL WT KB=%d:\n", KB);
   for (mp=mmb; mp; mp = mp->next)
   {
      const int mu=mp->mu, nu=mp->nu, ku=mp->ku, ID=mp->ID;
      const int mb=((KB+mu-1)/mu)*mu, nb=((KB+nu-1)/nu)*nu;
      int kb=KB;
      const char *rt=mp->rout;
      double mf;

      if (!KernHandlesThisKB(mp, KB))
      {
         if (ID)
            printf("      %d-%s: skipped, cannot handle KB=%d\n", ID, rt, KB);
         else
         {
            printf("      0-");
            PrintGen0(stdout, mp, 0, 0, 0);
            printf(": skipped, cannot handle KB=%d\n", KB);
         }
         continue;
      }
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         kb = ((KB+mp->vlen-1)/mp->vlen)*mp->vlen;
      if (!mp->ID && FLAG_IS_SET(mp->flag, MMF_KUISKB))
      {
         mp->kbmin = kb-mp->vlen+1;
         mp->kbmax = mp->ku = kb;
         mp->kbB = KB;
         if (mp->genstr);
            free(mp->genstr);
         mp->genstr = MMGetGenString(pre, mp);
      }
      mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, KB, 0,  0, -1);
      if (mf > mfB)
      {
         mfB = mf;
         mpB = mp;
      }
      if (ID)
         printf("      %d-%s, M=%d, N=%d, K=%d: %.0f\n", ID, rt, mb,nb,KB, mf);
      else
      {
         printf("      0-");
         PrintGen0(stdout, mp, mb, nb, KB);
         printf(": %.0f\n", mf);

      }
   }
   assert(mpB);
   printf("   BEST FOR KB=%d: %d-%s (%.1f MFLOPS)\n", 
          KB, mpB->ID, mpB->rout, mfB);
   mpB = CloneMMNode(mpB);
   mpB->mflop[0] = mfB;
   mpB->kbB = KB;
   mpB->mbB = ((KB+mpB->mu-1)/mpB->mu)*mpB->mu;
   mpB->nbB = ((KB+mpB->nu-1)/mpB->nu)*mpB->nu;
   return(mpB);
}

ATL_mmnode_t *DoRankK(char pre, int verb, int nregs, const ATL_mmnode_t *mainb)
{
   ATL_mmnode_t *rkb=NULL, *mp, *mmb;
   const ATL_mmnode_t *cmp;
   int maxB=0, b;
   const char upr = (pre == 'z' || pre == 'd') ? 'd' : 's';
   rkb = TimeMMFileWithPath(pre, "res", "rkAMMRES.sum", 0, verb|1, 0, 1, 0, -1);
   if (rkb)
      return(rkb);
/*
 * Find largest KB used by main kernels; we will time all near-square kernels
 * of this size and below
 */
   for (cmp=mainb; cmp; cmp = cmp->next)
      if (cmp->kbB > maxB)
         maxB = cmp->kbB;
   if (!maxB)
      maxB = 256;
/*
 * All we need main kerns for is to find maxB, so now reuse the ptr to hold
 * all user cases that work on this platform
 */
   mmb = GetGenCases(pre);
   mp = ATL_LastMMNode(mmb);
   mp->next = GetWorkingUserCases(verb, upr);
@beginskip
   mmb = GetWorkingUserCases(verb, upr);
   mp = DecentGenCase(verb, pre, nregs);
   assert(mp);
   mp->next = mmb;
   mmb = mp;
@endskip
   ResetMoveBitsInQ(rkb, 5);
   printf("TUNING RANK-K, 3 <= K <= %d:\n", maxB);
   for (b = maxB; b > 2; b--)
   {
      mp = BestKernForKB(verb, pre, mmb, b);
      mp->next = rkb;
      rkb = mp;
   }
   WriteRefreshedMMFileWithPath(pre, "res", "rkAMMRES.sum", rkb);
   return(rkb);
}

int main(int nargs, char **args)
{
   char pre='d';
   int verb, nregs, nb, CS, gmu, gnu;
   char *fnout;
   ATL_mmnode_t *mmb, *rnkK, *grnkK, *emb, *mp, *mmSQ;

   GetFlags(nargs, args, &pre, &verb, &nregs, &nb, &CS);
   mmb = DoMainMM(pre, verb, nregs, CS);
   emb = TimeExtraBlockings(pre, verb);
   if (emb)
   {
      emb = SortMMQByIntVal(emb, &(emb->kbB));
      mp = MergeCases(0, mmb, emb);
      KillAllMMNodes(mmb);
      KillAllMMNodes(emb);
      mmb = WinnowCases(0, mp);
      WriteMMFileWithPath(pre, "res", "geAMMRES.sum", mmb);
   }
   rnkK = DoRankK(pre, verb, nregs, mmb);
   DoSquare(pre, verb, nregs, rnkK);
@skip   GenAllIPViews(pre, verb);
/*
 * Handle K-cleanup
 */
   ComputeKClean(verb, pre);
/*
 * Time TRSM kernels with matching block factors as square cases
 */
   DoTRSM(pre, verb);
/*
 * Join mmb & rnkK to make master list of all kernels required in this search
 */
   if (rnkK)
   {
      for (mp=mmb; mp->next; mp = mp->next);
      mp->next = rnkK;
   }
   mp = GetUniqueUserKerns(mmb);
   KillAllMMNodes(mmb);
   WriteRefreshedMMFileWithPath(pre, "res", "AMMFRCLST.sum", mp);
   KillAllMMNodes(mp);
   GetGenKernForNB(pre, 0);  /* dealloc static mmnodes */
   exit(0);
}
@ROUT uammsearch
/*
 * ASSUMES: mmb comes in ordered from smallest blocking to largest.  
 * Kills any kernel that is not faster than a smaller-NB kernel.
 */
ATL_mmnode_t *HarshPrune(ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mmp=mmb;
   while (mmp)
   {
      if (!mmp->next)
         return(mmb);
      do
      {
         if (!mmp->next)
            return(mmb);
         if (mmp->mflop[0] > mmp->next->mflop[0])
            mmp->next = KillMMNode(mmp->next);
         else
            mmp = mmp->next;
      }
      while (mmp);
   }
}
/*
 * ASSUMES: mmb comes in ordered from smallest blocking to largest.  
 * Kills any kernel that is not faster than a smaller-NB kernel.
 */
ATL_mmnode_t *TolerantPrune
(
   ATL_mmnode_t *mmb,   /* list of kernels to prune */
   double tol           /* set > 1 to allow slow kernels to stay */
)                       /* < 1 to make pruning harsher */
{
   ATL_mmnode_t *mmp=mmb;
   double mfB = 0.0;
   while (mmp)
   {
      if (!mmp->next)
         return(mmb);
      do
      {
         if (!mmp->next)
            return(mmb);
         if (mmp->mflop[0] > mfB)
            mfB = mmp->mflop[0];
         if (mfB > tol*mmp->next->mflop[0])
            mmp->next = KillMMNode(mmp->next);
         else
            mmp = mmp->next;
      }
      while (mmp);
   }
}
#define CON_NOKVEC 0
#define CON_NOMVEC 1
#define CON_NOCOMPK 2
/*
 * RETURNS: N-length queue wt best-performing kernel for specified dims
 */
ATL_mmnode_t *FindBestKerns
(
   char pre, 
   int verb, 
   ATL_mmnode_t *mmb,            /* candidate user-supplied kerns */
   int N,                        /* number of forced block factors */
   int *mbs, int *nbs, int *kbs, /* forced block factors */
   int C,                        /* constraints */
   float tol                     /* tolerance in getting rid of slow kerns */
)
{
   ATL_mmnode_t *nmmb=NULL, *mp, *mpB, *mpG, *mpg;
   const int TRYKVEC=!(C & (1<<CON_NOKVEC));
   const int TRYMVEC=!(C & (1<<CON_NOMVEC));
   int i, mbB=0;
   double mfB, mf;
/*
 * Find basic register blocking for generated case
 */
   mpG = DecentGenCase(verb, pre, 32);
   if (mpG->vlen != VLEN[VECi])
      VECi = VTSC;
   assert (mpG->kmaj < 2);
/*
 * Loop over all required blocking factors
 */
   printf("SEARCHING %d USER BLOCKINGS:\n", N);
   for (i=N-1; i >= 0; i--)
   {
      int mb=mbs[i], nb=nbs[i], kb=kbs[i], MB=mbs[i];
      int kuG, KK=kb, veci0=VECi;
      double mfK=0.0, mfM=0.0;
      int iveci = VECi, VL=VLEN[VECi];
/*
 *    If mb not specified, choose one near specified KB
 */
      printf("\n   FINDING KERNEL FOR MB=%d, NB=%d, KB=%d:\n", mb, nb, kb);
/*
 *    Find best of M- or K-vectorized generated code for this problem size
 */
      mpg = mpB = NULL;
      if (TRYMVEC)
      {
         int muG=mpG->mu, nuG=mpG->nu, ut=muG*nuG; 
/*
 *       If mb is not specified, make it a multiple of mu & vlen
 */
         if (!MB)
         {
            int mb0;
            mb = Mylcm(muG, VL);
            mb0 = (kb/mb)*mb;
            mb = ((kb+mb-1)/mb)*mb;
            if (mb0 && mb-kb > kb-mb0)
               mb = mb0;
         }
/*
 *       If specified mb not a multiple of vlen, reduce vlen until it is
 */
         else if (mb%VL)
         {
            if (VECi == VTAVX && !(mb%VLEN[VTSSE]))
               VECi = VTSSE;
            else
               VECi = VTSC;
         }
/*
 *       Make register block a multiple of mandated block
 */
         muG = (muG / VL)*VLEN[VECi];
         ut = muG * nuG;
         while (muG > 1 && mb%muG)
            muG -= VLEN[VECi];
         if (muG < 1)
            muG = 1;
         while(muG*(nuG+1) <= ut)
            nuG++;
         while (nb%nuG)
            nuG--;
         kuG = 1;
         mpg = GetNewGenNode(pre, kb, 0, muG/VLEN[VECi], nuG, 1, 0);
         mpg->mbB = mb;
         mfM = TimeMMKernel(verb, 0, mpg, pre, mb, nb, KK, KK, KK, mb, 1, 0,-1);
         printf("      Gen mu=%d, nu=%d, kmaj=%d, mf=%.2f\n", muG, nuG, 0, mfM);
      }
      VECi = iveci;
/*
 *    Generator currently does not support k-vectorized kernels
 */
      if (0 && TRYKVEC)
      {
         int muG, nuG=mpG->nu, ut;

         if (VLEN[VECi] > 1)
            muG = mpG->mu / VLEN[VECi];
         else
            muG = mpG->mu;
         ut = muG * nuG;
/*
 *       If kb not a multiple of vlen, reduce it until it is
 */
         if (kb%VLEN[VECi])
         {
            if (VECi == VTAVX && !(kb%VLEN[VTSSE]))
               VECi = VTSSE;
            else
               VECi = VTSC;
         }
         kuG = VLEN[VECi];
/*
 *       Make register block a multiple of mandated block
 */
         while (mb%muG)
            muG--;
         while(muG*(nuG+1) <= ut)
            nuG++;
         while (nb%nuG)
            nuG--;
         if (kuG > 1)
         {
            mpB =  GetNewGenNode(pre, kb, 0, muG, nuG, kuG, kuG);
            mpg->mbB = mb;
            mfK = TimeMMKernel(verb, 0, mpB, pre, mb, nb, KK, KK, KK, mb,
                               1, 0,-1);
            printf("      Gen mu=%d, nu=%d, kmaj=%d, mf=%.2f\n", muG, nuG, kuG,
                   mfK);
         }
      }
      if (mfM >= mfK)  /* use M-vectorized gen kernel */
      {
         if (mpB)
            KillMMNode(mpB);
         mpB = mpg;
         mfB = mfM;
      }
      else
      {
         if (mpg)
            KillMMNode(mpg);
         mpg = mpB;
         mfB = mfK;
      }
      VECi = iveci;
      if (KK != kb)
         mfB *= (double)kb / (double)KK;
      mpg->mflop[0] = mfB;
/*
 *    Search through all user kernels, and take best performing
 */
      mpB = mpg;
      mbB = mpg->mbB;
      for (mp=mmb; mp; mp = mp->next)
      {
         const int mu=mp->mu, nu=mp->nu, ku=mp->ku, kmaj=mp->kmaj;
         const int KB = (kmaj < 2) ? kb : ((kb+ku-1)/ku)*ku;
         int SKIP=0;
         if (!MB)
         {
            if (nb%nu || KB%ku)
               SKIP=1;
            else
            {
               int mb0;
               mb0 = (kb/mu)*mu;
               mb = ((kb+mu-1)/mu)*mu;
               if (mb0 && (mb-kb > kb-mb0))
                  mb = mb0;
            }
         }
         else if (mb%mu || nb%nu || KB%ku)
            SKIP=1;
         if (mp->kbmin && mp->kbmin > kb)
            SKIP=1;
         else if (mp->kbmax && mp->kbmax < kb)
            SKIP=1;
         if (SKIP)
         {
            printf("      %d-%s: SKIPPED\n", mp->ID, mp->rout);
            continue;
         }
         mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, KB, KB, KB, mb, 1, 0, -1);
         if (KB != kb)
            mf *= (double)kb / (double)KB;
         printf("      %d-%s: %.2f\n", mp->ID, mp->rout, mf);
         if (mf > mfB)
         {
            mfB = mf;
            mpB = mp;
            mbB = mb;
         }
      }
      printf("    [M,N,K]B=%d,%d,%d BEST: %d-%s %.2f\n", mbB, nb, kb,
             mpB->ID, mpB->rout, mfB);
      if (mpB == mpg)
      {
         mpg->next = nmmb;
         nmmb = mpg;
      }
      else
      {
         KillMMNode(mpg);
         mp = CloneMMNode(mpB);
         mp->next = nmmb;
         nmmb = mp;
      }
      nmmb->mflop[0] = mfB;
      nmmb->mbB = mbB;
      nmmb->nbB = nb;
      nmmb->kbB = kb;
      VECi = veci0;
   }
   KillAllMMNodes(mmb);
   KillMMNode(mpG);
@skip   PrintMMNodes(stderr, nmmb);
   if (tol > 0.0)
      nmmb = TolerantPrune(nmmb, tol);
@skip   ApplyMoves2Flags(nmmb, MOVES);  /* gen must know operand movement pattern */
   WriteMMFileWithPath(pre, "res", "uAMMFRC.sum", nmmb);
   printf("DONE.\n");
   return(nmmb);
}

/*
 * This routine applies the contraints C to mmb, and returns winnowed queue
 * RETURNS: Q wt all kernels failing constraints stropped out
 */
ATL_mmnode_t *ApplyConstraints(ATL_mmnode_t *mmb, int C)
{
    if (C)
    {
       ATL_mmnode_t *mp = mmb, *next;
       while (mp)
       {
          next = mp->next;
          if ((C & (1<<CON_NOKVEC)) && mp->kmaj > 1)
             mmb = KillMMNodeFromQ(mmb, mp);
          else if ((C & (1<<CON_NOMVEC)) && mp->kmaj < 2)
             mmb = KillMMNodeFromQ(mmb, mp);
          else if ((C & (1<<CON_NOCOMPK)) && 
                   !FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
             mmb = KillMMNodeFromQ(mmb, mp);
          mp = next;
       }
    }
    return(mmb);
}
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr, 
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, 
   "   -S <file> : take kerns from sum file, force square sizes\n");
   fprintf(stderr, "   -T #  : set pruning tolerance for slower kernels:\n");
   fprintf(stderr, 
   "      # <= 0.0 : keep all legal kernel sizes regardless of performance\n");
   fprintf(stderr, 
   "      # >=0.0 : delete all kerns wt perf*# < maxSmallerPerf\n");
   fprintf(stderr, 
   "                maxSmallerPerf= max perf found in smaller-sized kern\n");
   fprintf(stderr, "   -p [s,d]: set precision prefix (d) \n");
   fprintf(stderr, "   -b # nb1 ... nb# : square NBs to force\n");
   fprintf(stderr, "   -B # mb1 nb1 kb1 ... mb# nb# kb#: dims to force\n");
   fprintf(stderr, 
           "   -M # abc1 ... abc#: which matblks should be cache flushed\n");
   fprintf(stderr, "   -v <verb> : set verbosity (1)\n");
   fprintf(stderr, "   -C [kmc] : Constrain kernel choice:\n");
   fprintf(stderr, "      k : don't allow K-vectorized storage\n");
   fprintf(stderr, "      m : don't allow M-vectorized storage\n");
   fprintf(stderr, "      c : don't allow compile-time K kernels\n");
   fprintf(stderr, "   -K <1/0> : do/don't generate K cleanup\n");

   fprintf(stderr,
      "   -F <b0> <bN> <KI> <idx> <rfn>: brute-force blocking search:\n");
   fprintf(stderr, "       b0: smallest value to try for all dims\n");
   fprintf(stderr, "       b1: largest value to try for all dims\n");
   fprintf(stderr, "       KI: min K increment\n");
   fprintf(stderr, "      idx: index in rfn to use; -1 means last\n");
   fprintf(stderr, "      rfn: search result file name to read kern from\n");
   exit(ierr ? ierr : -1);
}

ATL_mmnode_t *GetFlags(int nargs, char **args, char *PRE, int *VERB, int *NN,
                       int *C, int **MBS, int **NBS, int **KBS, float *TOL,
                       int *KCLEAN)
{
   ATL_mmnode_t *mmb=NULL;
   int B0=0, BN, KI;
   int *mbs=NULL, *nbs=NULL, *kbs=NULL;
   int i, k, j, N=0, ALL=0, MV;
   char *cs;

@skip   MOVES = NULL;
   *TOL = 0.0;
   *VERB = 1;
   *PRE = 'd';
   *C = 0;
   *KCLEAN = 1;
   for (i=1; i < nargs; i++)
   {
      int n;
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'T':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *TOL = atof(args[i]);
         if (*TOL < 0.0)
            *TOL = 0.0;
         break;
      case 'F':  /* <b0> <bN> <KI> <idx> <rfn> */
         if (i+5 >= nargs)
            PrintUsage(args[0], i-1, NULL);
         else
         {
            int I, k;
            ATL_mmnode_t *mp;

            B0 = atoi(args[i+1]);
            BN = atoi(args[i+2]);
            KI = atoi(args[i+3]);
            I = atoi(args[i+4]);
            mmb = ReadMMFile(args[i+5]);
            assert(mmb);
            if (I < 0)
               for (mp=mmb; mp->next; mp = mp->next);
            else
               for (k=0, mp=mmb; k < I && mp; k++, mp = mp->next);
            assert(mp);
            mp = CloneMMNode(mp);
            KillAllMMNodes(mmb);
            mmb = mp;
         }
         i += 5;
         break;
      case 'M':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         n = atoi(args[i]);
         for (MV=k=0; k < n; k++)
         {
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            if (args[i][0] == 'a' || args[i][0] == 'A')
               MV |= 1;
            else if (args[i][0] == 'b' || args[i][0] == 'B')
               MV |= 2;
            else if (args[i][0] == 'c' || args[i][0] == 'C')
               MV |= 4;
            else
               PrintUsage(args[0], -i, "UNKNOWN MATRIX FOR -M");
         }
         IMVS = MV;
@beginskip
         n=0;
         if (MV&1) n++;
         if (MV&2) n++;
         if (MV&4) n++;
         if (n == 1)
         {
            MOVES = DupString("-DMoveA");
            if (MV == 2)
               (MOVES)[6] = 'B';
            else if (MV == 4)
               (MOVES)[6] = 'C';
         }
         else if (n == 2)
         {
            MOVES = DupString("-DMoveA -DMoveB");
            if ((MV&1) == 0)
               MOVES[6] = 'C';
            else if ((MV&2) == 0)
               MOVES[14] = 'C';
         }
         else
            MOVES = DupString("-DMoveA -DMoveB -DMoveC");
@endskip
         break;
      case 'S':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         mmb = ReadMMFile(args[i]);
         break;
      case 'K':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *KCLEAN = atoi(args[i]);
         break;
      case 'v':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *VERB = atoi(args[i]);
         break;
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *PRE = tolower(args[i][0]);
        assert(*PRE == 's' || *PRE == 'd' || *PRE == 'z' || *PRE == 'c');
        break;
      case 'C':  /* -C <constraint string */
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         cs = args[i];
         n = strlen(cs);
         for (k=0; k < n; k++)
         {
            switch(cs[k])
            {
            case 'm':
               *C |= 1<<CON_NOMVEC;
               break;
            case 'k':
               *C |= 1<<CON_NOKVEC;
               break;
            case 'c':
               *C |= 1<<CON_NOCOMPK;
               break;
            default:
               PrintUsage(args[0], -i, "UNKNOWN CONSTRAINT");
            }
         }
      case 'B':
         if (nbs)
         {
            free(mbs);
            free(nbs);
            free(kbs);
         }
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         N = atoi(args[i]);
         assert(N > 0);
         nbs = malloc(N*sizeof(int));
         assert(nbs);
         mbs = malloc(N*sizeof(int));
         assert(mbs);
         kbs = malloc(N*sizeof(int));
         assert(kbs);
         for (k=0; k < N; k++)
         {
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           mbs[k] = atoi(args[i]);
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           nbs[k] = atoi(args[i]);
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           kbs[k] = atoi(args[i]);
         }
         break;
      case 'b':
         if (nbs)
         {
            free(mbs);
            free(nbs);
            free(kbs);
         }
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         N = atoi(args[i]);
         if (N < 0)
         {
            ALL = (N == -2) ? 32 : -1;  /* -2: don't force MB */
            N = 36;
         }
         assert(N > 0);
         nbs = malloc(N*sizeof(int));
         assert(nbs);
         mbs = malloc(N*sizeof(int));
         assert(nbs);
         kbs = malloc(N*sizeof(int));
         assert(nbs);
         if (ALL)  /* special case to just try most possible NBs */
         {
            mbs[ 0]=nbs[ 0]=kbs[ 0]=4;
            mbs[ 1]=nbs[ 1]=kbs[ 1]=6;
            mbs[ 2]=nbs[ 2]=kbs[ 2]=8;
            mbs[ 3]=nbs[ 3]=kbs[ 3]=12;
            mbs[ 4]=nbs[ 4]=kbs[ 4]=14;
            mbs[ 5]=nbs[ 5]=kbs[ 5]=16;
            mbs[ 6]=nbs[ 6]=kbs[ 6]=20;
            mbs[ 7]=nbs[ 7]=kbs[ 7]=22;
            mbs[ 8]=nbs[ 8]=kbs[ 8]=24;
            mbs[ 9]=nbs[ 9]=kbs[ 9]=26;
            mbs[10]=nbs[10]=kbs[10]=28;
            mbs[11]=nbs[11]=kbs[11]=32;
            mbs[12]=nbs[12]=kbs[12]=36;
            mbs[13]=nbs[13]=kbs[13]=40;
            mbs[14]=nbs[14]=kbs[14]=44;
            mbs[15]=nbs[15]=kbs[15]=48;
            mbs[16]=nbs[16]=kbs[16]=52;
            mbs[17]=nbs[17]=kbs[17]=56;
            mbs[18]=nbs[18]=kbs[18]=60;
            mbs[19]=nbs[19]=kbs[19]=64;
            mbs[20]=nbs[20]=kbs[20]=72;
            mbs[21]=nbs[21]=kbs[21]=80;
            mbs[22]=nbs[22]=kbs[22]=84;
            mbs[23]=nbs[23]=kbs[23]=88;
            mbs[24]=nbs[24]=kbs[24]=96;
            mbs[25]=nbs[25]=kbs[25]=104;
            mbs[26]=nbs[26]=kbs[26]=112;
            mbs[27]=nbs[27]=kbs[27]=120;
            mbs[28]=nbs[28]=kbs[28]=128;
            mbs[29]=nbs[29]=kbs[29]=132;
            mbs[30]=nbs[30]=kbs[30]=144;
            mbs[31]=nbs[31]=kbs[31]=156;
            mbs[32]=nbs[32]=kbs[32]=168;
            mbs[33]=nbs[33]=kbs[33]=192;
            mbs[34]=nbs[34]=kbs[34]=216;
            mbs[35]=nbs[35]=kbs[35]=240;
            for (k=0; k < ALL; k++)     /* don't force any particular */
               mbs[k] = 0;              /* MB during search */
         }
         else
         {
            for (k=0; k < N; k++)
            {
              if (++i >= nargs)
                  PrintUsage(args[0], i-1, NULL);
               mbs[k] = kbs[k] = nbs[k] = atoi(args[i]);
            }
         }
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (B0 && mmb)
   {
      ATL_mmnode_t *mp;
      mp = BestBlocking_BFI(1, *PRE, mmb, B0, BN, KI, 0);
      KillMMNode(mmb);
      KillMMNode(mp);
      exit(0);
   }
   if (!nbs && !mmb)
      PrintUsage(args[0], -1, "Dimensional flag (-b or -B) or -S required!");
   *MBS = mbs;
   *NBS = nbs;
   *KBS = kbs;
   if (*PRE == 's' || *PRE == 'c')
   {
      VLEN[VTAVXZ] = 16;
      VLEN[VTAVX] = 8;
      VLEN[VTSSE] = 4;
      VLEN[VTGV] = 4;
      TSIZE = 4;
   }
   #ifdef ATL_AVXZ
      VECi = VTAVXZ;
   #elif defined(ATL_AVX)
      VECi = VTAVX;
   #elif defined(ATL_SSE1)
      if (*PRE == 's')
         VECi = VTSSE;
      #ifdef ATL_SSE2
      else
         VECi = VTSSE;
      #endif
   #elif (defined(ATL_AltiVec) && !defined(ATL_VSX)) || \
         (defined(ATL_NEON) && defined(ATL_NONIEEE) && ATL_NONIEEE != 0) || \
         (defined(ATL_3DNow) && defined(ATL_NONIEEE) && ATL_NONIEEE != 0)
      if (pre == 's')
         VECi = VTGV;
   #elif defined(ATL_VSX)
      VECi = VTGV;
   #endif
   *NN = N;
   return(mmb);
}

/*
 * Finds best-performing square cases from input list of good kernels, which
 * are first pruned of any losers (any kernel that is not faster than a
 * kernel with a smaller NB).
 */
ATL_mmnode_t *FindBestSquareKern(char pre, int verb, ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mmp, *mmSQ=NULL, *prev=NULL;
   int maxNB=0;

   mmb = HarshPrune(mmb);  /* kill uncompetitive kernels */
   assert(mmb);

   mmSQ = FindBestSquareCases(pre, verb, mmb);
   assert(mmSQ);
   KillAllMMNodes(mmb);
@skip   ApplyMoves2Flags(mmSQ, MOVES);  /* gen must know operand movement pattern */
   WriteMMFileWithPath(pre, "res", "uAMMFRC.sum", mmSQ);
   printf("DONE.\n");
   return(mmSQ);
}

int main(int nargs, char **args)
{
   int *nbs, *mbs, *kbs, verb, N, C=0, KCLEAN;
   float tol;
   char pre;
   ATL_mmnode_t *mmb, *mp, *mmB;
   double mfB;

   mmb = GetFlags(nargs, args, &pre, &verb, &N, &C, &mbs, &nbs, &kbs, &tol,
                  &KCLEAN);
/*
 * If -S is thrown, we take kernels from prior search, and just retune with
 * requirement that the kernels be square
 */
   if (mmb)
   {
      mmb = ApplyConstraints(mmb, C);
      assert(mmb);
      ApplyMoves2Flags(mmb, IMVS);
@beginskip
      if (MOVES)
      {
         for (mp=mmb; mp; mp = mp->next)
            mp->moves = DupString(MOVES);
      }
@endskip
      mmb = FindBestSquareKern(pre, verb, mmb);
   }
   else
   {
      char upr=pre;
      if (pre == 'z')
         upr = 'd';
      else if (pre == 'c')
         upr = 's';
      mmb = GetWorkingUserCases(verb, upr);  /* get all working kernels */
      mmb = ApplyConstraints(mmb, C);        /* reject disallowed kerns */
      ApplyMoves2Flags(mmb, IMVS);           /* indicate A/B/C movememnt */
      mmb = FindBestKerns(pre, verb, mmb, N, mbs, nbs, kbs, C, tol);
   }
   if (KCLEAN)
      ComputeKClean(verb, pre, mmb);
   mmb = ATL_SortMMNodesByMflop(0, mmb);
   mmB = ReadMMFileWithPath(pre, "res", "geAMMRES.sum");
   mmB = ATL_SortMMNodesByMflop(0, mmB);
   printf("\n");
   if (mmb)
      printf("YOUR BEST CASE: %d-%s, BLK=%d,%d,%d  %.2f\n", 
             mmb->ID, mmb->rout, mmb->mbB, mmb->nbB, mmb->kbB, mmb->mflop[0]);
   if (mmB)
   {
      printf("ATLAS BEST CASE: %d-%s, BLK=%d,%d,%d  %.2f\n", mmB->ID, 
             mmB->rout, mmB->mbB, mmB->nbB, mmB->kbB, mmB->mflop[0]);
      if (mmb)
         printf("   RATIO=%0.4f\n", mmb->mflop[0] / mmB->mflop[0]);
   }

   KillAllMMNodes(mmb);
   KillAllMMNodes(mmB);
   free(mbs);
   free(nbs);
   free(kbs);
@skip   if (MOVES)
@skip      free(MOVES);
   return(0);
}
@ROUT gmmsearch

int NumberBetaFails(FILE *fperr, char pre, int nb, ATL_mmnode_t *p)
{
   const int mu = p->mu, nu = p->nu, ku = p->ku;
   int mb = ((nb+mu-1)/mu)*mu, kb = ((nb+ku-1)/ku)*ku;
   int i, nfail = 0;

   if (kb < p->kbmin)
      kb = p->kbmin;
   if (p->kbmax && kb > p->kbmax)
      kb = p->kbmax;
   nb = ((nb+nu-1)/nu)*nu;
   for (i=(-1); i < 2; i++)
   {
      if (pre == 'z' || pre == 'c')  /* beta=0 case tests all 3 real betas */
         i = 0;
      if (MMKernelFailsTest(pre, mb, nb, kb, i, p))
      {
         if (fperr)
         {
            char *sp;
            fprintf(fperr, "FAIL: B=(%d,%d,%d), rout='%s', genstr='%s'\n", 
                    mb, nb, kb, p->rout?p->rout:"NULL", 
                    p->genstr?p->genstr:"NULL");
            sp = MMGetTestString(pre, mb, nb, kb, i, p);
            fprintf(fperr,"   '%s'\n", sp);
            free(sp);
         }
         nfail++;
      }
      if (pre == 'z' || pre == 'c')
         break;
   }
   return(nfail);
}
@beginskip
ATL_mmnode_t *FindVecVL(int verb, char pre, int NB)
/*
 * This search attempts to find both the best VLEN for this platform, and
 * if vectorizing K or M dimension provides the best performance for a problem
 * of roughly nb square.
 */
{
   int vl, vlB, kvecB=0, mb, nb, kb, mu, nu;
   double mf, mfB;
   char *vtyp;
   ATL_mmnode_t *mmB, *mmN;
   printf("\nSEARCHING FOR VEC TYPE AND LEN FOR PRE='%c':\n", pre);
   printf("    MB  NB  KB  VTYP  VLEN            MFLOP\n");
   printf("   === === ===  ====  ====  ===============\n");
/*
 * If we know the VLEN based on CPP defined, take that as our minimal VLEN.
 * We don't assume VLEN can't be larger, due to backwards compatability
 * (eg., an AVX machine would be detected as SSE): ATLAS could lack support
 * for newest standard, but gcc have it in gnuvec!
 * If VLEN unknown, start search at 2 (minimum len vector).
 */
   vl = GetNativeVLEN(pre);
   vl = Mmax(vl, 2);
   mu = vl >> 1;
   nu = 2;
   mb = (NB/mu)*mu;
   nb = (NB/nu)*nu;
   kb = NB;
   mmB = MMGetNodeGEN(pre, 0, kb, mu, nu, 1, 1, 0, 0, NULL);
   mfB = TimeMMKernel(2, 3, mmB, pre, mb, nb, kb, 1, 0, 0);
   printf("  %4d %3d %3d  %4s %5d  %15.0f\n", mb, nb, kb, "SCLR", 1, mfB);
   do
   {
   }
   while(0);
   if (mmB->vlen < 2)
      vtyp = "SCALAR";
   else if (FLAG_IS_SET(mmB->flag, MMF_KVEC))
      vtyp = "VEC-K";
   else 
      vtyp = "VEC-M";
   mmB->mflop[3] = mfB;
   printf("BEST VEC IS '%s', VLEN=%d, MFLOP=%e\n", vtyp, mmB->vlen, mfB);
   return(mmB);
}
@endskip

/*
 * RETURNS: 0 if bcast slower than ld/splat combo
 */
int UseBcast(int flg, int verb, char pre, int kb, int nreg, int VL)
{
   int nu=VL, mu, mb, nb, TEST=flg&1;
   ATL_mmnode_t *mpBC, *mpNO;
   double mfBC, mfNO;

   if (flg&FKO_FLAG)        /* temporary for Majedul */
      return(1);            /* replace wt analysis later */
   if (VL < 2)
      return(1);
   mu = (nreg-nu-1) / (nu+1);
   if (mu < 2)
      mu = (nreg - 2) / (nu+1);
   mu = (mu) ? mu : 1;
   mb = ((kb+mu-1)/mu)*mu;
   nb = ((kb+nu-1)/nu)*nu;
   mpBC = MMGetNodeGEN(pre, 0, nb, mu*VL, nu, 1, VL, 0, 0, 0, NULL);
   mpNO = MMGetNodeGEN(pre, 1, nb, mu*VL, nu, 1, VL, 0, 0, 0, NULL);
   printf("TIMING BCAST VS SPLAT MVEC WITH: B=(%d,%d,%d) U=(%d,%d,1)\n",
          mb, nb, kb, mu, nu);
   mfBC = TimeMMKernel(verb, 1, mpBC, pre, mb, nb, kb, 1, 0, -1);
   printf("   BCAST = %.0f MFLOP\n", mfBC);
   mfNO = TimeMMKernel(verb, 1, mpNO, pre, mb, nb, kb, 1, 0, -1);
   printf("   SPLAT = %.0f MFLOP\n", mfNO);
   if (TEST)
   {
      printf("   TESTING . . .");
      assert(!NumberBetaFails(stderr, pre, nb, mpBC));
      printf("  . . . ");
      assert(!NumberBetaFails(stderr, pre, nb, mpNO));
      printf("   PASS!\n");
   }
   KillMMNode(mpBC);
   KillMMNode(mpNO);
   if (mfNO > mfBC)
   {
      printf("VLD/VSPLAT PROVIDES %.4f SPEEDUP\n", mfNO/mfBC);
      return(0);
   }
   printf("VBCAST PROVIDES %.4f SPEEDUP\n", mfBC/mfNO);
   return(1);
}

ATL_mmnode_t *DoSyrkMUNU
   (int flg, int vrb, char pre, int nreg, int nb, int kb, int VL)
{
   ATL_mmnode_t *pM, *pB, *pK, *mp;
   double mfB = 0.0;
   int i, j, uB=VL, bcB=1, kvecB=0, kbB=0;
   const char *frm="   %c%c %4d %4d %3d %9.0f\n";
   const int bf=(flg&FKO_FLAG)?FKO_FLAG:0;

   pM = MMGetNodeGEN(pre, 0|bf, 0, VL, 1, 1, VL, 0, 0, 0, 
                     DupString("ATL_tmp.c"));
   pB = MMGetNodeGEN(pre, 1|bf, 0, VL, 1, 1, VL, 0, 0, 0, 
                     DupString("ATL_tmp.c"));
   pK = MMGetNodeGEN(pre, 0|bf, 0, 1, 1, VL, VL, 1, 0, 0, 
                     DupString("ATL_tmp.c"));
   pM->blask = pB->blask = pK->blask = 1;
   pK->next = pM;
   pM->next = pB;

   pM->ku = pB->ku = 1;
   pM->kbB = pB->kbB = kb;
   pK->ku = VL;
   pK->kbB = ((kb+VL-1)/VL)*VL;
   free(pM->genstr); free(pB->genstr); free(pK->genstr);

   printf("Full search for SYRK kernel for nb=%d, NREG=%d, VLEN=%d\n",
          nb, nreg, VL);
   printf("   VD   NB   KB  NU      MFLOP\n");
   printf("   ==  ===  ===  ==  =========\n");
   for (i=1; i <= nreg; i++)
   {
      for (j=1; j <= nreg; j++)
      {
         if (i*j+1 > nreg || j > nb)
            continue;
         if (i*VL == j) /* legal M-vectorized SYRK kernel */
         {
            const int b = (nb > j) ? (nb/j)*j : j;
            double mf;

            pB->mu = pB->nu = pM->mu = pM->nu = j;
            pB->mbB = pB->nbB = pM->mbB = pM->nbB = b;
            if (i*j+i+j > nreg)
            {
               pB->flag |= 1<<MMF_BREG1;
               pM->flag |= 1<<MMF_BREG1;
            }
            else
            {
               pB->flag &= ~(1<<MMF_BREG1);
               pM->flag &= ~(1<<MMF_BREG1);
            }
            pM->genstr = MMGetGenString(pre, pM);
            pB->genstr = MMGetGenString(pre, pB);
            mf = TimeMMKernel(vrb, 0, pM, pre, b, b, kb, 1, 0, -1);
            assert(!MMKernelFailsTest(pre, b, b, kb, 1, pM));
            printf(frm, 'M', 'b', b, kb, j, mf);
            if (mf > mfB)
            {
               mfB = mf;
               uB = j;
               kvecB = 0;
               bcB = 0;
               kbB = kb;
            }
            mf = TimeMMKernel(vrb, 0, pB, pre, b, b, kb, 1, 0, -1);
            assert(!MMKernelFailsTest(pre, b, b, kb, 1, pB));
            printf(frm, 'M', 's', b, nb, j, mf);
            if (mf > mfB)
            {
               mfB = mf;
               uB = j;
               kvecB = 0;
               bcB = 1;
               kbB = kb;
            }
            free(pM->genstr);
            free(pB->genstr);
         }
         if (i == j)    /* legal k-vectorized SYRK kernel */
         {
            const int b = (nb > j) ? (nb/j)*j : j;
            double mf;

            pK->mbB = pK->nbB = b;
            pK->mu = pK->nu = j;
            if (i*j+i+j > nreg)
               pK->flag |= 1<<MMF_BREG1;
            else
               pK->flag &= ~(1<<MMF_BREG1);
            pK->genstr = MMGetGenString(pre, pK);
            mf = TimeMMKernel(vrb, 0, pK, pre, b, b, pK->kbB, 1, 0, -1);
            assert(!MMKernelFailsTest(pre, b, b, pK->kbB, 1, pK));
            printf(frm, 'K', ' ', b, nb, j, mf);
            if (mf > mfB)
            {
               mfB = mf;
               uB = j;
               kvecB = VL;
               bcB = 1;
               kbB = pK->kbB;
            }
            free(pK->genstr);
         }
      }
   }
   pM->genstr = pK->genstr = pB->genstr = NULL;
   KillAllMMNodes(pK);
   printf("Done.\n");
   pK = MMGetNodeGEN(pre, bcB|bf, 0, uB, uB, kvecB ? kvecB:1, VL, kvecB, 
                      0, 0, NULL);
   if (uB*uB+uB+uB > nreg)
   {
      pK->flag |= 1<<MMF_BREG1;
      if (pK->genstr)
         free(pK->genstr);
      pK->genstr = MMGetGenString(pre, pK);
   }
   if (pre == 'z' || pre == 'c')
      pK->flag |= 1<<MMF_COMPLEX;
   pK->blask = 1;
   pK->mflop[0] = mfB;
   pK->mbB = pK->nbB = nb;
   pK->kbB = kbB;
   pK->blask = 1;
   return(pK);
}

void DoSyrkKU(int vrb, char pre, ATL_mmnode_t *mb)
/*
 * For KVEC, we currently force ku=vlen, so this routine does nothing.
 * For other kernels, see if 2 <= ku <= 4 provide speedup over default ku=1
 */
{
   int ku, kuB;
   double mf, mfB, mf0;
   if (FLAG_IS_SET(mb->flag, MMF_KVEC))
      return;
   mf0 = mfB = mb->mflop[0];
   printf("TUNING KU, CURRENTLY KU=%d, mf=%.2f\n", mb->ku, mfB);
   for (ku=2; ku <= 4; ku++)
   {
      char *gen0=mb->genstr;
      int ku0=mb->ku;
      mb->ku = ku;
      mb->genstr = MMGetGenString(pre, mb);
      mf = TimeMMKernel(vrb, 0, mb, pre, mb->mbB, mb->nbB, mb->kbB, 1, 0, -1);
      printf("ku=%u: mf=%.2f, SPEEDUP=%.4f\n", ku, mf, mf/mfB);
      if (mf >= 1.005*mfB) /* require further unrolling to prove .5% speedup */
      {
         free(gen0);
         mfB = mf;
      }
      else
      {
         free(mb->genstr);
         mb->genstr = gen0;
         mb->ku = ku0;
      }
   }
   if (mfB == mf0)
      printf("NO SPEEDUP, KEEPING KU=%u\n\n", mb->ku);
   else
      printf("KU=%u PROVIDES SPEEDUP=%.4f\n\n", mb->ku, mfB/mf0);
}

ATL_mmnode_t *FullSrchMUNU(int flg, int verb, char pre, int nreg, int nb, 
                           int VL, int KVEC)
{
   char fn[32];
   ATL_mmnode_t *mmp;
   double mf, mfB=0.0;
   const int CHK=(flg&1), ku = (KVEC) ? VL : 1;
   int n, i, j, mbB, nbB, kbB, muB=1, nuB=1, b1B=0;
   char ch;
   const int bf=(flg&FKO_FLAG)?FKO_FLAG:0;

   assert(VL < 1000 && nreg < 1000);  /* don't overflow fn len */
   if (VL < 2)
      ch = 'U';
   else
      ch = (KVEC) ? 'K':'M';
   if (bf)
      sprintf(fn, "gAMMUR_%c%d_%d_fko.sum", ch, VL, nreg);
   else
      sprintf(fn, "gAMMUR_%c%d_%d.sum", ch, VL, nreg);
   mmp = ReadMMFileWithPath(pre, "res", fn);
   if (mmp)
   {
      MMFillInGenStrings(pre, mmp);
      TimeNegMMKernels(0, verb, 0, mmp, pre, 1, 0, -1);
      WriteMMFileWithPath(pre, "res", fn, mmp);
      return(mmp);
   }
   assert(nb%VL == 0);
   mmp = MMGetNodeGEN(pre, 0|bf, nb, 1, 1, ku, 1, KVEC, 0, 0,
                      DupString("ATL_Xamm_munu.c"));
   mmp->rout[4] = pre;
   mmp->mbB = mmp->nbB = mmp->kbB = nb;
   mmp->vlen = VL;
   if (KVEC)
      mmp->flag |= (1<<MMF_KVEC);
   else if (!UseBcast(flg, verb, pre, nb, nreg, VL))
      mmp->flag |= (1<<MMF_NOBCAST);
/*
 * Try all MU/NU unrollings
 */
   printf("Full search on MUxNU for nb=%d, NREG=%d, VLEN=%d, KVEC=%d\n",
          nb, nreg, VL, KVEC);
   for (i=1; i <= nreg; i++)
   {
      for (j=1; j <= nreg; j++)
      {
@skip         int ONETIME=0;
         int mbu, nbu, mu, nu;
         if (i*j+Mmin(i,j)+1 > nreg)
            continue;
@beginskip
         if (KVEC)  /* vec on K needs mu*nu mult of VLEN */
         {
            if (VL >= nreg)
            {
               ONETIME=1;
               i = VL;
               j = 1;
            }
            else if ((i*j)%VL)
               continue;
            mu = i;
         }
         else /* vect on M dim need mu multiple of VLEN */
@endskip
         mu = (KVEC) ? i : i*VL;
         nu = j;
         if (i*j+i+j > nreg)
            mmp->flag |= 1<<MMF_BREG1;
         else
            mmp->flag &= ~(1<<MMF_BREG1);
         mmp->mu = mu;
         mmp->nu = nu;
         if (mmp->genstr)
           free(mmp->genstr);
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         if (bf) mmp->flag |= 1<<MMF_FKO;
         mmp->genstr = MMGetGenString(pre, mmp);
         mf = TimeMMKernel(verb, 0, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (CHK)
         {
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
         }
         if (mf > mfB)
         {
            mbB = mbu;
            nbB = nbu;
            kbB = nb;
            muB = mu;
            nuB = nu;
            mfB = mf;
            b1B = ((mmp->flag)>>MMF_BREG1)&1;
         }
@skip         if (ONETIME)
@skip            goto DONE;
      }
   }
DONE:
   assert(mfB > 0.0);
   i = FLAG_IS_SET(mmp->flag, MMF_NOBCAST);
   i |= (b1B) ? 2 : 0;
   KillMMNode(mmp);
   mmp = MMGetNodeGEN(pre, i|bf, nb, muB, nuB, ku, VL, KVEC, 0, 0, NULL);
   mmp->mbB = mbB;
   mmp->nbB = nbB;
   mmp->kbB = kbB;
   mmp->mflop[0] = mfB;
   printf("BEST FULL-SEARCH CASE IS B=(%d,%d,%d), U=(%d,%d) MFLOP=%.2f\n\n", 
          mbB, nbB, kbB, muB, nuB, mfB);
   WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
   return(mmp);
}

ATL_mmnode_t *SrchNU(int flg, int verb, char pre, int nreg, int nb, int VL, 
                     int I)
/*
 * M-vectorized search for with mu=I*VLEN.  It allows us to find a case
 * that can handle smaller blocks with VLEN is long.
 */
{
   char fn[32];
   ATL_mmnode_t *mmp;
   double mf, mfB=0.0;
   const int CHK=(flg&1), mu = I*VL;
   int n, i, j, mbB, nbB, kbB, nuB=1, b1B=0, mbu;
   const int bf=(flg&FKO_FLAG)?FKO_FLAG:0;

   if (bf)
      sprintf(fn, "gAMMUR_MU%d_M%d_%d_fko.sum", I, VL, nreg);
   else
      sprintf(fn, "gAMMUR_MU%d_M%d_%d.sum", I, VL, nreg);
   mmp = ReadMMFileWithPath(pre, "res", fn);
   if (mmp)
   {
      MMFillInGenStrings(pre, mmp);
      TimeNegMMKernels(0, verb, 0, mmp, pre, 1, 0, -1);
      WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
      return(mmp);
   }
   mmp = MMGetNodeGEN(pre, 0|bf, nb, 1, 1, 1, 1, 0, 0, 0, 
                      DupString("ATL_Xamm_munu.c"));
   mmp->rout[4] = pre;
   mmp->mbB = mmp->nbB = mmp->kbB = nb;
   mmp->vlen = VL;
   mmp->mu = mu;
   mbu = (nb >= mu) ? (nb/mu)*mu : mu;
   if (!UseBcast(flg, verb, pre, nb, nreg, VL))
      mmp->flag |= (1<<MMF_NOBCAST);
/*
 * Try all powers of 2 MU/NU unrollings
 */
   printf("Searching M-VEC MU=%d xNU case for mb=%d, kb=%d, NREG=%d, VLEN=%d\n",
          I, mbu, nb, nreg, VL);
   for (j=1; j <= nreg; j++)
   {
      int nbu, nu;
      if (I*j+Mmin(I,j)+1 > nreg)
         continue;
      nu = j;
      mmp->nu = nu;
      if (mmp->genstr)
        free(mmp->genstr);
      nbu = (nb >= nu) ? (nb/nu)*nu : nu;
      if (I*j+I+j > nreg)
         mmp->flag |= 1<<MMF_BREG1;
      else
         mmp->flag &= ~(1<<MMF_BREG1);
      if (bf) mmp->flag |= 1<<MMF_FKO;
      mmp->genstr = MMGetGenString(pre, mmp);
      mf = TimeMMKernel(verb, 0, mmp, pre, mbu, nbu, nb, 1, 0, -1);
      printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", I, j, mf);
      if (CHK)
      {
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
      }
      if (mf > mfB)
      {
         mbB = mbu;
         nbB = nbu;
         kbB = nb;
         nuB = nu;
         mfB = mf;
         b1B = ((mmp->flag)>>MMF_BREG1)&1;
      }
   }
   i = FLAG_IS_SET(mmp->flag, MMF_NOBCAST);
   i |= (b1B) ? 2 : 0;
   KillMMNode(mmp);
   if (mfB == 0.0)  /* no legal kern found! */
   {
      printf("NO LEGAL KERNS FOR MU=%d!\n", I);
      return(NULL);
   }
   mmp = MMGetNodeGEN(pre, i|bf, nb, mu, nuB, 1, VL, 0, 0, 0, NULL);
   mmp->mbB = mbB;
   mmp->nbB = nbB;
   mmp->kbB = kbB;
   mmp->mflop[0] = mfB;
   assert(mfB > 0.0);
   printf("BEST MU=%d CASE IS B=(%d,%d,%d) U=(%d,%d), MFLOP=%.2f\n\n", 
          I, mbB, nbB, kbB, mu, nuB, mfB);
   WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
   return(mmp);
}

ATL_mmnode_t *SrchMUNUp2(int flg, int verb, char pre, int nreg, int nb,
                         int VL, int KVEC)
{
   char fn[32];
   ATL_mmnode_t *mmp;
   double mf, mfB=0.0;
   const int CHK=(flg&1), ku = (KVEC) ? VL : 1;
   int n, i, j, mbB, nbB, kbB, muB=1, nuB=1, b1B=0;
   char ch;
   const int bf=(flg&FKO_FLAG)?FKO_FLAG:0;

   if (VL < 2)
      ch = 'U';
   else
      ch = (KVEC) ? 'K':'M';
   if (bf)
      sprintf(fn, "gAMMURP2_%c%d_%d_fko.sum", ch, VL, nreg);
   else
      sprintf(fn, "gAMMURP2_%c%d_%d.sum", ch, VL, nreg);
   mmp = ReadMMFileWithPath(pre, "res", fn);
   if (mmp)
   {
      MMFillInGenStrings(pre, mmp);
      TimeNegMMKernels(0, verb, 0, mmp, pre, 1, 0, -1);
      WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
      return(mmp);
   }
   mmp = MMGetNodeGEN(pre, 0|bf, nb, 1, 1, ku, 1, KVEC, 0, 0,
                      DupString("ATL_Xamm_munu.c"));
   mmp->rout[4] = pre;
   mmp->mbB = mmp->nbB = mmp->kbB = nb;
   mmp->vlen = VL;
   if (KVEC)
      mmp->flag |= (1<<MMF_KVEC);
   else if (!UseBcast(flg, verb, pre, nb, nreg, VL))
      mmp->flag |= (1<<MMF_NOBCAST);
/*
 * Try all powers of 2 MU/NU unrollings
 */
   printf("Searching PWR-2 MUxNU cases for nb=%d, NREG=%d, VLEN=%d, KVEC=%d\n",
          nb, nreg, VL, KVEC);
@beginskip
/*
 * Long VLEN with small NREG can be impossible to do with mu*nu%VLEN==0,
 * so force at least one case even if it overruns registers
 */
@endskip
   for (i=1; i <= nreg; i += i)
   {
      for (j=1; j <= nreg; j += j)
      {
@skip         int ONETIME=0;
         int mbu, nbu, mu, nu;
         if (i*j+Mmin(i,j)+1 > nreg)
            continue;
@beginskip
         if (KVEC)  /* vec on K needs mu*nu mult of VLEN */
         {
            if (VL >= nreg)
            {
               ONETIME = 1;
               i=VL;
               j=1;
            }
            else if ((i*j)%VL)
               continue;
            mu = i;
         }
         else /* vect on M dim need mu multiple of VLEN */
@endskip
         if (i*j+i+j > nreg)
            mmp->flag |= 1<<MMF_BREG1;
         else
            mmp->flag &= ~(1<<MMF_BREG1);
         mu = (KVEC) ? i : i*VL;
         nu = j;
         mmp->mu = mu;
         mmp->nu = nu;
         if (mmp->genstr)
           free(mmp->genstr);
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         if (bf) mmp->flag |= 1<<MMF_FKO;
         mmp->genstr = MMGetGenString(pre, mmp);
         mf = TimeMMKernel(verb, 0, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (CHK)
         {
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
         }
         if (mf > mfB)
         {
            mbB = mbu;
            nbB = nbu;
            kbB = nb;
            muB = mu;
            nuB = nu;
            mfB = mf;
            b1B = ((mmp->flag)>>MMF_BREG1)&1;
         }
@skip         if (ONETIME)
@skip            goto DONE;
      }
   }
DONE:
   assert(mfB != 0.0);
   i = FLAG_IS_SET(mmp->flag, MMF_NOBCAST);
   i |= (b1B) ? 2 : 0;
   KillMMNode(mmp);
   mmp = MMGetNodeGEN(pre, i|bf, nb, muB, nuB, ku, VL, KVEC, 0, 0, NULL);
   mmp->mbB = mbB;
   mmp->nbB = nbB;
   mmp->kbB = kbB;
   mmp->mflop[0] = mfB;
   printf("BEST POW2 CASE IS B=(%d,%d,%d) U=(%d,%d), MFLOP=%.2f\n\n", 
          mbB, nbB, kbB, muB, nuB, mfB);
   WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
   return(mmp);
}

ATL_mmnode_t *SrchMUNU(int flg, int verb, char pre, int nreg, int nb, 
                       int VL, int KVEC)
{
   ATL_mmnode_t *mmp, *mmp2;
   char fn[32];
   double mf, mfB=0.0;
   const int CHK=(flg&1), ku = (KVEC) ? VL : 1;
   #if (defined(ATL_GAS_x8664) || defined(ATL_GAS_x8632)) && !defined(ATL_AVX)
      int DO1D=1;
   #else
      int DO1D=(nreg < 9 || nreg < VL);
   #endif
   int n, i, j, kb, mbB, nbB, kbB, muB=1, nuB=1, b1B=0;
   char ch;
   const int bf=(flg&FKO_FLAG)?FKO_FLAG:0;

   if (flg&2)
      return(FullSrchMUNU(flg, verb, pre, nreg, nb, VL, KVEC));
   mmp2 = SrchMUNUp2(flg, verb, pre, nreg, nb, VL, KVEC);
   assert(VL < 1000 && nreg < 1000);  /* don't overflow fn len */
   if (VL < 2)
      ch = 'U';
   else
      ch = (KVEC) ? 'K':'M';
   if (bf)
      sprintf(fn, "gAMMUR_%c%d_%d_fko.sum", ch, VL, nreg);
   else
      sprintf(fn, "gAMMUR_%c%d_%d.sum", ch, VL, nreg);
   mmp = ReadMMFileWithPath(pre, "res", fn);
   if (mmp)
   {
      KillAllMMNodes(mmp2);
      MMFillInGenStrings(pre, mmp);
      TimeNegMMKernels(0, verb, 0, mmp, pre, 1, 0, -1);
      WriteMMFileWithPath(pre, "res", fn, mmp);
      return(mmp);
   }
   mmp = MMGetNodeGEN(pre, 0|bf, nb, 1, 1, ku, 1, KVEC, 0, 0,
                      DupString("ATL_Xamm_munu.c"));
   mmp->rout[4] = pre;
   mmp->mbB = mmp->nbB = mmp->kbB = nb;
   mmp->vlen = VL;
   if (KVEC)
      mmp->flag |= (1<<MMF_KVEC);
   else if (!UseBcast(flg, verb, pre, nb, nreg, VL))
      mmp->flag |= (1<<MMF_NOBCAST);
/*
 * Try all near-square register blocking cases
 */
   printf("Finding best MUxNU case for nb=%d, NREG=%d, VLEN=%d, KVEC=%d\n",
          nb, nreg, VL, KVEC);
   for (n=4; n <= nreg; n++)
   {
@skip      int ONETIME=0;
      int mbu, nbu, mu, nu;
      for (j=1; j*j < n; j++);
      i = n / j;
      if (nb%i || nb%j)
         continue;
      mu = (KVEC) ? i : i*VL;
      nu = j;
      if (i*j+i+j > nreg)
         mmp->flag |= 1<<MMF_BREG1;
      else
         mmp->flag &= ~(1<<MMF_BREG1);
      mmp->mu = mu;
      mmp->nu = nu;
      if (mmp->genstr)
        free(mmp->genstr);
      mbu = (nb >= mu) ? (nb/mu)*mu : mu;
      nbu = (nb >= nu) ? (nb/nu)*nu : nu;
      if (bf) mmp->flag |= 1<<MMF_FKO;
      mmp->genstr = MMGetGenString(pre, mmp);
      mf = TimeMMKernel(verb, 0, mmp, pre, mbu, nbu, nb, 1, 0, -1);
      printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
      if (CHK)
      {
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
      }
      if (mf > mfB)
      {
         mbB = mbu;
         nbB = nbu;
         kbB = nb;
         muB = mu;
         nuB = nu;
         mfB = mf;
         b1B = ((mmp->flag)>>MMF_BREG1)&1;
      }
@skip      if (ONETIME)
@skip         break;
   }
/*
 * For non-AVX x86, try 1-D cases since they are 2-operand assemblies; always
 * try 1-D for low registers
 */
   if (DO1D)
   {
      printf("BEST NEAR-SQUARE CASE IS MU=%d, NU=%d, MFLOP=%.2f\n\n", 
             muB, nuB, mfB);
      printf("Finding best 1-D outer loop unrolling for nb=%d\n", nb);
      for (n=2; n <= nreg; n++)
      {
         int mbu, nbu, mu, nu;
         i = 1; j = n;
         if (nb % n)
            continue;
         mu = (KVEC) ? i : i*VL;
         nu = mmp->nu = j;
         if (mmp->genstr)
           free(mmp->genstr);
         if (bf) mmp->flag |= 1<<MMF_FKO;
         mmp->genstr = MMGetGenString(pre, mmp);
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         mf = TimeMMKernel(verb, 0, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (CHK)
         {
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
         }
         if (mf > mfB)
         {
            muB = i;
            nuB = j;
            mfB = mf;
            b1B = 0;
         }
         i = n; j = 1;
         mu = mmp->mu = (KVEC) ? i : i * VL;
         nu = mmp->nu = j;
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         if (mmp->genstr)
           free(mmp->genstr);
         if (bf) mmp->flag |= 1<<MMF_FKO;
         mmp->genstr = MMGetGenString(pre, mmp);
         mf = TimeMMKernel(verb, 1, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (CHK)
         {
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
         }
         if (mf > mfB)
         {
            muB = i;
            nuB = j;
            mfB = mf;
            b1B = 0;
         }
      }
   }

   assert(mfB > 0.0);
   i = FLAG_IS_SET(mmp->flag, MMF_NOBCAST);
   i |= (b1B) ? 2 : 0;
   KillMMNode(mmp);
   mmp = MMGetNodeGEN(pre, i|bf, nb, muB, nuB, ku, VL, KVEC, 0, 0, NULL);
   mmp->mbB = mbB;
   mmp->nbB = nbB;
   mmp->kbB = kbB;
   mmp->mflop[0] = mfB;
   if (mmp->mflop[0] < mmp2->mflop[0])
   {
      printf("Taking pow2 srch (%d,%d:%.0f) over square (%d,%d:%.0f)\n",
             mmp2->mu, mmp2->nu, mmp2->mflop[0],
             mmp->mu, mmp->nu, mmp->mflop[0]);
      KillMMNode(mmp);
      mmp = mmp2;
   }
   else
      KillAllMMNodes(mmp2);
   WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
   printf("BEST CASE IS B=(%d,%d,%d), U=(%d,%d), MFLOP=%.2f\n\n", 
          mmp->mbB, mmp->nbB, mmp->kbB, mmp->mu, mmp->nu, mmp->mflop[0]);
   return(mmp);
}

#if 0
/* this idea doesn't really work */
int FindKvecXover(int flg, int verb, char pre, int nreg, int VL, int nb)
/*
 * On some machines, vectorizing the M dim will win for small problems,
 * due to not needing to the summation at the end of the K-loop.  However,
 * once this cost is dominated by the K-loop, K dim vectorization can
 * start to win, possibly by reducing the C write traffic, as well as
 * avoiding vec bcast inside the K-loop.
 *
 * For finding this crossover, we use best pw2 M/K, since we can be sure
 * they can always use a pwr2 block factor for direct comparison.  If pwr2
 * cases are much different than normal, this may cause problems!
 * IDEA: Read in normal MUNU results, and don't use this test if gap is wide.
 */
{
   ATL_mmnode_t *mmM, *mmK; 
   double mfM, mfK;
   int b, b0;

   mmM = SrchMUNUp2(flg, verb, pre, nreg, nb, VL, 0);
   mmK = SrchMUNUp2(flg, verb, pre, nreg, nb, VL, 1);
   printf("FINDING NB CROSSOVER FOR M- AND K-VECTORIZATION:");
   b = Mmax(mmM->mu, mmK->mu);
   b = Mmax(b, mmM->nu);
   b = Mmax(b, mmK->nu);
   b = Mmax(b,16);
   b0 = b;
   while (b < 512)
   {
      mfM = TimeMMKernel(verb, 0, mmM, pre, b, b, b, 1, 0, -1);
      mfK = TimeMMKernel(verb, 0, mmK, pre, b, b, b, 1, 0, -1);
      printf("   B=%d, mflopM=%.0f, mflopK=%.0f\n", b, mfM, mfK);
      if (mfK > mfM*1.02)
         break;
      b += b;
   }
   if (b == b0)
   {
      printf("K-VECTORIZATION BETTER FROM FIRST BLOCK!\n");
      b = 1;            /* Kvec always better */
   }
   else if (b == 512)
   {
      printf("M-VECTORIZATION ALWAYS BETTER\n");
      b = 0;            /* Kvec never better */
   }
   else
      printf("K-VEC BEGINS WINNING AROUND %d\n", b);
   return(b);
}
#endif

void FindDefMUNU(int flg, int verb, char pre, int nb, int *NREG, int *VLEN)
{
   ATL_mmnode_t *mp, *mmM, *mmK;
   int nreg=(*NREG), VL=(*VLEN), chkNR=0, chkVL=0;

   if (nreg < 1)
      nreg = GetNumVecRegs(pre);
   if (nreg < 1)
   {
      #ifdef ATL_GAS_x8632
         nreg = 8;
      #else
         nreg = 16;
      #endif
      chkNR = 1;
   }
   if (VL < 1)
      VL = GetNativeVLEN(pre);
   if (!VL)
   {
      VL = (pre == 'c' || pre == 's') ? 4:2;
      chkVL = 1;
   }
/* 
 * Always do full search for low number of registers, where this is only search
 */
   if (!chkNR && nreg > 0 && nreg < 20)
      flg |= 2;
   mmM = SrchMUNU(flg, verb, pre, nreg, nb, VL, 0);
   mmK = SrchMUNU(flg, verb, pre, nreg, nb, VL, 1);
   printf("MVEC: B=(%d,%d,%d) mu=%d, nu=%d, MFLOP=%.0f\n",
          mmM->mbB,  mmM->nbB,  mmM->kbB, mmM->mu, mmM->nu, mmM->mflop[0]);
   printf("KVEC: B=(%d,%d,%d) mu=%d, nu=%d, MFLOP=%.0f\n",
          mmK->mbB,  mmK->nbB,  mmK->kbB, mmK->mu, mmK->nu, mmK->mflop[0]);
/*
 * After this, fastest code in mmM, slowest mmK
 */
   if (mmK->mflop[0] > mmM->mflop[0])
   {
      mp = mmK;
      mmK = mmM;
      mmM = mp;
   }
   KillAllMMNodes(mmK);
/*
 * If we only guessed a lower bound on # regs, try some searches with
 * increasing regs
 */
   if (chkNR)
   {
      const int KVEC = FLAG_IS_SET(mmM->flag, MMF_KVEC);
      int i, nr = nreg+nreg;
      printf("NREG=%d, U=(%d,%d): MFLOP=%.0f\n", 
             nreg, mmM->mu, mmM->nu, mmM->mflop[0]);
      for (i=0; i < 4; i++)  /* sanity check for stopping */
      {
         mp = SrchMUNU(flg, verb, pre, nr, nb, VL, KVEC);
         printf("NREG=%d, U=(%d,%d): MFLOP=%.0f\n", 
                nr, mp->mu, mp->nu, mp->mflop[0]);
         if (mp->mu*mp->nu + mp->mu + 1 <= (nr>>1)) /* did not use more regs */
            break;
         if (mp->mflop[0] < 1.03*mmM->mflop[0])     /* perf not better */
            break;
         KillMMNode(mmM);
         mmM = mp;
         nreg = nr;
         nr += nr;
      }
   }
/*
 * Now that we are confident in our NREG, see if we need to confirm VLEN
 */
   if (chkVL)
   {
   }
   *NREG = nreg;
   *VLEN = VL;
#if 0
/*
 * Now see if K-vec has a crossover with M-vec
 */
   FindKvecXover(flg, verb, pre, nreg, VL, nb);
#endif
   KillAllMMNodes(mmM);
}

void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
   fprintf(stderr, "   -r <nreg> : set max # of registers to try\n");
   fprintf(stderr, "   -V <vlen> : force vector length\n");
   fprintf(stderr, "   -b <nb>   : set initial block factor to try\n");
   fprintf(stderr, "   -v <verb> : set verbosity (1)\n");
   fprintf(stderr, "   -T 1      : test all legal kerns, and exit\n");
   fprintf(stderr, 
           "   -f <flg>  : bitvec for srch control, add vals you want set:\n");
   fprintf(stderr, "        1: test all generated kernels\n");
   fprintf(stderr, "        2: do full MUxNU search\n");
   fprintf(stderr, "        4: print # of regs to res/<pre>nreg\n");
   fprintf(stderr, "        8: pref tune & time kerns in time.sum & exit\n");
   fprintf(stderr, "       16: create [d,s]flops.frc and return\n");
   fprintf(stderr, "   %d: use iFKO generator\n", FKO_FLAG);
   fprintf(stderr, "      DEFAULT: all bits unset\n");
   exit(ierr ? ierr : -1);
}

void GetFlags(int nargs, char **args, int *FLG, int *VERB, char *PRE, int *NREG,
              int *VLEN, int *NB, int *TEST)
{
   int i, flg=0, nreg=0;
   char pre = 'd';

   *VERB = 0;
   *NB = 120;
   *VLEN = 0;
   *TEST = 0;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        break;
      case 'T':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *TEST = atoi(args[i]);
         break;
      case 'V':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *VLEN = atoi(args[i]);
         break;
      case 'f':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         flg = atoi(args[i]);
         break;
      case 'r':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         nreg = atoi(args[i]);
         break;
      case 'v':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *VERB = atoi(args[i]);
         break;
      case 'b':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *NB = atoi(args[i]);
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (!nreg)
      nreg = GetNumVecRegs(pre);
   if (pre == 's' || pre == 'c' && (*NB)%16)
      *NB = (*NB == 120) ? 240 : (((*NB+15)>>4)<<4);
   *PRE = pre;
   *FLG = flg;
   *NREG = nreg;
}

/*
 * Using best discovered kernel, figure out the largest NB < 512 that
 * gets good performance
 */
int GetMaxNB(int flag, int verb, char pre, ATL_mmnode_t *mp)
{
   int inc, i, bB=0, badrow=0;
   double mf, mfB=0.0;

   printf("FINDING RANGE OF NB FOR GENKERN MU=%d, NU=%d, %cVEC=%d:\n",
          mp->mu, mp->nu, FLAG_IS_SET(mp->flag, MMF_KVEC)?'K':'M', mp->vlen);
   inc = Mylcm(mp->mu, mp->nu);
   inc = Mylcm(inc,mp->ku);
   while (inc < 12)
      inc += inc;

   for (i=inc; i < 512; i += inc)
   {
       mf = TimeMMKernel(verb, 0, mp, pre, i, i, i, 1, 0, -1);
       printf("   NB=%d, mf=%.0f\n", i, mf);
       if (mf > mfB)
       {
          bB=i;
          mfB = mf;
       }
       else badrow++;
       if (badrow > 4)
          break;
   }
   mp->mbB = mp->kbB = mp->nbB = bB;
   mp->mflop[0] = mfB;
   printf("BEST SQUARE NB=%d (%.0f)\n", bB, mfB);
   return(bB+inc-1);
}

void FindInfo(int flag, int verb, char pre, int NB, int *NREG, int *VLEN)
{
   const int WNR=(flag&4);
   int nreg=(*NREG), vlen=(*VLEN);
   ATL_mmnode_t *mp, *mpN, *mpB;
   const int bf=(flag&FKO_FLAG)?FKO_FLAG:0;
   char *mvsum, *kvsum;
   char fn[16]={pre,'m','f','l','o','p','s','.','f','r','c','\0'};

   if (pre == 'z')
      pre = 'd';
   else if (pre == 'c')
      pre = 's';
   if (bf)
   {
      mvsum = "gmvAMMUR_fko.sum";
      kvsum = "gkvAMMUR_fko.sum";
   }
   else
   {
      mvsum = "gmvAMMUR.sum";
      kvsum = "gkvAMMUR.sum";
   }
   mp = ReadMMFileWithPath(pre, "res", mvsum);
   mpN = ReadMMFileWithPath(pre, "res", kvsum);
   if (mp && mpN)
   {
      FILE *fp;
      *VLEN = mp->vlen;
      *NREG = mp->ivar;
      MMFillInGenStrings(pre, mp);
      MMFillInGenStrings(pre, mpN);
      TimeNegMMKernels(0, verb, 0, mp, pre, 1, 0, -1);
      TimeNegMMKernels(0, verb, 0, mpN, pre, 1, 0, -1);
      WriteRefreshedMMFileWithPath(pre, "res", mvsum, mp);
      WriteRefreshedMMFileWithPath(pre, "res", kvsum, mpN);
      mpB = FindMaxMflopMMQ(mp, 0);
      mpB = CloneMMNode(mpB);
      KillAllMMNodes(mp);
      mp = FindMaxMflopMMQ(mpN, 0);
      if (mp->mflop[0] > mpB->mflop[0])
         CopyMMNode(mpB, mp);
      KillAllMMNodes(mpN);
      if (WNR)
      {
         FILE *fp;
         char fn[12];
         sprintf(fn, "res/%cnreg", pre);
         fp = fopen(fn, "w");
         fprintf(fp, "%d\n", *NREG);
         fclose(fp);
      }
      fp = fopen(fn, "r");
      if (!fp)
         goto FIND_REPS;
      KillMMNode(mpB);
      return;
   }
   else if (mp)
      KillAllMMNodes(mp);
   else if (mpN)
      KillAllMMNodes(mpN);
   FindDefMUNU(flag, verb, pre, NB, &nreg, &vlen);
   printf("\nNREG=%d, VLEN=%d\n", nreg, vlen);
   if (NB%vlen)
   {
      if ((NB+NB)%vlen == 0)
         NB += NB;
      else
         while((++NB)%vlen);
   }
/*
 * With nreg & vlen set, create output with best K- & M- vectorized code
 * in standard names with nreg in mp->ivar
 */
   mp = SrchMUNU(flag, verb, pre, nreg, NB, vlen, 0);
   mpN = SrchMUNUp2(flag, verb, pre, nreg, NB, vlen, 0);
   mpB = (mpN->mflop[0] > mp->mflop[0]) ? mpN : mp;
   mpN->next = SrchNU(flag, verb, pre, nreg, NB, vlen, 1);
   mpB = (mpB->mflop[0] >= mpN->next->mflop[0]) ? mpB : mpN->next;
   if (mpN->next)
   {
      mpN->next->next = SrchNU(flag, verb, pre, nreg, NB, vlen, 2);
      mpB = (mpB->mflop[0] >= mpN->next->next->mflop[0]) ? mpB:mpN->next->next;
      if (mpN->next->next)
          mpN->next->next->next = SrchNU(flag, verb, pre, nreg, NB, vlen, 3);
   }
   mpB = CloneMMNode(mpB);
   mp = AddUniqueMMKernCompList(mp, mpN);
   KillAllMMNodes(mpN);
   mp = ReverseMMQ(mp);
   mp->ivar = nreg;
   WriteRefreshedMMFileWithPath(pre, "res", mvsum, mp);
   KillAllMMNodes(mp);

   mp = SrchMUNU(flag, verb, pre, nreg, NB, vlen, 1);
   if (mp->mflop[0] > mpB->mflop[0])
      CopyMMNode(mpB, mp);
   mp->ivar = nreg;
   mpN = SrchMUNUp2(flag, verb, pre, nreg, NB, vlen, 1);
   if (mpN->mflop[0] > mpB->mflop[0])
      CopyMMNode(mpB, mpN);
   mp = AddUniqueMMKernCompList(mp, mpN);
   KillAllMMNodes(mpN);
   mp = ReverseMMQ(mp);
   WriteRefreshedMMFileWithPath(pre, "res", kvsum, mp);
   KillAllMMNodes(mp);
   if (WNR)
   {
      FILE *fp;
      char fn[12];
      sprintf(fn, "res/%cnreg", pre);
      fp = fopen(fn, "w");
      fprintf(fp, "%d\n", nreg);
      fclose(fp);
   }
   *VLEN = vlen;
   *NREG = nreg;
/*
 * Now, use best-performing kernel found so far to set target MFLOP timing
 * interval for all subsequent timings
 */
   FIND_REPS:
   {
      double tim, nrep=1.0, mf;
      FILE *fp;
      printf(
      "FINDING NUMBER OF FLOPS TO FORCE FOR .2 SECOND TIMING INTERVAL:\n");
      mf = (mpB->mbB*1e-6)*mpB->nbB*2.0*mpB->kbB;
      tim = mf / mpB->mflop[0];
      if (tim < 0.2)
         nrep = .22 / tim;
      fprintf(stdout, "\nINCREASING TIMING INTERVAL BY: %.2f, MFLOP=%e!\n\n", 
              nrep, nrep*mf);
      fp = fopen(fn, "w");
      fprintf(fp, "%le", nrep*mf);
      fclose(fp);
   }
}

ATL_mmnode_t *GetBestKernVT(char pre, char vt, int flg)
{
   ATL_mmnode_t *mp;
   char *mvsum, *kvsum;
   const int bf=(flg&FKO_FLAG)?FKO_FLAG:0;

   if (bf)
   {
      mvsum = "gmvAMMUR_fko.sum";
      kvsum = "gkvAMMUR_fko.sum";
   }
   else
   {
      mvsum = "gmvAMMUR.sum";
      kvsum = "gkvAMMUR.sum";
   }
   if (vt == 'K')
      mp = ReadMMFileWithPath(pre, "res", kvsum);
   else
      mp = ReadMMFileWithPath(pre, "res", mvsum);
   assert(mp);
   if (mp->next)
   {
      KillAllMMNodes(mp->next);
      mp->next = NULL;
   }
   return(mp);
}

ATL_mmnode_t *GetBestKern(char pre, int flg)
{
   ATL_mmnode_t *mp, *mpB;
   mpB = GetBestKernVT(pre, 'M', flg);
   mp =  GetBestKernVT(pre, 'K', flg);
   if (mp->mflop[0] > mpB->mflop[0])
   {
      KillAllMMNodes(mpB);
      mpB = mp;
   }
   else
      KillAllMMNodes(mp);
   return(mpB);
}


void DoSquare(int flag, int verb, char pre, int nreg, int VL)
{
   ATL_mmnode_t *mp;
   int maxNB;

   mp = GetBestKern(pre, flag);
   maxNB = GetMaxNB(flag, verb, pre, mp);
}

int TestWithKU(int verb, char pre, int NB, ATL_mmnode_t *mp, FILE *fperr)
{
   int nf;
   mp->flag |= (1<<MMF_KUISKB);
   mp->kbB = mp->ku = NB;
   free(mp->rout);
   free(mp->genstr);
   mp->rout = MMGetGenName(pre, NB, mp);
   mp->genstr = MMGetGenString(pre, mp);
   nf = NumberBetaFails(fperr, pre, NB, mp);
   return(nf);
}

int CountFails(int TEST, int flg, int verb, char pre, int NB, int nreg, int VL)
{
   int i, j, ntest=0, nfail=0;
   char *frm="%8d %4d %3d %3d %3d  %2d   %c %2d  %5d\n";
   FILE *fperr;
   const int bf=(flg&FKO_FLAG)?FKO_FLAG:0;

   fperr = fopen("res/FAIL.OUT", "w");
   assert(fperr);

   assert(VL);
   assert(nreg);
   assert(NB > 0);
   printf("     NUM    B  MU  NU  KU  VL VEC BC  NPASS\n");
   printf("======== ==== === === ===  == === ==  =====\n");
   for (i=1; i <= nreg; i++)
   {
      for (j=1; j <= nreg; j++)
      {
         ATL_mmnode_t *mp;
         int nf, flg=0;
         if (i == 1 || j == 1)
         {
            if (i*j+1 > nreg)
               continue;
         }
         else if (i*j+Mmin(i,j)+1 > nreg)
               continue;
         else if (i*j+i+j > nreg)
            flg = 2;

         mp = MMGetNodeGEN(pre, flg|bf, NB, i*VL, j, 1, VL, 0, 0, 0, NULL);
         nf = NumberBetaFails(fperr, pre, NB, mp);
         printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 0, 3-nf);
         nfail += nf;
         ntest += 3;
         if (!nf)  /* try fully unrolled case if rolled worked*/
         {
            nf = TestWithKU(verb, pre, NB, mp, fperr);
            printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 0, 3-nf);
            nfail += nf;
            ntest += 3;
         }
         mp = KillMMNode(mp);
         @skip "fko doesn't support splat!"
         if (j%VL == 0 && !bf)  /* try m-vec w/o bcast */
         {
            mp = MMGetNodeGEN(pre, 1, NB, i*VL, j, 1, VL, 0, 0, 0, NULL);
            nf = NumberBetaFails(fperr, pre, NB, mp);
            printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 
                   FLAG_IS_SET(mp->flag, MMF_NOBCAST), 3-nf);
            nfail += nf;
            ntest += 3;
            if (!nf)  /* try fully unrolled case if rolled worked*/
            {
               nf = TestWithKU(verb, pre, NB, mp, fperr);
               printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 
                      FLAG_IS_SET(mp->flag, MMF_NOBCAST), 3-nf);
               nfail += nf;
               ntest += 3;
            }
            mp = KillMMNode(mp);
         }
         if (1 /*(i*j)%VL == 0*/) /* try k-vec */
         {
            mp = MMGetNodeGEN(pre, flg|bf, NB, i, j, VL, VL, 1, 0, 0, NULL);
            nf = NumberBetaFails(fperr, pre, NB, mp);
            printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'K', 0, 3-nf);
            nfail += nf;
            ntest += 3;
            if (!nf)  /* try fully unrolled case if rolled worked*/
            {
               nf = TestWithKU(verb, pre, NB, mp, fperr);
               printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'K', 0, 3-nf);
               nfail += nf;
               ntest += 3;
            }
            mp = KillMMNode(mp);
         }
      }
   }
   if (TEST > 1)
   {
      printf("\n   .... start of prefetch tests ....\n");
/*
 *    Now test some pref on both 1- & 2-D kernels.  Prefetch of next block of
 *    A & B affect peeling, and so can cause errors (K-loop prefetch no).
 *    Fully unrolled cases don't need to be tested again, since they are
 *    totally peeled with or without prefetch.
 */
      assert(nreg > 2);
      for (i=0; i < 7; i++)  /* 1-D in both directions, and some 2-D */
      {
         const int NOBCAST = (i == 5 || i == 6); /* spec cases for no-bcast */
         int MU;
         int mu, nu, pfLS;
         if (i == 0)
         {
            mu = nreg - 2;
            nu = 1;
         }
         else if (i == 1)
         {
            mu = 1;
            nu = nreg - 2;
            if (nu > VL)
               nu = (nu / VL) * VL;
         }
         else if (i == 2)
         {
            mu = 3;
            for (nu=3; nu*mu+mu+1 < nreg; nu++);
         }
         else if (i == 4)
            mu = nu = 2;
         else if (i == 5)
         {
            nu = VL;
            mu = 3;
         }
         else if (i == 6)
         {
            nu = VL*2;
            mu = 2;
         }
   
         if (i <= 2)  /* 1-D case */
         {
            if (mu*nu+1 > nreg)
               continue;
         }
         else if (mu*nu+Mmin(mu,nu)+1 > nreg)
            continue;
   
         MU = mu*VL;
   
         for (pfLS=16; pfLS < 128; pfLS += pfLS)
         {
            int k, pfs[6]={1, 2, 4, 1|2, 2|4, 1|2|4};
            for (k=0; k < 5; k++)
            {
               ATL_mmnode_t *mp;
               int nf;
/*
 *             Test M-vec using broadcast
 */
               if (!NOBCAST)
               {
                  mp = MMGetNodeGEN(pre, 0|bf, NB, MU, nu, 1, VL, 0, 
                                    pfs[k], pfLS, NULL);
                  nf = NumberBetaFails(fperr, pre, NB, mp);
                  printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 
                         FLAG_IS_SET(mp->flag, MMF_NOBCAST), 3-nf);
                  nfail += nf;
                  ntest += 3;
                  KillMMNode(mp);
               }
               @skip "fko doesn't support splat"
               if (nu%VL == 0 && !bf)  /* try m-vec using splat & w/o bcast */
               {
                  mp = MMGetNodeGEN(pre, 1, NB, MU, nu, 1, VL, 0, 
                                    pfs[k], pfLS, NULL);
                  nf = NumberBetaFails(fperr, pre, NB, mp);
                  printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 
                         FLAG_IS_SET(mp->flag, MMF_NOBCAST), 3-nf);
                  nfail += nf;
                  nfail += nf;
                  ntest += 3;
                  KillMMNode(mp);
               }
               if (!NOBCAST && (mu*nu)%VL == 0)  /* try k-vec */
               {
                  mp = MMGetNodeGEN(pre, 0|bf, NB, mu, nu, VL, VL, 1, 
                                    pfs[k], pfLS, NULL);
                  nf = NumberBetaFails(fperr, pre, NB, mp);
                  printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'K', 
                         0, 3-nf);
                  nfail += nf;
                  ntest += 3;
                  KillMMNode(mp);
               }
            }
         }
      }
   }
   if (!nfail)
   {
      printf("ALL %d TESTS PASS!\n", ntest);
      fprintf(fperr, "ALL %d TESTS PASS!\n", ntest);
   }
   else
   {
      printf("FAILED %d OF %d TESTS!!\n\n", nfail, ntest);
      fprintf(fperr, "FAILED %d OF %d TESTS!!\n\n", nfail, ntest);
   }
   fclose(fperr);
   return(nfail);
}

int FindBlockingRegions(int flag, int verb, char pre)
/*
 * This routine attempts to find the best prefetch kernel for all problem sizes
 * using timings of the fastest unprefetched kernel found in MU/NU search.
 * We can prefetch or not each of the three operands, and for each we an
 * also use ATL_pfl1 (pref to L1) or ATL_pfl2.  L2 may really be last-lvl cache.
 * We assume there are five operand size ranges of interest:
 * 1. nb <= sqrt(L1sz/5) : can fit 5 blks of A/B in L1.  May be worthwhile
 *    to prefetch next block of A & B to L1 cache
 * 2. nb <= sqrt(L1sz/4) : fit 4 blks, try fetching A or B to L1, other to L2
 * 3. nb <= sqrt(L2sz/6) : pref next A&B blocks to L2
 * 4. nb <= sqrt(L2sz/5) : pref only one of A/B to L2
 * 5. else only do inter-block prefetch
 * RETURNS: maximum NB providing speedup 
 */
{
   int maxNB=0;

   return(maxNB);
}

int TryKU(char pre, int verb, ATL_mmnode_t *mp, int imf, int ku)
/*
 * Assumes mp->mflop[imf] presently holds perf of present ku unrolling.
 * Times (& tests) unrolling of ku, and retains best setting.
 * Penalizes larger unroll very slightly due to potential code size problems.
 * RETURNS: 1 if new ku is faster, else 0.
 */
{
   const double newmul = (mp->ku < ku) ? 0.99 : 1.01; /* bias big unroll */
   double mf0=mp->mflop[0], mfN;
   char *gs0=mp->genstr;
   int ku0 = mp->ku, fail;

   mp->ku = ku;
   if (mp->rout)
      free(mp->rout);
   mp->rout = MMGetGenName(pre, mp->kbB, mp);
   mp->genstr = MMGetGenString(pre, mp);
   fail = MMKernelFailsAnyBeta(pre, mp->mbB, mp->nbB, mp->kbB, mp);
   if (fail)
      printf("   ku=%d FAILS TESTS!\n", ku);
   else
   {
      mfN = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB, mp->kbB, 1, 0, -1);
      printf("      ku=%d, MFLOP=%.2f, SPEEDUP=%.3f\n", ku, mfN, mfN/mf0);
   }
   if (!fail && mfN*newmul > mf0)  /* is new timing better? */
   {
      if (gs0)
         free(gs0);
      mp->mflop[0] = mfN;
      if (ku == mp->kbB)
         mp->flag |= (1<<MMF_KUISKB);
      return(1);
   }
   else  /* original ku best */
   {
      free(mp->genstr);
      free(mp->rout);
      mp->ku = ku0;
      mp->genstr = gs0;
      mp->rout = MMGetGenName(pre, mp->kbB, mp);
   }
}

int TryPref(char pre, int verb, int vrb, ATL_mmnode_t *mp, int ibet, int imf, 
            int ipf, int pfLS)
/*
 * Times mmb with present prefetch setting, and (ipf,pfLS), and returns
 * in mmb the best.  mp->mflop[imf] must contain the timing for the present
 * prefetch settings.
 * RETURNS: 1 if new settings taken, 0 if old are kept
 */
{
   char *gs0=mp->genstr, *rt0=mp->rout;
   int ipf0=mp->pref, pfLS0=mp->pfLS;
   double mf0=mp->mflop[imf], mfN;

   if (mp->pref == ipf && mp->pfLS == pfLS)
   {
      if (vrb)
         printf("      pref settings unchanged!\n");
      return(0);
   }
   mp->pref = ipf;
   mp->pfLS = pfLS;
   mp->rout = DupString("ATL_tmp.c");
   mp->genstr = MMGetGenString(pre, mp);
   mfN = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB, mp->kbB, ibet, 0, -1);
   if (vrb)
      printf("      old=(%d,%d,%.0f), new=(%d,%d,%.0f), spdup=%.3f\n", 
             ipf0, pfLS0, mf0, mp->pref, mp->pfLS, mfN, mfN/mf0);
   if (mfN > mf0)  /* new settings win */
   {
      if (gs0)
         free(gs0);
      if (rt0)
         free(rt0);
      mp->mflop[imf] = mfN;
      return(1);
   }
   else  /* old settings best */
   {
      free(mp->genstr);
      mp->genstr = gs0;
      free(mp->rout);
      mp->rout = rt0;
      mp->pref = ipf0;
      mp->pfLS = pfLS0;
   }
   return(0);
}

void DoKUs(char pre, int flg, int verb, ATL_mmnode_t *mmb)
/*
 * Given routs times with KU=1 (mflop stored at imf), try various KU settings
 * and return the best
 */
{
   ATL_mmnode_t *mp;
   printf("TUNING KU FOR ALL KERNELS:\n");
   for (mp=mmb; mp; mp = mp->next)
   {
      int kumax, kumul, ku;
      const double mf0 = mp->mflop[0];

      printf("   TRYING KUs, RT='%s' B=(%d,%d,%d)\n", mp->rout,
             mp->mbB, mp->nbB, mp->kbB);
      printf("      ku=%d, MFLOP=%.2f, SPEEDUP=1.0\n", mp->ku, mf0);
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         assert(mp->ku == mp->vlen);
      else
         assert(mp->ku == 1);
      #if 0  /* present generator handles only ku=1,full */
      kumax = (mp->kbB)>>1;
      kumax = Mmin(kumax, 128);
      kumul = Mmin(mp->mu, mp->nu); /* square-friendly K unrollings */
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         kumul = Mylcm(kumul, mp->vlen);
      else
         kumul = (kumul != 1) ? kumul : 2;

      for (ku=kumul; ku <= kumax; ku += kumul)
         TryKU(pre, verb, mp, 0, ku);
      #endif
      TryKU(pre, verb, mp, 0, mp->kbB);

      printf("   DONE: KU=%d gives MFLOP=%.0f, SPEEDUP=%.3f\n", 
             mp->ku, mp->mflop[0], mp->mflop[0]/mf0);
   }
   printf("DONE TUNING KU FOR ALL KERNELS.\n\n");
}

@ROUT prefparse
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
@ROUT prefparse gmmsearch
void PrintPref(FILE *fp, int ipf)
{
   if (ipf & 2)
   {
      if (ipf & 64)
         fprintf(fp, " Ab to L1");
      else if (ipf & 512)
         fprintf(fp, " Ab to LLC");
      else
         fprintf(fp, " Ab to L2");
   }
   else
      fprintf(fp, " NO Ab PREF");
   if (ipf & 4)
   {
      if (ipf & 128)
         fprintf(fp, ", Bb to L1");
      else if (ipf & 1024)
         fprintf(fp, ", Bb to LLC");
      else
         fprintf(fp, ", Bb to L2");
   }
   else
      fprintf(fp, ", NO Bb PREF");
   if (ipf & 8)
   {
      if (ipf & 2048)
         fprintf(fp, ", Ak to L1");
      else if (ipf & 8192)
         fprintf(fp, ", Ak to LLC");
      else
         fprintf(fp, ", Ak to L2");
   }
   else
      fprintf(fp, ", NO Ak PREF");
   if (ipf & 16)
   {
      if (ipf & 4096)
         fprintf(fp, ", Bk to L1");
      else if (ipf & 16384)
         fprintf(fp, ", Bk to LLC");
      else
         fprintf(fp, ", Bk to L2");
   }
   else
      fprintf(fp, ", NO Bk PREF");
   if (ipf & 1)
   {
      if (ipf & 32)
         fprintf(fp, ", C to L1");
      else if (ipf &256)
         fprintf(fp, ", C to LLC");
      else
         fprintf(fp, ", C to L2");
   }
   else
      fprintf(fp, ", NO C PREF");
}
@ROUT gmmsearch

void DoPref1(char pre, int flg, int verb, int vrb0, ATL_mmnode_t *mmb)
/*
 * Given routs times with no prefetch (mflop stored at imf), try various
 * prefetch strategies, and return the best
 */
{
   ATL_mmnode_t *mp;
                    /* Lx(A)  ; Lx(B),   Lx(A&B)       2(A),x(B),  x(A),2(B) */
   const int ipfs[11]={2|512, 4|1024, 2|4|512|1024, 2|4|1024, 2|512|4,
                  /*L2(A); L2(B);L2(A&B);1(A),2(B);2(A)1(B),    L1(A&B) */
                        2,     4, 2|4,   2|64|4,   2|4|128, 2|64|4|128};
   int k, n, vrb=(vrb0 > 1);

/*
 * First, try A/B prefetch, since they are N^3
 */
   for (n=0,mp=mmb; mp; n++,mp = mp->next);
   if (vrb0)
      printf("PREFETCH TUNING FOR ALL %d KERNELS\n", n);
   for (k=0,mp=mmb; mp; k++,mp = mp->next)
   {
      const int ipf=mp->pref;
      int npf, i;
      double mf0=mp->mflop[0];
      mp->mflop[1] = mf0;
      npf = 11;     /* try all cases */
      if (vrb)
         printf("TUNING A/B PREFETCH FOR KERN %d of %d\n", k+1, n);
/*
 *    First, try only next-block prefetch
 */
      for (i=0; i < npf; i++)
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|ipfs[i], 64);
/*
 *    Now let's try K-loop prefetch, both in addition to prior setting and
 *    w/o other prefetch
 */
      for (i=0; i < npf; i++)
      {
         const int kpf = mp->pref;
         const double kmf = mp->mflop[0];
         int pf;

         mp->mflop[0] = mf0;
         mp->pref = ipf;
/*
 *       Try fetching next B working set to L1, L2, & L3
 */
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|16|4096, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|16, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|16|16384, 64);
         pf = mp->pref;
/*
 *       Using B setting, try A working set prefetch.  Not as likely to help,
 *       since we prefetch same set MB/mu times for 1 use.
 */
         TryPref(pre, verb, vrb, mp, 1, 0, pf|16|4096, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, pf|16, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, pf|16|16384, 64);
/*
 *       Now try combining best-found with above
 */
         pf = mp->pref;
         if (pf != kpf && kpf)
            TryPref(pre, verb, vrb, mp, 1, 0, pf|kpf, 64);
         if (mp->mflop[0] < kmf*1.005) /* if new settings (pen expen k-pref) */
         {                              /* slower M/N fetch alone, revert */
            mp->pref = kpf;
            mp->mflop[0] = kmf;
         }
         if (vrb)
            printf("   A/B PREFETCH FOR %d SPEEDUP=%.3f\n", 
                   k+1,mp->mflop[0]/mf0);
      }
      {
         const int ipf=mp->pref;
         double mf0=mp->mflop[0];
         if (vrb)
            printf("   TUNING C PREFETCH FOR %d\n", k+1);
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|1, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|1|32, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|1|256, 64);
         if (vrb)
            printf("   C PREFETCH FOR %d SPEEDUP=%.3f\n", k+1, 
                   mp->mflop[0]/mf0);
      }
      if (vrb0)
      {
         printf("   PREF:");
         PrintPref(stdout, mp->pref);
         printf("; SPD=%.2f\n", mp->mflop[0] / mp->mflop[1]);
      }
      mp->mflop[1] = 0.0;
   }
   if (vrb0)
      printf("DONE  PREFETCH TUNING FOR ALL %d KERNELS\n\n", n);
}

void DoPref(char pre, int flg, int verb, ATL_mmnode_t *mmb)
/*
 * Given routs times with no prefetch (mflop stored at imf), try various
 * prefetch strategies, and return the best
 */
{
   ATL_mmnode_t *mp;
   char *ctxt[5]={"3BLKS IN L1", "1BLKS IN L1", "0BLKS IN L1", 
                  "4BLKS IN L1", "5BLKS IN L1"};
                    /* Lx(A)  ; Lx(B),   Lx(A&B)       2(A),x(B),  x(A),2(B) */
   const int ipfs[11]={2|512, 4|1024, 2|4|512|1024, 2|4|1024, 2|512|4,
                  /*L2(A); L2(B);L2(A&B);1(A),2(B);2(A)1(B),    L1(A&B) */
                        2,     4, 2|4,   2|64|4,   2|4|128, 2|64|4|128};
   int k;

   printf("START PREFETCH TUNING FOR ALL CACHE CONTEXTS\n");
/*
 * First, try A/B prefetch, since they are N^3
 */
   for (k=0,mp=mmb; mp; k++,mp = mp->next)
   {
      const int ipf=mp->pref;
      int npf, i;
      double mf0=mp->mflop[0];
      mp->mflop[1] = mf0;
      if (k <= 2) /* for cases where L1 is full */
         npf = 8; /* only try prefetches to L2 (really last level cache) */
      else if (k == 3) /* room for one block */
         npf = 9;      /* try fetching one block to L1 */
      else             /* room for 5 blocks */
         npf = 11;     /* try all cases */
      printf("   TUNING A/B PREFETCH FOR %s\n", ctxt[k]);
/*
 *    First, try only next-block prefetch
 */
      for (i=0; i < npf; i++)
         TryPref(pre, verb, 1, mp, 1, 0, ipf|ipfs[i], 64);
/*
 *    Now let's try K-loop prefetch, both in addition to prior setting and
 *    w/o other prefetch
 */
      for (i=0; i < npf; i++)
      {
         const int kpf = mp->pref;
         const double kmf = mp->mflop[0];
         int pf;

         mp->mflop[0] = mf0;
         mp->pref = ipf;
/*
 *       Try fetching next B working set to L1, L2, & L3
 */
         TryPref(pre, verb, 1, mp, 1, 0, ipf|16|4096, 64);
         TryPref(pre, verb, 1, mp, 1, 0, ipf|16, 64);
         TryPref(pre, verb, 1, mp, 1, 0, ipf|16|16384, 64);
         pf = mp->pref;
/*
 *       Using B setting, try A working set prefetch.  Not as likely to help,
 *       since we prefetch same set MB/mu times for 1 use.
 */
         TryPref(pre, verb, 1, mp, 1, 0, pf|16|4096, 64);
         TryPref(pre, verb, 1, mp, 1, 0, pf|16, 64);
         TryPref(pre, verb, 1, mp, 1, 0, pf|16|16384, 64);
/*
 *       Now try combining best-found with above
 */
         pf = mp->pref;
         if (pf != kpf && kpf)
            TryPref(pre, verb, 1, mp, 1, 0, pf|kpf, 64);
         if (mp->mflop[0] < kmf*1.005) /* if new settings (pen expen k-pref) */
         {                              /* slower M/N fetch alone, revert */
            mp->pref = kpf;
            mp->mflop[0] = kmf;
         }
      }
      printf("   A/B PREFETCH FOR %s SPEEDUP=%.3f\n", ctxt[k],mp->mflop[0]/mf0);
   }
   printf("\n");
/*
 * First, try prefC for each kernel
 */
   for (k=0,mp=mmb; mp; k++,mp = mp->next)
   {
      const int ipf=mp->pref;
      double mf0=mp->mflop[0];
      printf("   TUNING C PREFETCH FOR %s\n", ctxt[k]);
      TryPref(pre, verb, 1, mp, 1, 0, ipf|1, 64);
      TryPref(pre, verb, 1, mp, 1, 0, ipf|1|32, 64);
      TryPref(pre, verb, 1, mp, 1, 0, ipf|1|256, 64);
      printf("   C PREFETCH FOR %s SPEEDUP=%.3f\n", ctxt[k], mp->mflop[0]/mf0);
      printf("   PREF:");
      PrintPref(stdout, mp->pref);
      printf("; SPD=%.2f\n", mp->mflop[0] / mp->mflop[1]);
      mp->mflop[1] = 0.0;
   }
   printf("DONE  PREFETCH TUNING FOR ALL CACHE CONTEXTS\n\n");
}

void FixContextMflop(ATL_mmnode_t *mm3)
/*
 * Put all context mflop back to ->mflop[0]
 */
{
   ATL_mmnode_t *mp;

   mm3->mflop[0] = mm3->mflop[1]; mm3->mflop[1] = 0.0;
   mp = mm3->next;
   mp->mflop[0] = mp->mflop[2]; mp->mflop[2] = 0.0;
   mp = mp->next;
   mp->mflop[0] = mp->mflop[3]; mp->mflop[3] = 0.0;
   mp = mp->next;
   if (mp)
   {
      mp->mflop[0] = mp->mflop[4]; mp->mflop[4] = 0.0;
      mp = mp->next;
      if (mp)
      {
         mp->mflop[0] = mp->mflop[5]; mp->mflop[5] = 0.0;
      }
   }
}
void DoBlock(char pre, int flg, int verb)
{
   int L1ELTS;
   ATL_mmnode_t *mmb, *mm3, *mp;
   int b;
   char upr;
   char *ressum, *mvsum, *kvsum;

   if (flg&FKO_FLAG)
   {
      ressum = "gAMMRES_fko.sum";
      mvsum = "gmvAMMUR_fko.sum";
      kvsum = "gkvAMMUR_fko.sum";
   }
   else
   {
      ressum = "gAMMRES.sum";
      mvsum = "gmvAMMUR.sum";
      kvsum = "gkvAMMUR.sum";
   }
   mmb = TimeMMFileWithPath(pre, "res", ressum, 0, verb|1, 0, 1, 0, -1);
   if (mmb)
   {
      KillAllMMNodes(mmb);
      return;
   }
   if (pre == 'c')
      upr = 's';
   else 
      upr = (pre == 'z') ? 'd' : pre;
/*
 * Compute # of L1 cache elements, and join M- & K-vec kernels found so far
 */
   L1ELTS = GetL1CacheElts(upr);
   mmb = ReadMMFileWithPath(upr, "res", mvsum);
   assert(mmb);
   mp = ReadMMFileWithPath(upr, "res", kvsum);
   ATL_LastMMNode(mmb)->next = mp;
   MMFillInGenStrings(pre, mmb);
/*
 * mm3: A,B,C in L1, mm3->next: B fits in L1, 
 * mm3->next->next: mu*KB panel of A fits in L1 (L2 blocked)
 */
   mm3 = FindBestCacheBudgetCases(verb, pre, L1ELTS, mmb);
   KillAllMMNodes(mmb);
   FixContextMflop(mm3);
   mmb = mm3;
   DoKUs(pre, flg, verb, mmb);   /* find best ku */
   DoPref(pre, flg, verb, mmb);  /* find best prefetch patterns */
   WriteRefreshedMMFileWithPath(pre, "res", ressum, mmb);
   KillAllMMNodes(mmb);
}

void DoSyrkAmmUM(char pre, int flag, int verb, int nreg)
/*
 * Find best generated ammm kernel to use for SYRK with restriction that MU
 * must be a multiple of NU (or vice versa if NU > MU).
 */
{
   ATL_mmnode_t *mb, *mD, *pT;
   ATL_UINT KVEC, KB, NB, VL, i, flg, muB=1, nuB=1, flgB;
   double mfB = 0.0;

   mb = TimeMMFileWithPath(pre, "res", "gSYRKUM.sum", 0, verb|1, 0, 1, 0, -1);
   if (mb)
   {
      KillAllMMNodes(mb);
      return;
   }
/*
 * Should read in 5 kernels, we want only highest performing
 */
   mb = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   mD = FindMaxMflopMMQ(mb, 0);
   mb = RemoveMMNodeFromQ(mb, mD);
   KillAllMMNodes(mb);
/*
 * If mu already a multiple of nu (or vice versa), no need to search!
 */
   if (!(mD->mu % mD->nu) || !(mD->nu % mD->mu))
   {
      WriteMMFileWithPath(pre, "res", "gSYRKUM.sum", mD);
      KillMMNode(mD);
      return;
   }
   VL = mD->vlen;
   NB = (mD->mbB + mD->nbB)>>1;
   KB = (mD->kbB);
   flg = mD->flag;
   KVEC = ((flg>>MMF_KVEC)&1)*VL;
   flg &= ~(1<<MMF_KUISKB);
   flg |= (1<<MMF_KRUNTIME);
   pT = MMGetNodeGEN(pre, 0, 0, VL, 1, 1, VL, 0, 0, 0,
                     DupString("ATL_tmp.c"));
   pT->flag = flg;
   printf("FULL SEARCH FOR MU%%NU == 0 (or vice versa) AMM, NREG=%u, "
          "B=(%u,%u), VLEN=%u:\n", nreg, NB, KB, VL);
   for (i=1; i <= nreg; i++)
   {
      ATL_UINT j;
      if (i > NB)
         break;
      for (j=1; j <= nreg; j++)
      {
         double mf;
         ATL_UINT mu, nu, mb, nb;
         if (j > NB || i*j+1 > nreg)
            break;
         if (i*j+i+j > nreg)
            pT->flag |= 1<<MMF_BREG1;
         else
            pT->flag &= ~(1<<MMF_BREG1);
         pT->mu = mu = (KVEC) ? i : i*VL;
         pT->nu = nu = j;
         pT->ku = (KVEC) ? KVEC : 1;
         mb = (NB/mu)*mu;
         nb = (NB/nu)*nu;
         if (mu%nu && nu%mu)
            continue;
         if (!mb || !nb)
            continue;
         if (pT->genstr)
            free(pT->genstr);
         pT->genstr = MMGetGenString(pre, pT);
         mf = TimeMMKernel(verb, 0, pT, pre, mb, nb, KB, 1, 0, -1);
         printf("   MU=%2u/%2u, NU=%2u, MFLOP=%.2f\n", i, mu, j, mf);
         if (mf > mfB)
         {
            muB = mu;
            nuB = nu;
            mfB = mf;
            flgB = pT->flag;
         }
      }
   }
   assert(mfB > 0.0);
   KillMMNode(pT);
   pT = MMGetNodeGEN(pre, flgB, mD->kbB, muB, nuB, mD->ku, VL, KVEC, 
                     mD->pref, mD->pfLS, NULL);
   pT->mbB = (NB/muB)*muB;
   pT->nbB = (NB/nuB)*nuB;
   pT->mbB = mD->kbB;
   printf("BEST MU%%NU==0 CASE is B=(%u,%u,%u), U=(%u,%u), MFLOP=%.2f\n", 
          pT->mbB, pT->nbB, pT->kbB, muB, nuB, mfB);
   KillMMNode(mD);
   WriteRefreshedMMFileWithPath(pre, "res", "gSYRKUM.sum", pT);
   KillMMNode(pT);
}

int getSzC(ATL_mmnode_t *mp, int nb)
{
   const int nu = mp->nu, nnu = (nb+nu-1)/nu;
   const int vlen=mp->vlen, nvec=(nu*nu+vlen-1)/vlen, blksz=nvec*vlen;
   return(nnu*nnu*blksz);
}
int getSzA(ATL_mmnode_t *mp, int nb, int kb)
{
   const int nu = mp->nu, nnu = (nb+nu-1)/nu, ku=mp->ku, nku=(kb+ku-1)/ku;
   return(nnu*nku*nu*ku);
}

void TryAllSyrkPref(int flag, int vrb, char pre, ATL_mmnode_t *mp, 
                    int nb, int kb)
/* 
 * This kernel is designed to do an inner-product syrk.  This means we actually
 * reuse workspace for both A & C all the time, so it doesn't make sense to
 * prefetch anything from outside the block.
 */
{
   double mf0, mfB;
   int i, ipf, ils;
   const int thsA[3] = {8|8192, 8, 8|2048};
   const int thsC[3] = {1|256, 1, 1|32};
@skip   const int nxtA[3] = {2|512, 2, 2|64};
   printf("PREFETCH TUNING NB=%d, KB=%d, U=%d, KVEC=%d, SPLAT=%d:\n", nb, kb, 
          mp->nu, FLAG_IS_SET(mp->flag, MMF_KVEC)?mp->vlen:0, 
          FLAG_IS_SET(mp->flag, MMF_NOBCAST));
   mp->pref = 0; mp->pfLS=64;
   mf0 = mfB = TimeMMKernel(vrb, 0, mp, pre, nb, nb, kb, 1, 0, -1);
   mp->mflop[0] = mf0;
   printf("   No prefetch, MFLOP=%.0f\n", mf0);
   printf("   TRY PREFETCH A:\n");
/*
 * Try K-loop A/At pref for LS=64 & 128, since it's N^3 cost
 */
   for (i=0; i < 3; i++)
   {
      TryPref(pre, vrb, 1, mp, 1, 0, thsA[i], 64);
      TryPref(pre, vrb, 1, mp, 1, 0, thsA[i], 128);
   }
/*
 * Now try C prefetch (N^2 cost)
 */
  printf("   TRY PREFETCH C:\n");
  ipf = mp->pref;
  ils = mp->pfLS;
  for (i=0; i < 3; i++)
     TryPref(pre, vrb, 1, mp, 1, 0, ipf|thsC[i], ils);
  printf("DONE PREFETCH=(%d,%d), FINAL MFLOP=%.0f, SPEEDUP=%.3f\n",
         mp->pref, mp->pfLS, mp->mflop[0], mp->mflop[0] / mf0);
}
double TimeSyrkKBs(int flg, int vrb, char pre, ATL_mmnode_t *mp, int nb)
{
   const unsigned int ku=mp->ku, kb=(nb+ku-1)/ku;
   unsigned int KB, sz;
   static int l1elts=0;
   double mf0, mf=0.0;

   if (l1elts == 0)
      l1elts = GetL1CacheElts((pre=='c' || pre=='s') ? 's':'d');

   mf0 = TimeMMKernel(vrb, 0, mp, pre, nb, nb, kb, 1, 0, -1);
/*
 * For problems that fit entirely in L1 (including A you're copying from),
 * find a large KB that fills L1.  This will reduce the N^2 costs, which
 * are important for these small problems.  We can do this, since this
 * kernel is intended for inner product (large K, small N).
 */
   KB = kb;
   do
   {
      KB += ku;
      sz = (getSzA(mp, nb, KB)<<1)+getSzC(mp, nb);
   }
   while (l1elts > sz);
   KB -= ku;
   if (KB > kb)
      mf = TimeMMKernel(vrb, 0, mp, pre, nb, nb, KB, 1, 0, -1);

   if (mf0 > mf)
   {
      mp->mflop[0] = mf0;
      mp->kbB = kb;
   }
   else
   {
      mp->mflop[0] = mf;
      mp->kbB = KB;
      mf0 = mf;
   }
   return(mf0);
}

int SyrkXoverUp(int flg, int vrb, char pre, ATL_mmnode_t *ms,/* syrk kerns */
                ATL_mmnode_t *mg)  /* gemm largest kb */
{
   const double mfG = mg->mflop[0];
   double mfS=ms->mflop[0], mfR; /* MFLOP for SYRK & recursion */
   const unsigned int nuS = ms->nu, kuS=ms->ku, NB=ms->nbB;
   int nb, incb;

   incb = Mylcm(nuS,kuS);
   nb = NB;
   printf("ESTIMATING SYRK RECURSIVE STOPPING POINT BY INCREASING N:\n");
   while (1)
   {
      int nbn = nb+incb, nbS, nbG;
      double mfR, mfn;            /* mflop for recursion & syrk(N/2) */
      if (nbn > 512)
         break;
      mfn = TimeSyrkKBs(flg, vrb, pre, ms, nbn);
      mfR = 0.5*(mfS + mg->mflop[0]);
      printf("   SYRK-%d = %.0f, GEMM/SYRK-%d = %.0f (S:%.0f,G:%.0f)\n",
             nbn, mfn, nb, mfR, mfS, mfG);
      if (mfR > mfn)
         break;
      mfS = mfn;
      nb = nbn;
   }
   printf("STOPPING POINT N = %d\n", nb);
   return(nb);
}
int SyrkXover(int flg, int vrb, char pre, ATL_mmnode_t *ms,/* syrk kerns */
              ATL_mmnode_t *mG)  /* gemm kernels */
{
   ATL_mmnode_t *mg=mG, *mp;
   const double mf0 = ms->mflop[0];
   double mfS=mf0, mfR; /* MFLOP for SYRK & recursion */
   const unsigned int nuS = ms->nu, kuS=ms->ku, NB=ms->nbB;
   int nb;
/*
 * We are using the SYRK kernel when we stop recurring on SYRK.  In each
 * recursion, we divide C into hi&low triangles (SYRK) and a square GEMM.  
 * During recursion, each SYRK is again divided to continue to use GEMM.
 * When we stop the recursion, we call the SYRK kernel we are tuning here
 * for the high & low triangles, and then unwind all the GEMM calls.
 * We note that SYRK has roughly half the flops as GEMM, but during the
 * recursion we make two SYRK calls, so at the stopping point, we can
 * simply average the MFLOP rate of SYRK & GEMM to estimate the MFLOP rate
 * the non-recursive call would get.
 *
 * We want to estimate where we should stop our recursion based on kernel
 * timings.  At each candidate N, we can make one SYRK call, or recur.
 * If we assume this is the stopping point, then its MFLOP rate is
 * that of a single syrk call.  If we assume the N/2 (next candidate N)
 * is the stopping point, its mflop rate is (syrkMF(N/2)+gemmMF(N/2)).
 * So, we have reached the estimated crossover point when 
 * syrkMF(N) >= syrkMF(N/2)+gemmMF(N/2).
 *
 * This code attempts to find this point.  Note that this is a very rough
 * estimation, since the kernel timer doesn't include cpy of A, which is
 * an important part of inner product.  SYRK has to copy only A, whereas
 * GEMM needs both A & B, so we should give SYRK the benefit of the doubt,
 * and err on the side of stopping the recursion.
 */
 
   nb = NB;
   mg = mG;
   printf("ESTIMATING SYRK RECURSIVE STOPPING POINT:\n");
   while (1)
   {
      int nb2 = nb>>1, nbS, nbG;
      double mfR, mfs;            /* mflop for recursion & syrk(N/2) */
      if (nb2 < nuS)
         break;
      for (; mg; mg=mg->next)     /* find gemm used by nb/2 */
         if (mg->nbB <= nb2)
            break;
      if (!mg)
         break;
      nbS = (nb2/nuS)*nuS;       /* basic syrk perf estimate */
      mfs = TimeSyrkKBs(flg, vrb, pre, ms, nbS);
      mfR = 0.5*(mfs + mg->mflop[0]);
      printf("   N=%3d (S:%d,G:%d), SYRK=%.0f, RECUR=%.0f (S:%.0f,G:%.0f)\n", 
             nb, nbS, mg->nbB, mfS, mfR, mfs, mg->mflop[0]);
      if (mfR < mfS)
         break;
      mfS = mfs;
      nb = nb2;
   }
   ms->mbB = ms->nbB = ((nb+nuS-1)/nuS)*nuS;
   ms->kbB = ((nb+kuS-1)/kuS)*kuS;
   if (nb == NB)
   {
      ms->mflop[0] = mf0;
      nb = SyrkXoverUp(flg, vrb, pre, ms, mG);
   }
   else
      printf("STOPPING POINT N = %d\n", nb);
   return(nb);
}

void DoAllSyrkNB(char pre, int vrb, ATL_mmnode_t *mSQ, ATL_mmnode_t *sy, int flg)
{
   ATL_mmnode_t *mSY, *mp;
   const unsigned int nu=sy->nu, ku=sy->ku, maxD;
   if (flg&FKO_FLAG)
      mp = TimeMMFileWithPath(pre, "res", "SYRKFNL_fko.sum", 0, 1, 0, 1, 0, -1);
   else
      mp = TimeMMFileWithPath(pre, "res", "SYRKFNL.sum", 0, 1, 0, 1, 0, -1);
   if (mp)
   {
      KillAllMMNodes(mp);
      return;
   }
/*
 * Make a syrk node for all nodes in mSQ
 */
   printf("TIMING SYRK KERN FOR ALL NBs:\n");
   for (mSY=NULL,mp=mSQ; mp; mp = mp->next)
   {
      ATL_mmnode_t *syp;
      double mf, mul=1.0, mfG;

      syp = CloneMMNode(sy);
      syp->mbB = syp->nbB = ((mp->nbB+nu-1) / nu)*nu;
      syp->kbB = ((syp->kbB+ku-1)/ku)*ku;
@skip      MMExpandK(vrb, pre, syp->flag, 1, syp, 0);
      mf = TimeMMKernel(vrb, 0, syp, pre, syp->mbB, syp->nbB, syp->kbB, 1,0,-1);
      syp->mflop[0] = mf;
      if (syp->nbB != mp->nbB)
      {
         mul = mp->nbB;
         mul /= syp->nbB;
         mul *= mul;
      }
@skip      if (syp->kbB != mp->kbB)
@skip         mul *= ((double)mp->kbB)/((double)syp->kbB);
      syp->mflop[0] *= mul;
      printf("   NB=%4u,%4u KB=%4u,%4u: GEMM=%.0f,(%.0f), SYRK=%.0f,(%.0f)\n", 
             mp->nbB, syp->nbB, mp->kbB, syp->kbB, 
             mp->mflop[0]/2.0,mp->mflop[0],syp->mflop[0],mf);
      syp->next = mSY;
      mSY = syp;
   }
   printf("DONE TIMING SYRK KERN FOR ALL NBs.\n");
   if (mSY->next && mSY->nbB > mSY->next->nbB)
      mSY = ReverseMMQ(mSY);
   if(flg&FKO_FLAG)
      WriteMMFileWithPath(pre, "res", "SYRKFNLi_fko.sum", mSY);
   else
      WriteMMFileWithPath(pre, "res", "SYRKFNL.sum", mSY);
   KillAllMMNodes(mSY);
}

void DoSyrkTim(char pre, int verb, int flg)
{
   ATL_mmnode_t *tb, *tp, *sb, *syp, *syb=NULL;
   int mu, nu;
   if (flg&FKO_FLAG)
      tb = ReadMMFileWithPath(pre, "res", "syrkKi_fko.sum");
   else
      tb = ReadMMFileWithPath(pre, "res", "syrkK.sum");
   if (tb)  /* already ran! */
   {
      for (tp=tb; tp; tp = tp->next)
      {
         if (tp->mflop[0] <= 0.0)
         {
            tp->mflop[0] = TimeMMKernel(verb, 0, tp, pre, tp->mbB, tp->nbB, 0,
                                        1, 0, -1);
            if (verb)
               printf("   syrkK %dx%d: %.2f\n", tp->mbB, tp->nbB, tp->mflop[0]);
         }
      }
      if (flg&FKO_FLAG)
         WriteRefreshedMMFileWithPath(pre, "res", "syrkK_fko.sum", tb);
      else
         WriteRefreshedMMFileWithPath(pre, "res", "syrkK.sum", tb);
      KillAllMMNodes(tb);
      return;
   }
   if (flg&FKO_FLAG)
   {
      tb = ReadMMFileWithPath(pre, "res", "sqAMMRES_fko.sum");
      syp = ReadMMFileWithPath(pre, "res", "gAMSYRK_fko.sum");
   }
   else
   {
      tb = ReadMMFileWithPath(pre, "res", "sqAMMRES.sum");
      syp = ReadMMFileWithPath(pre, "res", "gAMSYRK.sum");
   }
   assert(syp);
   mu=syp->mu; 
   nu=syp->nu;
   printf("\nFINDING PERFORMANCE OF SYRK KERNELS FOR MB=NB AMM:\n");
   for (tp=tb; tp; tp = tp->next)
   {
      ATL_mmnode_t *new;
      double ratio, mf;
      int mb=tp->mbB, nb=tp->nbB;
      
      new = CloneMMNode(syp);
      mb = ((mb+mu-1)/mu)*mu;
      nb = ((nb+nu-1)/nu)*nu;
      new->mbB = mb;
      new->nbB = nb;
      new->kbB = tp->kbB;
      if (mb == tp->mbB && nb == tp->nbB)
         ratio = 1.0;
      else
         ratio = (((double)tp->mbB)*tp->nbB) / (((double)mb)*nb);
      mf = TimeMMKernel(verb, 0, new, pre, mb, nb, tp->kbB, 1, 0, -1);
      mf *= ratio;  /* don't count useless flops */
      new->mflop[0] = mf;
      printf("   syrkK %dx%d: %.2f (%.2f)\n", tp->mbB, tp->nbB, mf, ratio);
      new->next = syb;
      syb = new;
   }
   KillAllMMNodes(tb);
   KillAllMMNodes(syp);
   syb = ReverseMMQ(syb);
   if (flg&FKO_FLAG)
      WriteRefreshedMMFileWithPath(pre, "res", "syrkK_fko.sum", syb);
   else
      WriteRefreshedMMFileWithPath(pre, "res", "syrkK.sum", syb);
   printf("DONE SYRK TIMING.\n");
   KillAllMMNodes(syb);
}

void DoSyrk(int flg, int vrb, char pre, int nreg, int nb, int VL)
{
   ATL_mmnode_t *mb, *mSQ, *mp, *mSY;
   int L1ELTS, i, maxNB, nu, ku, kb;
   char upr = (pre == 'c' || pre == 's') ? 's' : 'd';
   double mf0, mfB;
   char *ipsum, *syrksum;

   if (flg&FKO_FLAG)
   {
      ipsum = "ipmen_fko.sum";
      syrksum = "gAMSYRK_fko.sum";
   }
   else
   {
      ipsum = "ipmen.sum";
      syrksum = "gAMSYRK.sum";
   }
   mSQ = TimeMMFileWithPath(pre, "res", ipsum, 0, vrb|1, 0, 1, 0, -1);
   if (!mSQ)
      return;
   mb = TimeMMFileWithPath(pre, "res", syrksum, 0, vrb|1, 0, 1, 0, -1);
   if (mb)
   {
      DoAllSyrkNB(pre, vrb, mSQ, mb, flg);
      KillAllMMNodes(mb);
      KillAllMMNodes(mSQ);
@skip      DoSyrkTim(pre, vrb, flg);
      return;
   }
   mSQ = ReverseMMQ(mSQ);  /* sorted from large to small NB */
   mb = DoSyrkMUNU(flg, vrb, pre, nreg, mSQ->nbB, mSQ->kbB, VL); 
   DoSyrkKU(vrb, pre, mb);
   mp = mb;
   nu = mp->nu;
   ku = mp->ku;
   mp->nbB = mp->mbB = nb = (mSQ->nbB / nu)*nu;
   mp->kbB = kb = (mSQ->kbB / ku)*ku;
   assert(nb && kb);
   TryAllSyrkPref(flg, vrb, pre, mp, nb, kb);
@skip   maxNB = SyrkXover(flg, vrb, pre, mp, mSQ);
@skip   mb->mbB = mb->nbB = mb->kbB = maxNB;
   WriteMMFileWithPath(pre, "res", syrksum, mp);
/*
 * Make a syrk node for all nodes in mSQ
 */
   DoAllSyrkNB(pre, vrb, mSQ, mb, flg);
   KillAllMMNodes(mSQ);
   KillMMNode(mb);
@skip   DoSyrkTim(pre, vrb, flg);
}

void DoPrefOnList(int flg, int vrb, char pre, int maxB)
{
   ATL_mmnode_t *mb, *mp, *pb;
   int b, binc;
   FILE *fp;

   if (flg&FKO_FLAG)
      mb = ReadMMFile("time.sum"); /* may use different name later */
   else
      mb = ReadMMFile("time.sum");
   if (!mb)
   {
      fprintf(stderr, "No files in time.sum, exiting!\n");
      remove("NB-pref.txt");
      return;
   }
   binc = Mylcm(mb->mu, mb->nu);
   for (mp=mb->next; mp; mp = mp->next)
   {
      binc = Mylcm(binc, mp->mu);
      binc = Mylcm(binc, mp->nu);
   }
   fp = fopen("NB-pref.txt", "w");
   assert(fp);
   fprintf(fp, "      ");
   for (mp=mb; mp->next; mp = mp->next)
      fprintf(fp, "-----------");
   fprintf(fp, "---------  ");
   for (mp=mb; mp->next; mp = mp->next)
      fprintf(fp, "-----------");
   fprintf(fp, "---------\n");
   fprintf(fp, "  NB");
   for (mp=mb; mp; mp = mp->next)
      fprintf(fp, "   %c%c:%2dx%2d", FLAG_IS_SET(mp->flag, MMF_KVEC) ? 'K':'M', 
              FLAG_IS_SET(mp->flag,MMF_NOBCAST)?'s':'b', mp->mu, mp->nu);
   for (mp=mb; mp; mp = mp->next)
      fprintf(fp, "  PREF %c%2dx%2d", 
              FLAG_IS_SET(mp->flag, MMF_KVEC) ? 'K':'M', mp->mu, mp->nu);
   fprintf(fp, "\n====");
   for (mp=mb; mp; mp = mp->next)
      fprintf(fp, "  =========");
   for (mp=mb; mp; mp = mp->next)
      fprintf(fp, "  ==== ======");
   fprintf(fp, "\n");
   fflush(fp);
   for (b=binc; b <= maxB; b += binc)
   {
      fprintf(fp, "%4d", b);
      for (mp=mb; mp; mp = mp->next)
      {
         double mf;
         mp->pref = 0;
         mp->nbB = mp->mbB = mp->kbB = b;
         if (mp->genstr)
            free(mp->genstr);
         mp->genstr = NULL;
         mf = TimeMMKernel(vrb, 0, mp, pre, b, b, b, 1, 0, -1);
         mp->mflop[0] = mf;
         fprintf(fp, "     %6.0f", mf);
      }
      DoPref1(pre, flg, vrb, 1, mb);
      for (mp=mb; mp; mp = mp->next)
         fprintf(fp, "  %4.4x %6.0f", mp->pref, mp->mflop[0]);
      fprintf(fp, "\n");
      fflush(fp);
   }
   fclose(fp);
   KillAllMMNodes(mb);  /* done with these! */
}

void SetFlops(int flg, int verb, char pre, int VL)
/* 
 * This search finds a decent generated kernel, and uses it to find the
 * number of flops that must be forced to get 
 * 1:  each problem above .25 sec?
 * 2:  10 timings withing 2% of each other?
 * which should be enough to avoid huge timing error bars
 */
{
   ATL_mmnode_t *mp;
   FILE *fp;
   char *rt;
   char fn[16];
   int b, i;
   int muB, nuB, kvecB, bB, bcB;
   #define TOL .015
   const double mbig=(1.0+TOL), msml=(1.0-TOL);
   double mfB, mf, mul, nmf, tim;
   const int bf=(flg&FKO_FLAG)?FKO_FLAG:0;

/*
 * Get square blocking factor that fills cache with one block
 */
   i = GetL1CacheElts(pre);
   for (b=4; b*b <= i; b += 4);
   b -= 4;
/*
 * If we have no vector length set, see if we know the platform, else
 * attempt to determine it empirically (can use gnuvec to vectorize
 * archs where ATLAS has no explicit support).
 */
   if (VL < 1)
      VL = GetNativeVLEN(pre);
   @skip "don't use fko to findout vlen"
   if (VL < 1)  /* no good guess, will have to probe for it */
   {
      int vl, vlB=1;
      int B = (b>>1)<<1;
      mp = MMGetNodeGEN(pre, 0, 0, 2, 2, 1, 1, 1, 0, 0, DupString("ATL_tmp.c"));
      mp->mbB = mp->nbB = 2;
      mp->kbB = 480;
      mp->flag &= ~( (1<<MMF_MVA)|(1<<MMF_MVB)|(1<<MMF_MVC) );
      mfB = 0.0;
      printf("ATTEMPTING TO DETECT VECTOR LENGTH:\n");
      for (vl=1; vl < 16; vl += vl)
      {
         mp->ku = mp->vlen = vl;
         if (vl == 2)
            mp->flag |= (1<<MMF_KVEC);
         if (mp->genstr)
            free(mp->genstr);
         mp->genstr = NULL;
         mf = TimeMMKernel(verb, 1, mp, pre, 2, 2, 480, 1, mul, 0);
         printf("   VL=%d, KVEC=1, B=(2,2,480) U=2: %.0f\n", vl, mf);
         if (mf > mfB)
         {
            mfB = mf;
            vlB=vl;
         }
      }
      printf("VLEN SET TO %d\n\n", vlB);
      VL = vlB;
      KillMMNode(mp);
   }
   
   mp = MMGetNodeGEN(pre, 0|bf, 0, 1, 1, VL, VL, 1, 0, 0, DupString("ATL_tmp.c"));
   mp->ku = 1;
   mp->flag &= ~( (1<<MMF_MVA)|(1<<MMF_MVB)|(1<<MMF_MVC) ); /* no cache flush */
   printf("SCOPING FOR A DECENT SQUARE REGISTER BLOCKING, VLEN=%d\n", VL);
   printf("     B   U  Mb MFLOP  Ms MFLOP  K  MFLOP\n");
   printf("   ===  ==  ========  ========  ========\n");
   bB = Mylcm(VL, 6);
   bB = ((b+bB-1)/bB)*bB;
   i = MMTimeAllVecGen(verb, 1, mp, pre, bB, bB, bB, 0, 0, 0);
   printf("%6d %3d %9.0f %9.0f %9.0f\n", i, 1, 
          mp->mflop[0],mp->mflop[1],mp->mflop[2]);
   fflush(stdout);
   mfB = mp->mflop[i];
   muB = nuB = 1;
   kvecB = (i == 2) ? 1 : 0;
   bcB = (i != 1);
   for (i=2; i*i <= 64; i++)
   {
      int B = (b > i) ? (b/i)*i : i, iB; 
      mp->mu = mp->nu = i;
      iB = MMTimeAllVecGen(verb, 1, mp, pre, B, B, B, 0, 0, 0);
      printf("%6d %3d %9.0f %9.0f %9.0f\n", B, i, 
             mp->mflop[0],mp->mflop[1],mp->mflop[2]);
      if (mp->mflop[iB] > mfB)
      {
         mfB = mp->mflop[iB];
         muB = nuB = i;
         bB = B;
         bcB = (iB != 1);
         kvecB = (iB == 2) ? 1 : 0;
      }
      fflush(stdout);
   }
   if (mp->genstr)
      free(mp->genstr);
   mp->genstr = NULL;
/*
 * Now, pump up mflop until the run takes 3 seconds or we can get 8 timings
 * in a row that are within 1.5% of each other
 */
   mp->mflop[0] = mfB;
   mp->mflop[1] = mp->mflop[2] = 0.0;
   mp->nu = nuB;
   mp->mbB = mp->nbB = mp->kbB = bB;
   if (kvecB)
   {
      mp->ku = VL;
      mp->mu = muB;
      mp->flag |= (1<<MMF_KVEC);
      mp->flag &= ~(1<<MMF_NOBCAST);
   }
   else
   {
      mp->ku = 1;
      mp->mu = muB * VL;
      mp->flag &= ~(1<<MMF_KVEC);
      if (bcB) 
         mp->flag &= ~(1<<MMF_NOBCAST);
      else
         mp->flag |= (1<<MMF_NOBCAST);
   }
/*
 * aim for a run that should take .08 sec if above timing was good
 *    (seconds / mflop) * nmfl = .08 -> nmflop = .08*mfB;
 */
   nmf = .08*mfB;
   if (nmf < 1.0)
      nmf = 1.0;
   while(1)
   {
      double mf0;
      int inmf = (int) nmf;
      tim = nmf/mfB;
      fprintf(stderr, "nmf=%d, pred time = %e seconds\n", inmf, 
              1.0/(nmf*mfB));
      if (tim >= 2.0)
         break;
      mf0 = TimeMMKernel(verb, 1, mp, pre, bB, bB, bB, 1, nmf, 0);
      printf("mf=%.0f:", mf0);
      for (i=0; i < 7; i++)
      {
         double spdup;
         mf = TimeMMKernel(verb, 1, mp, pre, bB, bB, bB, 1, mul, 0);
         spdup = mf*mf0;
         printf(" %.4f%c", mf/mf0, i==6?'.':',');
         if (mf > mf0*mbig || mf < mf0*msml)
            break;
      }
      printf("\n");
      fflush(stdout);
      if (i == 7)
         break;
      nmf *= 2.0;
   }
   printf("Final timing interval: %e seconds, nmflops=%.0f\n", tim, nmf);
   
   if(bf)
      sprintf(fn, "%cmflopsi_fko.frc", pre);
   else
      sprintf(fn, "%cmflops.frc", pre);
   fp = fopen(fn, "w");
   fprintf(fp, "%e", nmf);
   fclose(fp);
   KillMMNode(mp);
}
int DoTrmmLeft(char pre, int flag, int verb, int nrg)
{
   ATL_mmnode_t *mb, *mD, *pT;
   ATL_mmnode_t *mbn, *mbt;
   ATL_UINT KVEC, KB, NB, VL, i, flg, muB=1, nuB=1, flgB;
   double mfB = 0.0;
/*
 * FIXME: need to update timer to have correct timer data
 */
   mbn = TimeMMFileWithPath(pre, "res", "trmmL_LN.sum", 0, verb|1, 0, 1, 0, -1);
   mbt = TimeMMFileWithPath(pre, "res", "trmmL_LT.sum", 0, verb|1, 0, 1, 0, -1);
   if (mbn && mbt) /* generated either both or none for now */
   {
      KillAllMMNodes(mbn);
      KillAllMMNodes(mbt);
      return(0);
   }
/*
 * Should read in 5 kernels, we want only highest performing
 */
   mb = ReadMMFileWithPath(pre, "res", "ipmek.sum");
   if (!mb) return(0); /* no ipmek yet! */
   mD = FindMaxMflopMMQ(mb, 0);
   mb = RemoveMMNodeFromQ(mb, mD);
   KillAllMMNodes(mb);
/*
 * If mu already a multiple of nu (or vice versa), no need to search!
 */
   if (!(mD->mu % mD->ku) || !(mD->ku % mD->mu))
   {
      /*mD->blask = ATL_KTRMM; */
      WriteMMFileWithPath(pre, "res", "trmmL_LN.sum", mD);
      WriteMMFileWithPath(pre, "res", "trmmL_LT.sum", mD);
      KillMMNode(mD);
      return(0);
   }
/*
 * FIXME: need to write search for trmm... returning error now, 
 * will implement it later 
 */
   return(1);
}

int DoTrmmRight(char pre, int flag, int verb, int nrg)
{
   ATL_mmnode_t *mb, *mD, *pT;
   ATL_mmnode_t *mbn, *mbt;
   ATL_UINT KVEC, KB, NB, VL, i, flg, muB=1, nuB=1, flgB;
   double mfB = 0.0;
/*
 * FIXME: need to update timer to time
 */
   mbn = TimeMMFileWithPath(pre, "res", "trmmR_LN.sum", 0, verb|1, 0, 1, 0, -1);
   mbt = TimeMMFileWithPath(pre, "res", "trmmR_LT.sum", 0, verb|1, 0, 1, 0, -1);
   if (mbn && mbt) /* generated either both or none for now */
   {
      KillAllMMNodes(mbn);
      KillAllMMNodes(mbt);
      return(0);
   }
/*
 * Should read in 5 kernels, we want only highest performing
 */
   mb = ReadMMFileWithPath(pre, "res", "ipnek.sum");
   if (!mb) return(0); /* no ipnek yet! */
   mD = FindMaxMflopMMQ(mb, 0);
   mb = RemoveMMNodeFromQ(mb, mD);
   KillAllMMNodes(mb);
/*
 * If mu already a multiple of nu (or vice versa), no need to search!
 */
   if (!(mD->mu % mD->ku) || !(mD->ku % mD->mu))
   {
      /*mD->blask = ATL_KTRMM;*/
      WriteMMFileWithPath(pre, "res", "trmmR_LN.sum", mD);
      WriteMMFileWithPath(pre, "res", "trmmR_LT.sum", mD);
      KillMMNode(mD);
      return(0);
   }
/*
 * FIXME: need to write search for trmm... returning error now, 
 * will implement it later 
 */
   return(1);
}

static int AdjustForTRMM(char pre, int flag, ATL_mmnode_t *mp, ATL_mmnode_t *gd)
/*
 * Takes an amm kernel, and adjusts it for use as a TRMM.  We will do following:
 * Adjust ku: KVEC must use VLEN, otherwise number between 1-4 where U%ku==0
 * or ku%U == 0.  KRUNTIME is also forced, and it doesn't need KCLEAN.
 * if gd non-null, we also change mp's block factors to roughly match its.
 * RETURNS: old U (mu if flag&1, else nu)
 */
{
   const double mfR = mp->mflop[0];
   const unsigned int UU=(flag&1)?mp->mu:mp->nu;
   unsigned int U=UU, B;
/*
 * Make K-loop runtime
 */
   if (mp->ID)
   {
      int ln;
      char *s, *srmflg="-x assembler-with-cpp";
      mp->ID = 0;
      if (mp->rout)
         free(mp->rout);
      mp->rout = DupString("ATL_tmp.c");
/*
 *    removing all '-x assembler-with-cpp' from cflags
 */
      s = mp->cflags;
      if (s)
      {
         ln = strlen(srmflg);
         while(s=strstr(s,srmflg))
            memmove(s,s+ln,1+strlen(s+ln));
      }
   }
   mp->flag &= ~((1<<MMF_KUISKB)|(1<<MMF_KCLN));
   mp->flag |= 1<<MMF_KRUNTIME;
/*
 * For kvec kernel, KU is fixed, so we must adjust U
 */
   if (FLAG_IS_SET(mp->flag, MMF_KVEC))
   {
      const unsigned int ku = mp->vlen;
      unsigned int u, nreg=mp->mu*(mp->nu+1);

      mp->ku = ku;
      nreg += (mp->flag & (1<<MMF_BREG1)) ? 1 : mp->nu;
/*
 *    If U not multiple of ku, or vice versa, must adjust U
 */
      if ((U/ku)*ku != U && (ku/U)*U != ku)
      {
         if (U > ku) 
            U = (U/ku)*ku;
         else
            U = ku;
         if (flag&1) /* U == mu */
            mp->mu = U;
         else        /* U == nu */
            mp->nu = U;
      }
   }
   else  /* MVEC kernel can adjust both U and ku, but we just reduce ku */
   {
      unsigned int ku = Mmax(mp->ku,4);
      while ((U/ku)*ku != U)
         ku--;
      mp->ku = ku;
   }
   if (flag & 1)  /* Left, MB == KB */
   {
      unsigned int sz = mp->mbB * mp->kbB;
      U = Mylcm(mp->mu, mp->ku);
      for (B=U; B*B < sz; B += U) ;
      if (B*B > sz && B > U)
         B -= U;
      mp->mbB = mp->kbB = B;
      U = mp->nu;
      B = mp->nbB;
      mp->nbB = (B >= U) ? ((B/U)*U) : U;
   }
   else           /* Right, NB == KB */
   {
      unsigned int sz = mp->nbB * mp->kbB;
      U = Mylcm(mp->nu, mp->ku);
      for (B=U; B*B < sz; B += U) ;
      if (B*B > sz && B > U)
         B -= U;
      mp->nbB = mp->kbB = B;
      U = mp->mu;
      B = mp->mbB;
      mp->mbB = (B >= U) ? ((B/U)*U) : U;
   }
   if (mp->genstr)
      free(mp->genstr);
   mp->genstr = MMGetGenString(pre, mp);

   return(UU);
}

ATL_mmnode_t *srchTrmm(char pre, int flag, int verb, int nreg, 
                       int MB, int NB, ATL_mmnode_t *mmB)
/*
 * Assumes mmB is best-performing case found so far, MB, NB block factors of
 * original (unadapted) TRMM case.  Searches for all U that match ku.
 * RETURNS: (possibly new) mmB case (kills original mmB in this case).
 */
{
   ATL_mmnode_t *pM, *pK;
   const char *frm="    %c %4d %4d %3d %3d %9.0f\n";
   unsigned int MU, KU=mmB->ku, bf=mmB->flag;

   pM = MMGetNodeGEN(pre, bf&(~(1<<MMF_KVEC)), 0, 0, 0, 1, mmB->vlen,
                     0, 0, 0, DupString("ATL_tmp.c"));
   pM->ku = 1;
   pK = MMGetNodeGEN(pre, bf|(1<<MMF_KVEC), 0, 0, 0, mmB->vlen, mmB->vlen, 
                     mmB->vlen, 0, 0, DupString("ATL_tmp.c"));
   free(pM->genstr);
   free(pK->genstr);
   pK->ku = mmB->vlen;
   printf("Search for TRMM kernel for SD=%c, B=(%u,%u), NREG=%d, VLEN=%d\n",
          (flag&1) ? 'R':'L', MB, NB, nreg, mmB->vlen);
   printf("   VD   MB   NB  MU  NU     MFLOP\n");
   printf("   ==  ===  ===  ==  ==  =========\n");
   for (MU=1; MU < nreg; MU++)
   {
      unsigned int NU, mb, nb, kb;
      double mf;
      for (NU=1; NU < nreg; NU++)
      {
         if (MU*(NU+1)+1 > nreg)
            continue;
         if (MU*(NU+1)+NU > nreg)
         {
            pM->flag |= 1<<MMF_BREG1;
            pK->flag |= 1<<MMF_BREG1;
         }
         else
         {
            pM->flag &= ~(1<<MMF_BREG1);
            pK->flag &= ~(1<<MMF_BREG1);
         }
         pK->mu = MU;
         pM->mu = MU * pM->vlen;
         pK->nu = pM->nu = NU;
         pM->genstr = MMGetGenString(pre, pM);
         mb = (MB > MU) ? (MB/MU)*MU : MU;
         nb = (NB > NU) ? (NB/NU)*NU : NU;
         kb = (flag&1) ? mb:nb;
         /* assert(!MMKernelFailsTest(pre, mb, nb, kb, 1, pM)); */
         mf = TimeMMKernel(0, 0, pM, pre, mb, nb, kb, 1, 0, -1);
         printf(frm, 'M', mb, nb, MU, NU, mf);
         if (mf > mmB->mflop[0])
         {
            CopyMMNode(mmB, pM);
            mmB->mbB = mb;
            mmB->nbB = nb;
            mmB->kbB = kb;
            /* assert(!MMKernelFailsTest(pre, mb, nb, kb, 1, mmB)); */
            mmB->mflop[0] = mf;
         }
         free(pM->genstr);
         if (KU%MU == 0 || MU%KU == 0)
         {
            unsigned int U;
            if (flag&1)
            {
               U = Mylcm(MU, KU);
               mb = (MB > U) ? (MB/U)*U : U;
            }
            else
            {
               U = Mylcm(NU, KU);
               nb = (NB > U) ? (NB/U)*U : U;
            }
            kb = (flag&1) ? mb:nb;
            pK->genstr = MMGetGenString(pre, pK);
            mf = TimeMMKernel(0, 0, pK, pre, mb, nb, kb, 1, 0, -1);
            printf(frm, 'K', mb, nb, MU, NU, mf);
            if (mf > mmB->mflop[0])
            {
               CopyMMNode(mmB, pK);
               mmB->mbB = mb;
               mmB->nbB = nb;
               mmB->kbB = kb;
               /* assert(!MMKernelFailsTest(pre, mb, nb, kb, 1, mmB)); */
               mmB->mflop[0] = mf;
            }
            free(pK->genstr);
         }
      }
   }
   printf("BEST TRMM CASE:\n");
   PrintMMLine(stdout, mmB);
   assert(!MMKernelFailsTest(pre, mmB->mbB, mmB->nbB, mmB->kbB, 1, mmB));
/*
 * If best case was M-vectorized, try ku=2,3,4
 */
   if (!(mmB->flag & (1<<MMF_KVEC)))
   {
      const unsigned U = (flag&1) ? mmB->mu : mmB->nu;
      const unsigned B = (flag&1) ? mmB->mbB : mmB->nbB;
      unsigned int mb, nb;
      unsigned int ku;

      pK->genstr = NULL;
      printf("\nTUNING TRMM's KU:\n");
      CopyMMNode(pK, mmB);
      free(pK->genstr);
      for (ku=2; ku < 4; ku++)
      {
         double mf;
         if (U%ku || B%ku)
            continue;
         pK->ku = ku;
         pK->genstr = MMGetGenString(pre, pK);
         mf = TimeMMKernel(0, 0, pK, pre, pK->mbB, pK->nbB, pK->kbB, 1, 0, -1);
         printf("   KU=%d, mf=%.2f\n", ku, mf);
         if (mf > mmB->mflop[0])
         {
            CopyMMNode(mmB, pK);
            mmB->mflop[0] = mf;
         }
         free(pK->genstr);
      }
   }
   pK->genstr = pM->genstr = NULL;
   KillMMNode(pK);
   KillMMNode(pM);
   printf("BEST TRMM CASE:\n");
   PrintMMLine(stdout, mmB);
   printf("\n");
   return(mmB);
}

void DoTrmmS(char pre, int flag, int verb, int nreg)
{
   ATL_mmnode_t *bp, *mmB;
   unsigned int U, ku, MB, NB, KB;
   double mf0, mfB, mf;

   bp = TimeMMFileWithPath(pre,"res",(flag&1)?"trmmKLL.sum":"trmmKRL.sum", 
                           0, 0, 0, 1, 0, -1);
   if (bp)
   {
      WriteMMFileWithPath(pre,"res",(flag&1)?"trmmKLU.sum":"trmmKRU.sum", bp);
      WriteMMFileWithPath(pre,"res",(flag&1)?"trmmKLL.sum":"trmmKRL.sum", bp);
      KillAllMMNodes(bp);
      return;
   }
   bp = ReadMMFileWithPath(pre, "res", (flag&1)?"ipmek.sum":"ipnek.sum");
   if (!bp)
      return;
   printf("\nSEARCHING FOR TRMM KERNEL, SIDE=%c\n", (flag&1) ? 'L':'R');
   mmB = FindMaxMflopMMQ(bp, 0);
   KillAllMMNodes(RemoveMMNodeFromQ(bp, mmB));
   MB = mmB->mbB;
   NB = mmB->nbB;
   KB = mmB->kbB;
   U = (flag&1) ? mmB->mu : mmB->nu;
   ku = mmB->ku;
   mf0 = mmB->mflop[0];
   AdjustForTRMM(pre, flag, mmB, NULL);
/*
 * Adjust given kernel to allow it to use with TRMM, and see what perf we get
 */
   mf = TimeMMKernel(0, 0, mmB, pre, mmB->mbB, mmB->nbB, mmB->kbB, 1, 0,-1);
   printf("   AMM=%.2f, TRM=%.2f\n", mf0, mf);
   mfB = mmB->mflop[0] = mf;
/*
 * If performance drops significantly, try tuning a kernel specifically for TRMM
 */
   if (mf*1.035 < mf0)
   {
      ATL_mmnode_t *mp;
      unsigned int B, Ug;

      mmB->mflop[0] = mfB;
      bp = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
      assert(bp);
      mp = FindMaxMflopMMQ(bp, 0);
      KillAllMMNodes(RemoveMMNodeFromQ(bp, mp));
      Ug = (flag&1) ? mp->mu : mp->nu;
/*
 *    Set blocking factor to one found by [m,n]eqk
 */
      if (flag&1)  /* MB = KB */
      {
         Ug = Mylcm(mp->mu, mp->ku);
         assert(MB == KB);  /* sanity check for expected case */
         mp->kbB = (KB > Ug) ? ((KB)/Ug)*Ug : Ug;
         mp->mbB = mp->kbB;
         mp->nbB = (NB/mp->nu)*mp->nu;
      }
      else         /* NB = KB */
      {
         Ug = Mylcm(mp->nu, mp->ku);
         assert(NB == KB);  /* sanity check for expected case */
         mp->kbB = (KB > Ug) ? ((KB)/Ug)*Ug : Ug;
         mp->nbB = mp->kbB;
         mp->mbB = (MB > mp->mu) ? (MB/mp->mu)*mp->mu : mp->mu;
      }
/*
 *    If best generated kernel works w/o modification, simply use it unless
 *    its performance worse than adapted main kernel
 */
      if ((mp->flag&(1<<MMF_KRUNTIME)) && 
          ((Ug/ku)*ku == Ug || (ku/Ug)*Ug == ku))
      {
         mf = TimeMMKernel(0, 0, mp, pre, mp->mbB, mp->nbB, mp->kbB, 1, 0,-1);
         printf("   Using best generated case,\n      AMM=(%u,%u,%u) %.2f, "
                "TRM=(%u,%u,%u) %.2f\n", 
                MB, NB, KB, mf0, mp->mbB, mp->nbB, mp->kbB, mf);
         if (mf > mmB->mflop[0])
         {
            KillMMNode(mmB);
            mmB = mp;
            mp->mflop[0] = mfB = mf;
         }
         else
            KillMMNode(mp);
      }
      else
      {
         ATL_mmnode_t *gp;
         unsigned int NOSRCH;

         gp = CloneMMNode(mp);
         AdjustForTRMM(pre, flag, gp, NULL);
         mf = TimeMMKernel(0, 0, gp, pre, gp->mbB, gp->nbB, gp->kbB, 1, 0,-1);
         gp->mflop[0] = mf;
         if (mmB->mflop[0] >= mf)
            KillMMNode(gp);
         else
         {
            KillMMNode(mmB);
            mmB = gp;
         }
         printf("   Using adapted generated case,\n      AMM=(%u,%u,%u) %.2f, "
                "TRM=(%u,%u,%u) %.2f\n", 
                MB, NB, KB, mf0, mp->mbB, mp->nbB, mp->kbB, mf);
/*
 *       If we didn't change register blocking, just go with gAMMRES
 */
         NOSRCH = (flag&1) ? (mp->mu == gp->mu) : (mp->nu == gp->nu);
         KillMMNode(mp);
         if (!NOSRCH || mf*1.035 < mf0)
            mmB = srchTrmm(pre, flag, verb, nreg, mmB->mbB, mmB->nbB, mmB);
      }
   }
   if (!(flag&1))
      mmB->flag |= 1<<MMF_RIGHT;
   WriteMMFileWithPath(pre,"res",(flag&1)?"trmmKLL.sum":"trmmKRL.sum",mmB);
   WriteMMFileWithPath(pre,"res",(flag&1)?"trmmKLU.sum":"trmmKRU.sum",mmB);
   KillMMNode(mmB);
}

void DoTrmm(char pre, int flag, int verb, int nreg)
{
#if 1
   DoTrmmS(pre, 0, verb, nreg);
   DoTrmmS(pre, 1, verb, nreg);
#else
/*
 * FIXME: add make target to time trmm to record 
 * correct perf data
 */
   assert(!DoTrmmLeft(pre,flag,verb,nreg));
   assert(!DoTrmmRight(pre,flag,verb,nreg));
#endif
}
int main(int nargs, char **args)
{
   int flg, verb, nreg, VLEN, NB, TEST;
   char pre, upr;
   GetFlags(nargs, args, &flg, &verb, &pre, &nreg, &VLEN, &NB, &TEST);
   upr = pre;
   if (pre == 'z')
      upr = 'd';
   else if (pre == 'c')
      upr = 's';
   if (TEST)
      return(CountFails(TEST, flg, verb, pre, NB, nreg, VLEN));
   if (flg&8)
   {
      DoPrefOnList(flg, verb, pre, NB);
      return(0);
   }
   if (flg&16)
   {
      SetFlops(flg, verb, upr, VLEN);
      return(0);
   }
   FindInfo(flg, verb, upr, NB, &nreg, &VLEN);
   if (flg&4)     /* If I just wanted nreg calc */
      return(0);  /* then I'm done */
   DoBlock(pre, flg, verb);
   DoSyrkAmmUM(pre, flg, verb, nreg);
   DoSyrk(flg, verb, pre, nreg, NB, VLEN);
   DoTrmm(pre, flg, verb, nreg);
   return(0);
}
@ROUT ATL_ammmABC
#include "atlas_misc.h"
/*
 * This routine loops over calls to the access-major matmul kernel given
 * in the arguments, using the NMK loop pattern, using the given blocking
 * parameters.  
 * alpha & beta are both applied by ablk2cmat.
 * It allocates an K*NB workspace for B, and an Mc*K workspace for A,
 * and a NB*NB workspace for C.
 */

typedef void (*mat2am_t)
   (ATL_CINT, ATL_CINT, const SCALAR, const TYPE*, ATL_CINT, TYPE*);
typedef void (*ablk2cmat_t)
   (ATL_CINT M, ATL_CINT N, const SCALAR al, const TYPE*A, 
    const SCALAR beta, TYPE*C, ATL_CINT ldc);
typedef void (*ammm_t)
   (ATL_CINT M, ATL_CINT N, ATL_CINT K, TYPE *A, TYPE *B, TYPE *C);
int Mjoin(PATL,ammmABC)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CINT M,
   ATL_CINT N,
   ATL_CINT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CINT lda,
   const TYPE *B,
   ATL_CINT ldb,
   const SCALAR beta,
   const TYPE *C,
   ATL_CINT ldc,
   ATL_CINT MB,                 /* chosen M blocking for this problem */
   ATL_CINT NB,                 /* chosen N blocking for this problem */
   ATL_CINT KB,                 /* chosen K blocking for this problem */
   ATL_CINT mu,                 /* M unrolling used by kernels */
   ATL_CINT nu,                 /* N unrolling used by kernels */
   ATL_CINT ku,                 /* K unrolling used by non-cleanup kernels */
   ammm_t ammmk_b0,             /* amm beta=0 kernel to use */
   ammm_t ammmk_b1,             /* amm beta=1 kernel to use */
   ammm_t ammmk_ku1,            /* amm beta=1 for K-cleanup */
   mat2am_t A2am,               /* routine to translate A into access-major */
   mat2am_t B2am,               /* routine to translate B into access-major */
   ablk2cmat_t ablk2cmat,       /* put ammmk's C back to user's C */
)
{
   ATL_CINT Mf = (M/mu)*mu, mr = M-Mf, Nf = (N/nu)*nu, nr = N-Nf;
   ATL_CINT Kf = (K/ku)*ku, kr = K-Kf;
   ATL_CINT Mc = (mr) ? Mf + mr : Mf;  /* compute CEIL from FLOOR */
   ATL_CINT Nc = (nr) ? Nf + nr : Nf;
   ATL_CINT Kc = (kr) ? Kf + kr : Kf;
   ATL_CINT incBn = (TB == AtlasNoTrans) ldb*NB-Kf : NB-Kf*ldb;
   ATL_CINT incAm = (TA == AtlasNoTrans) ? MB - Kf*ldb : MB*ldb - Kf;
   ATL_INT i, j, k;
   void *vp;
   TYPE *pA, *pB, *c;
   int COPYA=1;

   if (K <= KB) 
      return(1);   /* don't handle rank-K update with this routine */
   vp = malloc(3*ATL_Cacchelen + sizeof(TYPE)*(Mc*K+K*NB+NB*NB));
   if (!vp)
      return(2);
   pB = ATL_AlignPtr(vp);
   pA = pB + K*NB;
   pA = ATL_AlignPtr(pA);
   c = pA + Mc*K;
   c = ATL_AlignPtr(c);

   for (j=0; j != Nc; j += NB)
   {
      ATL_CINT n = Mmin(NB, Nc-j), incb = n*nu*KB, n0 = Mmin(NB, N-j);
      int COPYB=1;
      TYPE *b = pB, *a = pA;

      for (i=0; i != Mc; i += MB)
      {
         ATL_CINT m = Mmin(MB, Mc-i), inca = m*mu*KB, m0 = Mmin(NB,M-j);

/* 
 *       Handle first block, known to always have a full KB, using _b0
 *       case to initialize workspace c
 */
         if (COPYA)
            A2am(m, KB, ATL_rone, A, lda, a);
         if (COPYB)
            B2am(KB, n, ATL_rone, B, ldb, b);
         ammmk_b0(m, n, KB, a, b, c);
         a += inca; b += incb;
/*
 *       Loop over all remaining blocks that can use ammmk_b1
 */
         for (k=KB; k < Kf; k += KB, a += inca, b += incb)
         {
            ATL_CINT kk = Mmin(KB, Kf-i);
/*
 *          If necessary, copy both A & B blocks to access-major format
 */
            if (COPYA)
            {
               A2am(m, kk, ATL_rone, A, lda, a);
               A += (TA == AtlasNoTrans) ? kk*lda : kk;
            }
            if (COPYB)
            {
               B2am(kk, n, ATL_rone, B, ldb, b);
               B += (TB == AtlasNoTrans) ? kk : kk*ldb;
            }
            ammmk_b1(m, n, kk, a, b, c);
         }
/*
 *       Handle K cleanup using the provided kernel
 */
         if (kr)
         {
            if (COPYA)
               A2am(m, kr, ATL_rone, A, lda, a);
            if (COPYB)
               B2am(kr, n, ATL_rone, B, ldb, b);
            ammmk_ku1(m, n, kr, a, b, c);
            a += kr*m;
         }
         A += incAm;
/*
 *       Write answer back out to user's C 
 */
         ablk2cmat(m0, n0, alpha, c, beta, C, ldc);
         C += m0;
         COPYB = 0;
         b = pB;
      }
      B += incBn;
      COPYA = 0;
   }
   free(vp);
   return(0);
}
@ROUT ATL_ammm_IP ATL_cammm_IP ATL_ammm_tN_old ATL_cammm_tN ATL_ammmMNK ATL_cammmMNK
   @define rt @Mjoin(PATL,ammm_IP)@
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(ATLAS_PRE,ipgen_view.h))
@ROUT ATL_ammm_IP ATL_cammm_IP
#include "atlas_cache.h"
#include Mstr(Mjoin(ATLAS_UPR,amm_kern.h))
/*
 * This routine handles M <= MAXM && N <= MAXN && very long K, or
 * the inner-product GEMM form.  It appears in the GEMM-based SYRK, which
 * is important for Cholesky.  It is typically the worst-case for ATLAS,
 * since the copy of A and B are of the same order as the computation.
 * It is a minimal workspace routine.
 */
@ROUT ATL_cammm_1b
#include "atlas_misc.h"
#include "atlas_amm.h"
#include "atlas_level1.h"
#include "atlas_lvl2.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
@ROUT ATL_ammm_1b ATL_ammmKNM
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
@ROUT ATL_ammm ATL_cammm
#include "atlas_misc.h"
#include "atlas_amm.h"
#include "atlas_lvl2.h"
#include "atlas_level1.h"
#include Mstr(Mjoin(ATLAS_PRE,opgen_view.h))
#include Mstr(Mjoin(ATLAS_PRE,ipgen_view.h))
   @define rt @Mjoin(PATL,ammm)@
@ROUT ATL_cammm_tN ATL_cammmMNK
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
#define MY_MAXMB ATL_rkAMM_LASTMB
#define MY_MAXNB ATL_rkAMM_LASTNB
@ROUT ATL_ammm_tN_old ATL_cammm_tN ATL_ammmMNK @\
      ATL_ammmKNM ATL_cammmMNK

#ifdef __GNUC__
static __inline__ int ATL_ComputeB   /* RETURNS: selected blocking */
#else
static int ATL_ComputeB           /* RETURNS: selected blocking */
#endif
(
   size_t N,   /* problem dimension */
   int nu,     /* unrolling by kernel on this dim */
   int nb,     /* IN: large-case blocking */
   size_t *NS, /* OUT: # of blks of size NB-nu to perform */
   size_t *NT  /* OUT: # of blks to perform */
)
{
   size_t ns, nt, nblks, NN;
/*
 * If the entire problem is less than or equal to the unrolling, choose a block
 * of the ceiling of the unrolling and only do one
 */
   NN=((N+nu-1)/nu)*nu;  /* ceiling of number of unrollings in N */
   if (NN <= nu)
   {
      *NS = 0;
      *NT = 1;
      return(NN);
   }
/*
 * If suggested block size is smaller or same as unrolling, then the blocking
 * size is the unrolling, and we don't have an NB-nu sized-blocks, since that
 * would be zero sized
 */
   if (nb <= nu)
   {
      *NS = 0;
      *NT = NN/nu;
      return(nu);
   }

   nb = (nb/nu)*nu;      /* floor of number of unrollings in a block*/
/*
 * If 1 block is within NU of covering the entire dim, just make the
 * block size the entire dim
 */
   if (nb+nu >= NN)
   {
      *NS = 0;
      *NT = 1;
      return(NN);
   }
/*
 * Otherwise, compute how many blocks we need  of each type
 */
   while(1)
   {
      nblks = (N+nb-1)/nb;
      ns = (nblks*nb - NN)/nu;
      if (ns < nblks)
         break;
      nb -= nu;
   }

   *NS = ns;
   *NT = nblks;
   return(nb);
}
@ROUT ATL_ammmKNM

static int ATL_ammm_rkK
(
   const size_t M,
   const size_t nmblks,
   const size_t nsmblks,
   const int MB,
   const int NMU,
   const int mu,
   const size_t N,
   const size_t nnblks,
   const size_t nsnblks,
   const int NB,
   const int NNU,
   const int nu,
   const int K,
   const int KK,
   const int ku,
   const TYPE *A,      /* pts to beginning of matrix */
   const size_t lda,
   const size_t incAm0,
   const size_t incAm,
   const TYPE *B,      /* pts to 1 past END of matrix */
   const size_t ldb,
   const size_t incBn0,
   const size_t incBn,
   TYPE *C,            /* pts to 1 past END of matrix */
   const size_t ldc,
   const SCALAR alpA, 
   const SCALAR alpB,
   const SCALAR beta,
   TYPE *pA,
   const size_t incAw0,
   const size_t incAw,
   TYPE *pB,
   TYPE *pC,
   const ammkern_t amm,
   const cm2am_t a2blk,
   const cm2am_t b2blk,
   const ablk2cmat_t blk2c
)
{
   size_t n, j;
   int mb, nb;
   TYPE *pA0=pA;

   n = N;
   for (n=N, j=0; j < nnblks; j++)
   {
      int nmu, mb, nnu, nb, nn;
      size_t i, m;
      TYPE *c;
      if (j < nsnblks)
      {
         nb = NB-nu;
         nnu = NNU-1;
         B -= incBn0;
      }
      else
      {
         nb = NB;
         nnu = NNU;
         B -= incBn;
      }
      nn = Mmin(n, nb);
      C -= nn*ldc;
      c=C;

      b2blk(K, nn, alpB, B, ldb, pB);

      mb = MB-mu;
      nmu = NMU-1;
      pA = pA0;
      for (m=M,i=0; i < nsmblks; i++, m -= mb, c += mb)
      {
         const int mm = Mmin(m, mb);
         TYPE *pAn = pA + incAw0;
         if (!j)
         {
            a2blk(K, mm, alpA, A, lda, pA);
            A += incAm0;
         }
         amm(nmu, nnu, KK, pA, pB, pC, pAn, pB, pC);
         blk2c(mm, nn, ATL_rone, pC, beta, c, ldc);
         pA = pAn;
      }

      for (mb=MB, nmu=NMU; i < nmblks; i++, m -= mb, c += mb)
      {
         const int mm = Mmin(m, mb);
         TYPE *pAn = pA + incAw;
         if (!j)
         {
            a2blk(K, mm, alpA, A, lda, pA);
            A += incAm;
         }
         amm(nmu, nnu, KK, pA, pB, pC, pAn, pB, pC);
         blk2c(mm, nn, ATL_rone, pC, beta, c, ldc);
         pA = pAn;
      }
      n -= nb;
   }
   return(0);
}

@ROUT ATL_ammmKNM
   @define rt @Mjoin(PATL,ammmKNM)@
/*
 * This routine called for very large matrices; requires workspace of
 * one panel and 2 blocks at most
 */
@ROUT ATL_ammmMNK ATL_cammmMNK
   @define rt @Mjoin(PATL,ammmMNK)@
/*
 * This routine called when N < M and K is large
 */
@ROUT ATL_ammm_1b ATL_cammm_1b
   @define rt @Mjoin(PATL,ammm_1b)@
/* 
 * This routine called in degenerate case where all dims less than max block,
 * so we can do entire operation with one kernel call
 */
@ROUT ATL_ammm ATL_cammm
#if 0
   #define USEREF 1
   #include "atlas_reflevel3.h"
#endif

static int ATL_ammm
@ROUT ATL_ammm_tN_old ATL_cammm_tN
/* 
 * This routine handles N <= MAXN, K & M large (left-looking shape)
 */
int Mjoin(PATL,ammm_tN)
@ROUT ATL_ammm_1b ATL_cammm_1b ATL_ammmMNK ATL_cammmMNK ATL_cammm_IP ATL_ammmKNM
int @(rt)
@ROUT ATL_ammm ATL_ammm_1b  ATL_cammm ATL_cammm_1b ATL_ammmMNK @\
      ATL_cammm_IP ATL_ammm_tN_old ATL_cammm_tN ATL_ammmKNM ATL_cammmMNK
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
@ROUT ATL_ammmMNK ATL_cammmMNK
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   size_t m, nsmblks, nmblks, nsnblks, nnblks, i, incAm0, incAm, incAw0;
   size_t nkb, incAk, incAk0, mulAm, incBk, incBk0, mulBn;
   int mu, nu, ku, MB, NB, KB, KB0, kb0, NMU, NNU, A_1TRIP;
   void *vp;
@ROUT ATL_ammmMNK
   TYPE *pC, *pB, *pB0, *pA, *pA0;
   ammkern_t ammK0, amm;
   const int B_BYCOLS = (TB == AtlasNoTrans);
   const int A_BYROWS = (TA == AtlasNoTrans);
   TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
@ROUT ATL_cammmMNK
   TYPE *rC, *iC, *iB, *pB0, *iA, *pA0;
   ammkern_t ammK0, ammK0_bn, ammK0_b1, amm_b1, amm_bn;
   const int B_BYCOLS = (TB == AtlasNoTrans || TB == AtlasConj);
   const int A_BYROWS = (TA == AtlasNoTrans || TA == AtlasConj);
   const TYPE ONE[2] = {ATL_rone, ATL_rzero};
   const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
@ROUT ATL_ammmMNK ATL_cammmMNK
   amminfo_t mminfo;

   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else 
      alpC = alpha;
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
@ROUT ATL_cammmMNK
   MB = ATL_ComputeB(M, mu, MY_MAXMB, &nsmblks, &nmblks);
   NMU = MB / mu;
   NB = ATL_ComputeB(N, nu, MY_MAXNB, &nsnblks, &nnblks);
@ROUT ATL_ammmMNK
   MB = ATL_ComputeB(M, mu, ATL_geAMM_LASTMB, &nsmblks, &nmblks);
   NMU = MB / mu;
   NB = ATL_ComputeB(N, nu, ATL_geAMM_LASTNB, &nsnblks, &nnblks);
@ROUT ATL_ammmMNK ATL_cammmMNK
   NNU = NB / nu;
   KB = mminfo.kb;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0 = mminfo.amm_b0;
         else
            ammK0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && kb0 == (kb0/ku)*ku &&
          kb0 > mminfo.kbmin)
         ammK0 = mminfo.amm_b0;
   }
@ROUT ATL_ammmMNK
   amm = mminfo.amm_b1;
@ROUT ATL_cammmMNK
   if (ammK0 == mminfo.amm_b0)
   {
      amm_b1 = ammK0_b1 = mminfo.amm_b1;
      amm_bn = ammK0_bn = mminfo.amm_bn;
   }
   else
   {
      ammK0_b1 = mminfo.amm_k1_b1;
      ammK0_bn = mminfo.amm_k1_bn;
      amm_b1 = mminfo.amm_b1;
      amm_bn = mminfo.amm_bn;
   }
@ROUT ATL_ammmMNK ATL_cammmMNK
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;
   i = nkb*KB+KB0;
/*
 * Determine worspace requirements and allocate
 */
   {
      size_t tsz;
      const size_t szA=MB*i;
      const size_t szB=i*(nsnblks*(NB-nu)+(nnblks-nsnblks)*NB);
      const int szC = MB*NB;

      tsz = ATL_MulBySize(szA + szB + szC + mu*nu*ku) + 3*ATL_Cachelen;
      if (tsz > ATL_MaxMalloc)
         return(2);
      vp = malloc(tsz);
      if (!vp)
         return(1);
@ROUT ATL_ammmMNK
      pC = ATL_AlignPtr(vp);
      pA = pC + szC;
      pA0 = pA = ATL_AlignPtr(pA);
      pB = pA + szA;
      pB0 = pB = ATL_AlignPtr(pB);
@ROUT ATL_cammmMNK
      iC = ATL_AlignPtr(vp);
      rC = iC + szC;
      iA = rC + szC;
      pA0 = iA = ATL_AlignPtr(iA);
      iB = iA + szA + szA;
      pB0 = iB = ATL_AlignPtr(iB);
@ROUT ATL_ammmMNK ATL_cammmMNK
   }
   if (A_BYROWS)
   {
      incAk = KB*(lda SHIFT);
      incAk0 = kb0*(lda SHIFT);
      mulAm = 1 SHIFT;
   }
   else
   {
      incAk = KB SHIFT;
      incAk0 = kb0 SHIFT;
      mulAm = lda SHIFT;
   }
   if (B_BYCOLS)
   {
      incBk = KB SHIFT;
      incBk0 = kb0 SHIFT;
      mulBn = ldb SHIFT;
   }
   else
   {
      incBk = (KB SHIFT)*ldb;
      incBk0 = kb0*(ldb SHIFT);
      mulBn = 1 SHIFT;
   }

   for (m=M, i=0; i < nmblks; i++)
   {
      size_t j, n;
      int mb, mm, nmu, incAw, incAw0;
      TYPE *c=C;
      if (i < nsmblks)
      {
         mb = MB-mu;
         nmu = NMU-1;
      }
      else
      {
         mb = MB;
         nmu = NMU;
      }
      mm = Mmin(m, mb);  /* number of A/C rows left */
      m -= mm;
      incAw = mb*KB;
      incAw0 = mb*KB0;
      for (n=N, j=0; j < nnblks; j++)
      {
         size_t k;
@ROUT ATL_ammmMNK
         int nb, nn, nnu, incBw;
         const TYPE *b=B, *a=A; 
         TYPE *pAn, *pBn;
@ROUT ATL_cammmMNK
         int nb, nn, nnu, incBw, incBw0;
         const TYPE *b=B, *a=A; 
         TYPE *pAn, *pBn, *rA, *rB;
@ROUT ATL_ammmMNK ATL_cammmMNK

         if (j < nsnblks)
         {
            nb = NB-nu;
            nnu = NNU-1;
         }
         else
         {
            nb = NB;
            nnu = NNU;
         }
         incBw = KB*nb;
         nn = Mmin(n, nb);  /* number of B/C cols left */
         n -= nn;
@ROUT ATL_ammmMNK
         if (!j)
         {
            a2blk(kb0, mm, alpA, a, lda, pA);
            a += incAk0;
         }
         if (!i)
         {
             b2blk(kb0, nn, alpB, b, ldb, pB);
             b += incBk0;
         }
         pAn = pA + incAw0;
         pAn = (nkb) ? pAn : pA0;
         pBn = pB + KB0*nb;
         ammK0(nmu, nnu, KB0, pA, pB, pC, pAn, pBn, pC);
         pA = pAn;
         pB = pBn;
         for (k=0; k < nkb; k++)
         {
            if (!j)
            {
               a2blk(KB, mm, alpA, a, lda, pA);
               a += incAk;
            }
            if (!i)
            {
                b2blk(KB, nn, alpB, b, ldb, pB);
                b += incBk;
            }
            pAn = pA + incAw;
            pAn = (k != nkb-1) ? pAn : pA0;
            pBn = pB + incBw;
            pBn = (k != nkb-1 || j != nnblks-1) ? pBn : pB0;
            amm(nmu, nnu, KB, pA, pB, pC, pAn, pBn, pC);
            pA = pAn;
            pB = pBn;
         }
         blk2c(mm, nn, alpC, pC, beta, c, ldc);
         c += nn*(ldc SHIFT);
         B += nn*mulBn;
      }
      pB = pB0;
      A += mm*mulAm;
      C += mm;
   }
@ROUT ATL_cammmMNK
         incBw0 = KB0*nb;

         rA = iA + incAw0;
         pAn = rA + incAw0;
         pAn = (nkb) ? pAn : pA0;
         rB = iB + incBw0;
         pBn = rB + incBw0;
         if (!j)
         {
            a2blk(kb0, mm, alpA, a, lda, rA, iA);
            a += incAk0;
         }
         if (!i)
         {
             b2blk(kb0, nn, alpB, b, ldb, rB, iB);
             b += incBk0;
         }
         ammK0(nmu, nnu, KB0, iA, iB, rC, rA, iB, iC);
         ammK0(nmu, nnu, KB0, rA, iB, iC, rA, rB, rC);
         ammK0_bn(nmu, nnu, KB0, rA, rB, rC, iA, rB, iC);
         ammK0_b1(nmu, nnu, KB0, iA, rB, iC, pAn, pBn, rC);
         iA = pAn;
         iB = pBn;
         for (k=0; k < nkb; k++)
         {
            rA = iA + incAw;
            rB = iB + incBw;
            if (!j)
            {
               a2blk(KB, mm, alpA, a, lda, rA, iA);
               a += incAk;
            }
            if (!i)
            {
                b2blk(KB, nn, alpB, b, ldb, rB, iB);
                b += incBk;
            }
            pAn = rA + incAw;
            pAn = (k != nkb-1) ? pAn : pA0;
            pBn = rB + incBw;
            pBn = (k != nkb-1 || j != nnblks-1) ? pBn : pB0;
            amm_bn(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
            amm_b1(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
            amm_bn(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
            amm_b1(nmu, nnu, KB, iA, rB, iC, pAn, pBn, rC);
            iA = pAn;
            iB = pBn;
         }
         blk2c(mm, nn, alpC, rC, iC, beta, c, ldc);
         c += nn*(ldc SHIFT);
         B += nn*mulBn;
      }
      iB = pB0;
      A += mm*mulAm;
      C += mm SHIFT;
   }
@ROUT ATL_ammmMNK ATL_cammmMNK

   free(vp);
   return(0);
}
@ROUT ATL_ammmKNM
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   size_t n, nsmblks, nmblks, nsnblks, nnblks, j, incAm0, incAm, incAw0, incAw;
   size_t KK, incAk, incBk, incBn0, incBn, k;
   int mu, nu, ku, MB, NB, KB, mb, nb, NMU, NNU, A_1TRIP, nkb, kb0, KB0;
   void *vp;
   TYPE *pC, *pB, *pA, *pA0;
   ammkern_t ammK0, amm;
   const int B_BYCOLS = (TB == AtlasNoTrans);
   const int A_BYROWS = (TA == AtlasNoTrans);
   TYPE alpA=ATL_rone, alpB=ATL_rone;
   amminfo_t mminfo;

@skip   ATL_assert(N > ATL_AMM_MAXNB & M > ATL_AMM_MAXMB & K > ATL_AMM_MAXKB);
   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else
      alpB = alpha;
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   MB = ATL_ComputeB(M, mu, ATL_geAMM_LASTMB, &nsmblks, &nmblks);
   NMU = MB / mu;
   NB = ATL_ComputeB(N, nu, ATL_geAMM_LASTMB, &nsnblks, &nnblks);
   NNU = NB / nu;
   A_1TRIP = (nnblks < 2);
   KB = mminfo.kb;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0 = mminfo.amm_b0;
         else
            ammK0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && kb0 == (kb0/ku)*ku &&
          kb0 > mminfo.kbmin)
         ammK0 = mminfo.amm_b0;
   }
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;
   KK = nkb*KB + KB0;
/*
 * Do memory allocation, setup pointers
 */
   {
      size_t tsz, szA;
      const int szB = NB*KB, szC = MB*NB;

      if (A_1TRIP)
         szA = KB*MB;
      else
         szA = (nsmblks*(MB-mu)+(nmblks-nsmblks)*MB)*KB;
      tsz = ATL_MulBySize(szA + szB + szC + mu*nu*ku) + 3*ATL_Cachelen;
      if (tsz > ATL_MaxMalloc)
         return(2);
      vp = malloc(tsz);
      if (!vp)
         return(1);
      pC = ATL_AlignPtr(vp);
      pB = pC + szC;
      pB = ATL_AlignPtr(pB);
      pA = pB + szB;
      pA = ATL_AlignPtr(pA);
   }

   if (A_BYROWS)
   {
      incAm0 = (MB-mu);
      incAm = MB;
      incAk = KB*lda;
   }
   else
   {
      incAm0 = (MB-mu)*lda;
      incAm = MB*lda;
      incAk = KB;
   }
   if (B_BYCOLS)
   {
      incBn0 = (NB-nu)*ldb;
      incBn = NB*ldb;
   }
   else
   {
      incBn0 = (NB-nu);
      incBn = NB;
   }
   if (A_1TRIP)
      incAw0 = incAw = 0;
   else
   {
      incAw0 = (MB-mu)*KB0;
      incAw = MB*KB0;
   }

   C += N*ldc;
   j = (nnblks-nsnblks)*NB + nsnblks*(NB-nu);
   if (B_BYCOLS)
   {
      B += j*ldb;
      incBk = KB;
   }
   else
   {
      B += j;
      incBk = KB*ldb;
   }
/*
 * Handle remainder/full block using the actual beta; all remaining K blks
 * will be of size KB after this
 */
   ATL_ammm_rkK(M, nmblks, nsmblks, MB, NMU, mu, N, nnblks, nsnblks, NB,
                NNU, nu, kb0, KB0, ku, A, lda, incAm0, incAm, B, ldb, 
                incBn0, incBn, C, ldc, alpA, alpB, beta, pA, incAw0, incAw, 
                pB, pC, ammK0, a2blk, b2blk, blk2c);
   B += (B_BYCOLS) ? kb0 : kb0*ldb;
   A += (A_BYROWS) ? kb0*lda : kb0;
/* 
 * If A workspace is entire panel, must now base increment on full KB
 */
   if (!A_1TRIP && KB0 != KB)
   {
      incAw0 = (MB-mu)*KB;
      incAw = MB*KB;
   }
/*
 * Loop over all remaining blocks using beta=1 and full KB
 * ALSO: need to change blk2c if it is bn!
 */
   amm = mminfo.amm_b0;
   for (k=0; k < nkb; k++, B += incBk, A += incAk)
      ATL_ammm_rkK(M, nmblks, nsmblks, MB, NMU, mu, N, nnblks, nsnblks, NB,
                   NNU, nu, KB, KB, ku, A, lda, incAm0, incAm, B, ldb, 
                   incBn0, incBn, C, ldc, alpA, alpB, ATL_rone, 
                   pA, incAw0, incAw, pB, pC, amm, a2blk, b2blk, blk2c);
   free(vp);
   return(0);
}
@ROUT ATL_aliased_rkK
#include "atlas_misc.h"
#include "atlas_amm.h"
#include "atlas_level1.h"
#include "atlas_lvl2.h"

static void *FixVector(enum ATLAS_TRANS TX, ATL_CSZT N, const SCALAR alpha,
                       const TYPE *X, ATL_CSZT incX)
{
   void *vx;
   TYPE *x;
   vx = malloc(ATL_MulBySize(N)+ATL_Cachelen);
   ATL_assert(vx);
   x = ATL_AlignPtr(vx);
   #ifndef TCPLX
      if (SCALAR_IS_ONE(alpha))
         Mjoin(PATL,copy)(N, X, incX, x, 1);
      else
         Mjoin(PATL,cpsc)(N, alpha, X, incX, x, 1);
   #else
      if (SCALAR_IS_ONE(alpha))
      {
         if (TX == AtlasTrans || TX == AtlasNoTrans)
            Mjoin(PATL,copy)(N, X, incX, x, 1);
         else
            Mjoin(PATL,copyConj)(N, X, incX, x, 1);
      }
      else
      {
         if (TX == AtlasTrans || TX == AtlasNoTrans)
            Mjoin(PATL,cpsc)(N, alpha, X, incX, x, 1);
         else
            Mjoin(PATL,moveConj)(N, alpha, X, incX, x, 1);
      }
   #endif
   return(vx);
}

/*
 * This entry makes rkK safe for L3kernel aliased calls.  It handles
 * only the aliasing required by the L3kernels, namely square blocks
 * less than ATLAS's largest blocking factor for the square dimensions,
 * with one of A/B aliased with C, and aliased by having
 * either A == C or B == C (i.e., not a partial overlap).  When A==C, 
 * M=K < ATL_rkAMM_LASTKB; when B==C, N=K < ATL_rkAMM_LASTKB.
 */
int Mjoin(PATL,ammm_aliased_rkK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alp,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef TCPLX
      const TYPE ONE[2] = {ATL_rone, ATL_rzero};
   #else
      #define ONE ATL_rone
   #endif
   void *vp=NULL;

   if (K == 0 || SCALAR_IS_ZERO(alp))
   {
      if (SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gezero)(M, N, C, ldc);
      else if (!SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gescal)(M, N, beta, C, ldc);
      return(0);
   }
   if (K == 1)
   {
      #ifdef TCPLX
         const SCALAR alpha = alp;
      #else
         TYPE alpha = alp;
      #endif
      void *xp=NULL, *yp=NULL;
      TYPE *a = (TYPE*)A, *b = (TYPE*)B;
      size_t ldA=lda, ldB=ldb;

      if (A == C)
      {
         xp = FixVector(TA, M, alpha, A, 
                        (TA == AtlasTrans || TA == AtlasConjTrans) ? lda:1);
         a = ATL_AlignPtr(xp);
         alpha = ONE;
         if (TA == AtlasConjTrans || TA == AtlasTrans)
         {
            TA = AtlasTrans;
            ldA = 1;
         }
         else if (TA == AtlasConj)
            TA = AtlasNoTrans;
      }
      if (B == C)
      {
         yp = FixVector(TB, N, alpha, B, 
                        (TB == AtlasTrans || TB == AtlasConjTrans) ? 1:ldb);
         b = ATL_AlignPtr(yp);
         alpha = ONE;
         if (TB == AtlasConjTrans)
            TB = AtlasTrans;
         else if (TB == AtlasConj || TB == AtlasNoTrans)
         {
            TA = AtlasNoTrans;
            ldB = 1;
         }
      }
      Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, a, ldA, b, ldB, beta, C, ldc);
      if (xp)
         free(xp);
      if (yp)
         free(yp);
      return(0);
   }

   if (K == 2)
   {
      #ifdef TCPLX
         const SCALAR alpha = alp;
      #else
         TYPE alpha = alp;
      #endif
/*
 *    If BETA != 1, ammm_rk2 will copy all inputs and thus aliasing safe
 */
      if (!SCALAR_IS_ONE(beta))
         Mjoin(PATL,ammm_rk2)(TA, TB, M, N, alpha, A, lda, B, ldb, beta, 
                              C, ldc);
/*
 *    For beta = 1, copy aliased input array(s) and then call GER2
 */
      else
      {
         void *wp=NULL, *xp=NULL, *yp=NULL, *zp=NULL;
         TYPE *w, *x, *y, *z;
         ATL_SZT incX, incY;
      #ifndef TCPLX
         if (A == C)
         {
            ATL_CSZT incx = (TA == AtlasTrans) ? lda:1;
      #else
         if (A == C || TA == AtlasConjTrans || TA == AtlasConj)
         {
            ATL_CSZT incx = (TA == AtlasTrans || TA == AtlasConjTrans) ? lda:1;
      #endif
            wp = FixVector(TA, M, alpha, A, incx);
            xp = FixVector(TA, M, alpha, A+((incx==1 ? lda:1)SHIFT), incx);
            alpha = ONE;
            w = ATL_AlignPtr(wp);
            incX = 1;
         }
         else  /* don't need to copy A */
         {
            w = (TYPE*)A;
            if (TA == AtlasNoTrans)
            {
               x = (TYPE*)(A + (lda SHIFT));
               incX = 1;
            }
            else /* if (TA == AtlasTrans) */
            {
               x = (TYPE*)(A + (1 SHIFT));
               incX = lda;
            }
         }
         if (B == C)
         {
            ATL_CSZT incy = (TB == AtlasTrans || TB == AtlasConjTrans) ? 1:ldb;
            yp = FixVector(TB, N, alpha, A, incy);
            zp = FixVector(TB, N, alpha, A+(((incy==1)?ldb:1)SHIFT), incy);
            y = ATL_AlignPtr(yp);
            z = ATL_AlignPtr(zp);
         #ifdef TCPLX
            if (TB == AtlasConj)
               TB = AtlasNoTrans;
            else if (TB == AtlasConjTrans)
               TB = AtlasTrans;
         #endif
            incY = 1;
            alpha = ONE;
         
         }
         else  /* no need to copy B */
         {
            y = (TYPE*)B;
         #ifdef TCPLX
            if (TB == AtlasNoTrans || TB == AtlasConj)
         #else
            if (TB == AtlasNoTrans)
         #endif
            {
               incY = ldb;
               z = (TYPE*)(B + (1 SHIFT));
            }
            else
            {
               incY = 1;
               z = (TYPE*)(B + (ldb SHIFT));
            }
         }
         #ifndef TCPLX
            Mjoin(PATL,ger2)(M, N, alpha, w, incX, y, incY, ONE, 
                             x, incX, z, incY, C, ldc);
         #else
            if (TB == AtlasNoTrans || TB == AtlasTrans)
               Mjoin(PATL,ger2u)(M, N, alpha, w, incX, y, incY, ONE, 
                                 x, incX, z, incY, C, ldc);
            else
               Mjoin(PATL,ger2c)(M, N, alpha, w, incX, y, incY, ONE, 
                                 x, incX, z, incY, C, ldc);
         #endif
         if (wp)
            free(wp);
         if (xp)
            free(xp);
         if (yp)
            free(yp);
         if (zp)
            free(zp);
         return(0);
      }
      return(0);
   }
/*
 * For K > 3, ATL_ammm_rkK is safe for these precise aliasing conditions
 */
   ATL_assert(!Mjoin(PATL,ammm_rkK)(TA, TB, M, N, K, alp, A, lda, B, ldb, 
                                    beta, C, ldc));
   return(0);
@beginskip
   if (K < 3)
   {
      lda = (TA == AtlasNoTrans || TA == AtlasConj) ? M:K;
      ldb = (TB == AtlasNoTrans || TB == AtlasConj) ? K:N;
      a = malloc(ATL_MulBySize((M+N)*K));
      ATL_assert(a);
      b = a + ((M*K)SHIFT);
      if (lda == M)
         Mjoin(PATL,gecopy)(M, K, A, ldA, a, lda);
      else
         Mjoin(PATL,gecopy)(K, M, A, ldA, a, lda);
      if (ldb == K)
         Mjoin(PATL,gecopy)(K, N, B, ldB, b, ldb);
      else
         Mjoin(PATL,gecopy)(N, K, B, ldB, b, ldb);
   }
   ATL_assert(!Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, a, lda, b, ldb, 
              beta, C, ldc));
   if (a != A)
      free(a);
@endskip
}
@ROUT ATL_ammm_tN
#include "atlas_amm.h"
/* 
 * This routine handles N <= MAXN, K & M large (left-looking shape)
 */
int Mjoin(PATL,ammm_tN)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   size_t szB, szC;
   TYPE *a, *b, *c;
   void *vp;
   int idx;
   ipinfo_t ip;


   Mjoin(PATL,ipgenInfo)(&ip, 2, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta);
   szC = ip.szC;
   szB = ip.pszB*ip.npnblks + ip.szB*ip.nfnblks;
   szB = ip.szB*(ip.nfkblks+1);
   vp = malloc(ATL_MulBySize(szC+ip.szA+szB+ip.exsz) + 3*ATL_Cachelen);
   if (!vp)
      return(1);
   a = ATL_AlignPtr(vp);
   b = a + (ip.szA SHIFT);
   b = ATL_AlignPtr(b);
   c = b + (szB SHIFT);
   c = ATL_AlignPtr(c);
   Mjoin(PATL,iploopsMK)(&ip, 0, 0, A, B, C, 2, a, b,
   #ifdef TCPLX
                         c+szC, c, beta, ip.blk2c);
   #else
                         c, c, beta, ip.blk2c);
   #endif

   free(vp);
   return(0);
}
@ROUT ATL_ammm_tN_old
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   ammkern_t ammK0, amm;
   amminfo_t mminfo;
   TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   TYPE *pA, *pB0, *pB, *pC;
   int mu, nu, ku, nnu, NN, MB, NMU, KB, KB0, kb0, incBw, incBw0;
   size_t incAk0, incAk, mulAm, incBk0, incBk, nkb, k, nmblks, nsmblks, i, m;
   void *vp;

   ATL_assert(N <= ATL_geAMM_LASTNB);
   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   MB = ATL_ComputeB(M, mu, ATL_geAMM_LASTMB, &nsmblks, &nmblks);
   NMU = MB / mu;
   nnu = (N+nu-1)/nu;
   KB = mminfo.kb;
   NN = nnu * nu;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0 = mminfo.amm_b0;
         else
            ammK0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && kb0 == (kb0/ku)*ku &&
          kb0 > mminfo.kbmin)
         ammK0 = mminfo.amm_b0;
   }
   amm = mminfo.amm_b1;
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;

/*
 * Do memory allocation, setup pointers
 */
   {
      const int szA = MB*KB, szC=MB*NN; 
      size_t szB = (nkb*KB+KB0)*NN;
      const size_t tsz = ATL_MulBySize(szA+szB+szC+mu*nu*ku) + 3*ATL_Cachelen;
      if (tsz > ATL_MaxMalloc)
         return(2);
      vp = malloc(tsz);
      if (!vp)
         return(1);
      pA = ATL_AlignPtr(vp);
      pB = pA + szA;
      pB0 = pB = ATL_AlignPtr(pB);
      pC = pB + szB;
      pC = ATL_AlignPtr(pC);
   }
   if (TA == AtlasNoTrans)
   {
      incAk = lda*KB;
      incAk0 = lda*kb0;
      mulAm = 1;
   }
   else
   {
      incAk = KB;
      incAk0 = kb0;
      mulAm = lda;
   }
   if (TB == AtlasNoTrans)
   {
      incBk = KB;
      incBk0 = kb0;
   }
   else
   {
      incBk = KB*ldb;
      incBk0 = kb0*ldb;
   }
   if (nkb)
   {
      incBw0 = KB0*NN;
      if (nkb > 1)
         incBw = KB*NN;
      else incBw = 0;
   }
   else 
      incBw = incBw0 = 0;
   for (m=M,i=0; i < nmblks; i++)
   {
      const TYPE *An;
      TYPE *pBn;
      int mb, nmu, mm;

      if (i < nsmblks)
      {
         mb = MB-mu;
         nmu = NMU-1;
      }
      else
      {
         mb = MB;
         nmu = NMU;
      }
      mm = Mmin(m, mb);
      m -= mm;
      An = A + mm*mulAm;
/*
 *    Do first (possibly partial) K-block
 */
      a2blk(kb0, mm, alpA, A, lda, pA);
      A += incAk0;
      if (!i)
      {
         b2blk(kb0, N, alpB, B, ldb, pB);
         B += incBk0;
      }
      pBn = pB + incBw0;
      ammK0(nmu, nnu, KB0, pA, pB, pC, pA, pBn, pC);
      pB = pBn;
/*
 *    Loop over all full-sized blocks
 */
      for (k=0; k < nkb; k++)
      {
         a2blk(KB, mm, alpA, A, lda, pA);
         A += incAk;
         if (!i)
         {
            b2blk(KB, N, alpB, B, ldb, pB);
            B += incBk;
         }
         pBn = (k < nkb-1) ? pB+incBw : pB0;
         amm(nmu, nnu, KB, pA, pB, pC, pA, pBn, pC);
         pB = pBn;
      }
      blk2c(mm, N, alpC, pC, beta, C, ldc);
      C += mm;
      A = An;
   }

   free(vp);
   return(0);
}
@ROUT ATL_cammm_tN
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   ammkern_t ammK0_b0, ammK0_b1, ammK0_bn, amm_b1, amm_bn;
   amminfo_t mminfo;
   const TYPE ONE[2] = {ATL_rone, ATL_rzero};
   const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
   TYPE *rA, *iA, *pB0, *rC, *iC;
   int mu, nu, ku, nnu, NN, MB, NMU, KB, KB0, kb0, incBw, incBw0;
   size_t incAk0, incAk, mulAm, incBk0, incBk, nkb, k, nmblks, nsmblks, i, m;
   void *vp;

   ATL_assert(N <= ATL_geAMM_LASTNB);
   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   MB = ATL_ComputeB(M, mu, MY_MAXMB, &nsmblks, &nmblks);
   NMU = MB / mu;
   nnu = (N+nu-1)/nu;
   KB = mminfo.kb;
   NN = nnu * nu;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0_b0 = mminfo.amm_b0;
         else
            ammK0_b0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0_b0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && (kb0/ku)*ku == kb0 &&
          kb0 > mminfo.kbmin)
         ammK0_b0 = mminfo.amm_b0;
   }
   amm_b1 = mminfo.amm_b1;
   amm_bn = mminfo.amm_bn;
   if (ammK0_b0 == mminfo.amm_b0)
   {
      ammK0_b1 = mminfo.amm_b1;
      ammK0_bn = mminfo.amm_bn;
   }
   else
   {
      ammK0_b1 = mminfo.amm_k1_b1;
      ammK0_bn = mminfo.amm_k1_bn;
   }
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;

/*
 * Do memory allocation, setup pointers
 */
   {
      const int szA = MB*KB, szC=MB*NN; 
      size_t szB = (nkb*KB+KB0)*NN;
      const size_t tsz = ATL_MulBySize(szA+szB+szC+mu*nu*ku) + 3*ATL_Cachelen;
      if (tsz > ATL_MaxMalloc)
         return(2);
      vp = malloc(tsz);
      if (!vp)
         return(1);
      iA = ATL_AlignPtr(vp);
      rA = iA + szA;
      iC = rA + szA;
      iC = ATL_AlignPtr(iC);
      rC = iC + szC;
      pB0 = rC + szC;
      pB0 = ATL_AlignPtr(pB0);
   }
   if (TA == AtlasNoTrans)
   {
      incAk = (lda*KB)SHIFT;
      incAk0 = (lda*kb0)SHIFT;
      mulAm = 2;
   }
   else
   {
      incAk = KB SHIFT;
      incAk0 = kb0 SHIFT;
      mulAm = lda SHIFT;
   }
   if (TB == AtlasNoTrans)
   {
      incBk = KB SHIFT;
      incBk0 = kb0 SHIFT;
   }
   else
   {
      incBk = (KB*ldb)SHIFT;
      incBk0 = (kb0*ldb)SHIFT;
   }
   incBw0 = KB0*NN;
   incBw = KB*NN;
   for (m=M,i=0; i < nmblks; i++)
   {
      const TYPE *An;
      TYPE *iB=pB0, *rB=pB0+incBw0, *pBn=rB+incBw0;
      int mb, nmu, mm;

      if (i < nsmblks)
      {
         mb = MB-mu;
         nmu = NMU-1;
      }
      else
      {
         mb = MB;
         nmu = NMU;
      }
      mm = Mmin(m, mb);
      m -= mm;
      An = A + mm*mulAm;
/*
 *    Do first (possibly partial) K-block
 */
      a2blk(kb0, mm, alpA, A, lda, rA, iA);
      A += incAk0;
      if (!i)
      {
         b2blk(kb0, N, alpB, B, ldb, rB, iB);
         B += incBk0;
      }
      rB = iB + incBw0;
      pBn = rB + incBw0;
      ammK0_b0(nmu, nnu, KB0, iA, iB, rC, rA, iB, iC);
      ammK0_b0(nmu, nnu, KB0, rA, iB, iC, rA, rB, rC);
      ammK0_bn(nmu, nnu, KB0, rA, rB, rC, iA, rB, iC);
      ammK0_b1(nmu, nnu, KB0, iA, rB, iC, rA, pBn, iC);
      iB = pBn;
/*
 *    Loop over all full-sized blocks
 */
      for (k=0; k < nkb; k++)
      {
         a2blk(KB, mm, alpA, A, lda, rA, iA);
         A += incAk;
         rB = iB + incBw;
         if (!i)
         {
            b2blk(KB, N, alpB, B, ldb, rB, iB);
            B += incBk;
         }
         pBn = (k < nkb-1) ? rB+incBw : pB0;
         amm_bn(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
         amm_b1(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
         amm_bn(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
         amm_b1(nmu, nnu, KB, iA, rB, iC, rA, pBn, iC);
         iB = pBn;
      }
      blk2c(mm, N, alpC, rC, iC, beta, C, ldc);
      C += mm+mm;
      A = An;
   }

   free(vp);
   return(0);
}
@ROUT ATL_cammm_IP
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   ammkern_t ammK0_b0, ammK0_b1, ammK0_bn, amm_b1, amm_bn;
   amminfo_t mminfo;
   const TYPE ONE[2] = {ATL_rone, ATL_rzero};
   const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
   TYPE *rA, *iA, *rB, *iB, *rC, *iC;
   int mu, nu, ku, nmu, nnu, MM, NN, KB, KB0, kb0;
   size_t incA, incB, nkb, k;
   void *vp;

   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   nmu = (M+mu-1)/mu;
   nnu = (N+nu-1)/nu;
   KB = mminfo.kb;
   MM = nmu * mu;
   NN = nnu * nu;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0_b0 = mminfo.amm_b0;
         else
            ammK0_b0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0_b0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && (kb0/ku)*ku == kb0 && 
          kb0 > mminfo.kbmin)
         ammK0_b0 = mminfo.amm_b0;
   }
   amm_b1 = mminfo.amm_b1;
   amm_bn = mminfo.amm_bn;
   if (ammK0_b0 == mminfo.amm_b0)
   {
      ammK0_b1 = amm_b1;
      ammK0_bn = amm_bn;
   }
   else
   {
      ammK0_b1 = mminfo.amm_k1_b1;
      ammK0_bn = mminfo.amm_k1_bn;
   }
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;

/*
 * Do memory allocation, setup pointers
 */
   {
      const int szA=MM*KB, szB=KB*NN, szC=MM*NN;
      vp = malloc(ATL_MulBySize(szA + szB + szC + mu*nu*ku) + 3*ATL_Cachelen);
      ATL_assert(vp);
      iA = ATL_AlignPtr(vp);
      rA = iA + szA;
      iB = rA + szA;
      iB = ATL_AlignPtr(iB);
      rB = iB + szB;
      iC = rB + szB;
      iC = ATL_AlignPtr(iC);
      rC = iC + szC;
   }
   incA = ((TA == AtlasNoTrans) ? lda*KB : KB)SHIFT;
   incB = ((TB == AtlasNoTrans) ? KB : KB*ldb)SHIFT;
/*
 * Do first (possibly partial) K-block
 */
   a2blk(kb0, M, alpA, A, lda, rA, iA);
   b2blk(kb0, N, alpB, B, ldb, rB, iB);
   ammK0_b0(nmu, nnu, KB0, iA, iB, rC, rA, iB, iC);
   ammK0_b0(nmu, nnu, KB0, rA, iB, iC, rA, rB, rC);
   ammK0_bn(nmu, nnu, KB0, rA, rB, rC, iA, rB, iC);
   ammK0_b1(nmu, nnu, KB0, iA, rB, iC, iA, iB, rC);
   A += ((TA == AtlasNoTrans) ? lda*kb0 : kb0)SHIFT;
   B += ((TB == AtlasNoTrans) ? kb0 : kb0*ldb)SHIFT;
/*
 * Loop over all full-sized blocks
 */
   for (k=0; k < nkb; k++)
   {
      a2blk(KB, M, alpA, A, lda, rA, iA);
      b2blk(KB, N, alpB, B, ldb, rB, iB);
      ammK0_bn(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
      ammK0_b1(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
      ammK0_bn(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
      ammK0_b1(nmu, nnu, KB, iA, rB, iC, iA, iB, rC);
      A += incA;
      B += incB;
   }
   blk2c(M, N, alpC, rC, iC, beta, C, ldc);

   free(vp);
   return(0);
}
@ROUT ATL_ammm_IP_0
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   ammkern_t ammK0, amm;
   amminfo_t mminfo;
   TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   TYPE *pA, *pB, *pC;
   int mu, nu, ku, nmu, nnu, MM, NN, KB, KB0, kb0;
   size_t incA, incB, nkb, k;
   void *vp;

   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   nmu = (M+mu-1)/mu;
   nnu = (N+nu-1)/nu;
   KB = mminfo.kb;
   MM = nmu * mu;
   NN = nnu * nu;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0 = mminfo.amm_b0;
         else
            ammK0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && kb0 == (kb0/ku)*ku && 
          kb0 > mminfo.kbmin)
         ammK0 = mminfo.amm_b0;
   }
   amm = mminfo.amm_b1;
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;

/*
 * Do memory allocation, setup pointers
 */
   {
      const int szA=MM*KB, szB=KB*NN, szC=MM*NN;
      vp = malloc(ATL_MulBySize(szA + szB + szC + mu*nu*ku) + 3*ATL_Cachelen);
      ATL_assert(vp);
      pA = ATL_AlignPtr(vp);
      pB = pA + szA;
      pB = ATL_AlignPtr(pB);
      pC = pB + szB;
      pC = ATL_AlignPtr(pC);
   }
   incA = (TA == AtlasNoTrans) ? lda*KB : KB;
   incB = (TB == AtlasNoTrans) ? KB : KB*ldb;
/*
 * Do first (possibly partial) K-block
 */
   a2blk(kb0, M, alpA, A, lda, pA);
   b2blk(kb0, N, alpB, B, ldb, pB);
   ammK0(nmu, nnu, KB0, pA, pB, pC, pA, pB, pC);
   A += (TA == AtlasNoTrans) ? lda*kb0 : kb0;
   B += (TB == AtlasNoTrans) ? kb0 : kb0*ldb;
/*
 * Loop over all full-sized blocks
 */
   for (k=0; k < nkb; k++)
   {
      a2blk(KB, M, alpA, A, lda, pA);
      b2blk(KB, N, alpB, B, ldb, pB);
      amm(nmu, nnu, KB, pA, pB, pC, pA, pB, pC);
      A += incA;
      B += incB;
   }
   blk2c(M, N, alpC, pC, beta, C, ldc);

   free(vp);
   return(0);
}
@ROUT ATL_ammm_IP
int Mjoin(PATL,ammm_IP)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   ipinfo_t ip;
   TYPE *a, *b, *c;
   void *vp, *ipp;
   unsigned int i, imm, mu, nu, mb, nb;

   Mjoin(PATL,ipgenInfo)(&ip, 3, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta);
   vp = malloc(ATL_MulBySize(ip.szC+ip.szA+ip.szB+ip.exsz)
               + 3*ATL_Cachelen);
   if (!vp)
      return(1);

   a = ATL_AlignPtr(vp);
   b = a + (ip.szA SHIFT);
   b = ATL_AlignPtr(b);
   c = b + (ip.szB SHIFT);
   c = ATL_AlignPtr(c);
   Mjoin(PATL,iploopsK)(&ip, 0, 0, A, B, C, 0, a, b, 
   #ifdef TCPLX
                        c+ip.szC, c, beta, ip.blk2c);
   #else
                        c, c, beta, ip.blk2c);
   #endif
   free(vp);
   return(0);
}
@beginskip
int Mjoin(PATL,ammm_IP)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef TCPLX
      const TYPE ONE[2]={ATL_rone,ATL_rzero}, ZERO[2]={ATL_rzero,ATL_rzero};
      const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
   #else
      #define ONE ATL_rone
      TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   #endif
   TYPE *a, *b, *rC, *iC;
   void *vp;
   size_t sz, incAk, incBk;
   ATL_INT lenA, lenB, lenC;
   int mu, nu, ku, nmu, nnu, kb, MB, NB, KB, kb0, KB0;
   ATL_INT nfkblks;
   amminfo_t mminf;


   mu = Mjoin(PATL,GetAmmmInfo)(&mminf, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminf.mu;
   nu = mminf.nu;
   ku = mminf.ku;
   nmu = (M+mu-1)/mu;
   nnu = (N+nu-1)/nu;
   KB = kb = mminf.kb;
   nfkblks = K / kb;
   MB = nmu * mu;
   NB = nnu * nu;
   kb0 = K - nfkblks*kb;
   if (!kb0)
   {
      kb0 = KB0 = kb;
      nfkblks--;
   }
   else
   {
      #if ATL_geAMM_MAXKVEC > 1
         if (ATL_AMMFLG_KMAJOR(mminf.flag))
         {
            KB0 = ((kb0+ku-1)/ku)*ku;
            KB = Mmax(KB, KB0);
         }
         else
      #endif
      KB0 = kb0;
   }
   lenA = MB*KB;
   lenB = KB*NB;
   lenC = MB*NB;
   sz = lenA + lenB + lenC + 2*mu*nu;
   sz = ATL_MulBySize(sz) + 4*ATL_Cachelen;
   vp = malloc(sz);
   ATL_assert(vp);
   a = ATL_AlignPtr(vp);
   b = a + (lenA SHIFT);
   b = ATL_AlignPtr(b);
   iC = b + (lenB SHIFT);
   iC = ATL_AlignPtr(iC);
   #ifdef TCPLX
      rC = iC + lenC;
      rC = ATL_AlignPtr(rC);
   #else
      rC = iC;
   #endif
   incAk = (IS_COLMAJ(TA)) ? lda*kb : kb;
   incBk = (IS_COLMAJ(TB)) ? kb : kb*ldb;
   #ifdef TCPLX
      incAk += incAk;
      incBk += incBk;
   #endif
   Mjoin(PATL,ammmK)(&mminf, M, nmu, N, nnu, nfkblks, kb, kb0, KB0, A, lda,
                     incAk, B, ldb, incBk, mminf.Cblk2cm, C, ldc, a, 0, b, 0,
                     rC, iC, alpA, alpB, alpC, beta);
   free(vp);
   return(0);
}
@endskip
@ROUT ATL_ammm_1b
{
   size_t szA, szB, szC;
   int i;
   int nmu, nnu, mu, nu, ku;
   void *vp;
   #ifdef TCPLX
      int KK;
      TYPE *iA, *iB, *iC, *rA, *rB, *rC, *p;
      ammkern_t amm;
   #else
      TYPE *pA, *pB, *pC, *p;
   #endif
   opinfo_t mminfo;

   if (K > ATL_rkAMM_LASTKB || M > ATL_rkAMM_LASTMB || N > ATL_rkAMM_LASTNB)
      return(1);
   if (Mjoin(PATL,GetInfo_1b_oprk)(&mminfo, TA, TB, M, N, K, lda, ldb, ldc,
                                   alpha, beta) == -1)
      return(-1);  /* can't do this problem with 1b! */
/*
 * These kernels all take runtime M/N, and do well with near-square, so
 * blindly use this kernel with nM = CEIL(M/mu)*mu, nN = CEIL(N/nu)*nu
 */
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   nmu = (mminfo.nfmblks) ? mminfo.nmu : mminfo.pnmu;
   nnu = (mminfo.nfnblks) ? mminfo.nnu : mminfo.pnnu;

   szA = mminfo.szA;
   szB = mminfo.szB;
   szC = mminfo.szC;
   vp = malloc(ATL_MulBySize(szC+szA+szB + (mu+mu)*nu*ku) + 3*ATL_Cachelen);
   if (!vp)
      return(1);
   #ifdef TCPLX
      iB = ATL_AlignPtr(vp);
      rB = iB + szB;
      iA = rB + szB;
      iA = ATL_AlignPtr(iA);
      rA = iA + szA;
      iC = rA + szA;
      iC = ATL_AlignPtr(iC);
      rC = iC + szC;
   #else
      pB = ATL_AlignPtr(vp);
      pA = pB + szB;
      pA = ATL_AlignPtr(pA);
      pC = pA + szA;
      pC = ATL_AlignPtr(pC);
   #endif
/*
 * Copy A & B into workspace, and pad K its if necessary
 */
   #ifdef TCPLX
      amm = mminfo.amm_b0;
      KK = mminfo.KB;

      mminfo.a2blk(K, M, mminfo.alpA, A, lda, rA, iA);
      mminfo.b2blk(K, N, mminfo.alpB, B, ldb, rB, iB);
      amm(nmu, nnu, KK, iA, iB, rC, rA, iB, iC);
      amm(nmu, nnu, KK, rA, iB, iC, rA, rB, rC);
      mminfo.amm_bn(nmu, nnu, KK, rA, rB, rC, iA, rB, iC);
      mminfo.amm_b1(nmu, nnu, KK, iA, rB, iC, iA, rB, iC);
      mminfo.blk2C(M, N, mminfo.ONE, rC, iC, beta, C, ldc);
   #else
      mminfo.a2blk(K, M, mminfo.alpA, A, lda, pA);
      mminfo.b2blk(K, N, mminfo.alpB, B, ldb, pB);
      mminfo.amm_b0(nmu, nnu, mminfo.KB, pA, pB, pC, pA, pB, pC);
      mminfo.blk2C(M, N, ATL_rone, pC, beta, C, ldc);
   #endif

   free(vp);
   return(0);
}
@ROUT ATL_cammm_1b
{
   int i;
   int nmu, nnu, nku, bM, bN, bK;
   int szA, szB, szC;
   int KK;
   int mu, nu, ku, appAl;
   void *vp;
   TYPE *rA, *iA, *rB, *iB, *rC, *iC, *p, *w;
   const TYPE one[2] = {ATL_rone, ATL_rzero};
   const TYPE *alpA=one, *alpB=one, *alpC=one;
   ammkern_t amm;
   opinfo_t mminfo;

   ATL_assert(K <= ATL_rkAMM_LASTKB)
   Mjoin(PATL,GetInfo_oprk)(&mminfo, TA, TB, M, N, K, lda, ldb, ldc, 
                            alpha, beta);
/*
 * These kernels all take runtime M/N, and do well with near-square, so
 * blindly use this kernel with nM = CEIL(M/mu)*mu, nN = CEIL(N/nu)*nu
 */
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   KK = mminfo.KB;
   nmu = mminfo.nmu;
   nnu = mminfo.nnu;
   amm = mminfo.amm_b0;
   szB = mminfo.szB;
   szA = mminfo.szA;
   szC = mminfo.szC;
   vp = malloc(ATL_MulBySize((szC+mu*nu*ku + szA + szB)) + 3*ATL_Cachelen);
   ATL_assert(vp);
   iB = ATL_AlignPtr(vp);
   rB = iB + szB;
   rB = ATL_AlignPtr(rB);
   iA = rB + szB;
   iA = ATL_AlignPtr(iA);
   rA = iA + szA;
   iC = rA + szA;
   rC = iC + szC;
   w = rC + szC;
/*
 * Copy A & B into workspace, and pad K its if necessary
 */
   mminfo.a2blk(K, M, alpA, A, lda, rA, iA);
   mminfo.b2blk(K, N, alpB, B, ldb, rB, iB);
   amm(nmu, nnu, KK, iA, iB, rC, rA, iB, iC);
   amm(nmu, nnu, KK, rA, iB, iC, rA, rB, rC);
   mminfo.amm_bn(nmu, nnu, KK, rA, rB, rC, iA, rB, iC);
   mminfo.amm_b1(nmu, nnu, KK, iA, rB, iC, iA, rB, iC);
   mminfo.blk2C(M, N, alpC, rC, iC, beta, C, ldc);

   free(vp);
   return(0);
}
@ROUT ATL_ammm
{
@beginskip
   #ifdef TREAL
      if (TA == AtlasConj)
         TA = AtlasNoTrans;
      else if (TA == AtlasConjTrans)
         TA = AtlasTrans;
      if (TB == AtlasConj)
         TB = AtlasNoTrans;
      else if (TB == AtlasConjTrans)
         TB = AtlasTrans;
   #endif
@endskip
/*
 * Just do a scale and return
 */
   if (SCALAR_IS_ZERO(alpha) || !K)
   {
      if (SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gezero)(M, N, C, ldc);
      else if (!SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gescal)(M, N, beta, C, ldc);
      return(0);
   }
/*
 * Scope for degenerate cases that should call Level-2 BLAS; these
 * routines assert they work, since their workspace is O(N) and so are
 * not allowed to fail.
 */
   if (K == 1)  /* really a GER */
   {
   #ifdef TCPLX
      if (!SCALAR_IS_ONE(beta))  /* can't use GER for beta != 1 */
      {
         int i;
         const register TYPE ral=alpha[0], ial=alpha[1];
         const size_t ldc2 = ldc+ldc;
         ATL_CSZT incB = ((TB == AtlasNoTrans) ? ldb : 1)SHIFT;
         const register TYPE
            cjm = (TB==AtlasConj || TB==AtlasConjTrans) ? ATL_rnone:ATL_rone;
         TYPE *X=(TYPE*)A;
         void *vp=NULL;
/*
 *       Copy A if it's a row or if it must be conjugated
 */
         if (TA == AtlasTrans || TA == AtlasConjTrans || TA == AtlasConj)
         {
            vp = malloc(ATL_MulBySize(M)+ATL_Cachelen);
            ATL_assert(vp);
            X = ATL_AlignPtr(vp);
            if (TA == AtlasTrans)
               Mjoin(PATL,copy)(M, A, lda, X, 1);
            else if (TA == AtlasConjTrans)
               Mjoin(PATL,copyConj)(M, A, lda, X, 1);
            else
               Mjoin(PATL,copyConj)(M, A, 1, X, 1);
         }
         for (i=0; i < N; i++, B += incB, C += ldc2)
         {
            TYPE scal[2];
            register TYPE rb=(*B), ib=cjm*B[1];
            scal[0] = rb*ral - ib*ial;
            scal[1] = rb*ial + ib*ral;
            Mjoin(PATL,axpby)(M, scal,  X, 1, beta, C, 1);
         }
         if (vp)
            free(vp);
      }
      else  /* BETA=1, can use GERU/GERC */
      {
         if (TA == AtlasConjTrans || TA == AtlasConj)  /* must copyConj A */
         {
            void *vp;
            TYPE *X;
            const TYPE ONE[2] = {ATL_rone, ATL_rzero};
            vp = malloc(ATL_MulBySize(M)+ATL_Cachelen);
            ATL_assert(vp);
            X = ATL_AlignPtr(vp);
            Mjoin(PATL,moveConj)(M, alpha, A, (TA == AtlasConj) ? 1:lda, X, 1);
            if (TB == AtlasConjTrans || TB == AtlasConj)  /* use gerc */
               Mjoin(PATL,gerc)(M, N, ONE, X, 1, B,
                                (TB == AtlasConj) ? ldb : 1, C, ldc);
            else
               Mjoin(PATL,geru)(M, N, ONE, X, 1, B,
                                (TB == AtlasNoTrans) ? ldb : 1, C, ldc);
            free(vp);
         }
         else if (TB == AtlasConjTrans || TB == AtlasConj)  /* use gerc */
            Mjoin(PATL,gerc)(M, N, alpha, A, (TA == AtlasNoTrans) ? 1 : lda,
                             B, (TB == AtlasConj) ? ldb : 1, C, ldc);
         else /* use geru */
            Mjoin(PATL,geru)(M, N, alpha, A, (TA == AtlasNoTrans) ? 1 : lda,
                            B, (TB == AtlasNoTrans) ? ldb : 1, C, ldc);
      }
   #else
      if (!SCALAR_IS_ONE(beta)) /* can't use GER for beta != 1 */
      {
         int i;
         ATL_CSZT incA = ((TA == AtlasNoTrans) ? 1 : lda);
         ATL_CSZT incB = ((TB == AtlasNoTrans) ? ldb : 1);
         for (i=0; i < N; i++, B += incB, C += ldc)
            Mjoin(PATL,axpby)(M, alpha * *B,  A, incA, beta, C, 1);
      }
      else
         Mjoin(PATL,ger)(M, N, alpha, A, (TA == AtlasNoTrans) ? 1 : lda,
                         B, (TB == AtlasNoTrans) ? ldb : 1, C, ldc);
   #endif
      return(0);
   }
   if (K == 2)
      return(Mjoin(PATL,ammm_rk2)(TA, TB, M, N, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
   if (N == 1)  /* Really GEMV with A as matrix, A & C as vectors */
   {
   #ifdef TCPLX
      TYPE *X = (TYPE*)B;
      void *vp = NULL;
      int incX = 1;
/*
 *    Copy B if it we need to conjugate it
 */
      if (TB == AtlasConj || TB == AtlasConjTrans)
      {
         vp = malloc(ATL_MulBySize(K)+ATL_Cachelen);
         ATL_assert(vp);
         X = ATL_AlignPtr(vp);
         Mjoin(PATL,copyConj)(K, B, (TB == AtlasConj) ? 1:ldb, X, 1);
      }
      else
         incX = (TB == AtlasNoTrans) ? 1:ldb;
      if (TA == AtlasNoTrans || TA == AtlasConj)
         Mjoin(PATL,gemv)(TA, M, K, alpha, A, lda, X, incX, beta, C, 1);
      else /* if (TA == AtlasTrans || TA == AtlasConjTrans) */
         Mjoin(PATL,gemv)(TA, K, M, alpha, A, lda, X, incX, beta, C, 1);
      if (vp)
         free(vp);
   #else
      if (TA == AtlasNoTrans)
         Mjoin(PATL,gemv)(AtlasNoTrans, M, K, alpha, A, lda, B,
                          (TB == AtlasNoTrans) ? 1:ldb, beta, C, 1);
      else
         Mjoin(PATL,gemv)(AtlasTrans, K, M, alpha, A, lda, B,
                          (TB == AtlasNoTrans) ? 1:ldb, beta, C, 1);
   #endif
      return(0);
   }
   if (M == 1)  /* Really GEMV with B as matrix, A & C as vectors */
   {
   #ifdef TCPLX
      TYPE *X = (TYPE*)A;
      void *vp = NULL;
      int incX = 1;
/*
 *    Copy A if it we need to conjugate it
 */
      if (TA == AtlasConj || TA == AtlasConjTrans)
      {
         vp = malloc(ATL_MulBySize(K)+ATL_Cachelen);
         ATL_assert(vp);
         X = ATL_AlignPtr(vp);
         Mjoin(PATL,copyConj)(K, A, (TA == AtlasConj) ? lda:1, X, 1);
      }
      else
         incX = (TA == AtlasNoTrans) ? lda:1;
      if (TB == AtlasNoTrans)
         Mjoin(PATL,gemv)(AtlasTrans, K, N, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasConj)
         Mjoin(PATL,gemv)(AtlasConjTrans, K, N, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasTrans)
         Mjoin(PATL,gemv)(AtlasNoTrans, N, K, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasConjTrans)
         Mjoin(PATL,gemv)(AtlasConj, N, K, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      if (vp)
         free(vp);
   #else
      if (TB == AtlasNoTrans)
         Mjoin(PATL,gemv)(AtlasTrans, K, N, alpha, B, ldb, A,
                          (TA == AtlasNoTrans) ? lda:1, beta, C, ldc);
      else
         Mjoin(PATL,gemv)(AtlasNoTrans, N, K, alpha, B, ldb, A,
                          (TA == AtlasNoTrans) ? lda:1, beta, C, ldc);
   #endif
      return(0);
   }
/*
 * Special case mainly for real LU, where K==4, N==4 beta=1.0, TA==AtlasNoTrans;
 * Can do a no-copy update with only one loop.
 */
   #ifndef TCPLX
   if (K == 4 && N == 4 && TA==AtlasNoTrans && SCALAR_IS_ONE(beta))
   {
      int Mjoin(PATL,rk4n4)(enum ATLAS_TRANS,ATL_CSZT,const SCALAR,
          const TYPE*,ATL_CSZT,const TYPE*,ATL_CSZT,TYPE*,ATL_CSZT);
      if (!Mjoin(PATL,rk4n4)(TB, M, alpha, A, lda, B, ldb, C, ldc))
         return(0);
   }
   #endif
/*
 * Rank-K can fail to allocate space, so return success/failure
 */
   if (K <= ATL_VWopgen_MAX_KB)
      return(Mjoin(PATL,ammm_rkK)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
/*
 * Handle case that is really an inner product shape (M<=MB, N<=NB, large K)
 * This case not allowed to fail since it requires only 3*NB^2 workspace.
 */
   if (M <= ATL_VWipgen_MAX_MB && N <= ATL_VWipgen_MAX_NB)
      if (!Mjoin(PATL,ammm_IP)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                               beta, C, ldc))
         return(0);
/*
 * If B/C have only one column panel, call special low-workspace (3NB^3)
 * code for additional performance.  This shape occurs in left-looking LU.
 */
   if (N <= ATL_VWipgen_BEST_NB)
      return(Mjoin(PATL,ammm_tN)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                 beta, C, ldc));
/*
 * Next two loop orderings are general case, so use whichever uses least
 * workspace
 */
   if (M > N)
      return(Mjoin(PATL,ammmKMNK)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
   return(Mjoin(PATL,ammmKNMK)(TA, TB, M, N, K, alpha, A, lda, B, ldb, 
                               beta, C, ldc));
}
@ROUT ATL_cammm
{
/*
 * Just do a scale and return
 */
   if (SCALAR_IS_ZERO(alpha) || !K)
   {
      if (SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gezero)(M, N, C, ldc);
      else if (!SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gescal)(M, N, beta, C, ldc);
      return(0);
   }
/*
 * Scope for degenerate cases that should call Level-2 BLAS; these
 * routines assert they work, since their workspace is O(N) and so they
 * are not allowed to fail.
 */
   if (K == 1)  /* really a GER */
   {
      if (!SCALAR_IS_ONE(beta))  /* can't use GER for beta != 1 */
      {
         int i;
         const register TYPE ral=alpha[0], ial=alpha[1];
         const size_t ldc2 = ldc+ldc;
         ATL_CSZT incB = ((TB == AtlasNoTrans) ? ldb : 1)SHIFT;
         const register TYPE 
            cjm = (TB==AtlasConj || TB==AtlasConjTrans) ? ATL_rnone:ATL_rone;
         TYPE *X=(TYPE*)A;
         void *vp=NULL;
/*
 *       Copy A if it's a row or if it must be conjugated
 */
         if (TA == AtlasTrans || TA == AtlasConjTrans || TA == AtlasConj)
         {
            vp = malloc(ATL_MulBySize(M)+ATL_Cachelen);
            ATL_assert(vp);
            X = ATL_AlignPtr(vp);
            if (TA == AtlasTrans)
               Mjoin(PATL,copy)(M, A, lda, X, 1);
            else if (TA == AtlasConjTrans)
               Mjoin(PATL,copyConj)(M, A, lda, X, 1);
            else
               Mjoin(PATL,copyConj)(M, A, 1, X, 1);
         }
         for (i=0; i < N; i++, B += incB, C += ldc2)
         {
            TYPE scal[2];
            register TYPE rb=(*B), ib=cjm*B[1];
            scal[0] = rb*ral - ib*ial;
            scal[1] = rb*ial + ib*ral;
            Mjoin(PATL,axpby)(M, scal,  X, 1, beta, C, 1);
         }
         if (vp) 
            free(vp);
      }
      else  /* BETA=1, can use GERU/GERC */
      {
         if (TA == AtlasConjTrans || TA == AtlasConj)  /* must copyConj A */
         {
            void *vp;
            TYPE *X;
            const TYPE ONE[2] = {ATL_rone, ATL_rzero};
            vp = malloc(ATL_MulBySize(M)+ATL_Cachelen);
            ATL_assert(vp);
            X = ATL_AlignPtr(vp);
            Mjoin(PATL,moveConj)(M, alpha, A, (TA == AtlasConj) ? 1:lda, X, 1);
            if (TB == AtlasConjTrans || TB == AtlasConj)  /* use gerc */
               Mjoin(PATL,gerc)(M, N, ONE, X, 1, B, 
                                (TB == AtlasConj) ? ldb : 1, C, ldc);
            else
               Mjoin(PATL,geru)(M, N, ONE, X, 1, B, 
                                (TB == AtlasNoTrans) ? ldb : 1, C, ldc);
            free(vp);
         }
         else if (TB == AtlasConjTrans || TB == AtlasConj)  /* use gerc */
            Mjoin(PATL,gerc)(M, N, alpha, A, (TA == AtlasNoTrans) ? 1 : lda, 
                             B, (TB == AtlasConj) ? ldb : 1, C, ldc);
         else /* use geru */
            Mjoin(PATL,geru)(M, N, alpha, A, (TA == AtlasNoTrans) ? 1 : lda, 
                            B, (TB == AtlasNoTrans) ? ldb : 1, C, ldc);
      }
      return(0);
   }
   if (K == 2)
      return(Mjoin(PATL,ammm_rk2)(TA, TB, M, N, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
   if (N == 1)  /* GEMV wt A as matrix, B&C vecs */
   {                     
      TYPE *X = (TYPE*)B;
      void *vp = NULL;
      int incX = 1;
/*
 *    Copy B if it we need to conjugate it
 */
      if (TB == AtlasConj || TB == AtlasConjTrans)
      {
         vp = malloc(ATL_MulBySize(K)+ATL_Cachelen);
         ATL_assert(vp);
         X = ATL_AlignPtr(vp);
         Mjoin(PATL,copyConj)(K, B, (TB == AtlasConj) ? 1:ldb, X, 1);
      }
      else
         incX = (TB == AtlasNoTrans) ? 1:ldb;
      if (TA == AtlasNoTrans || TA == AtlasConj)
         Mjoin(PATL,gemv)(TA, M, K, alpha, A, lda, X, incX, beta, C, 1);
      else /* if (TA == AtlasTrans || TA == AtlasConjTrans) */
         Mjoin(PATL,gemv)(TA, K, M, alpha, A, lda, X, incX, beta, C, 1);
      if (vp)
         free(vp);
      return(0);
   }
   if (M == 1)  /* Really GEMV with B as matrix, A & C as vectors */
   {
      TYPE *X = (TYPE*)A;
      void *vp = NULL;
      int incX = 1;
/*
 *    Copy A if it we need to conjugate it
 */
      if (TA == AtlasConj || TA == AtlasConjTrans)
      {
         vp = malloc(ATL_MulBySize(K)+ATL_Cachelen);
         ATL_assert(vp);
         X = ATL_AlignPtr(vp);
         Mjoin(PATL,copyConj)(K, A, (TA == AtlasConj) ? lda:1, X, 1);
      }
      else
         incX = (TA == AtlasNoTrans) ? lda:1;
      if (TB == AtlasNoTrans)
         Mjoin(PATL,gemv)(AtlasTrans, K, N, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasConj)
         Mjoin(PATL,gemv)(AtlasConjTrans, K, N, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasTrans)
         Mjoin(PATL,gemv)(AtlasNoTrans, N, K, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasConjTrans)
         Mjoin(PATL,gemv)(AtlasConj, N, K, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      if (vp)
         free(vp);
      return(0);
   }
/*
 * 1-block special case code can return w/o doing op if it thinks
 * rank-K would be faster
 */
   if (M <= ATL_geAMM_LASTMB && N <= ATL_geAMM_LASTNB && K <= ATL_geAMM_LASTKB)
   {
      if (!Mjoin(PATL,ammm_1b)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                               beta, C, ldc))
         return(0);
   }
/*
 * Rank-K could fail to allocate M*KB+KB*N+MB*KB workspace
 */
   if (K > 2 && K <= ATL_rkAMM_LASTKB)
      return(Mjoin(PATL,ammm_rkK)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
/*
 * If B/C have only one column panel, call special low-workspace (3NB^3)
 * code for additional performance.  This shape occurs in left-looking algs.
 */
   if (N <= ATL_geAMM_LASTNB)
      return(Mjoin(PATL,ammm_tN)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                 beta, C, ldc));
/*
 * Handle case that is really an inner product shape (M<=MB, N<=NB, large K)
 */
   if (M <= ATL_geAMM_LASTMB && N <= ATL_geAMM_LASTNB)
      return(Mjoin(PATL,ammm_IP)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                 beta, C, ldc));
/*
 * Next two loop orderings are general case, so use whichever uses least
 * workspace
 */
#if 0
   if (M > N)
      return(Mjoin(PATL,ammmMNK)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                 beta, C, ldc));
/*
 * This guy tries to allocate (M+NB)*K + NB^2 worskpace, so recursion
 * may be needed to keep it within allotted memory.
 */
   return(Mjoin(PATL,ammmNMK)(TA, TB, M, N, K, alpha, A, lda, B, ldb, 
                              beta, C, ldc));
#else
   if (M > N)
      return(Mjoin(PATL,ammmKMNK)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
   return(Mjoin(PATL,ammmKNMK)(TA, TB, M, N, K, alpha, A, lda, B, ldb, 
                               beta, C, ldc));
#endif
}
@ROUT ATL_ammm ATL_cammm
/*
 * Recur to get K below this value; this puts a ceiling on workspace and
 * usually improves performance (in huge problems, reduces TLB pressure)
 */
#define ATL_MAX_RK 3000


/*
 * This routine uses recursion to cut the dimensions of the matrices until
 * workspace requirements are low enough that a call to ATL_ammm succeeds
 */
void Mjoin(PATL,ammm)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef USEREF
   Mjoin(PATL,refgemm)(TA, TB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
   return;
   #endif
   if (!M || !N)
      return;
/*
 * Cases where all we must do is possibly scale and return
 */
   if (SCALAR_IS_ZERO(alpha) || !K)
   {
      if (SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gezero)(M, N, C, ldc);
      else if (!SCALAR_IS_ONE(beta))
         Mjoin(PATL,gescal)(M, N, beta, C, ldc);
      return;
   }
/*
 * Our stopping criteria is if ATL_ammm signals success in mallocing mem
 */
   if (K <= ATL_MAX_RK)
   {
      if(!ATL_ammm(TA, TB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc))
         return;
   }
/*
 * =========================================================================
 * Otherwise, problem too large, so we'll recursively divide its largest dim
 * =========================================================================
 */
/*
 * if K is tied for largest, cut it, since it reduces size of A & B
 * NOTE: C always uses only NB^2 workspace, so only A/B matters.
 */
   if (K > ATL_MAX_RK || (K >= N && K >= M))
   {
      const size_t kL=(K>>4)<<3, kR=K-kL;
      #ifdef TCPLX
         const TYPE ONE[2] = {ATL_rone, ATL_rzero};
      #else
         #define ONE ATL_rone
      #endif

      Mjoin(PATL,ammm)(TA, TB, M, N, kL, alpha, A, lda, B, ldb, beta, C, ldc);
      if (TA == AtlasNoTrans || TA == AtlasConj)
         A += (lda*kL)SHIFT;
      else
         A += kL SHIFT;
      if (TB == AtlasNoTrans)
         B += kL SHIFT;
      else
         B += (ldb*kL) SHIFT;
      Mjoin(PATL,ammm)(TA, TB, M, N, kR, alpha, A, lda, B, ldb, 
                       ONE, C, ldc);
      #ifdef ONE
         #undef ONE
      #endif
   }
   else if (N >= M)  /* cutting N */
   {
      const size_t nL = (N>>1), nR = N-nL;
      Mjoin(PATL,ammm)(TA, TB, M, nL, K, alpha, A, lda, B, ldb, beta, C, ldc);
      if (TB == AtlasNoTrans || TB == AtlasConj)
         B += (ldb*nL)SHIFT;
      else 
         B += nL SHIFT;
      C += (ldc*nL)SHIFT;
      Mjoin(PATL,ammm)(TA, TB, M, nR, K, alpha, A, lda, B, ldb, beta, C, ldc);
   }
   else  /* cutting M */
   {
      const size_t mL = (M>>1), mR = M-mL;
      Mjoin(PATL,ammm)(TA, TB, mL, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
      if (TA == AtlasNoTrans || TA == AtlasConj)
         A += mL SHIFT;
      else
         A += (mL*lda)SHIFT;
      C += mL SHIFT;
      Mjoin(PATL,ammm)(TA, TB, mR, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
   }
}

void Mjoin(PATL,gemm)(const enum ATLAS_TRANS TA, const enum ATLAS_TRANS TB,
                      ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, const SCALAR alpha,
                      const TYPE *A, ATL_CSZT lda, const TYPE *B, 
                      ATL_CSZT ldb, const SCALAR beta, TYPE *C, ATL_CSZT ldc)
{
   Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
}
@ROUT atlas_simd.h
#ifndef ATLAS_SIMD_H
   #define  ATLAS_SIMD_H 1
#ifdef ATL_GAS_ARM64
   #define ATL_VECARM1 1
/*
 * On 32-bit ARM, disable SIMD unless NONIEEE flag is thrown
 */
#elif defined(ATL_GAS_ARM)
   #if !defined(ATL_NONIEEE) || !(defined(SREAL) || defined(SCPLX))
      #ifdef ATL_VLEN
         #undef ATL_VLEN
      #endif
      #define ATL_VLEN 1
   #else
      #define ATL_NEON 1
   #endif
#endif
#if 0
#undef ATL_AVX
#undef ATL_SSE3
#undef ATL_SSE2
#undef ATL_SSE1
#define ATL_FRCGNUVEC 1
#define ATL_VLEN 32
#endif
/*
 * This header files contains wrappers to allow you to use SIMD vector
 * extensions in a very simplified way in a type-independent manner.
 * ATL_VLEN is treated differently, depending on whether we are using
 * system-dependent vectorization (eg., AVX, VSX, etc.) or gnu vectorization:
 * - For gnu vectorization, ATL_VLEN must be defined as a power of 2.
 * - For non-gnu vec ATL_VLEN should match the system, or be undefined.
* All macro funcs first arg is the destination.  vr stands for vector register.
 * We support the following miscellaneous instructions:
 *    ATL_vzero(vr)       : zero all vr entries
 *    ATL_vcopy(vrd, vrs) : vrd = vrs
 *
 * We support 5 load/store operations (where p is a pointer):
 *    ATL_vbcast(vr, p) : broadcast pointed-to scalar to all vr entries
 *    ATL_vuld(vr, p)   : unaligned load from ptr to vr
 *    ATL_vld(vr, p)    : aligned load from ptr to vr
 *    ATL_vust(p, vr)   : unaligned store to ptr from vr
 *    ATL_vst(p, vr)    : aligned store to ptr from vr
 * NOTE: if VLEN < native length, all  usually assume unaligned data,
 *       and (except bcast) become a series of instructions rather than one.
 *
 * We support 3 computational macros:
 * ATL_vadd(vrd, vrs1, vrs2) : vrd = vrs1 + vrs2
 * ATL_vsub(vrd, vrs1, vrs2) : vrd = vrs1 - vrs2
 * ATL_vmul(vrd, vrs1, vrs2) : vrd = vrs1 * vrs2
 * ATL_vmac(vrd, vrs1, vrs2) : vrd += vrs1 * vrs2
 *
 * For L1BLAS, we support a vector being summed to a scalar.
 * NOTE: srd must be a scalar reg
 *    ATL_vrsum1(srd, vrs)        : srd = sum(vrs[:])
 * For k-vec amm, we need to support summing up VLEN different accumulators,
 * and placing the result in one destination.  This requires the using code
 * to know VLEN (perhaps with a cpp if/else chain), but allows us to get
 * high performance on C stores.  We show the answer for vvrsum2 & 4, but
 * remember that only vvrsumVLEN will actually exist:
 *    ATL_vvrsum2(d, s0, s1) : d[0] = sum(s0[:]), d[1] = sum(s1[:])
 *    ATL_vvrsum4(d, s1, s2, s3, s4) : d[0:3] = sum(s0:4)
 */
/*
 * If ATL_VLEN is set, force gnuvec if it isn't set to the native length
 */
#ifdef ATL_VLEN
   #ifdef ATL_VSX
      #if ((defined(SREAL) || defined(SCPLX)) && ATL_VLEN != 4) || \
          ((defined(DREAL) || defined(DCPLX)) && ATL_VLEN != 2)
         #define ATL_FRCGNUVEC
      #endif
   #elif defined(ATL_VXZ)
      #if ATL_VLEN != 2;
         #define ATL_FRCGNUVEC
      #endif
   #elif defined(ATL_NEON)
      #if ((defined(SREAL) || defined(SCPLX)) && ATL_VLEN != 4) || \
          ((defined(DREAL) || defined(DCPLX)) && ATL_VLEN != 1)
         #define ATL_FRCGNUVEC
      #endif
@multidef vl    2   2    4      4    8      2
@whiledef sv SSE1 SSE2 AVX AVXMAC AVXZ VECARM1
   @iexp vl2 @(vl) @(vl) +
   #elif defined(ATL_@(sv))
      #if ((defined(SREAL) || defined(SCPLX)) && ATL_VLEN != @(vl2)) || \
          ((defined(DREAL) || defined(DCPLX)) && ATL_VLEN != @(vl))
         #define ATL_FRCGNUVEC
      #endif
   @undef vl
@endwhile
   #endif
/*
 * Compute ATL_VLEN based on SIMD extension & TYPE, if not already set
 */
#else
   #ifdef ATL_VSX
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLEN 4
      #else
         #define ATL_VLEN 2
      #endif
   #elif defined(ATL_VXZ)
      #define ATL_VLEN 2
   #elif defined(ATL_NEON)
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLEN 4
      #else
         #define ATL_VLEN 1
      #endif
@multidef vl    2   2    4      4    8      2
@whiledef sv SSE1 SSE2 AVX AVXMAC AVXZ VECARM1
   @iexp vl2 @(vl) @(vl) +
   #elif defined(ATL_@(sv))
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLEN @(vl2)
      #else
         #define ATL_VLEN @(vl)
      #endif
   @undef vl
@endwhile
   #endif
#endif
/*
 * Derive ATL_VLENb (veclen in bytes) from ATL_VLEN
 */
#ifndef ATL_VLEN
   #error "ATL_VLEN not defined!"
#else
   #if ATL_VLEN == 1
      #define ATL_VLSH 0
      #define ATL_DivByVLEN(i_) (i_)
      #define ATL_MulByVLEN(i_) (i_)
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLENb 4
      #else
         #define ATL_VLENb 8
      #endif
   @define i @1@
   @define p @2@
   @iwhile i < 6
   #elif ATL_VLEN == @(p)
      #define ATL_VLSH @(i)
      #define ATL_DivByVLEN(i_) ((i_)>>@(i))
      #define ATL_MulByVLEN(i_) ((i_)<<@(i))
      @iexp vl @(p) 4 *
      @iexp vl2 @(p) 8 *
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLENb @(vl)
      #else
         #define ATL_VLENb @(vl2)
      #endif
      @iexp p @(p) 2 *
      @iexp i @(i) 1 +
   @endiwhile
   #else
      #define ATL_DivByVLEN(i_) ((i_)/ATL_VLEN)
      #define ATL_MulByVLEN(i_) ((i_)*ATL_VLEN)
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLENb (ATL_VLEN*4)
      #else
         #define ATL_VLENb (ATL_VLEN*8)
      #endif
   #endif
#endif
/*
 * We may want to force use of GNU vectorization on any platform.  If so,
 * undefine any defined system-specific vectorization.  
 * Undefine all vectorization if VLEN=1 (scalar code)!
 */
#if defined(ATL_FRCGNUVEC) || ATL_VLEN < 2
@whiledef sv VXZ VSX AVXMAC AVX AVXZ SSE3 SSE2 SSE1 VECARM1 NEON
   #ifdef ATL_@(sv)
      #undef ATL_@(sv)
   #endif
@endwhile
   #if ATL_VLEN < 2 && defined(ATL_FRCGNUVEC)
       #undef ATL_FRCGNUVEC
   #endif
#endif
/*
 * Now set computational macros based on ATL_VLEN & SIMD defines
 */
#if defined(ATL_VSX)
   #include <altivec.h>
/*
 * Older gcc don't support don't support xxpermdi, merge[o,e], xxsel
 */
   #if (__GNUC__ > 4) || (__GNUC__ == 4 && __GNUC_MINOR__ > 9) || \
        (__GNUC__ == 4 && __GNUC_MINOR__ == 9 && __GNU_PATHLEVEL__ > 1) || \
        !defined(__GNUC__)
      #define ATL_FULLGCCVSX 1
   #else
      #define ATL_FULLGCCVSX 0
   #endif
   #if defined(SREAL) || defined(SCPLX)
      #define ATL_VTYPE vector float
      #if ATL_VLEN != 4
         #error "VSX supports only VLEN = 4 for floats!"
      #endif
   #else        /* double precision */
      #define ATL_VTYPE vector double
      #if ATL_VLEN != 2
         #error "VSX supports only VLEN = 2 for doubles!"
      #endif
   #endif
   #define ATL_vzero(v_) v_ = vec_splats((TYPE)0.0)
   #define ATL_vcopy(d_, s_) d_ = s_
   #define ATL_vbcast(v_, p_) v_ =  vec_splats(*((TYPE*)(p_)))
   #define ATL_vuld(v_, p_) v_ = vec_vsx_ld(0, (ATL_VTYPE*)(p_))
   #define ATL_vld(v_, p_) v_ = vec_ld(0, (ATL_VTYPE*)(p_))
   #define ATL_vust(p_, v_) vec_vsx_st(v_, 0, (ATL_VTYPE*)(p_))
   #define ATL_vst(p_, v_)  vec_st(v_, 0, (ATL_VTYPE*)(p_))
   #define ATL_vadd(d_, s1_, s2_) d_ =  vec_add(s1_, s2_)
   #define ATL_vsub(d_, s1_, s2_) d_ =  vec_sub(s1_, s2_)
   #define ATL_vmul(d_, s1_, s2_) d_ =  vec_mul(s1_, s2_)
   #define ATL_vmac(d_, s1_, s2_) d_ = vec_madd(s1_, s2_, d_)
   #if defined(SREAL) || defined(SCPLX)
      #define ATL_vrsum1(d_, s_) \
      { \
         VTYPE t_; \
         d_ = vec_splat(s_, 1); \
         d_ = vec_add(d_, s_) ; \
         t_ = vec_splat(s_, 2); \
         d_ = vec_add(d_, t_) ; \
         t_ = vec_splat(s_, 3); \
         d_ = vec_add(d_, t_) ; \
      }
      #if ATL_FULLGCCVSX
         #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
         {  ATL_VTYPE t_, h_;                    /*{s0d,s0c,s0b,s0a}*/\
            t_ = vec_vmrghw(s0_, s1_);           /*{s1b,s0b,s1a,s0a}*/\
            s0_ = vec_vmrglw(s0_, s1_);          /* s1d,s0d,s1c,s0c}*/ \
            s0_ = ATL_vadd(s0_, s0_, t_);        /*{s1bd,s0bd,s1ac,s0ac}*/\
            h_ = vec_vmrghw(s2_, s3_);           /*{s3b,s2b,s3a,s2a}*/\
            s2_ = vec_vmrglw(s2_, s3_);          /*{s3d,s2d,s3c,s2c}*/ \
            s2_ = ATL_vadd(s2_, s2_, h_);        /*{s3bd,s2bd,s3ac,s2ac}*/\
            t_ =  vec_xxpermdi(s0_, s2_, 0);     /*{s3ac,s2ac,s1ac,s0ac}*/\
            s0_ = vec_xxpermdi(s0_, s2_, 3);     /*{s3bd,s2bd,s1bd,s0bd}*/ \
            ATL_vadd(s0_, s0_, t_); \
            s0_ = vec_xxpermdi(s0_, s0_, 2);     /* pwr8 endian-insanity */ \
         }
         #define ATL_vvrsum2(s0_, s1_) \
         {  ATL_VTYPE t_, h_;                    /*{s0d,s0c,s0b,s0a}*/\
            t_ = vec_vmrghw(s0_, s1_);           /*{s1b,s0b,s1a,s0a}*/\
            s0_ = vec_vmrglw(s0_, s1_);          /*{s1d,s0d,s1c,s0c}*/ \
            s0_ = ATL_vadd(s0_, s0_, t_);        /*{s1bd,s0bd,s1ac,s0ac}*/\
            t_ =  vec_xxpermdi(s0_, s0_, 0);     /*{s1ac,s0ac,s1ac,s0ac}*/\
            s0_ = vec_xxpermdi(s0_, s0_, 3);     /*{s1bd,s0bd,s1bd,s0bd}*/ \
            ATL_vadd(s0_, s0_, t_); \
            s0_ = vec_xxpermdi(s0_, s0_, 2);     /* pwr8 endian-insanity */ \
         }
         #define ATL_vvrsum1(s0_) \
         {  ATL_VTYPE t_, h_;                    /*{s0d,s0c,s0b,s0a}*/\
            t_ = vec_vmrghw(s0_, s0_);           /*{s0b,s0b,s0a,s0a}*/\
            s0_ = vec_vmrglw(s0_, s0_);          /*{s0d,s0d,s0c,s0c}*/ \
            s0_ = ATL_vadd(s0_, s0_, t_);        /*{s0bd,s0bd,s0ac,s0ac}*/\
            t_ =  vec_xxpermdi(s0_, s0_, 0);     /*{s0ac,s0ac,s0ac,s0ac}*/\
            s0_ = vec_xxpermdi(s0_, s0_, 3);     /*{s0bd,s0bd,s0bd,s0bd}*/ \
            ATL_vadd(s0_, s0_, t_); \
            s0_ = vec_xxpermdi(s0_, s0_, 2);     /* pwr8 endian-insanity */ \
         }
      #endif
   @iexp i 0 0 +
   @iwhile i < 4
      #define ATL_vsplat@(i)(d_, s_) d_ = vec_splat(s_, @(i))
      @iexp i @(i) 1 +
   @endiwhile
   #else
      #define ATL_vrsum1(d_, s_) \
      { \
         d_ = vec_splat(s_, 1); \
         d_ = vec_add(d_, s_) ; \
      }
      #if ATL_FULLGCCVSX 
         #define ATL_vvrsum2(s0_, s1_) \
         {  ATL_VTYPE t_;\
            t_ =  vec_xxpermdi(s0_, s1_, 0); \
            s0_ = vec_xxpermdi(s0_, s1_, 3); \
            ATL_vadd(s0_, s0_, t_); \
            s0_ = vec_xxpermdi(s0_, s0_, 2); /* pwr8 endian-insanity */ \
         }
         #define ATL_vvrsum1(s0_) \
         {  ATL_VTYPE t_;\
            t_ =  vec_xxpermdi(s0_, s0_, 0); \
            ATL_vadd(s0_, s0_, t_); \
         }
      #else
         #define ATL_vvrsum1(s0_) \
         {  ATL_VTYPE t_;\
            t_ = vec_splat(s0_, 1); \
            ATL_vadd(s0_, s0_, t_); \
         }
      #endif
   @iexp i 0 0 +
   @iwhile i < 2
      #define ATL_vsplat@(i)(d_, s_) d_ = vec_splat(s_, @(i))
      @iexp i @(i) 1 +
   @endiwhile
   #endif
#elif defined(ATL_VXZ)
   #include <vecintrin.h>

   #if ATL_VLEN != 2
      #error "VSXZ supports only VLEN = 2!"
   #endif
   #define ATL_VTYPE vector double
   #if (defined(DREAL) || defined(DCPLX))
      #define ATL_vld(v_, p_) {v_[0] = *(p_); v_[1] = (p_)[1]; }
      #define ATL_vst(p_, v_)  {*(p_) = v_[0]; (p_)[1] = v_[1];}
   #else
      #define ATL_vld(v_, p_) v_ = vec_ld2f(p_);
      #define ATL_vst(p_, v_) vec_st2f(v_, p_);
   #endif
   #define ATL_vzero(v_) v_ = vec_splats((TYPE)0.0)
   #define ATL_vcopy(d_, s_) d_ = s_
   #define ATL_vbcast(v_, p_) v_ =  vec_splats(*((TYPE*)(p_)))
   #define ATL_vuld(v_, p_) ATL_vld(v_, p_)
   #define ATL_vust(p_, v_) ATL_vst(p_, v_)
   #define ATL_vadd(d_, s1_, s2_) d_ =  s1_ + s2_
   #define ATL_vsub(d_, s1_, s2_) d_ =  s1_ - s2_
   #define ATL_vmul(d_, s1_, s2_) d_ =  s1_ * s2_
   #define ATL_vmac(d_, s1_, s2_) d_ = vec_madd(s1_, s2_, d_)
   #define ATL_vvrsum1(s0_) \
   {  ATL_VTYPE t_;\
      t_ = vec_splat(s0_, 1); \
      s0 += t_; \
   }
   #define ATL_vsplat0(d_, s_) d_ = vec_splat(s_, 0)
   #define ATL_vsplat1(d_, s_) d_ = vec_splat(s_, 1)
#elif defined(ATL_NEON) && (defined(SREAL) || defined(SCPLX))
   #include "arm_neon.h"
   #define ATL_VTYPE float32x4_t
  #define ATL_vzero(v_) v_ = vdupq_n_f32(0.0f)
   #define ATL_vbcast(v_, p_) v_ =  vdupq_n_f32(*(p_));
   #define ATL_vld(v_, p_) v_ = vld1q_f32(p_)
   #define ATL_vst(p_, v_) vst1q_f32(p_, v_)
   #define ATL_vadd(d_, s1_, s2_) d_ = vaddq_f32(s1_, s2_)
   #define ATL_vsub(d_, s1_, s2_) d_ = vsubq_f32(s1_, s2_)
   #define ATL_vmul(d_, s1_, s2_) d_ = vmulq_f32(s1_, s2_)
   #define ATL_vmac(d_, s1_, s2_) d_ = vmlaq_f32(d_, s1_, s2_)
   #define ATL_vrsum1(d_, s_) \
   {  ATL_VTYPE t4_; float32x2_t t2_, t1_; \
      t1_ = vget_high_f32(s_); \
      t2_ = vget_low_f32(s_); \
      t2_ = vpadd_f32(t1_, t2_); \
      d_ = vget_lane_f32(t2_, 0); \
      d_ += vget_lane_f32(t2_, 1); \
   }
   #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
   { ATL_VTYPE t0_, t1_; \
      t0_[0] = s0_[0]; \
      t0_[1] = s1_[0]; \
      t0_[2] = s2_[0]; \
      t0_[3] = s3_[0]; \
      t1_[0] = s0_[1]; \
      t1_[1] = s1_[1]; \
      t1_[2] = s2_[1]; \
      t1_[3] = s3_[1]; \
      t0_ = vaddq_f32(t0_, t1_); \
      t1_[0] = s0_[2]; \
      t1_[1] = s1_[2]; \
      t1_[2] = s2_[2]; \
      t1_[3] = s3_[2]; \
      t0_ = vaddq_f32(t0_, t1_); \
      t1_[0] = s0_[3]; \
      t1_[1] = s1_[3]; \
      t1_[2] = s2_[3]; \
      t1_[3] = s3_[3]; \
      s0_ = vaddq_f32(t0_, t1_); \
   }
   @beginskip
   #define ATL_vsplat0(d_, s_) d_[0] = d_[1] = d_[2] = d_[3] = s_[0]
   #define ATL_vsplat1(d_, s_) d_[0] = d_[1] = d_[2] = d_[3] = s_[1]
   #define ATL_vsplat2(d_, s_) d_[0] = d_[1] = d_[2] = d_[3] = s_[2]
   #define ATL_vsplat3(d_, s_) d_[0] = d_[1] = d_[2] = d_[3] = s_[3]
   @endskip
   #define ATL_vsplat0(d_, s_) d_ = vmovq_n_f32(vgetq_lane_f32(s_, 0))
   #define ATL_vsplat1(d_, s_) d_ = vmovq_n_f32(vgetq_lane_f32(s_, 1))
   #define ATL_vsplat2(d_, s_) d_ = vmovq_n_f32(vgetq_lane_f32(s_, 2))
   #define ATL_vsplat3(d_, s_) d_ = vmovq_n_f32(vgetq_lane_f32(s_, 3))
   #define ATL_vuld(v_, p_) ATL_vld(v_, p_)
   #define ATL_vust(p_, v_) ATL_vst(p_, v_)
#elif defined(ATL_VECARM1)
   #include "arm_neon.h"
   #if defined(SREAL) || defined(SCPLX)
      #define ATL_VTYPE float32x4_t
   #else
      #define ATL_VTYPE float64x2_t
   #endif
   #if defined(SREAL) || defined(SCPLX)
      #define ATL_vzero(v_) v_ = vdupq_n_f32(0.0f)
      #define ATL_vbcast(v_, p_) v_ =  vld1q_dup_f32(p_)
      #define ATL_vld(v_, p_) v_ = vld1q_f32(p_)
      #define ATL_vst(p_, v_) vst1q_f32(p_, v_)
      #define ATL_vadd(d_, s1_, s2_) d_ = vaddq_f32(s1_, s2_)
      #define ATL_vsub(d_, s1_, s2_) d_ = vsubq_f32(s1_, s2_)
      #define ATL_vmul(d_, s1_, s2_) d_ = vmulq_f32(s1_, s2_)
      #define ATL_vmac(d_, s1_, s2_) d_ = vfmaq_f32(d_, s1_, s2_)
      #define ATL_vrsum1(d_, s_) \
      {  ATL_VTYPE t4_; float32x2_t t2_, t1_; \
         t1_ = vget_high_f32(s_); \
         t2_ = vget_low_f32(s_); \
         t2_ = vpadd_f32(t1_, t2_); \
         d_ = vget_lane_f32(t2_, 0); \
         d_ += vget_lane_f32(t2_, 1); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      { ATL_VTYPE t0_, t1_; \
         t0_[0] = s0_[0]; \
         t0_[1] = s1_[0]; \
         t0_[2] = s2_[0]; \
         t0_[3] = s3_[0]; \
         t1_[0] = s0_[1]; \
         t1_[1] = s1_[1]; \
         t1_[2] = s2_[1]; \
         t1_[3] = s3_[1]; \
         t0_ = vaddq_f32(t0_, t1_); \
         t1_[0] = s0_[2]; \
         t1_[1] = s1_[2]; \
         t1_[2] = s2_[2]; \
         t1_[3] = s3_[2]; \
         t0_ = vaddq_f32(t0_, t1_); \
         t1_[0] = s0_[3]; \
         t1_[1] = s1_[3]; \
         t1_[2] = s2_[3]; \
         t1_[3] = s3_[3]; \
         s0_ = vaddq_f32(t0_, t1_); \
      }
   @iexp i 0 0 +
   @iwhile i < 4
      #define ATL_vsplat@(i)(d_, s_) d_ = vdupq_laneq_f32(s_, @(i))
      @iexp i @(i) 1 +
   @endiwhile
   #else  /* double */
      #define ATL_vzero(v_) v_ = vdupq_n_f64(0.0)
@skip      #define ATL_vbcast(v_, p_) v_ =  vdupq_n_f64((*p_))
      #define ATL_vbcast(v_, p_) v_ =  vld1q_dup_f64(p_)
      #define ATL_vld(v_, p_) v_ = vld1q_f64(p_)
      #define ATL_vst(p_, v_) vst1q_f64(p_, v_)
      #define ATL_vadd(d_, s1_, s2_) d_ = vaddq_f64(s1_, s2_)
      #define ATL_vsub(d_, s1_, s2_) d_ = vsubq_f64(s1_, s2_)
      #define ATL_vmul(d_, s1_, s2_) d_ = vmulq_f64(s1_, s2_)
      #define ATL_vmac(d_, s1_, s2_) d_ = vfmaq_f64(d_, s1_, s2_)
      #define ATL_vrsum1(d_, s_) d_ = vget_low_f64(vpaddq_f64(s_, s_))
      #define ATL_vvrsum2(s0_, s1_) s0_ = vpaddq_f64(s0_, s1_)
   @iexp i 0 0 +
   @iwhile i < 2
      #define ATL_vsplat@(i)(d_, s_) d_ = vdupq_laneq_f64(s_, @(i))
      @iexp i @(i) 1 +
   @endiwhile
   #endif
   #define ATL_vuld(v_, p_) ATL_vld(v_, p_)
   #define ATL_vust(p_, v_) ATL_vst(p_, v_)
#elif defined(ATL_AVXZ) && \
      ( (ATL_VLEN == 16 && (defined(SREAL) || defined(SCPLX))) || \
        (ATL_VLEN ==  8 && (defined(DREAL) || defined(DCPLX))) )
   #include <immintrin.h>
   #if defined(SREAL) || defined(SCPLX)
      #define ATL_VTYPE __m512
      #define ATL_vzero(v_) v_ = _mm512_setzero_ps()
      #define ATL_vbcast(v_, p_) v_ =  _mm512_set1_ps(*(p_))
      #define ATL_vuld(v_, p_) v_ = _mm512_loadu_ps(p_)
      #define ATL_vld(v_, p_) v_ = _mm512_load_ps(p_)
      #define ATL_vust(p_, v_) _mm512_storeu_ps(p_, v_)
      #define ATL_vst(p_, v_) _mm512_store_ps(p_, v_)
      #define ATL_vadd(d_, s1_, s2_) d_ =  _mm512_add_ps(s1_, s2_)
      #define ATL_vsub(d_, s1_, s2_) d_ =  _mm512_sub_ps(s1_, s2_)
      #define ATL_vmul(d_, s1_, s2_) d_ =  _mm512_mul_ps(s1_, s2_)
      #ifdef ATL_AVXMAC
         #define ATL_vmac(d_, s1_, s2_) \
            d_ = _mm512_fmadd_ps(s1_, s2_, d_)
      #else
         #define ATL_vmac(d_, s1_, s2_) \
         { ATL_VTYPE t_; \
            t_ = _mm512_mul_ps(s1_, s2_); \
            d_ = _mm512_add_ps(t_, d_); \
         }
      #endif
      #define ATL_vvrsum8_256(s0_, s1_, s2_, s3_, s4_, s5_, s6_, s7_) \
      { \
         s0_ = _mm256_hadd_ps(s0_, s1_); \
            /*{s1gh,s1ef,s0gh,s0ef,s1cd,s1ab,s0cd,s0ab}*/\
         s2_ = _mm256_hadd_ps(s2_, s3_); \
            /*{s3gh,s3ef,s2gh,s2ef,s3cd,s3ab,s2cd,s2ab}*/\
         s4_ = _mm256_hadd_ps(s4_, s5_); \
            /*{s5gh,s5ef,s4gh,s4ef,s5cd,s5ab,s4cd,s4ab}*/\
         s6_ = _mm256_hadd_ps(s6_, s7_); \
            /*{s7gh,s7ef,s6gh,s6ef,s7cd,s7ab,s6cd,s6ab}*/\
         s0_ = _mm256_hadd_ps(s0_, s2_); \
            /*{s3e-h,s2e-h,s1e-h,s0e-g,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         s4_ = _mm256_hadd_ps(s4_, s6_); \
            /*{s7e-h,s6e-h,s5e-h,s4e-g,s7a-d,s6a-d,s5a-d,s4a-d}*/\
         s1_ = _mm256_permute2f128_ps(s0_, s4_, 0x31); \
            /*{s7e-h,s6e-h,s5e-h,s4e-g,s3e-h,s2e-h,s1e-h,s0e-g}*/\
         s0_ = _mm256_permute2f128_ps(s0_, s4_, 0x20); \
            /*{s7a-d,s6a-d,s5a-d,s4a-d,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         s0_ = _mm256_add_ps(s0_, s1_); \
      }
      #define ATL_vvrsum4_256(s0_, s1_, s2_, s3_) \
      { \
         s0_ = _mm256_hadd_ps(s0_, s1_); \
            /*{s1gh,s1ef,s0gh,s0ef,s1cd,s1ab,s0cd,s0ab}*/\
         s2_ = _mm256_hadd_ps(s2_, s3_); \
            /*{s3gh,s3ef,s2gh,s2ef,s3cd,s3ab,s2cd,s2ab}*/\
         s0_ = _mm256_hadd_ps(s0_, s2_); \
            /*{s3e-h,s2e-h,s1e-h,s0e-g,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         s1_ = _mm256_permute2f128_ps(s0_, s0_, 0x31); \
            /*{s3e-h,s2e-h,s1e-h,s0e-g,s3e-h,s2e-h,s1e-h,s0e-g}*/\
         s0_ = _mm256_permute2f128_ps(s0_, s0_, 0x20); \
            /*{s3a-d,s2a-d,s1a-d,s0a-d,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         s0_ = _mm256_add_ps(s0_, s1_); \
      }
      #define ATL_vvrsum2_256(s0_, s1_) \
      { \
         s0_ = _mm256_hadd_ps(s0_, s1_); \
            /*{s1gh,s1ef,s0gh,s0ef,s1cd,s1ab,s0cd,s0ab}*/\
         s0_ = _mm256_hadd_ps(s0_, s0_); \
            /*{s1e-h,s0e-h,s1e-h,s0e-g,s1a-d,s0a-d,s1a-d,s0a-d}*/\
         s1_ = _mm256_permute2f128_ps(s0_, s0_, 0x31); \
            /*{s1e-h,s0e-h,s1e-h,s0e-g,s1e-h,s0e-h,s1e-h,s0e-g}*/\
         s0_ = _mm256_permute2f128_ps(s0_, s0_, 0x20); \
            /*{s1a-d,s0a-d,s1a-d,s0a-d,s1a-d,s0a-d,s1a-d,s0a-d}*/\
         s0_ = _mm256_add_ps(s0_, s1_); \
      }
      #define ATL_vrsum1(d_, s_) \
      { __m256 t0_, t1_; __m128 x0_, x1_; \
         t0_ = _mm512_extractf32x8_ps(s_, 0); \
         t1_ = _mm512_extractf32x8_ps(s_, 1); \
         t0_ = _mm256_add_ps(t0_, t1_); \
         x0_ = _mm256_extractf128_ps(t0_, 0); \
         x1_ = _mm256_extractf128_ps(t0_, 1); \
         x0_ = _mm_add_ps(x0_, x1_); \
         x0_ = _mm_hadd_ps(x0_, x0_); /* {X,X,x0dc,x0ab} */ \
         x0_ = _mm_hadd_ps(x0_, x0_); /* {X,X,X,x0abcd} */ \
         d_ = x0_[0]; \
      }
      #define ATL_vvrsum1(s0_) \
      { __m256 t0_, t1_; __m128 x0_, x1_; \
         t0_ = _mm512_extractf32x8_ps(s0_, 0); \
         t1_ = _mm512_extractf32x8_ps(s0_, 1); \
         t0_ = _mm256_add_ps(t0_, t1_); \
         x0_ = _mm256_extractf128_ps(t0_, 0); \
         x1_ = _mm256_extractf128_ps(t0_, 1); \
         x0_ = _mm_add_ps(x0_, x1_); \
         x0_ = _mm_hadd_ps(x0_, x0_); /* {X,X,x0dc,x0ab} */ \
         x0_ = _mm_hadd_ps(x0_, x0_); /* {X,X,X,x0abcd} */ \
         s0_ = _mm512_insertf32x4(s0_, x0_, 0); \
      }
      #define ATL_vvrsum2(s0_, s1_) \
      { __m256 t0_, t1_, t2_, t3_; \
         t0_ = _mm512_extractf32x8_ps(s0_, 0); \
         t1_ = _mm512_extractf32x8_ps(s0_, 1); \
         t0_ = _mm256_add_ps(t0_, t1_); \
         t2_ = _mm512_extractf32x8_ps(s1_, 0); \
         t1_ = _mm512_extractf32x8_ps(s1_, 1); \
         t2_ = _mm256_add_ps(t2_, t1_); \
         ATL_vvrsum2_256(t0_, t2_); \
         s0_ = _mm512_insertf32x8(s0_, t0_, 0); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      { __m256 t0_, t1_, t2_, t3_, t4_, t5_, t6_, t7_; \
         t0_ = _mm512_extractf32x8_ps(s0_, 0); \
         t4_ = _mm512_extractf32x8_ps(s0_, 1); \
         t0_ = _mm256_add_ps(t0_, t4_); \
         t1_ = _mm512_extractf32x8_ps(s1_, 0); \
         t4_ = _mm512_extractf32x8_ps(s1_, 1); \
         t1_ = _mm256_add_ps(t1_, t4_); \
         t2_ = _mm512_extractf32x8_ps(s2_, 0); \
         t4_ = _mm512_extractf32x8_ps(s2_, 1); \
         t2_ = _mm256_add_ps(t2_, t4_); \
         t3_ = _mm512_extractf32x8_ps(s3_, 0); \
         t4_ = _mm512_extractf32x8_ps(s3_, 1); \
         t3_ = _mm256_add_ps(t3_, t4_); \
         ATL_vvrsum4_256(t0_, t1_, t2_, t3_); \
         s0_ = _mm512_insertf32x8(s0_, t0_, 0); \
      }
      #define ATL_vvrsum8_512_256(t0_, s0_, s1_, s2_, s3_, s4_, s5_, s6_, s7_) \
      { __m256 t1_, t2_, t3_, t4_, t5_, t6_, t7_, t8_; \
         t0_ = _mm512_extractf32x8_ps(s0_, 0); \
         t8_ = _mm512_extractf32x8_ps(s0_, 1); \
         t0_ = _mm256_add_ps(t0_, t8_); \
         t1_ = _mm512_extractf32x8_ps(s1_, 0); \
         t8_ = _mm512_extractf32x8_ps(s1_, 1); \
         t1_ = _mm256_add_ps(t1_, t8_); \
         t2_ = _mm512_extractf32x8_ps(s2_, 0); \
         t8_ = _mm512_extractf32x8_ps(s2_, 1); \
         t2_ = _mm256_add_ps(t2_, t8_); \
         t3_ = _mm512_extractf32x8_ps(s3_, 0); \
         t8_ = _mm512_extractf32x8_ps(s3_, 1); \
         t3_ = _mm256_add_ps(t3_, t8_); \
         t4_ = _mm512_extractf32x8_ps(s4_, 0); \
         t8_ = _mm512_extractf32x8_ps(s4_, 1); \
         t4_ = _mm256_add_ps(t4_, t8_); \
         t5_ = _mm512_extractf32x8_ps(s5_, 0); \
         t8_ = _mm512_extractf32x8_ps(s5_, 1); \
         t5_ = _mm256_add_ps(t5_, t8_); \
         t6_ = _mm512_extractf32x8_ps(s6_, 0); \
         t8_ = _mm512_extractf32x8_ps(s6_, 1); \
         t6_ = _mm256_add_ps(t6_, t8_); \
         t7_ = _mm512_extractf32x8_ps(s7_, 0); \
         t8_ = _mm512_extractf32x8_ps(s7_, 1); \
         t7_ = _mm256_add_ps(t7_, t8_); \
         ATL_vvrsum8_256(t0_, t1_, t2_, t3_, t4_, t5_, t6_, t7_); \
      }
      #define ATL_vvrsum8(s0_, s1_, s2_, s3_, s4_, s5_, s6_, s7_) \
      { __m256 t0_;\
         ATL_vvrsum8_512_256(t0_, s0_, s1_, s2_, s3_, s4_, s5_, s6_, s7_); \
         s0_ = _mm512_insertf32x8(s0_, t0_, 0); \
      }
      #define ATL_vvrsum16(s0_, s1_, s2_, s3_, s4_, s5_, s6_, s7_, \
                           s8_, s9_, sA_, sB_, sC_, sD_, sE_, sF_) \
      { __m256 t0_;\
         ATL_vvrsum8_512_256(t0_, s0_, s1_, s2_, s3_, s4_, s5_, s6_, s7_); \
         s0_ = _mm512_insertf32x8(s0_, t0_, 0); \
         ATL_vvrsum8_512_256(t0_, s8_, s9_, sA_, sB_, sC_, sD_, sE_, sF_); \
         s0_ = _mm512_insertf32x8(s0_, t0_, 1); \
      }
      #define ATL_vsplat0(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,0)); \
      }
      #define ATL_vsplat1(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0x55); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,0)); \
      }
      #define ATL_vsplat2(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0xAA); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,0)); \
      }
      #define ATL_vsplat3(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0xFF); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,0)); \
      }
      #define ATL_vsplat4(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,1)); \
      }
      #define ATL_vsplat5(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0x55); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,1)); \
      }
      #define ATL_vsplat6(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0xAA); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,1)); \
      }
      #define ATL_vsplat7(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0xFF); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,1)); \
      }
      #define ATL_vsplat8(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,2)); \
      }
      #define ATL_vsplat9(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0x55); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,2)); \
      }
      #define ATL_vsplat10(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0xAA); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,2)); \
      }
      #define ATL_vsplat11(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0xFF); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,2)); \
      }
      #define ATL_vsplat12(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,3)); \
      }
      #define ATL_vsplat13(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0x55); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,3)); \
      }
      #define ATL_vsplat14(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0xAA); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,3)); \
      }
      #define ATL_vsplat15(d_, s_) \
      { \
         d_ = _mm512_shuffle_ps(s_, s_, 0xFF); \
         d_ = _mm512_broadcast_f32x4(_mm512_extractf32x4_ps(d_,3)); \
      }
   #else        /* double precision */
      #if ATL_VLEN == 8
         #define ATL_VTYPE __m512d
      #else
         #error "AVX SUPPORTS ONLY VLEN=8 FOR DOUBLE!"
      #endif
      #define ATL_vzero(v_) v_ = _mm512_setzero_pd()
      #define ATL_vbcast(v_, p_) v_ =  _mm512_set1_pd(*(p_))
      #define ATL_vuld(v_, p_) v_ = _mm512_loadu_pd(p_)
      #define ATL_vld(v_, p_) v_ = _mm512_load_pd(p_)
      #define ATL_vust(p_, v_) _mm512_storeu_pd(p_, v_)
      #define ATL_vst(p_, v_) _mm512_store_pd(p_, v_)
      #define ATL_vadd(d_, s1_, s2_) d_ =  _mm512_add_pd(s1_, s2_)
      #define ATL_vsub(d_, s1_, s2_) d_ =  _mm512_sub_pd(s1_, s2_)
      #define ATL_vmul(d_, s1_, s2_) d_ =  _mm512_mul_pd(s1_, s2_)
      #ifdef ATL_AVXMAC
         #define ATL_vmac(d_, s1_, s2_) \
            d_ = _mm512_fmadd_pd(s1_, s2_, d_)
      #else
         #define ATL_vmac(d_, s1_, s2_) \
         { ATL_VTYPE t_; \
            t_ = _mm512_mul_pd(s1_, s2_); \
            d_ = _mm512_add_pd(t_, d_); \
         }
      #endif
      #define ATL_vvrsum4_256(s0_, s1_, s2_, s3_) \
      { \
         s0_ = _mm256_hadd_pd(s0_, s1_); /*{s1cd,s0cd,s1ab,s0ab}*/ \
         s2_ = _mm256_hadd_pd(s2_, s3_); /*{s3cd,s2cd,s3ab,s2ab}*/ \
         s1_ = _mm256_permute2f128_pd(s0_, s2_,0x31);/*{s3cd,s2cd,s1cd,s0cd}*/ \
         s0_ = _mm256_permute2f128_pd(s0_, s2_,0x20);/*{s3ab,s2ab,s1ab,s0ab}*/ \
         s0_ = _mm256_add_pd(s0_, s1_); \
      }
      #define ATL_vvrsum2_256(s0_, s1_) \
      { \
         s0_ = _mm256_hadd_pd(s0_, s1_); /*{s1cd,s0cd,s1ab,s0ab}*/ \
         s1_ = _mm256_permute2f128_pd(s0_, s1_,0x31);/*{s3cd,s2cd,s1cd,s0cd}*/ \
         s0_ = _mm256_add_pd(s0_, s1_); \
      }
      #define ATL_vvrsum4_512_256(t0_, s0_, s1_, s2_, s3_) \
      {  __m256d tt_, t1_, t2_, t3_; \
         t0_ = _mm512_extractf64x4_pd(s0_, 0); \
         tt_ = _mm512_extractf64x4_pd(s0_, 1); \
         t0_ = _mm256_add_pd(t0_, tt_); \
         t1_ = _mm512_extractf64x4_pd(s1_, 0); \
         tt_ = _mm512_extractf64x4_pd(s1_, 1); \
         t1_ = _mm256_add_pd(t1_, tt_); \
         t2_ = _mm512_extractf64x4_pd(s2_, 0); \
         tt_ = _mm512_extractf64x4_pd(s2_, 1); \
         t2_ = _mm256_add_pd(t2_, tt_); \
         t3_ = _mm512_extractf64x4_pd(s3_, 0); \
         tt_ = _mm512_extractf64x4_pd(s3_, 1); \
         t3_ = _mm256_add_pd(t3_, tt_); \
         ATL_vvrsum4_256(t0_, t1_, t2_, t3_); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      { \
         __m256d t0_; \
         ATL_vvrsum4_512_256(t0_, s0_, s1_, s2_, s3_); \
         s0_ = _mm512_insertf64x4(s0_, t0_, 0); \
      }
      #define ATL_vvrsum8(s0_, s1_, s2_, s3_, s4_, s5_, s6_, s7_) \
      {  __m256d t0_; \
         ATL_vvrsum4_512_256(t0_, s0_, s1_, s2_, s3_); \
         s0_ = _mm512_insertf64x4(s0_, t0_, 0); \
         ATL_vvrsum4_512_256(t0_, s4_, s5_, s6_, s7_); \
         s0_ = _mm512_insertf64x4(s0_, t0_, 1); \
      }
      #define ATL_vvrsum2(s0_, s1_) \
      {  __m256d t0_, t1_, t2_; \
         t0_ = _mm512_extractf64x4_pd(s0_, 0); \
         t1_ = _mm512_extractf64x4_pd(s0_, 1); \
         t0_ = _mm256_add_pd(t0_, t1_); \
         t2_ = _mm512_extractf64x4_pd(s1_, 0); \
         t1_ = _mm512_extractf64x4_pd(s1_, 1); \
         t2_ = _mm256_add_pd(t2_, t1_); \
         ATL_vvrsum2_256(t0_, t2_); \
         s0_ = _mm512_insertf64x4(s0_, t0_, 0); \
      }
      #define ATL_vrsum1(d_, s_) \
      { __m256d t0_, t1_; __m128d x0_, x1_; \
         t0_ = _mm512_extractf64x4_pd(s_, 0); \
         t1_ = _mm512_extractf64x4_pd(s_, 1); \
         t0_ = _mm256_add_pd(t0_, t1_); \
         x0_ = _mm256_extractf128_pd(t0_, 0); \
         x1_ = _mm256_extractf128_pd(t0_, 1); \
         x0_ = _mm_add_pd(x0_, x1_); \
         x0_ = _mm_hadd_pd(x0_, x0_); \
         d_ = x0_[0];  \
      }
      #define ATL_vvrsum1(s0_) \
      { __m256d t0_, t1_; __m128d x0_, x1_; \
         t0_ = _mm512_extractf64x4_pd(s0_, 0); \
         t1_ = _mm512_extractf64x4_pd(s0_, 1); \
         t0_ = _mm256_add_pd(t0_, t1_); \
         x0_ = _mm256_extractf128_pd(t0_, 0); \
         x1_ = _mm256_extractf128_pd(t0_, 1); \
         x0_ = _mm_add_pd(x0_, x1_); \
         x0_ = _mm_hadd_pd(x0_, x0_); \
         s0_ = _mm512_insertf64x2(s0_, x0_, 0); \
      }
      #define ATL_vsplat0(d_, s_) \
      { \
         d_ = _mm512_broadcastsd_pd(_mm256_extractf128_pd(_mm512_extractf64x4_pd(s_, 0), 0)); \
      }
      #define ATL_vsplat2(d_, s_) \
      { \
         d_ = _mm512_broadcastsd_pd(_mm256_extractf128_pd(_mm512_extractf64x4_pd(s_, 0), 1)); \
      }
      #define ATL_vsplat1(d_, s_) \
      { \
         d_ = _mm512_unpackhi_pd(s_, s_); \
         d_ = _mm512_broadcastsd_pd(_mm256_extractf128_pd(_mm512_extractf64x4_pd(d_, 0), 0)); \
      }
      #define ATL_vsplat3(d_, s_) \
      { \
         d_ = _mm512_unpackhi_pd(s_, s_); \
         d_ = _mm512_broadcastsd_pd(_mm256_extractf128_pd(_mm512_extractf64x4_pd(d_, 0), 1)); \
      }
      #define ATL_vsplat4(d_, s_) \
      { \
         d_ = _mm512_broadcastsd_pd(_mm256_extractf128_pd(_mm512_extractf64x4_pd(s_, 1), 0)); \
      }
      #define ATL_vsplat6(d_, s_) \
      { \
         d_ = _mm512_broadcastsd_pd(_mm256_extractf128_pd(_mm512_extractf64x4_pd(s_, 1), 1)); \
      }
      #define ATL_vsplat5(d_, s_) \
      { \
         d_ = _mm512_unpackhi_pd(s_, s_); \
         d_ = _mm512_broadcastsd_pd(_mm256_extractf128_pd(_mm512_extractf64x4_pd(d_, 1), 0)); \
      }
      #define ATL_vsplat7(d_, s_) \
      { \
         d_ = _mm512_unpackhi_pd(s_, s_); \
         d_ = _mm512_broadcastsd_pd(_mm256_extractf128_pd(_mm512_extractf64x4_pd(d_, 1), 1)); \
      }
   #endif
#elif defined(ATL_AVXMAC) || defined(ATL_AVX)
   #include <immintrin.h>
   #if defined(SREAL) || defined(SCPLX)
      #if ATL_VLEN == 8
         #define ATL_VTYPE __m256
      #else
         #error "VLEN != 8 not supported for AVX/AVX2!"
      #endif
      #define ATL_vzero(v_) v_ = _mm256_setzero_ps()
      #define ATL_vbcast(v_, p_) v_ =  _mm256_broadcast_ss(p_)
      #define ATL_vuld(v_, p_) v_ = _mm256_loadu_ps(p_)
      #define ATL_vld(v_, p_) v_ = _mm256_load_ps(p_)
      #define ATL_vust(p_, v_) _mm256_storeu_ps(p_, v_)
      #define ATL_vst(p_, v_) _mm256_store_ps(p_, v_)
      #define ATL_vadd(d_, s1_, s2_) d_ =  _mm256_add_ps(s1_, s2_)
      #define ATL_vsub(d_, s1_, s2_) d_ =  _mm256_sub_ps(s1_, s2_)
      #define ATL_vmul(d_, s1_, s2_) d_ =  _mm256_mul_ps(s1_, s2_)
      #ifdef ATL_AVXMAC
         #define ATL_vmac(d_, s1_, s2_) \
            d_ = _mm256_fmadd_ps(s1_, s2_, d_)
      #else
         #define ATL_vmac(d_, s1_, s2_) \
         { ATL_VTYPE t_; \
            t_ = _mm256_mul_ps(s1_, s2_); \
            d_ = _mm256_add_ps(t_, d_); \
         }
      #endif
      #define ATL_vvrsum8(s0_, s1_, s2_, s3_, s4_, s5_, s6_, s7_) \
      { \
         s0_ = _mm256_hadd_ps(s0_, s1_); \
            /*{s1gh,s1ef,s0gh,s0ef,s1cd,s1ab,s0cd,s0ab}*/\
         s2_ = _mm256_hadd_ps(s2_, s3_); \
            /*{s3gh,s3ef,s2gh,s2ef,s3cd,s3ab,s2cd,s2ab}*/\
         s4_ = _mm256_hadd_ps(s4_, s5_); \
            /*{s5gh,s5ef,s4gh,s4ef,s5cd,s5ab,s4cd,s4ab}*/\
         s6_ = _mm256_hadd_ps(s6_, s7_); \
            /*{s7gh,s7ef,s6gh,s6ef,s7cd,s7ab,s6cd,s6ab}*/\
         s0_ = _mm256_hadd_ps(s0_, s2_); \
            /*{s3e-h,s2e-h,s1e-h,s0e-g,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         s4_ = _mm256_hadd_ps(s4_, s6_); \
            /*{s7e-h,s6e-h,s5e-h,s4e-g,s7a-d,s6a-d,s5a-d,s4a-d}*/\
         s1_ = _mm256_permute2f128_ps(s0_, s4_, 0x31); \
            /*{s7e-h,s6e-h,s5e-h,s4e-g,s3e-h,s2e-h,s1e-h,s0e-g}*/\
         s0_ = _mm256_permute2f128_ps(s0_, s4_, 0x20); \
            /*{s7a-d,s6a-d,s5a-d,s4a-d,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      { \
         s0_ = _mm256_hadd_ps(s0_, s1_); \
            /*{s1gh,s1ef,s0gh,s0ef,s1cd,s1ab,s0cd,s0ab}*/\
         s2_ = _mm256_hadd_ps(s2_, s3_); \
            /*{s3gh,s3ef,s2gh,s2ef,s3cd,s3ab,s2cd,s2ab}*/\
         s0_ = _mm256_hadd_ps(s0_, s2_); \
            /*{s3e-h,s2e-h,s1e-h,s0e-g,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         s1_ = _mm256_permute2f128_ps(s0_, s0_, 0x31); \
            /*{s3e-h,s2e-h,s1e-h,s0e-g,s3e-h,s2e-h,s1e-h,s0e-g}*/\
         s0_ = _mm256_permute2f128_ps(s0_, s0_, 0x20); \
            /*{s3a-d,s2a-d,s1a-d,s0a-d,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vvrsum2(s0_, s1_) \
      { \
         s0_ = _mm256_hadd_ps(s0_, s1_); \
            /*{s1gh,s1ef,s0gh,s0ef,s1cd,s1ab,s0cd,s0ab}*/\
         s0_ = _mm256_hadd_ps(s0_, s0_); \
            /*{s1e-h,s0e-h,s1e-h,s0e-g,s1a-d,s0a-d,s1a-d,s0a-d}*/\
         s1_ = _mm256_permute2f128_ps(s0_, s0_, 0x31); \
            /*{s1e-h,s0e-h,s1e-h,s0e-g,s1e-h,s0e-h,s1e-h,s0e-g}*/\
         s0_ = _mm256_permute2f128_ps(s0_, s0_, 0x20); \
            /*{s1a-d,s0a-d,s1a-d,s0a-d,s1a-d,s0a-d,s1a-d,s0a-d}*/\
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vvrsum1(s0_) \
      {  ATL_VTYPE t1_; \
         s0_ = _mm256_hadd_ps(s0_, s0_); \
            /*{s0gh,s0ef,s0gh,s0ef,s0cd,s0ab,s0cd,s0ab}*/\
         s0_ = _mm256_hadd_ps(s0_, s0_); \
            /*{s0e-h,s0e-h,s0e-h,s0e-g,s0a-d,s0a-d,s0a-d,s0a-d}*/\
         t1_ = _mm256_permute2f128_ps(s0_, s0_, 0x31); \
            /*{s0e-h,s0e-h,s0e-h,s0e-g,s0e-h,s0e-h,s0e-h,s0e-g}*/\
         s0_ = _mm256_permute2f128_ps(s0_, s0_, 0x20); \
            /*{s0a-d,s0a-d,s0a-d,s0a-d,s0a-d,s0a-d,s0a-d,s0a-d}*/\
         ATL_vadd(s0_, s0_, t1_); \
      }
      #define ATL_vsplat0(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,0), 1); \
      }
      #define ATL_vsplat1(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0x55); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,0), 1); \
      }
      #define ATL_vsplat2(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0xAA); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,0), 1); \
      }
      #define ATL_vsplat3(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0xFF); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,0), 1); \
      }
      #define ATL_vsplat4(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,1), 0); \
      }
      #define ATL_vsplat5(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0x55); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,1), 0); \
      }
      #define ATL_vsplat6(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0xAA); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,1), 0); \
      }
      #define ATL_vsplat7(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0xFF); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,1), 0); \
      }
   #else        /* double precision */
      #if ATL_VLEN == 4
         #define ATL_VTYPE __m256d
      #elif ATL_VLEN == 8
         #define ATL_VTYPE __m512d
      #elif ATL_VLEN == 2
         #define ATL_VTYPE __m128d
      #else
         #error "AVX SUPPORTS ONLY VLEN=[2,4,8] FOR DOUBLE!"
      #endif
      #define ATL_vzero(v_) v_ = _mm256_setzero_pd()
      #define ATL_vbcast(v_, p_) v_ =  _mm256_broadcast_sd(p_)
      #define ATL_vuld(v_, p_) v_ = _mm256_loadu_pd(p_)
      #define ATL_vld(v_, p_) v_ = _mm256_load_pd(p_)
      #define ATL_vust(p_, v_) _mm256_storeu_pd(p_, v_)
      #define ATL_vst(p_, v_) _mm256_store_pd(p_, v_)
      #define ATL_vadd(d_, s1_, s2_) d_ =  _mm256_add_pd(s1_, s2_)
      #define ATL_vsub(d_, s1_, s2_) d_ =  _mm256_sub_pd(s1_, s2_)
      #define ATL_vmul(d_, s1_, s2_) d_ =  _mm256_mul_pd(s1_, s2_)
      #ifdef ATL_AVXMAC
         #define ATL_vmac(d_, s1_, s2_) \
            d_ = _mm256_fmadd_pd(s1_, s2_, d_)
      #else
         #define ATL_vmac(d_, s1_, s2_) \
         { ATL_VTYPE t_; \
            t_ = _mm256_mul_pd(s1_, s2_); \
            d_ = _mm256_add_pd(t_, d_); \
         }
      #endif
      #define ATL_vrsum1(d_, s_) \
      {  __m128d t_; \
         t_ = _mm_add_pd(_mm256_extractf128_pd(s_, 0), \
                         _mm256_extractf128_pd(s_, 1)); \
         t_ = _mm_hadd_pd(t_, t_); \
         d_ = _mm_cvtsd_f64(t_); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      { \
         s0_ = _mm256_hadd_pd(s0_, s1_); /*{s1cd,s0cd,s1ab,s0ab}*/ \
         s2_ = _mm256_hadd_pd(s2_, s3_); /*{s3cd,s2cd,s3ab,s2ab}*/ \
         s1_ = _mm256_permute2f128_pd(s0_, s2_,0x31);/*{s3cd,s2cd,s1cd,s0cd}*/ \
         s0_ = _mm256_permute2f128_pd(s0_, s2_,0x20);/*{s3ab,s2ab,s1ab,s0ab}*/ \
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vvrsum2(s0_, s1_) \
      { \
         s0_ = _mm256_hadd_pd(s0_, s1_); /*{s1cd,s0cd,s1ab,s0ab}*/ \
         s1_ = _mm256_permute2f128_pd(s0_, s1_,0x31);/*{s3cd,s2cd,s1cd,s0cd}*/ \
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vvrsum1(s0_) \
      { ATL_VTYPE s1_; \
         s0_ = _mm256_hadd_pd(s0_, s0_); /*{s0cd,s0cd,s0ab,s0ab}*/ \
         s1_ = _mm256_permute2f128_pd(s0_, s1_,0x31);/*{s0cd,s0cd,s0cd,s0cd}*/ \
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vsplat0(d_, s_) \
      { \
         d_ = _mm256_unpacklo_pd(s_, s_); \
         d_ = _mm256_insertf128_pd(d_, _mm256_extractf128_pd(d_,0), 1); \
      }
      #define ATL_vsplat2(d_, s_) \
      { \
         d_ = _mm256_unpacklo_pd(s_, s_); \
         d_ = _mm256_insertf128_pd(d_, _mm256_extractf128_pd(d_,1), 0); \
      }
      #define ATL_vsplat1(d_, s_) \
      { \
         d_ = _mm256_unpackhi_pd(s_, s_); \
         d_ = _mm256_insertf128_pd(d_, _mm256_extractf128_pd(d_,0), 1); \
      }
      #define ATL_vsplat3(d_, s_) \
      { \
         d_ = _mm256_unpackhi_pd(s_, s_); \
         d_ = _mm256_insertf128_pd(d_, _mm256_extractf128_pd(d_,1), 0); \
      }
   #endif
#elif defined(ATL_SSE2) && (defined(DREAL) || defined(DCPLX))
   #include <xmmintrin.h>
   #if defined(ATL_SSE3)
      #include <pmmintrin.h>
      #include <tmmintrin.h>
   #endif
   #define ATL_VTYPE __m128d
   #if ATL_VLEN != 2
      #error "VLEN == 2 only supported size for double precision SSE!"
   #endif
   #define ATL_vzero(v_) v_ = _mm_setzero_pd()
   #define ATL_vbcast(v_, p_) v_ =  _mm_load1_pd(p_)
   #define ATL_vuld(v_, p_) v_ = _mm_loadu_pd(p_)
   #define ATL_vld(v_, p_) v_ = _mm_load_pd(p_)
   #define ATL_vust(p_, v_) _mm_storeu_pd(p_, v_)
   #define ATL_vst(p_, v_) _mm_store_pd(p_, v_)
   #define ATL_vadd(d_, s1_, s2_) d_ =  _mm_add_pd(s1_, s2_)
   #define ATL_vsub(d_, s1_, s2_) d_ =  _mm_sub_pd(s1_, s2_)
   #define ATL_vmul(d_, s1_, s2_) d_ =  _mm_mul_pd(s1_, s2_)
   #define ATL_vmac(d_, s1_, s2_) \
   { ATL_VTYPE t_; \
      t_ = _mm_mul_pd(s1_, s2_); \
      d_ = _mm_add_pd(t_, d_); \
   }
   #ifdef ATL_SSE3
      #define ATL_vrsum1(d_, s_) d_ = _mm_cvtsd_f64(_mm_hadd_pd(s_, s_))
      #define ATL_vvrsum2(s0_, s1_) s0_ = _mm_hadd_pd(s0_, s1_)
      #define ATL_vvrsum1(s0_) s0_ = _mm_hadd_pd(s0_, s0_)
      #define ATL_vsplat0(d_, s_) d_ = _mm_movedup_pd(s_)
      #define ATL_vsplat1(d_, s_) d_ = (ATL_VTYPE) \
         _mm_shuffle_epi32((__m128i)(s_), 0xEE)
   #else
      #define ATL_vrsum1(d_, s_) \
         d_ = _mm_cvtsd_f64(_mm_add_sd(_mm_unpackhi_pd(s_, s_), s_))
      #define ATL_vvrsum2(s0_, s1_) \
      { \
         __m128d t0_; \
         t0_ = _mm_unpackhi_pd(s0_, s1_); \
         s0_ = _mm_unpacklo_pd(s0_, s1_); \
         ATL_vadd(s0_, s0_, t0_); \
      }
      #define ATL_vvrsum1(s0_) \
      { \
         __m128d t0_; \
         t0_ = _mm_unpackhi_pd(s0_, s0_); \
         s0_ = _mm_unpacklo_pd(s0_, s0_); \
         ATL_vadd(s0_, s0_, t0_); \
      }
      #define ATL_vsplat0(d_, s_) d_ = (ATL_VTYPE) \
         _mm_shuffle_epi32((__m128i)(s_), 0x0)
      #define ATL_vsplat1(d_, s_) d_ = (ATL_VTYPE) \
         _mm_shuffle_epi32((__m128i)(s_), 0x55)
      #define ATL_vsplat2(d_, s_) d_ = (ATL_VTYPE) \
         _mm_shuffle_epi32((__m128i)(s_), 0xAA)
      #define ATL_vsplat3(d_, s_) d_ = (ATL_VTYPE) \
         _mm_shuffle_epi32((__m128i)(s_), 0xFF)
   #endif
#elif defined(ATL_SSE1)
   #include <xmmintrin.h>
   #if defined(ATL_SSE3)
      #include <tmmintrin.h>
   #endif
   #define ATL_VTYPE __m128
   #if defined(ATL_VLEN) && ATL_VLEN != 4
      #error "VLEN == 4 only supported size for single precision SSE!"
   #elif !defined(ATL_VLEN)
      #define ATL_VLEN 4
   #endif
   #define ATL_vzero(v_) v_ = _mm_setzero_ps()
   #define ATL_vbcast(v_, p_) v_ =  _mm_load1_ps(p_)
   #define ATL_vuld(v_, p_) v_ = _mm_loadu_ps(p_)
   #define ATL_vld(v_, p_) v_ = _mm_load_ps(p_)
   #define ATL_vust(p_, v_) _mm_storeu_ps(p_, v_)
   #define ATL_vst(p_, v_) _mm_store_ps(p_, v_)
   #define ATL_vadd(d_, s1_, s2_) d_ =  _mm_add_ps(s1_, s2_)
   #define ATL_vsub(d_, s1_, s2_) d_ =  _mm_sub_ps(s1_, s2_)
   #define ATL_vmul(d_, s1_, s2_) d_ =  _mm_mul_ps(s1_, s2_)
   #define ATL_vmac(d_, s1_, s2_) \
   { ATL_VTYPE t_; \
      t_ = _mm_mul_ps(s1_, s2_); \
      d_ = _mm_add_ps(t_, d_); \
   }
   #ifdef ATL_SSE3
      #define ATL_vrsum1(d_, s_) \
      {  ATL_VTYPE t_; \
         t_ = _mm_hadd_ps(s_, s_); \
         d_ = _mm_cvtss_f32(_mm_hadd_ps(t_, t_)); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      { \
         s0_ = _mm_hadd_ps(s0_, s1_); /*{s1cd,s1ab,s0cd,s0ab}*/ \
         s2_ = _mm_hadd_ps(s2_, s3_); /*{s3cd,s3ab,s2cd,s2ab}*/ \
         s0_ = _mm_hadd_ps(s0_, s2_); /*{s3a-d,s2a-d,s1a-d,s0a-d}*/ \
      }
      #define ATL_vvrsum2(s0_, s1_) \
      { \
         s0_ = _mm_hadd_ps(s0_, s1_); /*{s1cd,s1ab,s0cd,s0ab}*/ \
         s0_ = _mm_hadd_ps(s0_, s0_); /*{s1a-d,s0a-d,s1a-d,s0a-d}*/ \
      }
      #define ATL_vvrsum1(s0_) \
      { \
         s0_ = _mm_hadd_ps(s0_, s0_); /*{s0cd,s0ab,s0cd,s0ab}*/ \
         s0_ = _mm_hadd_ps(s0_, s0_); /*{s0a-d,s0a-d,s0a-d,s0a-d}*/ \
      }
   #else
      #define ATL_vrsum1(d_, s_) \
      { \
         ATL_VTYPE t_; \
         t_ = _mm_movehl_ps(s_, s_); \
         t_ = _mm_add_ps(t_, s_); \
         t_ = _mm_add_ps(t_, _mm_shuffle_ps(t_, t_, 1)); \
         d_ = _mm_cvtss_f32(t_); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      {                                      /*{sXd,  sXc,  sXb,  sXa}*/ \
         ATL_VTYPE t0_; \
         t0_ = _mm_unpackhi_ps(s0_,s1_);     /*{s1d,  s0d,  s1c,  s0c}*/\
         s0_ = _mm_unpacklo_ps(s0_,s1_);     /*{s1b,  s0b,  s1a,  s0a}*/\
         s1_ = _mm_unpackhi_ps(s2_,s3_);     /*{s3d,  s2d,  s3c,  s2c}*/\
         ATL_vadd(s0_, s0_, t0_);            /*{s1bd, s0bd, s1ac, s0ac}*/\
         s2_ = _mm_unpacklo_ps(s2_,s3_);     /*{s3b,  s2b,  s3a,  s2a}*/\
         ATL_vadd(s2_, s2_, s1_);            /*{s3bd, s2bd, s3ac, s2ac}*/\
         t0_ = _mm_shuffle_ps(s0_,s2_,0xEE); /*{s3bd, s2bd, s1bd, s0bd}*/\
         s0_ = _mm_shuffle_ps(s0_,s2_,0x44); /*{s3ac, s2ac, s1ac, s0ac}*/\
         ATL_vadd(s0_,s0_,t0_);              /*{s3a-d,s2a-d,s1a-d,s0a-d}*/\
      }
      #define ATL_vvrsum2(s0_, s1_) \
      {                                      /*{sXd,  sXc,  sXb,  sXa}*/ \
         ATL_VTYPE t0_; \
         t0_ = _mm_unpackhi_ps(s0_,s1_);     /*{s1d,  s0d,  s1c,  s0c}*/\
         s0_ = _mm_unpacklo_ps(s0_,s1_);     /*{s1b,  s0b,  s1a,  s0a}*/\
         ATL_vadd(s0_, s0_, t0_);            /*{s1bd, s0bd, s1ac, s0ac}*/\
         t0_ = _mm_shuffle_ps(s0_,s0_,0xEE); /*{s1bd, s0bd, s1bd, s0bd}*/\
         s0_ = _mm_shuffle_ps(s0_,s0_,0x44); /*{s1ac, s0ac, s1ac, s0ac}*/\
         ATL_vadd(s0_,s0_,t0_);              /*{s1a-d,s0a-d,s1a-d,s0a-d}*/\
      }
      #define ATL_vvrsum1(s0_) \
      {                                      /*{sXd,  sXc,  sXb,  sXa}*/ \
         ATL_VTYPE t0_; \
         t0_ = _mm_unpackhi_ps(s0_,s0_);     /*{s0d,  s0d,  s0c,  s0c}*/\
         s0_ = _mm_unpacklo_ps(s0_,s0_);     /*{s0b,  s0b,  s0a,  s0a}*/\
         ATL_vadd(s0_, s0_, t0_);            /*{s0bd, s0bd, s0ac, s0ac}*/\
         t0_ = _mm_shuffle_ps(s0_,s0_,0xEE); /*{s0bd, s0bd, s0bd, s0bd}*/\
         s0_ = _mm_shuffle_ps(s0_,s0_,0x44); /*{s0ac, s0ac, s0ac, s0ac}*/\
         ATL_vadd(s0_,s0_,t0_);              /*{s0a-d,s0a-d,s0a-d,s0a-d}*/\
      }
   #endif
#elif ATL_VLEN > 1  /* use gnuvec when atlas knows no VEC ISA */
@skip   typedef TYPE ATL_gnuvec_t  __attribute__ ((vector_size (ATL_VLENb)))
@skip   #define ATL_VTYPE ATL_gnuvec_t
   #define ATL_VTYPE TYPE __attribute__ ((vector_size (ATL_VLENb)))
@skip   #define ATL_UPVTYPE TYPE __attribute__ ((vector_size (ATL_VLENb))) \
@skip                           __attribute__ ((aligned(8)))
   #if defined(SREAL) || defined(SCPLX)
      #define ATL_VITYPE int  __attribute__ ((vector_size (ATL_VLENb)))
   #else
      #define ATL_VITYPE long long  __attribute__ ((vector_size (ATL_VLENb)))
   #endif
   #define ATL_vzero(d_) d_ = (ATL_VTYPE)(((ATL_VITYPE)(d_))^((ATL_VITYPE)(d_)))
   #define ATL_vcopy(d_, s_) d_ = s_
   #ifndef ATL_vbcast
      #if 0
         #define ATL_vbcast(v_, p_) v_ = *((TYPE*)(p_));
      #elif 0
         #define ATL_vbcast(v_, p_) \
         { \
            (v_)[0] = p_; \
            v_ =  __builtin_shuffle(v_, (ATL_VITYPE){0}); \
         }
      #endif
   #endif
@skip   #define ATL_vuld(v_, p_) \
@skip      v_ = *((ATL_UPVTYPE*)(p_))
   #define ATL_vld(v_, p_) \
      v_ = *((ATL_VTYPE*)__builtin_assume_aligned(p_,ATL_VLENb))
   #define ATL_vust(p_, v_) *((ATL_VTYPE*)(p_)) = v_
   #define ATL_vst(p_, v_) \
      *((ATL_VTYPE*)__builtin_assume_aligned(p_,ATL_VLENb)) = v_
   #define ATL_vadd(d_, s1_, s2_) d_ =  s1_ + s2_
   #define ATL_vsub(d_, s1_, s2_) d_ =  s1_ - s2_
   #define ATL_vmul(d_, s1_, s2_) d_ =  s1_ * s2_
   #define ATL_vmac(d_, s1_, s2_) d_ += s1_ * s2_
   #if ATL_VLEN == 1
      #define ATL_vbcast(v_, p_) v_ = *(p_)
      #ifndef ATL_vuld
         #define ATL_vuld(v_, p_) v_ = {*(p_)}
      #endif
      #ifndef ATL_vrsum1
         #define ATL_vrsum1(d_, s_) d_ = (s_)
      #endif
   #elif ATL_VLEN == 2
      #define ATL_vbcast(v_, p_) v_ = (ATL_VTYPE){*(p_), *(p_)}
      #ifndef ATL_vuld
         #define ATL_vuld(v_, p_) v_ = (ATL_VTYPE){*(p_), (p_)[1]}
      #endif
      #ifndef ATL_vrsum1
         #define ATL_vrsum1(d_, s_) d_ = ((s_)[0] + (s_)[1])
      #endif
   #elif ATL_VLEN == 4
      #define ATL_vbcast(v_, p_) v_ = (ATL_VTYPE){*(p_), *(p_), *(p_), *(p_)}
      #ifndef ATL_vuld
      #define ATL_vuld(v_, p_) v_ = (ATL_VTYPE){*(p_),(p_)[1],(p_)[2],(p_)[3]}
      #endif
      #ifndef ATL_vrsum1
         #define ATL_vrsum1(d_, s_) d_ = ((s_)[0] + (s_)[1] + (s_)[2] + (s_)[3])
      #endif
   #elif ATL_VLEN == 8
      #ifndef ATL_vuld
      #define ATL_vuld(v_, p_) v_ = (ATL_VTYPE) \
         {*(p_), (p_)[1], (p_)[2], (p_)[3], (p_)[4], (p_)[5], (p_)[6], (p_)[7]}
      #endif
      #define ATL_vbcast(v_, p_) v_ = (ATL_VTYPE){*(p_), *(p_), *(p_), *(p_), \
               *(p_), *(p_), *(p_), *(p_)}
      #ifndef ATL_vrsum1
      #define ATL_vrsum1(d_, s_) d_ = ((s_)[0] + (s_)[1] + (s_)[2] + (s_)[3] + \
                                       (s_)[4] + (s_)[5] + (s_)[6] + (s_)[7])
      #endif
   #elif ATL_VLEN == 16
      #ifndef ATL_vuld
      #define ATL_vuld(v_, p_) v_ = (ATL_VTYPE) \
         {*(p_),(p_)[1],(p_)[2],(p_)[3],(p_)[4],(p_)[5],(p_)[6],(p_)[7], \
          (p_)[8],(p_)[9],(p_)[10],(p_)[11],(p_)[12],(p_)[13],(p_)[14],(p_)[15]}
      #endif
      #ifndef ATL_vrsum1
      #define ATL_vrsum1(d_, s_) d_ = \
      ((s_)[0]+(s_)[1]+(s_)[2]+(s_)[3]+(s_)[4]+(s_)[5]+(s_)[6]+(s_)[7] +\
       (s_)[ 8]+(s_)[ 9]+(s_)[10]+(s_)[11]+(s_)[12]+(s_)[13]+(s_)[14]+(s_)[15])
      #endif
   #elif ATL_VLEN == 32
      #ifndef ATL_vuld
      #define ATL_vuld(v_, p_) v_ = (ATL_VTYPE) \
      {*(p_),(p_)[1],(p_)[2],(p_)[3],(p_)[4],(p_)[5],(p_)[6],(p_)[7], \
       (p_)[8],(p_)[9],(p_)[10],(p_)[11],(p_)[12],(p_)[13],(p_)[14],(p_)[15],\
       (p_)[16],(p_)[17],(p_)[18],(p_)[19],(p_)[20],(p_)[21],(p_)[22],(p_)[23],\
       (p_)[24],(p_)[25],(p_)[26],(p_)[27],(p_)[28],(p_)[29],(p_)[30],(p_)[31]}
      #endif
      #define ATL_vrsum1(d_, s_) d_ = \
      ((s_)[0]+(s_)[1]+(s_)[2]+(s_)[3]+(s_)[4]+(s_)[5]+(s_)[6]+(s_)[7] \
      +(s_)[ 8]+(s_)[ 9]+(s_)[10]+(s_)[11]+(s_)[12]+(s_)[13]+(s_)[14]+(s_)[15] \
      +(s_)[16]+(s_)[17]+(s_)[18]+(s_)[19]+(s_)[20]+(s_)[21]+(s_)[22]+(s_)[23] \
      +(s_)[24]+(s_)[25]+(s_)[26]+(s_)[27]+(s_)[28]+(s_)[29]+(s_)[30]+(s_)[31])
   #else
      #error "Unsupported ATL_VLEN"
   #endif
#else
   #if defined(ATL_VLEN) && ATL_VLEN != 1
      #error "For systems without vector support, only ATL_VLEN=1 supported!"
   #elif !defined(ATL_VLEN)
      #define ATL_VLEN 1
   #endif
   #define ATL_VTYPE TYPE

   #define ATL_vzero(d_) d_ = 0.0
   #define ATL_vcopy(d_, s_) d_ = s_
   #define ATL_vbcast(d_, p_) d_ = *(p_)
   #define ATL_vuld(v_, p_) v_ = *(p_)
   #define ATL_vld(v_, p_) v_ = *(p_)
   #define ATL_vust(p_, s_) *(p_) = s_
   #define ATL_vst(p_, s_) *(p_) = s_
   #define ATL_vadd(d_, s1_, s2_) d_ =  (s1_) + (s2_)
   #define ATL_vsub(d_, s1_, s2_) d_ =  (s1_) - (s2_)
   #define ATL_vmul(d_, s1_, s2_) d_ =  (s1_) * (s2_)
   #define ATL_vmac(d_, s1_, s2_) d_ += (s1_) * (s2_)
   #define ATL_vrsum1(d_, s_) d_ = s_
#endif
@beginskip
@iexp p 1 0 +
@iexp j 0 0 +
@iwhile p < 64
   #if ATL_VLEN == @(p)
      #define ATL_VLSH @(j)
      #if defined(SREAL) || defined(SCPLX)
         @iexp i @(p) 4 *
         #define ATL_VLENb @(i)
      #else
         @iexp i @(p) 8 *
         #define ATL_VLENb @(i)
      #endif
   #endif
   @iexp j @(j) 1 +
   @iexp p @(p) 2 *
@endiwhile
@endskip
@SKIP produce a list of numbered args on 1 line, like: <nm>#<sf>
@BEGINPROC arglst n nm sf
   @define i @1@
   @define at @@(nm)0@(sf)@
   @iwhile i < @(n)
      @define nat @@(at)@
      @undef at
      @define at @@(nat), @(nm)@(i)@(sf)@
      @undef nat
      @iexp i @(i) 1 +
   @endiwhile
   @define arglst @@(at)@
   @undef at
   @undef i
@ENDPROC
@BEGINPROC addarr n nm
   @define i @1@
   @define at @@(nm)[0]@
   @iwhile i < @(n)
      @define nat @@(at)@
      @undef at
      @define at @@(nat)+@(nm)[@(i)]@
      @undef nat
      @iexp i @(i) 1 +
   @endiwhile
   @define addarr @@(at)@
   @undef at
   @undef i
@ENDPROC
@BEGINPROC asgarr n nm
   @define i @1@
   @define at @@(nm)[0]@
   @iwhile i < @(n)
      @define nat @@(at)@
      @undef at
      @define at @@(nat)=@(nm)[@(i)]@
      @undef nat
      @iexp i @(i) 1 +
   @endiwhile
   @define asgarr @@(at)@
   @undef at
   @undef i
@ENDPROC
/* 
 * If it isn't already defined (fast system-specific version), define vvrsumX
 * This may be horribly slow or great, depending on how smart the compiler is.
 */
#if ATL_VLEN == 2
   #ifndef ATL_vvrsum1
      #define ATL_vvrsum1(s0_) s0_[0] += s0_[1]
   #endif
   #ifndef ATL_vvrsum2
      #define ATL_vvrsum2(s0_, s1_) \
      { \
         s0_[0] += s0_[1]; \
         s0_[1] = s1_[0] + s1_[1]; \
      }
   #endif
#endif
@iexp vl 2 2 +
@iwhile vl < 64
#if ATL_VLEN == @(vl)
   @iexp n 1
   @iexp kk @(vl) 1 +
   @iwhile n < kk
   @CALLPROC arglst @(n) s _
   #ifndef ATL_vvrsum@(n)
      #define ATL_vvrsum@(n)(@(arglst))\
   @undef arglst
      { \
      @iexp i 0 0 +
      @iwhile i < @(n)
         @CALLPROC addarr @(vl) s@(i)_
         s0_[@(i)] = @(addarr); \
         @undef addarr
         @iexp i @(i) 1 +
      @endiwhile
      }
   #endif
      @iexp n @(n) @(n) +
   @endiwhile
#endif
   @iexp vl @(vl) @(vl) +
@endiwhile
/*
 * If it isn't defined already (fast sys-spec vers), define 
 *    vsplatI (0 <= I < VL) using vector indexing.  
 * This may be horribly slow or great, depending on how smart the compiler is.
 */
#if ATL_VLEN == 2
   #ifndef ATL_vsplat0
   #define ATL_vsplat0(d_, s_) d_[0] = d_[1] = s_[0]
   #endif
   #ifndef ATL_vsplat1
   #define ATL_vsplat1(d_, s_) d_[0] = d_[1] = s_[1]
   #endif
@iexp vl 2 2 +
@iwhile vl < 64
#elif ATL_VLEN == @(vl)
   @iexp k 0 0 +
   @iwhile k < @(vl)
      @CALLPROC asgarr @(vl) d_ s_[@(k)]
   #ifndef ATL_vsplat@(k)
   #define ATL_vsplat@(k)(d_, s_) \
      @(asgarr) = s_[@(k)]
      @iexp k @(k) 1 +
   #endif
   @endiwhile
@beginskip
   @CALLPROC arglst @(vl) s _
   #ifndef ATL_vvrsum@(vl)
   #define ATL_vvrsum@(vl)(@(arglst))\
   @undef arglst
   { \
   @iexp i 0 0 +
   @iwhile i < @(vl)
      @CALLPROC addarr @(vl) s@(i)_
      s0_[@(i)] = @(addarr); \
      @undef addarr
      @iexp i @(i) 1 +
   @endiwhile
   }
   #endif
@endskip
   @iexp vl @(vl) @(vl) +
@endiwhile
#endif
/*
 * If we don't have one defined, write slow version that should work with
 * any gcc-compatible compiler
 */
#ifndef ATL_vrsum1
   #define ATL_vrsum1(d_, s_) \
   {  TYPE mem_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
      int i_; \
      ATL_vst(mem_, s_); \
      d_ = *mem_; \
      for (i_=1; i_ < ATL_VLEN; i_++) \
         d_ += mem_[i_]; \
   }
#endif
@beginskip
/*
 * If no special case, do vrsum2/4 slow way by calling vrsum1
 * THESE ARE WRONG: vrsum2 should put 1st ans in d[0], 2nd in d[1], so on,
 *                  not add them all up!  Leave until needed (kvec).
 */
#ifndef ATL_vrsum2
   #define ATL_vrsum2(d_, s1_, s2_) \
   { \
      ATL_VTYPE t0_; \
      ATL_vrsum1(d_, s1_); \
      ATL_vrsum1(s1_, s2_); \
      ATL_vadd(d_, d_, s1_); \
   }
#endif
#ifndef ATL_vrsum4
   #define ATL_vrsum4(d_, s1_, s2_, s3_, s4_) \
   { \
      ATL_vrsum2(d_, s1_, s2_); \
      ATL_vrsum2(s1_, s3_, s4_); \
      ATL_vadd(d_, d_, s1_); \
   }
#endif
#ifndef ATL_vrsum8
   #define ATL_vrsum8(d_, s1_, s2_, s3_, s4_, s5_), s6_, s7_, s8_) \
   { \
      ATL_vrsum4(d_, s1_, s2_, s3_, s4); \
      ATL_vrsum4(s1_, s3_, s5_, s6_, s7_, s8_); \
      ATL_vadd(d_, d_, s1_); \
   }
#endif
#ifndef ATL_vrsum16
   #define ATL_vrsum16(d_, s1_, s2_, s3_, s4_, s5_), s6_, s7_, s8_, \
                           s9_, s10_, s11_, s12_, s13_, s14_, s15_, s16_) \
   { \
      ATL_vrsum8(d_, s1_, s2_, s3_, s4_, s5_, s6_, s7_, s8_); \
      ATL_vrsum8(s1_, s9_, s10_, s11_, s12_ s13_, s14_, s15_); \
      ATL_vadd(d_, d_, s1_); \
   }
#endif
@endskip

#endif  /* end multiple-inclusion guard */
@ROUT atlas_ammsimd.h
/*
 * Special functions for writing M&N or M&K vectorized amm:
 *  ATL_ammcomb<mu>x<ku> : (mu*ku)%VLEN==0 -> used when M&K are both vect
 *  ATL_ammldB<nu> : if defined, load & dup for (mu*nu)%VLEN == 0 code
 *  ATL_ammbcast<nu> : combine with ATL_vld/vld1, etc for MN-vec
 *  
 */
#ifndef ATLAS_AMMSIMD_H
   #define ATLAS_AMMSIMD_H 1
#include "atlas_simd.h"

#if VLEN == 2   /* only 1-d shapes, handled by simd.h */
#elif VLEN == 4
#ifndef ATL_ammcomb2x2
   #define ATL_ammcomb2x2(s0_, s1_, s2_, s3_) \
   { \
     s0_[0] += s0_[1]; \
     s0_[1] = s0_[2] + s0_[3]; \
     s0_[2] = s1_[0] + s1_[1]; \
     s0_[3] = s1_[2] + s1_[3]; \
   }
#endif
#ifndef ATL_ammbcast2x2_0
   #define ATL_ammbcast2x2_0(d_, s_) \
   { \
      d_[0] = d_[1] = s_[0]; \
      d_[2] = d_[3] = s_[1]; \
   }
#endif
#ifndef ATL_ammbcast2x2_1
   #define ATL_ammbcast2x2_1(d_, s_) \
   { \
      d_[0] = d_[1] = s_[2]; \
      d_[2] = d_[3] = s_[3]; \
   }
#endif
#ifndef ATL_ammldB2x2
   #define ATL_ammldB2x2(d_, s_) 
   { \
      d_[0] = d_[1] = *(s_); \
      d_[2] = d_[3] = (s_)[1]; \
   }
#endif
#elif VLEN == 8
#endif

#endif
#if ATL_VLEN 
@ROUT atlas_cplxsimd.h
#ifndef ATLAS_CPLXSIMD_H
   #define ATLAS_CPLXSIMD_H 1
#include "atlas_simd.h"
/*
 *                          FUNCTIONALITY SUMMARY
 * ============================================================================
 * Constant integers: ATL_CXVLEN, ATL_CXSPLDb
 * Load/store for partial vecs (replace I with 0 < I < VLEN/2, 1 always there):
 *    ATL_vcxldI, ATL_vcxuldI, ATL_vcxustI, ATL_vcxustI
 * Macros for axpy-based computation:
 *    ATL_vcxsplitRIld,  ATL_vcxsplitRI, ATL_vcxPrepAlpha
 * Macros for dot-based computation:
 *    ATL_vcxswapRI, ATL_vcxdotcomb
 * ============================================================================
 */
/*
 * ============================================================================
 * This file provides macros for doing the types complex computations 
 * needed by ATLAS in a machine, precision and VLEN-independent manner
 * (i.e., this file changes based on VLEN/SIMD ISA, float/double, VLEN,
 *  but kernels implemented using work unchanged regardless of these variables).
 * ATLAS essentially does dot-product based computations (dot,GEMVT,GEMM)
 * and AXPY-based (AXPY,GER,GER2).  Both types of computation need both
 * load and stores.  We just use the real load/store for full VLEN ops.
 * However, we also need the ability to load/store a single complex number, 
 * which means the ability to load/store pairs of real numbers.  In addition,
 * if we want to be able perform vector cleanup, we need the ability to
 * load/store I complex numbers (0 < I < ATL_VLEN/2), with loads zeroing any
 * elements above the loaded values.  Therefore, this file provides 
 * (ATL_VLEN/2 - 1)*4 routines for loading/store complex numbers:
 *    ATL_vcxldI(r_, p_) : load lower 2*I elts of aligned p_ to r_, zero rest
 *    ATL_vcxuldI(r_, p_): load lower 2*I elts of unaligned p_ to r_, zero rest
 *    ATL_vcxstI(p_, r_) : store lower 2*I real elts of r_ to aligned p_
 *    ATL_vcxustI(p_, r_): store lower 2*I real elts of r_ to unaligned p_
 *
 * There are numerous ways to do complex computations, but this file provides
 * a particular approach for both dot- and axpy-based computations.  
 *
 * For AXPY-based computations, we are performance limited by load/store of Y,
 * so we permute all other ops to allow us to keep Y in natural order.
 * Not all SIMD ISAs allow one to do different operations to different
 * vector elements (eg., ADDSUB), so instead we manipulate alpha outside
 * the main loop so that it is is permuted and scaled appropriately to allow
 * us to do MAC-based AXPY calculations.  We will split X into two vectors
 * with duplicated entries:
 *   {Xr, Xr}*(VLEN/2)          {Xi, Xi}*(VLEN/2)
 * This permutation must be done inside the loop, and is thus expensive.
 * We provide the following functions to accomplish this:
 *    ATL_vcxsplitRIld(rR_, rI, p_): split&dup cplx #s from aligned p_
      ATL_vcxsplitRI(rXr_, rXi_)  : split&dup from natural-order reg rXi_
 * ATL_vcxsplitRIld can be built out of ATL_vld & ATL_vcxsplitRI, which is how
 * it is done for cleanup, but on some systems it is more efficient to
 * do it directly from memory, so we provide a specialized high-performance
 * version.  On some systems, the alignment restrictions for this operation
 * are lower than full VLEN, so we also provide the const macro:
 *    ATL_CXSPLDb : required byte alignment for ATL_vcxsplitRIld.
 * We use ATL_cxsplit for vector cleanup & when X is not aligned to ATL_CXSPLDb.
 * axpy-based calcs are doing Y += alpha * X.  Alpha is loop-invariant, so we
 * can manipulate it outside the loop, even if that manipulation is relatively
 * inefficient.  In order to perform the two real MACs required for cplx MAC,
 * alpha is split into two vectors that match up with our X vecs as in:
 *   {Xr,   Xr}*(VLEN/2)          {Xi,    Xi}*(VLEN/2)
 *   {ALi, Alr}*(VLEN/2)          {ALr, -ALi}*(VLEN/2
 * The first of these is the natural order alpha (alN), and the second scaled 
 * and permuted (alS).  First the scalar complex number is loaded to the
 * register using ATL_cx[u]ld1, then it is transformed with:
 *    ATL_vcxPrepAlpha(alN, alS): alN is input & output, alS output only
 * 
 * The naive approach to performing complex MAC (multiply and accumulate)
 * requires permuting both X and Y inside the loop, which is very expensive.
 * However, we notice that DOT (the accumulator) is loop invariant, so we
 * can instead keep it in permuted & scaled form throughout the loop.  This
 * allows us to avoid either the permute of X or Y (but not both).
 * For DOT-based there is no performance difference between X and Y, so we
 * can choose to permute either one (one must be computed to build the complex
 * multiply and accumulate (MAC) out of real MACs).  In general you can only
 * force one vector to be aligned (vecs may be mutually misaligned), and that
 * load will be cheaper than the unaligned load.  We therefore perform loop
 * peeling to force X to be aligned whenever that is possible, and then
 * permute X rather than Y.  The permute adds to the dependence chain in the
 * loop, so you want dependent it on the fastest load.
 *
 * The technique for DOT-based calculations is that the two half of the MACs
 * are stored in two different dot variables throughout the loop, one storing
 * partial results for the real result, and one for the imaginary result.
 * The real/imag dot vectors must be internally summed up to produce the
 * final answer (this operation performed outside the loop).  The imaginary
 * dot looks like: {Xr*Yi, Xi*Yr}*(VLEN/2), so we add all elts to get the ans.
 * Real looks:     {Xi*Yi, Xr*Yr}*(VLEN/2), so we must subtract the odd elts
 * from the even.  We provide this macro to accomplish this:
 *    ATL_cxdotcomb(rR, rI) : put final ans in low 2 elts of rR
 *
 * Inside the loop, we keep Y in natural order, and have X in both natural
 * order (rN) and with imaginary and complex swapped (rS).  We provide:
 *    ATL_cxriswap(rS, rN): swap imag & real components of rN, store in rS
 *
 * ============================================================================
 */
/*
 * Define some length-specific constants.
 * ATL_VONEPN is used to scale so even words are negated (imag*imag).
@skip * ATL_VONENP is used to scale dot's odd words by -1 (i*i=-1).
 */
#if ATL_VLEN == 2
   #define ATL_CXVLEN 1
   #define ATL_CXVLSH 0
   #define ATL_VONEPN ((ATL_VTYPE){ATL_rone, ATL_rnone})
#elif ATL_VLEN == 4
   #define ATL_CXVLEN 2
   #define ATL_CXVLSH 1
   #define ATL_VONEPN ((ATL_VTYPE){ATL_rone, ATL_rnone,ATL_rone, ATL_rnone})
#elif ATL_VLEN == 8
   #define ATL_CXVLEN 4
   #define ATL_CXVLSH 2
   #define ATL_VONEPN ((ATL_VTYPE){ATL_rone, ATL_rnone,ATL_rone, ATL_rnone,\
                                   ATL_rone, ATL_rnone,ATL_rone, ATL_rnone})
#elif ATL_VLEN == 16
   #define ATL_CXVLEN 8
   #define ATL_CXVLSH 3
   #define ATL_VONEPN ((ATL_VTYPE){ATL_rone, ATL_rnone,ATL_rone, ATL_rnone,\
                                   ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                   ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                   ATL_rone, ATL_rnone,ATL_rone, ATL_rnone})
#elif ATL_VLEN == 32
   #define ATL_CXVLEN 16
   #define ATL_CXVLSH 4
   #define ATL_VONEPN (ATL_VTYPE){ATL_rone, ATL_rnone,ATL_rone, ATL_rnone,\
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone} \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone}
#else
   #error "unsupported VLEN!"
#endif

/*
 * Define ld/st I, 0 < I < VLEN/2, I=1 always present (scalar complex ld/st)
 */
#if ATL_VLEN == 2  /* 1 vec == 1 complex: DCPLX&(SSE2||VSX||ARM) or gnuvec */
   #define ATL_vcxld1(r_, p_) ATL_vld(r_, p_)
   #define ATL_vcxuld1(r_, p_) ATL_vuld(r_, p_)
   #define ATL_vcxst1(p_, r_) ATL_vst(p_, r_)
   #define ATL_vcxust1(p_, r_) ATL_vust(p_, r_)
#elif ATL_VLEN >= 4   /* gnuvec or DCPLX & AVX or SCPLX & (VSX || SSE) */
   #if (ATL_VSX) && defined(SCPLX)
      #if 0 /* gnuvec works better for unaligned load */
      #define ATL_vcxuld1(r_, p_) \
      {  ATL_VTYPE t0_, t1_;\
         t0_ = vec_splats(*(p_)); \
         t1_ = vec_splats((p_)[1]); \
         t0_ = vec_vmrglw(t0_, t1_); \
         ATL_vzero(r_); \
         r_ = vec_xxpermdi(t0_, r_, 0); \
      }
      #endif
      #define ATL_vcxld1(r_, p_) r_ = (ATL_VTYPE) \
         ((vector double){*((double*)(p_))})
      #define ATL_vcxust1(p_, r_) { *(p_) = r_[0]; (p_)[1] = r_[1]; }
      #define ATL_vcxst1(p_, r_) ATL_vcxust1(p_, r_)
   #elif (defined(ATL_VECARM1) || defined(ATL_NEON)) && defined(SCPLX)
      #define ATL_vcxuld1(r_, p_) \
         r_ = vcombine_f32(vld1_f32(p_), vdup_n_f32(0.0f))
      #define ATL_vcxust1(p_, r_) vst1_f32(p_, vget_low_f32(r_))
      #define ATL_vcxld1(r_, p_) ATL_vcxuld1(r_, p_)
      #define ATL_vcxst1(p_, r_) ATL_vcxust1(p_, r_)
   #elif defined(ATL_AVXZ) && defined(DCPLX)
      #define ATL_vcxld1(r_, p_) r_ = _mm512_maskz_load_pd(3, p_)
      #define ATL_vcxuld1(r_, p_) r_ = _mm512_maskz_loadu_pd(3, p_)
      #define ATL_vcxst1(p_, r_) _mm512_mask_store_pd(p_, 3, r_)
      #define ATL_vcxust1(p_, r_) _mm512_mask_storeu_pd(p_, 3, r_)
   #elif defined(ATL_AVX) && defined(DCPLX)
      #define ATL_vcxld1(r_, p_) \
      { \
         ATL_vzero(r_); \
         r_ = _mm256_insertf128_pd(r_, _mm_load_pd(p_), 0); \
      }
      #define ATL_vcxuld1(r_, p_) \
      { \
         ATL_vzero(r_); \
         r_ = _mm256_insertf128_pd(r_, _mm_loadu_pd(p_), 0); \
      }
      #define ATL_vcxst1(p_, r_) _mm_store_pd(p_, _mm256_extractf128_pd(r_, 0))
      #define ATL_vcxust1(p_, r_) _mm_storeu_pd(p_, _mm256_extractf128_pd(r_,0))
   #elif defined(ATL_AVXZ) && defined(SCPLX)
      #define ATL_vcxld1(r_, p_) r_ = _mm512_maskz_load_ps(3, p_)
      #define ATL_vcxuld1(r_, p_) r_ = _mm512_maskz_loadu_ps(3, p_)
      #define ATL_vcxst1(p_, r_) _mm512_mask_store_ps(p_, 3, r_)
      #define ATL_vcxust1(p_, r_) _mm512_mask_storeu_ps(p_, 3, r_)
   #elif defined(ATL_AVX) && defined(SCPLX)
      #define ATL_vcxld1(r_, p_) \
      {  __m128 t0_;\
         ATL_vzero(r_); \
         t0_ = _mm_setzero_ps(); \
         r_ = _mm256_insertf128_ps(r_, _mm_loadl_pi(t0_,(void*)(p_)), 0); \
      }
      #define ATL_vcxuld1(r_, p_) \
      {  __m128 t0_, t1_;\
         ATL_vzero(r_); \
         t0_ = _mm_load_ss(p_); \
         t1_ = _mm_load_ss((p_)+1); \
         t0_ = _mm_unpacklo_ps(t0_, t1_); \
         r_ = _mm256_insertf128_ps(r_, t0_, 0); \
      }
      #define ATL_vcxst1(p_, r_) \
         _mm_storel_pi((void*)(p_), _mm256_extractf128_ps(r_, 0))
      #define ATL_vcxust1(p_, r_) \
      {  __m128 t_;\
         t_ = _mm256_extractf128_ps(r_,0); \
         _mm_store_ss(p_, t_); \
         _mm_store_ss((p_)+1, _mm_shuffle_ps(t_, t_, 1)); \
      }
   #elif defined(ATL_SSE1) && defined(SCPLX)
      #define ATL_vcxld1(r_, p_) \
      { \
         ATL_vzero(r_); \
         r_ = _mm_loadl_pi(r_, ((void*)(p_))); \
      }
      #define ATL_vcxuld1(r_, p_) \
      {  ATL_VTYPE t_;\
         r_ = _mm_load_ss(p_); \
         t_ = _mm_load_ss((p_)+1); \
         r_ = _mm_unpacklo_ps(r_, t_); \
      }
      #define ATL_vcxst1(p_, r_) _mm_storel_pi((void*)(p_), r_)
      #define ATL_vcxust1(p_, r_) \
      { \
         _mm_store_ss(p_, r_); \
         _mm_store_ss((p_)+1, _mm_shuffle_ps(r_, r_, 1)); \
      }
   #else  /* gnuvec */
      #define ATL_vcxuld1(r_, p_) r_ = (ATL_VTYPE){*(p_), (p_)[1]}
      #define ATL_vcxust1(p_, r_) \
      { \
         *(p_) = (r_)[0]; \
         (p_)[1] = (r_)[1]; \
      }
      #define ATL_vcxld1 ATL_vcxuld1
      #define ATL_vcxst1 ATL_vcxust1
   #endif
/*
 * For VL == 8, is gnuvec or SCPLX&AVX or DCPLX&AVX512
 * For VL > 8, can only be SCPLX&AVX512 or gnuvec
 */
   #if ATL_VLEN >= 8  /* VL>=8, must define add op[2,3] */
      #if defined(ATL_AVXZ) && defined(SCPLX)
         #define ATL_vcxld2(r_, p_)  r_ = _mm512_maskz_load_ps(0xF, p_)
         #define ATL_vcxuld2(r_, p_) r_ = _mm512_maskz_loadu_ps(0xF, p_)
         #define ATL_vcxld3(r_, p_)  r_ = _mm512_maskz_load_ps(0x3F, p_)
         #define ATL_vcxuld3(r_, p_) r_ = _mm512_maskz_loadu_ps(0x3F, p_)
         #define ATL_vcxst2(p_, r_)  _mm512_mask_store_ps(p_, 0xF, r_)
         #define ATL_vcxust2(p_, r_) _mm512_mask_storeu_ps(p_, 0xF, r_)
         #define ATL_vcxst3(p_, r_)  _mm512_mask_store_ps(p_, 0x3F, r_)
         #define ATL_vcxust3(p_, r_) _mm512_mask_storeu_ps(p_, 0x3F, r_)
      #elif defined(SCPLX) && defined(ATL_AVX)
         #define ATL_vcxld2(r_, p_) \
         { \
            ATL_vzero(r_); \
            r_ = _mm256_insertf128_ps(r_, _mm_load_ps(p_), 0); \
         }
         #define ATL_vcxuld2(r_, p_) \
         { \
            ATL_vzero(r_); \
            r_ = _mm256_insertf128_ps(r_, _mm_loadu_ps(p_), 0); \
         }
         #define ATL_vcxld3(r_, p_) \
         { __m128 t_; \
            r_ = _mm256_insertf128_ps(r_, _mm_load_ps(p_), 0); \
            t_ = _mm_setzero_ps(); \
            t_ = _mm_loadl_pi(t_, ((void*)((p_)+4))); \
            r_ = _mm256_insertf128_ps(r_, t_, 1); \
         }
         #define ATL_vcxuld3(r_, p_) \
         { __m128 t0_, t1_; \
            r_ = _mm256_insertf128_ps(r_, _mm_loadu_ps(p_), 0); \
            t0_ = _mm_load_ss((p_)+4); \
            t1_ = _mm_load_ss((p_)+5); \
            t0_ = _mm_unpacklo_ps(t0_, t1_); \
            r_ = _mm256_insertf128_ps(r_, t0_, 1); \
         }
         #define ATL_vcxst2(p_, r_) \
            _mm_store_ps(p_, _mm256_extractf128_ps(r_, 0))
         #define ATL_vcxust2(p_, r_) \
             _mm_storeu_ps(p_, _mm256_extractf128_ps(r_,0))
         #define ATL_vcxst3(p_, r_) \
         {  __m128 t_; \
            ATL_vcxst2(p_, r_); \
            t_ = _mm256_extractf128_ps(r_, 0); \
            _mm_storel_pi((void*)((p_)+4), t_) ; \
         }
         #define ATL_vcxust3(p_, r_) \
         {  __m128 t_; \
            ATL_vcxust2(p_, r_); \
            t_ = _mm256_extractf128_ps(r_, 1); \
            _mm_store_ss((p_)+4, t_); \
            _mm_store_ss((p_)+5, _mm_shuffle_ps(t_, t_, 1)); \
         }
      #elif defined(DCPLX) &&  defined(ATL_AVXZ)
         #define ATL_vcxld2(r_, p_)  r_ = _mm512_maskz_load_pd(0xF, p_)
         #define ATL_vcxuld2(r_, p_) r_ = _mm512_maskz_loadu_pd(0xF, p_)
         #define ATL_vcxld3(r_, p_)  r_ = _mm512_maskz_load_pd(0x3F, p_)
         #define ATL_vcxuld3(r_, p_) r_ = _mm512_maskz_loadu_pd(0x3F, p_)
         #define ATL_vcxst2(p_, r_)  _mm512_mask_store_pd(p_, 0xF, r_)
         #define ATL_vcxust2(p_, r_) _mm512_mask_storeu_pd(p_, 0xF, r_)
         #define ATL_vcxst3(p_, r_)  _mm512_mask_store_pd(p_, 0x3F, r_)
         #define ATL_vcxust3(p_, r_) _mm512_mask_storeu_pd(p_, 0x3F, r_)
      #else /* gnuvec */
         #define ATL_vcxuld2(r_, p_) \
            r_ = (ATL_VTYPE){*(p_), (p_)[1], (p_)[2], (p_)[3]}
         #define ATL_vcxust2(p_, r_) \
         { \
            *(p_) = (r_)[0]; \
         @iexp i 1 0 +
         @iwhile i < 4
            (p_)[@(i)] = (r_)[@(i)]; \
            @iexp i @(i) 1 +
         @endiwhile
         }
         #define ATL_vcxuld3(r_, p_) \
            r_ = (ATL_VTYPE){*(p_), (p_)[1], (p_)[2], (p_)[3], (p_)[4], (p_)[5]}
         #define ATL_vcxust3(p_, r_) \
         { \
            *(p_) = (r_)[0]; \
         @iexp i 1 0 +
         @iwhile i < 6
            (p_)[@(i)] = (r_)[@(i)]; \
            @iexp i @(i) 1 +
         @endiwhile
         }

         @iexp i 2 0 +
         @iwhile i < 4
         #define ATL_vcxld@(i) ATL_vcxuld@(i)
         #define ATL_vcxst@(i) ATL_vcxust@(i)
            @iexp i @(i) 1 +
         @endiwhile
      #endif
      #if ATL_VLEN >= 16  /* need [4-7]: gnuvec or SREAL&AVX512 */
         #if defined(SCPLX) &&  defined(ATL_AVXZ)
            #define ATL_vcxld4(r_, p_)  r_ = _mm512_maskz_load_ps(0xFF, p_)
            #define ATL_vcxuld4(r_, p_) r_ = _mm512_maskz_loadu_ps(0xFF, p_)
            #define ATL_vcxld5(r_, p_)  r_ = _mm512_maskz_load_ps(0x3FF, p_)
            #define ATL_vcxuld5(r_, p_) r_ = _mm512_maskz_loadu_ps(0x3FF, p_)
            #define ATL_vcxld6(r_, p_)  r_ = _mm512_maskz_load_ps(0xFFF, p_)
            #define ATL_vcxuld6(r_, p_) r_ = _mm512_maskz_loadu_ps(0xFFF, p_)
            #define ATL_vcxld7(r_, p_)  r_ = _mm512_maskz_load_ps(0x3FFF, p_)
            #define ATL_vcxuld7(r_, p_) r_ = _mm512_maskz_loadu_ps(0x3FFF, p_)

            #define ATL_vcxst4(p_, r_)  _mm512_mask_store_ps(p_, 0xFF, r_)
            #define ATL_vcxust4(p_, r_) _mm512_mask_storeu_ps(p_, 0xFF, r_)
            #define ATL_vcxst5(p_, r_)  _mm512_mask_store_ps(p_, 0x3FF, r_)
            #define ATL_vcxust5(p_, r_) _mm512_mask_storeu_ps(p_, 0x3FF, r_)
            #define ATL_vcxst6(p_, r_)  _mm512_mask_store_ps(p_, 0xFFF, r_)
            #define ATL_vcxust6(p_, r_) _mm512_mask_storeu_ps(p_, 0xFFF, r_)
            #define ATL_vcxst7(p_, r_)  _mm512_mask_store_ps(p_, 0x3FFF, r_)
            #define ATL_vcxust7(p_, r_) _mm512_mask_storeu_ps(p_, 0x3FFF, r_)
         #else /* gnuvec */
            #define ATL_vcxuld4(r_, p_) r_ = (ATL_VTYPE)\
               {*(p_), (p_)[1], (p_)[2], (p_)[3], \
                 (p_)[4],(p_)[5],(p_)[6],(p_)[7]}
            #define ATL_vcxuld5(r_, p_) r_ = (ATL_VTYPE)\
               {*(p_), (p_)[1], (p_)[2], (p_)[3], \
                 (p_)[4],(p_)[5],(p_)[6],(p_)[7], \
                 (p_)[8],(p_)[9]}
            #define ATL_vcxuld6(r_, p_) r_ = (ATL_VTYPE)\
               {*(p_), (p_)[1], (p_)[2], (p_)[3], \
                 (p_)[4],(p_)[5],(p_)[6],(p_)[7], \
                 (p_)[8],(p_)[9],(p_)[10],(p_)[11]}
            #define ATL_vcxuld7(r_, p_) r_ = (ATL_VTYPE)\
               {*(p_), (p_)[1], (p_)[2], (p_)[3], \
                 (p_)[4],(p_)[5],(p_)[6],(p_)[7], \
                 (p_)[8],(p_)[9],(p_)[10],(p_)[11], \
                 (p_)[12],(p_)[13]}
   @iexp j 3 1 +
   @iwhile j < 8
            #define ATL_vcxust@(j)(p_, r_) \
            { \
               *(p_) = (r_)[0]; \
         @iexp h @(j) @(j) +
         @iexp i 1 0 +
         @iwhile i < @(h)
               (p_)[@(i)] = (r_)[@(i)]; \
            @iexp i @(i) 1 +
         @endiwhile
            }
      @iexp j @(j) 1 +
   @endiwhile

         @iexp i 4 0 +
         @iwhile i < 8
            #define ATL_vcxld@(i) ATL_vcxuld@(i)
            #define ATL_vcxst@(i) ATL_vcxust@(i)
            @iexp i @(i) 1 +
         @endiwhile
         #endif
         #if ATL_VLEN >= 32

   @iexp j 7 1 +
   @iwhile j < 16
         @iexp h @(j) @(j) +
         #define ATL_vcxuld@(j)(r_, p_) r_ = (ATL_VTYPE){*(p_),\
         @iexp i 1 0 +
         @iwhile i < @(h)
                                        (p_)[@(i)], \
            @iexp i @(i) 1 +
         @endiwhile
                                     }
            #define ATL_vcxust@(j)(p_, r_) \
            { \
               *(p_) = (r_)[0]; \
         @iexp i 1 0 +
         @iwhile i < @(h)
               (p_)[@(i)] = (r_)[@(i)]; \
            @iexp i @(i) 1 +
         @endiwhile
            }
      @iexp j @(j) 1 +
   @endiwhile
         @iexp i 8 0 +
         @iwhile i < 16
            #define ATL_vcxld@(i) ATL_vcxuld@(i)
            #define ATL_vcxst@(i) ATL_vcxust@(i)
            @iexp i @(i) 1 +
         @endiwhile
            #if ATL_VLEN > 32 /* VLEN == 32, gnuvec only */
               #error "Unsupported VLEN > 32"
            #endif
         #endif
      #endif
   #endif
#endif
/*
 * Define ATL_vcxswapRI, ATL_vcxsplitRI.
 * Define ATL_vcxsplitRIld if you dont want vld/splitRI version.
 * Define ATL_vcxdotcomb & ATL_vcxPrepAlpha if you don't want to use 
 * system-indep (slow) versions.  ATL_vcxdotcomb has a fast sys-indep
 * version for VLEN==2.
 */
#ifdef ATL_VSX
   #ifdef SCPLX
      #define ATL_vcxswapRI(d_, s_) d_ = vec_perm(s_,s_,(vector unsigned char) \
         {4, 5, 6, 7, 0, 1, 2, 3, 12, 13, 14, 15, 8, 9, 10, 11})
      #if ATL_FULLGCCVSX   /* not supported by older gcc (eg. 4.8) */
         #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */ \
         { \
            rXr_ = (ATL_VTYPE) vec_mergee((vector unsigned int)(rXi_), \
                                          (vector unsigned int) (rXi_)); \
            rXi_ = (ATL_VTYPE) vec_mergeo((vector unsigned int)(rXi_),\
                                          (vector unsigned int)(rXi_)); \
         }
         #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
         {  ATL_VTYPE t1_;\
            ATL_vmul(rR_, rR_, ATL_VONEPN); \
            t1_ = vec_vmrglw(rR_, rI_); \
            rR_ = vec_vmrghw(rR_, rI_); \
            ATL_vadd(rR_, rR_, t1_); \
            t1_ = vec_xxpermdi(rR_, rR_, 2); \
            ATL_vadd(rR_, rR_, t1_); \
         }
      #else
/*
 *       Using these guys as constants isn't so great: gcc 4.8.2 pulls
 *       the formation of the first iperm vector out of a loop, but then leaves
 *       the formation of the second (in terms of the first) inside the loop.
 *       The fix is to have this file define DECL/INIT macros, where we manually
 *       declare the perm vector, create it, and hoist it ourselves.
 *       We'll keep with crap way, since later gcc supports mergee/mergeo.
 */
         #define ATL_MERGEE (vector unsigned char) \
            {0, 1, 2, 3, 0, 1, 2, 3, 8, 9, 10, 11, 8, 9, 10, 11}
         #define ATL_MERGEO (vector unsigned char) \
            {4, 5, 6, 7, 4, 5, 6, 7, 12, 13, 14, 15, 12, 13, 14, 15}
         #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */ \
         { \
            rXr_ = vec_perm(rXi_, rXi, ATL_MERGEE); \
            rXi_ = vec_perm(rXi_, rXi, ATL_MERGEO); \
         }
      #endif
   #else /* DCPLX */
      #define ATL_vcxswapRI(d_, s_) d_ = vec_xxpermdi(s_, s_, 2)
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */ \
      { \
         rXr_ = vec_xxpermdi(rXi_, rXi_, 0); \
         rXi_ = vec_xxpermdi(rXi_, rXi_, 3); \
      }
      #define ATL_CXSPLDb ATL_VLENb
      #define ATL_vcxsplitRIld(rXr_, rXi_, pX_) \
      { \
         rXr_ = vec_splats(*(pX_)); \
         rXi_ = vec_splats(*((pX_)+1)); \
      }
   #endif
#elif defined(ATL_VECARM1) || defined(ATL_NEON)
   #ifdef SCPLX
      #if 0
      #define ATL_vcxsplitRIld(rXr_, rXi_, pX_) \
      { unsigned long long *lp_=(void*)(pX_), l0_, l1_, rl0_, il0_, rl1_, il1_;\
         l0_ = *lp_;                /* l0 = {i0, r0}   :: cycle 0 */\
         l1_ = lp_[1];              /* l1 = {i1, r1}   :: cycle 0 */\
         rl0_ = l0_ << 32;          /* rl0= {r0,  0}   :: cycle 1 */\
         il0_ = l0_ >> 32;          /* il0= { 0, i0}   :: cycle 1*/\
         rl1_ = l1_ << 32;          /* rl1= {r1,  0}   :: cycle 2*/\
         il1_ = l1_ >> 32;          /* il1= { 0, i1}   :: cycle 2*/\
         rl0_ |= (rl0_>> 32);       /* rl0= {r0, r0}   :: cycle 3*/\
         il0_ |= (il0_<< 32);       /* il0= {i0, i0}   :: cycle 3*/\
         rl1_ |= (rl1_>> 32);       /* rl1= {r1, r1}   :: cycle 4*/\
         il1_ |= (il1_<< 32);       /* il1= {i1, i1}   :: cycle 4*/\
         rXr_ = vcombine_f32(vreinterpret_f32_u64(rl0_), \
                             vreinterpret_f32_u64(rl1_)); /* cycle 5 */\
         rXi_ = vcombine_f32(vreinterpret_f32_u64(il0_), \
                             vreinterpret_f32_u64(il1_)); /* cycle 6 */\
      }
      #endif

      #if defined(ATL_VECARM1)
         #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
         {  \
            rXr_ = vtrn1q_f32(rXi_, rXi_); \
            rXi_ = vtrn2q_f32(rXi_, rXi_); \
         }
      #else
         #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
         { \
            rXr_[0] = rXr_[1] = rXi[0]; \
            rXr_[2] = rXr_[3] = rXi[2]; \
            rXi_[0] = rXi_[1] = rXi[1]; \
            rXi_[2] = rXi_[3] = rXi[3]; \
         }
      #endif
      #define ATL_vcxswapRI(d_, s_) \
         d_ = vreinterpretq_f32_s32(vrev64q_s32(vreinterpretq_s32_f32(s_)))
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      { \
         rR_[0] += (rR_)[2] - (rR_)[1] - (rR_)[3]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3]; \
      }
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      { \
         rALn_ = vreinterpretq_f32_u64(vdupq_lane_u64(\
                    vreinterpret_u64_f32(vget_low_f32(rALn_)),0)); \
         ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
         ATL_vcxswapRI(rALs_, rALs_); \
      }
   #else
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = vdupq_laneq_f64(rXi_, 0); \
         rXi_ = vdupq_laneq_f64(rXi_, 1); \
      }
      #define ATL_vcxswapRI(d_, s_) \
         d_ = vcombine_f64(vget_high_f64(s_),vget_low_f64(s_))
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      { \
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         rR_ = vpaddq_f64(rR_, rI_); \
      }
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      { \
         ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
         ATL_vcxswapRI(rALs_, rALs_); \
      }
   #endif
#elif defined(ATL_AVXZ)
   #ifdef SCPLX
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm512_moveldup_ps(rXi); \
         rXi_ = _mm512_movehdup_ps(rXi); \
      }
      #define ATL_vcxswapRI(d_, s_) d_ = _mm512_shuffle_ps(s_, s_, 0xB1)
   #else  /* DCPLX */
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm512_movedup_pd(rXi); \
         rXi_ = _mm512_shuffle_pd(rXi, rXi, 0xFF); \
      }
      #define ATL_vcxswapRI(d_, s_) d_ = _mm512_shuffle_pd(s_, s_, 0x55)
      #define ATL_vcxdotcomb(rR_, rI_) \
      { \
         (rR_)[0] += (rR_)[2]+(rR_)[4]+(rR_)[6] \
               - (rR_)[1]-(rR_)[3]-(rR_)[5]-(rR_)[7]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3] \
                  + (rI_)[4] + (rI_)[5] + (rI_)[6] + (rI_)[7]; \
      }
   #endif
#elif defined(ATL_AVXMAC) || defined(ATL_AVX)
   #ifdef SCPLX
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm256_moveldup_ps(rXi); \
         rXi_ = _mm256_movehdup_ps(rXi); \
      }
      #define ATL_vcxswapRI(d_, s_) d_ = _mm256_shuffle_ps(s_, s_, 0xB1)
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      {  __m128 t0_, t1_;\
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         rR_ = _mm256_hadd_ps(rR_, rI_); \
         rR_ = _mm256_hadd_ps(rR_, rR_); \
         t0_ =  _mm256_extractf128_ps(rR_, 1); \
         t0_ = _mm_add_ps(t0_, _mm256_extractf128_ps(rR_, 0)); \
         rR_ = _mm256_insertf128_ps(rR_, t0_, 0); \
      }
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      {  __m128 t0_; \
         t0_ = _mm256_extractf128_ps(rALn_,0); \
         t0_ = _mm_movelh_ps(t0_, t0_); \
         rALn_ = _mm256_insertf128_ps(rALn_,t0_, 0); \
         rALn_ = _mm256_insertf128_ps(rALn_,t0_, 1); \
         ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
         ATL_vcxswapRI(rALs_, rALs_); \
      }
   #else  /* DCPLX */
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm256_movedup_pd(rXi); \
         rXi_ = _mm256_shuffle_pd(rXi, rXi, 0xF); \
      }
      #define ATL_vcxswapRI(d_, s_) d_ = _mm256_shuffle_pd(s_, s_, 5)
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      {  __m128d t0_;\
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         rR_ = _mm256_hadd_pd(rR_, rI_); \
         t0_ =  _mm256_extractf128_pd(rR_, 1); \
         t0_ =  _mm_add_pd(t0_, _mm256_extractf128_pd(rR_, 0)); \
         rR_ = _mm256_insertf128_pd(rR_, t0_, 0); \
      }
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      { \
         rALn_ = _mm256_insertf128_pd(rALn_,_mm256_extractf128_pd(rALn_,0),1); \
         ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
         ATL_vcxswapRI(rALs_, rALs_); \
      }
   #endif
#elif defined(ATL_SSE2) && defined(DCPLX)
   #ifdef ATL_SSE3
      #define ATL_CXSPLDb 8
      #define ATL_vcxsplitRIld(rXr_, rXi_, pX_) \
      { \ 
         rXr = _mm_loaddup_pd(pX_); \
         rXi = _mm_loaddup_pd((pX_)+1); \
      }
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm_movedup_pd(rXi); \
         rXi_ = _mm_shuffle_pd(rXi, rXi, 0xF); \
      }
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      { \
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         rR_ = _mm_hadd_pd(rR_, rI_); \
      }
   #else
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm_unpacklo_pd(rXi, rXi); \
         rXi_ = _mm_unpackhi_pd(rXi, rXi); \
      }
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      {  __m128d t1_;\
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         t1_ = _mm_unpacklo_pd(rR_, rI_); \
         rR_ = _mm_unpackhi_pd(rR_, rI_); \
         ATL_vadd(rR_, rR_, t1_); \
      }
   #endif
   #define ATL_vcxswapRI(d_, s_) d_ = _mm_shuffle_pd(s_, s_, 5);
#elif defined(ATL_SSE1) && defined(SCPLX)
   #ifdef ATL_SSE3
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */ \
      { \
         rXr_ = _mm_moveldup_ps(rXi); \
         rXi_ = _mm_movehdup_ps(rXi); \
      }
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      { \
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         rR_ = _mm_hadd_ps(rR_, rI_); \
         rR_ = _mm_hadd_ps(rR_, rR_); \
      }
   #else
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm_shuffle_ps(rXi, rXi, 0xA0); \
         rXi_ = _mm_shuffle_ps(rXi, rXi, 0xF5); \
      }
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      {  __m128 t1_;\
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         t1_ = _mm_unpacklo_ps(rR_, rI_); \
         rR_ = _mm_unpackhi_ps(rR_, rI_); \
         ATL_vadd(rR_, rR_, t1_); \
         t1_ = _mm_movehl_ps(t1_, rR_); \
         ATL_vadd(rR_, rR_, t1_); \
      }
   #endif
   #define ATL_vcxswapRI(d_, s_) d_ = _mm_shuffle_ps(s_, s_, 0xB1)
   #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
   { \
      rALn_ = _mm_movelh_ps(rALn_, rALn_); \
      ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
      ATL_vcxswapRI(rALs_, rALs_); \
   }
#else  /* gnuvec */
   #if ATL_VLEN == 2
      #define ATL_VIPERMR ((ATL_VITYPE){0, 0})
      #define ATL_VIPERMI ((ATL_VITYPE){1, 1})
      #define ATL_vcxswapRI(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0})
      #define ATL_vcxdotcomb(rR_, rI_) \
      { \
         (rR_)[0] -= (rR_)[1]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1]; \
      }
   #elif  ATL_VLEN == 4
      #define ATL_vcxswapRI(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2})
      #define ATL_vcxdotcomb(rR_, rI_) \
      { \
         rR_[0] += (rR_)[2] - (rR_)[1] - (rR_)[3]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3]; \
      }
      #define ATL_VIPERMR ((ATL_VITYPE){0, 0, 2, 2})
      #define ATL_VIPERMI ((ATL_VITYPE){1, 1, 3, 3})
   #elif  ATL_VLEN == 8
      #define ATL_vcxswapRI(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2,5,4,7,6})
      #define ATL_vcxdotcomb(rR_, rI_) \
      { \
         (rR_)[0] += (rR_)[2]+(rR_)[4]+(rR_)[6] \
               - (rR_)[1]-(rR_)[3]-(rR_)[5]-(rR_)[7]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3] \
                  + (rI_)[4] + (rI_)[5] + (rI_)[6] + (rI_)[7]; \
      }
      #define ATL_VIPERMR ((ATL_VITYPE){0, 0, 2, 2, 4, 4, 6, 6})
      #define ATL_VIPERMI ((ATL_VITYPE){1, 1, 3, 3, 5, 5, 7, 7})
   #elif  ATL_VLEN == 16
      #define ATL_vcxswapRI(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2,5,4,7,6, \
                                                   9,8,11,10,13,12,15,14})
      #define ATL_vcxdotcomb(rR_, rI_) \
      { \
         (rR_)[0] += (rR_)[2]+(rR_)[4]+(rR_)[6]+(rR_)[8]+(rR_)[10]+(rR_)[12] \
                   + (rR_)[14] - (rR_)[1]-(rR_)[3]-(rR_)[5]-(rR_)[7] \
                   - (rR_)[9]-(rR_)[11]-(rR_)[13]-(rR_)[15]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3] \
                  + (rI_)[4] + (rI_)[5] + (rI_)[6] + (rI_)[7]  \
                  + (rI_)[8] + (rI_)[9] + (rI_)[10] + (rI_)[11]  \
                  + (rI_)[12] + (rI_)[13] + (rI_)[14] + (rI_)[15]; \
      }
      #define ATL_VIPERMR ((ATL_VITYPE){0, 0, 2, 2, 4, 4, 6, 6, \
                                        8, 8, 10, 10, 12, 12, 14, 14})
      #define ATL_VIPERMI ((ATL_VITYPE){1, 1, 3, 3, 5, 5, 7, 7, \
                                        9, 9, 11, 11, 13, 13, 15, 15})
   #elif  ATL_VLEN == 32
      #define ATL_vcxswapRI(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2,5,4,7,6, \
                                                   9,8,11,10,13,12,15,14, \
                                                   17,16,19,18,21,20,23,22, \
                                                   25,24,27,26,29,28,31,30})
      #define ATL_vcxdotcomb(rR_, rI_) \
      { \
         (rR_)[0] += (rR_)[2]+(rR_)[4]+(rR_)[6] \
                   + (rR_)[8]+(rR_)[10]+(rR_)[12]+(rR_)[14] \
                   + (rR_)[16]+(rR_)[18]+(rR_)[20]+(rR_)[22] \
                   + (rR_)[24]+(rR_)[26]+(rR_)[28]+(rR_)[30] \
                   - (rR_)[1]-(rR_)[3]-(rR_)[5]-(rR_)[7] \
                   - (rR_)[9]-(rR_)[11]-(rR_)[13]-(rR_)[15] \
                   - (rR_)[17]-(rR_)[19]-(rR_)[21]-(rR_)[23] \
                   - (rR_)[25]-(rR_)[27]-(rR_)[29]-(rR_)[31]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3] \
                  + (rI_)[4] + (rI_)[5] + (rI_)[6] + (rI_)[7]  \
                  + (rI_)[8] + (rI_)[9] + (rI_)[10] + (rI_)[11]  \
                  + (rI_)[12] + (rI_)[13] + (rI_)[14] + (rI_)[15] \
                  + (rI_)[16] + (rI_)[17] + (rI_)[18] + (rI_)[19] \
                  + (rI_)[20] + (rI_)[21] + (rI_)[22] + (rI_)[23] \
                  + (rI_)[24] + (rI_)[25] + (rI_)[26] + (rI_)[27] \
                  + (rI_)[28] + (rI_)[29] + (rI_)[30] + (rI_)[31]; \
      }
       #define ATL_VIPERMR ((ATL_VITYPE) \
        { 0,  0,  2,  2,  4,  4,  6,  6,  8,  8, 10, 10, 12, 12, 14, 14, \
          16, 16, 18, 18, 20, 20, 22, 22, 24, 24, 26, 26, 28, 28, 30, 30}) 
       #define ATL_VIPERMI ((ATL_VITYPE) \
        { 1,  1,  3,  3,  5,  5,  7,  7,  9,  9, 11, 11, 13, 13, 15, 15, \
         17, 17, 19, 19, 21, 21, 23, 23, 25, 25, 27, 27, 29, 29, 31, 31}) 
   #else
      #error "unsupported ATL_VLEN!"
   #endif
   #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
   { \
      rXr_ = __builtin_shuffle(rXi_, ATL_VIPERMR); \
      rXi_ = __builtin_shuffle(rXi_, ATL_VIPERMI); \
   }
#endif
/*
 * brute-force alpha prep works on any gcc-compat compiler & vec ISA
 */
#ifndef ATL_vcxPrepAlpha
   #if ATL_VLEN == 2  /* case that can be vec wt predef ops */
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      { \
         ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
         ATL_vcxswapRI(rALs_, rALs_); \
      }
   #else
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      { \
         TYPE mr_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
         TYPE a0_, a1_; int i_; \
         ATL_vst(mr_, rALn_); \
         a0_ = *(mr_); a1_ = mr_[1]; \
         for (i_=2; i_ < ATL_VLEN; i_ += 2) \
         { mr_[i_] = a0_; mr_[i_+1] = a1_; } \
         ATL_vld(rALn_, mr_); \
         a0_ = -a1_; a1_ = *(mr_); \
         for (i_=0; i_ < ATL_VLEN; i_ += 2) \
         { mr_[i_] = a0_; mr_[i_+1] = a1_; } \
         ATL_vld(rALs_, mr_); \
      }
   #endif
#endif
/*
 * brute force combine that will work on any gcc-compatible compiler/vec ISA
 */
#ifndef ATL_vcxdotcomb
   #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR gets ans */ \
   { \
      TYPE mr_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
      TYPE mi_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
      int i_;  \
      register TYPE dr_=ATL_rzero, di_=ATL_rzero; \
      ATL_vst(mr_, rR_); \
      ATL_vst(mi_, rI_); \
      for (i_=0; i_ < ATL_VLEN; i_ += 2) \
      { \
         dr_ += mr_[i_] - mr_[i_+1]; \
         di_ += mi_[i_] + mi_[i_+1]; \
      } \
      mr_[0] = dr_; \
      mr_[1] = di_; \
      ATL_vld(rR_, mr_); \
   }
#endif
/*
 * Default vcxsplitRIld that uses ATL_vld & ATL_vcxsplitRI
 */
#ifndef ATL_CXSPLDb
   #define ATL_CXSPLDb ATL_VLENb
#endif
#ifndef ATL_vcxsplitRIld
   #define ATL_vcxsplitRIld(rXr_, rXi_, pX_) \
   { \
      ATL_vld(rXi_, pX_); \
      ATL_vcxsplitRI(rXr_, rXi_); \
   }
#endif
/*
 * Convenience funcs for one vector iteration of DOT product, aligned &
 * unaligned Y. rX_ comes in already preloaded so that it can be used across mul
 * cols, as in GEMVT.  vX is natural order, vXs real/imag swapped (cxriswap).
 */
#define ATL_vcxdotA(dotR_, dotI_, vX_, vXs_, pY_) \
{\
   register ATL_VTYPE vY_; \
   ATL_vld(vY_, pY_); \
   ATL_vmac(dotR_, vX_, vY_); \
   ATL_vmac(dotI_, vXs_, vY); \
}

#define ATL_vcxdotU(dotR_, dotI_, vX_, vXs_, pY_) \
{\
   register ATL_VTYPE vY_; \
   ATL_vuld(vY_, pY_); \
   ATL_vmac(dotR_, vX_, vY_); \
   ATL_vmac(dotI_, vXs_, vY); \
}
/*
 * Convenience funcs for one vector iteration of AXPLY, [Un]&Aligned pY_
 * X comes in already split into vXr_ (real elts) and vXi_ (imag elts) so
 * that the same X values can be used across multiple Y vecs (which are
 * actually A columns for GER.
 */
#define ATL_vcxaxpyA(pY_, vXr_, vXi_, vALn_, vALs_) \
{                                      /* ALs={ALr,-iAL}; */ \
   register ATL_VTYPE vY_;             /* ALn={iAL,rAL} */ \
   ATL_vld(vY_, pY_);                  /* vY = {iY,rY, ...} */ \
   ATL_vmac(vY_, vXi_, vALs_);         /* vY += {iX*rAL, -iX*iAL} */ \
   ATL_vmac(vY_, vXr_, vALn_);         /* vY += {rX*iAL, rX*rAL} */ \
   ATL_vst(pY_, vY_); \
}

#define ATL_vcxaxpyU(pY_, vXr_, vXi_, vALn_, vALs_) \
{                                      /* ALs={ALr,-iAL}; */ \
   register ATL_VTYPE vY_, vXr_, vXi_; /* ALn={iAL,rAL} */ \
   ATL_vuld(vY_, pY_);                 /* vY = {iY,rY, ...} */ \
   ATL_vmac(vY_, vXi_, vALs_);         /* vY += {iX*rAL, -iX*iAL} */ \
   ATL_vmac(vY_, vXr_, vALn_);         /* vY += {rX*iAL, rX*rAL} */ \
   ATL_vst(pY_, vY_); \
}
/*
 * Remainder load/store functions.  They take 0 < n_ < (ATL_VLEN/2), which
 * is the number of complex elts to load/store from/to the ptr
 */

#if ATL_VLEN <= 4
   #define ATL_vcxldR(r_, p_, n_) ATL_vcxld1(r_, p_)
   #define ATL_vcxuldR(r_, p_, n_) ATL_vcxuld1(r_, p_)
   #define ATL_vcxstR(p_, r_, n_) ATL_vcxst1(p_, r_)
   #define ATL_vcxustR(p_, r_, n_) ATL_vcxust1(p_, r_)
   #define ATL_vcxldXYR(rX_, pX_, rY_, pY_, n_) \
   { \
      ATL_vcxld1(rX_, pX_); \
      ATL_vcxld1(rY_, pY_); \
   }
   #define ATL_vcxldXuYR(rX_, pX_, rY_, pY_, n_) \
   { \
      ATL_vcxld1(rX_, pX_); \
      ATL_vcxuld1(rY_, pY_); \
   }
   #define ATL_vcxlduXuYR(rX_, pX_, rY_, pY_, n_) \
   { \
      ATL_vcxuld1(rX_, pX_); \
      ATL_vcxuld1(rY_, pY_); \
   }
@BEGINPROC ldR2 nm nm1 arg1 nm2 arg2
   #define ATL_vcx@(nm)R(@(arg1),@(arg2),n_) \
   { \
      switch(n_) \
      { \
   @iexp k 2 @(j) /
   @iexp k @(k) -1 +
   @iexp i 1 0 +
   @iwhile i < @(k)
      case @(i) : \
         ATL_vcx@(nm1)@(i)(@(arg1)); \
         ATL_vcx@(nm2)@(i)(@(arg2)); \
         break; \
      @iexp i @(i) 1 +
   @endiwhile
      default: \
         ATL_vcx@(nm1)@(i)(@(arg1)); \
         ATL_vcx@(nm2)@(i)(@(arg2)); \
      } \
   }
@ENDPROC
@BEGINPROC ldstR1 nm arg
   #define ATL_vcx@(nm)R(@(arg),n_) \
   { \
      switch(n_) \
      { \
   @iexp k 2 @(j) /
   @iexp k @(k) -1 +
   @iexp i 1 0 +
   @iwhile i < @(k)
      case @(i) : \
         ATL_vcx@(nm)@(i)(@(arg)); \
         break; \
      @iexp i @(i) 1 +
   @endiwhile
      default: \
         ATL_vcx@(nm)@(i)(@(arg)); \
      } \
   }
@ENDPROC
@iexp j 4 4 +
@iwhile j < 64
#elif ATL_VLEN == @(j)
   @CALLPROC ldR2 ldXY ld rX_,pX_ ld rY_,pY_
   @CALLPROC ldR2 ldXuY ld rX_,pX_ uld rY_,pY_
   @CALLPROC ldR2 lduXuY uld rX_,pX_ uld rY_,pY_
   @CALLPROC ldstR1 ld r_,p_
   @CALLPROC ldstR1 st p_,r_
   @CALLPROC ldstR1 uld r_,p_
   @CALLPROC ldstR1 ust p_,r_
   @iexp j @(j) @(j) +
@endiwhile
#endif    /* end VLEN test for remainder definitions */

#endif   /* end multiple inclusion guard */
@ROUT atlas_cplxsimd.h00
/*
 * Now define the remainder terms, which depend only on VLEN and prior ld/st
 * For VLEN == 2, they should be empty, but we have them call the scalar
 * code so that it is always safe to use them for peeling.
 */
#if ATL_VLEN == 2
   #define ATL_vcxldR(r_, p_, n_) ATL_vcxld1(r_, p_)
   #define ATL_vcxuldR(r_, p_, n_) ATL_vcxuld1(r_, p_)
   #define ATL_vcxstR(p_, r_, n_) ATL_vcxst(p_, r_)
   #define ATL_vcxustR(p_, r_, n_) ATL_vcxst(p_, r_)
@iexp i 4 0 +
@iwhile i < 64
#elif ATL_VLEN == @(i)
   #define ATL_vcxuldR(r_, p_, n_) \
   { \
      switch(n_) \
      { \
   @iexp j 1 0 +
   @iexp h @(i) -1 +
   @iwhile j < @(h)
      case @(j): \
         ATL_vcxuld@(j)(r_, p_); \
         break; \
      @iexp j @(j) 1 +
   @endiwhile
      default: \
         ATL_vcxuld@(h)(r_, p_); \
      } \
   }
   @iexp i @(i) 2 *
@endiwhile
#else
   #error "unsupported ATL_VLEN!"
#endif

/*
 * ============================================================================
 * AXPY-based computation has the following features:
 * (1) Performance limited by load/store of Y, so ops permuted to keep Y in
 *     natural order
 * (2) X is split into real & imaginary components
 * (3) alpha is scaled & permuted to allow for MAC-based computation
 *
 * AXPY-BASED MACROS:
 *    ATL_cxaxp_ldALP(alpN, alpP, pALP)   : ld alpN, perm & scale alpP 
 *    ATL_cxaxp_spltX(realX, imagX, pX)   : split X into real/imag wt dup
 *    ATL_cxaxp_spltX_UA(realX, imagX, pX): above, assume pX is unaligned 
 *       Assuming n = VLEN/2:
 *       realX={real(Xn),real(Xn),...real(X1),real(X1),real(X0),real(X0)}
 *       imagX={imag(Xn),imag(Xn),...imag(X1),imag(X1),imag(X0),imag(X0)}
 * ============================================================================
 */
#if defined(ATL_VSX)
   #ifdef SCPLX
      #if ATL_FULLGCCVSX   /* not supported by older gcc (eg. 4.8) */
         #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
         { \
            ATL_vld(rXi_, pX_); \
            rXr_ = (ATL_VTYPE) vec_mergee((vector unsigned int)(rXi_), \
                                          (vector unsigned int) (rXi_)); \
            rXi_ = (ATL_VTYPE) vec_mergeo((vector unsigned int)(rXi_),\
                                          (vector unsigned int)(rXi_)); \
         }
         #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
         { \
            ATL_vuld(rXi_, pX_); \
            rXr_ = (ATL_VTYPE) vec_mergee((vector unsigned int)(rXi_),\
                                          (vector unsigned int) (rXi_)); \
            rXi_ = (ATL_VTYPE) vec_mergeo((vector unsigned int)(rXi_), \
                                          (vector unsigned int)(rXi_)); \
         }
      #else
/*
 *       Using these guys as constants isn't so great: gcc 4.8.2 pulls
 *       the formation of the first iperm vector out of a loop, but then leaves
 *       the formation of the second (in terms of the first) inside the loop.
 *       The fix is to have this file define DECL/INIT macros, where we manually
 *       declare the perm vector, create it, and hoist it ourselves. 
 *       For now, we'll keep with crap way, since later gcc should switch
 *       to mergee/mergeo anyway.
 */
         #define ATL_MERGEE (vector unsigned char) \
            {0, 1, 2, 3, 0, 1, 2, 3, 8, 9, 10, 11, 8, 9, 10, 11}
         #define ATL_MERGEO (vector unsigned char) \
            {4, 5, 6, 7, 4, 5, 6, 7, 12, 13, 14, 15, 12, 13, 14, 15}
         #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
         { \
            ATL_vld(rXi_, pX_); \
            rXr_ = vec_perm(rXi_, rXi, ATL_MERGEE); \
            rXi_ = vec_perm(rXi_, rXi, ATL_MERGEO); \
         }
         #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
         { \
            ATL_vuld(rXi_, pX_); \
            rXr_ = vec_perm(rXi_, rXi, ATL_MERGEE); \
            rXi_ = vec_perm(rXi_, rXi, ATL_MERGEO); \
         }
      #endif
   #else
      #define ATL_CXAXP_ALGX 8
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         rXr_ = vec_splats(*(pX_)); \
         rXi_ = vec_splats(*((pX_)+1)); \
      }
      #define ATL_cxaxp_spltX_UA ATL_cxaxp_spltX /* only need native algn */
   #endif
#elif defined(ATL_AVXMAC) || defined(ATL_AVX)
   #ifdef SCPLX
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         ATL_vld(rXi_, pX_); \
         rXr_ = _mm256_moveldup_ps(rXi); \
         rXi_ = _mm256_movehdup_ps(rXi); \
      }
      #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
      { \
         ATL_vuld(rXi_, pX_); \
         rXr_ = _mm256_moveldup_ps(rXi); \
         rXi_ = _mm256_movehdup_ps(rXi); \
      }
   #else /* double precision */
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         ATL_vld(rXi_, pX_); \
         rXr_ = _mm256_movedup_pd(rXi); \
         rXi_ = _mm256_shuffle_pd(rXi, rXi, 0xF); \
      }
      #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
      { \
         ATL_vuld(rXi_, pX_); \
         rXr_ = _mm256_movedup_pd(rXi); \
         rXi_ = _mm256_shuffle_pd(rXi, rXi, 0xF); \
      }
   #endif
#elif defined(ATL_SSE3)
   #ifdef SCPLX
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         ATL_vld(rXi_, pX_); \
         rXr_ = _mm_moveldup_ps(rXi); \
         rXi_ = _mm_movehdup_ps(rXi); \
      }
      #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
      { \
         ATL_vuld(rXi_, pX_); \
         rXr_ = _mm_moveldup_ps(rXi); \
         rXi_ = _mm_movehdup_ps(rXi); \
      }
   #else /* double precision */
      #define ATL_CXAXP_ALGX 8
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         rXr_ = _mm_loaddup_pd(pX_); \
         rXi_ = _mm_loaddup_pd(((TYPE*)(pX_))+1); \
      }
      #define ATL_cxaxp_spltX_UA ATL_cxaxp_spltX /* only need native algn */
   #endif
#elif defined(ATL_SSE2) && defined(DCPLX)
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         ATL_vld(rXi_, pX_); \
         rXr_ = _mm_unpacklo_pd(rXi, rXi); \
         rXi_ = _mm_unpackhi_pd(rXi, rXi); \
      }
      #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
      { \
         ATL_vuld(rXi_, pX_); \
         rXr_ = _mm_unpacklo_pd(rXi, rXi); \
         rXi_ = _mm_unpackhi_pd(rXi, rXi); \
      }
#elif defined(ATL_SSE1) && defined(SCPLX)
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         ATL_vld(rXi_, pX_); \
         rXr_ = _mm_shuffle_ps(rXi, rXi, 0xA0); \
         rXi_ = _mm_shuffle_ps(rXi, rXi, 0xF5); \
      }
      #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
      { \
         ATL_vuld(rXi_, pX_); \
         rXr_ = _mm_shuffle_ps(rXi, rXi, 0xA0); \
         rXi_ = _mm_shuffle_ps(rXi, rXi, 0xF5); \
      }
#else /* if all else fails, use gnu built vector  */
   #if ATL_VLEN == 2
      #define ATL_VIPERMR (ATL_VITYPE){0, 0}
      #define ATL_VIPERMI (ATL_VITYPE){1, 1}
      #define ATL_cxaxp_spltX_UA(rR_, rI_, p_) \
      { \
         rR_ = (ATL_VTYPE){*(p_),*(p_)}; \
         rI_ = (ATL_VTYPE){(p_)[1],(p_)[1]}; \
      }
   #elif ATL_VLEN == 4
      #define ATL_VIPERMR (ATL_VITYPE){0, 0, 2, 2}
      #define ATL_VIPERMI (ATL_VITYPE){1, 1, 3, 3}
      #define ATL_cxaxp_spltX_UA(rR_, rI_, p_) \
      { \
         rR_ = (ATL_VTYPE){*(p_),*(p_),(p_)[2],(p_)[2]}; \
         rI_ = (ATL_VTYPE){(p_)[1],(p_)[1],(p_)[3],(p_)[3]}; \
      }
   #elif ATL_VLEN == 8
      #define ATL_VIPERMR (ATL_VITYPE){0, 0, 2, 2, 4, 4, 6, 6}
      #define ATL_VIPERMI (ATL_VITYPE){1, 1, 3, 3, 5, 5, 7, 7}
      #define ATL_cxaxp_spltX_UA(rR_, rI_, p_) \
      { \
         rR_ = (ATL_VTYPE){*(p_),*(p_),(p_)[2],(p_)[2], \
                           (p_)[4],(p_)[4],(p_)[6],(p_)[6]}; \
         rI_ = (ATL_VTYPE){(p_)[1],(p_)[1],(p_)[3],(p_)[3], \
                           (p_)[5],(p_)[5],(p_)[7],(p_)[7]}; \
      }
   #elif ATL_VLEN == 16
      #define ATL_VIPERMR (ATL_VITYPE){0, 0, 2, 2, 4, 4, 6, 6, \
                                       8, 8, 10, 10, 12, 12, 14, 14};
      #define ATL_VIPERMI (ATL_VITYPE){1, 1, 3, 3, 5, 5, 7, 7, \
                                       9, 9, 11, 11, 13, 13, 15, 15};
      #define ATL_cxaxp_spltX_UA(rR_, rI_, p_) \
      { \
         rR_ = (ATL_VTYPE){*(p_),*(p_),(p_)[2],(p_)[2], \
                           (p_)[4],(p_)[4],(p_)[6],(p_)[6], \
                           (p_)[8],(p_)[8],(p_)[10],(p_)[10], \
                           (p_)[12],(p_)[12],(p_)[14],(p_)[14]}; \
         rI_ = (ATL_VTYPE){(p_)[1],(p_)[1],(p_)[3],(p_)[3], \
                           (p_)[5],(p_)[5],(p_)[7],(p_)[7], \
                           (p_)[9],(p_)[9],(p_)[11],(p_)[11], \
                           (p_)[13],(p_)[13],(p_)[15],(p_)[15]}; \
      }
   #elif ATL_VLEN == 32
       #define ATL_VIPERMR (ATL_VITYPE) \
        { 0,  0,  2,  2,  4,  4,  6,  6,  8,  8, 10, 10, 12, 12, 14, 14, \
         16, 16, 18, 18, 20, 20, 22, 22, 24, 24, 26, 26, 28, 28, 30, 30}; \
       #define ATL_VIPERMI (ATL_VITYPE) \
        { 1,  1,  3,  3,  5,  5,  7,  7,  9,  9, 11, 11, 13, 13, 15, 15, \
         17, 17, 19, 19, 21, 21, 23, 23, 25, 25, 27, 27, 29, 29, 31, 31}; \
      #define ATL_cxaxp_spltX_UA(rR_, rI_, p_) \
      { \
         rR_ = (ATL_VTYPE){*(p_),*(p_),(p_)[2],(p_)[2], \
                           (p_)[4],(p_)[4],(p_)[6],(p_)[6], \
                           (p_)[8],(p_)[8],(p_)[10],(p_)[10], \
                           (p_)[12],(p_)[12],(p_)[14],(p_)[14], \
                           (p_)[16],(p_)[18],(p_)[20],(p_)[22], \
                           (p_)[24],(p_)[24],(p_)[26],(p_)[26], \
                           (p_)[28],(p_)[28],(p_)[30],(p_)[30]}; \
         rI_ = (ATL_VTYPE){(p_)[1],(p_)[1],(p_)[3],(p_)[3], \
                           (p_)[5],(p_)[5],(p_)[7],(p_)[7], \
                           (p_)[9],(p_)[9],(p_)[11],(p_)[11], \
                           (p_)[13],(p_)[13],(p_)[15],(p_)[15], \
                           (p_)[17],(p_)[19],(p_)[21],(p_)[23], \
                           (p_)[25],(p_)[25],(p_)[27],(p_)[27], \
                           (p_)[29],(p_)[29],(p_)[31],(p_)[31]};
      }
   #else
      #error "VLEN != {2,4,8,16,32} unsupported "
   #endif
   #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
   {  ATL_VTYPE t_; \
      ATL_vld(rXi_, pX_); \
      rXr_ = __builtin_shuffle(rXi_, ATL_VIPERMR); \
      rXi_ = __builtin_shuffle(rXi_, ATL_VIPERMI); \
   }
#endif
/*
 * natural default alignment is default X/y align
 */
#ifndef ATL_CXAXP_ALGY
   #define ATL_CXAXP_ALGY ATL_VLENb
#endif
#ifndef ATL_CXAXP_ALGX
   #define ATL_CXAXP_ALGX ATL_VLENb
#endif
#ifndef ATL_cxaxp_ldALP
/*
 * rAn = {ialpha,  ralpha} repeated VLEN/2 times
 * rAs = {ralpha, -ialpha} repeated VLEN/2 times
 * Not written efficiently for portability.  Assumed called outside optloop.
 * System-specific code can provide more efficient version, then this generic
 * implementation won't be used.
 */
   #define ATL_cxaxp_ldALP(rAn_, rAs_, alp_) \
   {  TYPE al_[ATL_VLEN]; \
      int i;\
      const register TYPE ralp=(*(alp_)), ialp=(alp_)[1], ialpn=-ialp; \
      for (i=0; i < ATL_VLEN; i += 2) \
      { \
         al_[i] = ralp; \
         al_[i+1] = ialp; \
      } \
      ATL_vuld(rAn_, al_); \
      for (i=0; i < ATL_VLEN; i += 2) \
      { \
         al_[i] = ialpn; \
         al_[i+1] = ralp; \
      } \
      ATL_vuld(rAs_, al_); \
   }
#endif
/*
 * Convenience function for cleanup.  If vectorized cleanup not provided,
 * just use this scalar loop
 */
#ifndef ATL_cxaxp_clean
   #define ATL_cxaxp_clean(n_, pX_, pY_, alp_) \
   { \
      if (n_) \
      { \
         const TYPE *px_ = (pX_); \
         TYPE *py_ = (pY_); \
         const register TYPE ra_ = *(alp_), ia_ = (alp_)[1]; \
         int i_=n_; \
         do \
         { \
            const register TYPE rx_=(*px_), ix_=px_[1]; \
            *py_   += ra_*rx_ - ia_*ix_; \
            py_[1] += ra_*ix_ + ia_*rx_; \
            py_ += 2; \
            px_ += 2; \
         } \
         while(--i_); \
      } \
   }
#endif
/*
 * ============================================================================
 * The DOT-based compution is based on the idea of using separate accumulators
 * for real and imaginary computation, and using vector reduction to produce
 * the complete answer from partial results.
 * Doing this requires these macros:
 *    ATL_cxdot_riswap(rd, rs) : rd gets rs, with even/odd words swapped
 *    ATL_cxdot_comb(rR, rI): combine (rR,iR), ans in low 2 wrds rR, 0 upper
 *    ATL_cxdot_cxldR(r_,p_, n_): low n_ cplx elts from aligned p_, rest 0
 *    ATL_cxdot_cxuldR(r_,p_, n_): low n_ cplx elts from unaligned p_, rest 0
 *    -> used for cleanup, n_ < VLEN!
 * ============================================================================
 */
#if defined(ATL_VSX)
   #ifdef SCPLX
      #if ATL_FULLGCCVSX
         #define ATL_cxdot_cxldR(r_, p_, n_) \
         {  ATL_VTYPE zr_;\
            ATL_vld(r_, p_); /* no seg fault VLEN < CL */ \
            ATL_vzero(zr_); \
            r_ = vec_xxpermdi(r_, zr_, 2); \
         }
      #else
         #define ATL_cxdot_cxldR(r_, p_, n_) \
         {  ATL_VTYPE zr_;\
            ATL_vld(r_, p_); /* no seg fault VLEN < CL */ \
            ATL_vzero(zr_); \
            r_ = vec_perm(r_, zr_, ((vector unsigned char) \
               {0,1,2,3,4,5,6,7,8,16,17,18,19,20,21,22,23,24})); \
         }
      #endif
      #define ATL_cxdot_cxuldR(r_, p_, n_) \
      {  ATL_VTYPE zr_;\
         ATL_vld(r_, p_); /* no seg fault VLEN < CL */ \
         ATL_vzero(zr_); \
         r_ = vec_perm(r_, zr_, vec_lvsl(0, p_)); \
      }
      #define ATL_RISWAPV (vector unsigned char) \
          {4, 5, 6, 7, 0, 1, 2, 3, 12, 13, 14, 15, 8, 9, 10, 11}
   #else
      #if ATL_FULLGCCVSX
         #define ATL_cxdot_riswap(rd_, rs_) rd_ = vec_xxpermdi(rs_, rs_, 2)
      #else
         #define ATL_RISWAPV (vector unsigned char) \
             {8, 9, 10, 11, 12, 13, 14, 15, 0, 1, 2, 3, 4, 5, 6, 7}
      #endif
      #define ATL_cxdot_cxldR(r_, p_, n_) ATL_vld(r_, p_)
      #define ATL_cxdot_cxuldR(r_, p_, n_) ATL_vuld(r_, p_)
   #endif
/*
 * If we don't have access to better solution use vec_perm for real/imag swap
 */
   #ifndef ATL_cxdot_riswap
      #define ATL_cxdot_riswap(rd_, rs_) rd_ = vec_perm(rs_, rs_, ATL_RISWAPV)
   #endif
/*
 * brute force combine that will work on any altivec-supporting gcc
 */
   #ifndef ATL_cxdot_comb
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      { \
         TYPE mr_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
         TYPE mi_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
         int i_;  \
         register TYPE dr_=ATL_rzero, di_=ATL_rzero; \
         ATL_vst(mr_, rR_); \
         ATL_vst(mi_, rI_); \
         for (i_=0; i_ < ATL_VLEN; i_ += 2) \
         { \
            dr_ += mr_[i_] - mr_[i_+1]; \
            di_ += mi_[i_] + mi_[i_+1]; \
         } \
         *(p_) = dr_; \
         (p_)[1] = di_; \
      }
   #endif
#elif defined(ATL_AVXMAC) || defined(ATL_AVX)
   #ifdef SCPLX
      #define ATL_cxdot_riswap(rd_, rs_) rd_ = _mm256_shuffle_ps(rs_, rs_, 0xB1)
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      {  __m256 h_; __m128 t0_, t1_;\
         ATL_vmul(h_, rR_, ATL_VONEPN); \
         h_ = _mm256_hadd_ps(h_, rI_); \
         h_ = _mm256_hadd_ps(h_, h_); \
         t0_ =  _mm256_extractf128_ps(h_, 1); \
         t0_ = _mm_add_ps(t0_, _mm256_extractf128_ps(h_, 0)); \
         _mm_store_ss(p_, t0_); \
         t0_ = _mm_shuffle_ps(t0_, t0_, 0xE5); \
         _mm_store_ss(((p_)+1), t0_); \
      }
      #define ATL_cxdot_cxldR(r_, p_, n_) \
      {  __m128 t0_; \
         ATL_vzero(r_); \
         if (n_ == 1) \
         { \
            t0_ =  _mm_setzero_ps(); \
            t0_ = _mm_loadl_pi(t0_, (void*)(p_)); \
            r_ = _mm256_insertf128_ps(r_, t0_, 0); \
         } \
         else /* n_ is 2 or 3 */ \
         { \
            r_ = _mm256_insertf128_ps(r_, _mm_load_ps(p_), 0); \
            if (n_ != 2) \
            { \
               t0_ =  _mm_setzero_ps(); \
               t0_ = _mm_loadl_pi(t0_, (void*)((p_)+4)); \
               r_ = _mm256_insertf128_ps(r_, t0_, 1); \
            } \
         } \
      }
      #define ATL_cxdot_cxuldR(r_, p_, n_) \
      { \
         if (n_ == 2) \
         { \
            ATL_vzero(r_); \
            r_ = _mm256_insertf128_ps(r_, _mm_loadu_ps(p_), 0); \
         } \
         else  /* use maskmov for other cases */ \
         { \
             __m256i msk; \
             __m128i mskh; \
             mskh = _mm_setzero_si128(); \
             mskh = _mm_insert_epi64(mskh,(long long)0xFFFFFFFFFFFFFFFF,0);\
             if (n_ == 1) \
             { \
                msk = _mm256_setzero_si256(); \
                msk = _mm256_insertf128_si256(msk, mskh, 0); \
             } \
             else /* n == 3 */ \
             { \
                msk = _mm256_insertf128_si256(msk, mskh, 1); \
                mskh = _mm_unpacklo_epi64(mskh, mskh); \
                msk = _mm256_insertf128_si256(msk, mskh, 0); \
             } \
             r_ = _mm256_maskload_ps(p_, msk); \
         } \
      }
   #else
      #define ATL_cxdot_riswap(rd_, rs_) rd_ = _mm256_shuffle_pd(rs_, rs_, 5)
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      { __m256d h_; __m128d t0_;\
         ATL_vmul(h_, rR_, ATL_VONEPN); \
         h_ = _mm256_hadd_pd(h_, rI_); \
         t0_ =  _mm256_extractf128_pd(h_, 1); \
         t0_ = _mm_add_pd(t0_, _mm256_extractf128_pd(h_, 0)); \
         _mm_storeu_pd(p_, t0_); \
      }
      #define ATL_cxdot_cxldR(r_, p_, n_) \
      { \
         r_ = ATL_vzero(r_); \
         r_ = _mm256_insertf128_pd(r_, _mm_load_pd(p_), 0); \
      }
      #define ATL_cxdot_cxuldR(r_, p_, n_) \
      { \
         r_ = ATL_vzero(r_); \
         r_ = _mm256_insertf128_pd(r_, _mm_loadu_pd(p_), 0); \
      }
   #endif
#elif defined(ATL_SSE2) && defined(DCPLX)
      #define ATL_cxdot_riswap(rd_, rs_) rd_ = _mm_shuffle_pd(rs_, rs_, 1)
      #define ATL_cxdot_cxldR(r_, p_, n_) r_ = _mm_load_pd(p_)
      #define ATL_cxdot_cxuldR(r_, p_, n_) r_ = _mm_loadu_pd(p_)
      #ifdef ATL_SSE3
         #define ATL_cxdot_comb(p_, rR_, rI_) \
         {  __m128d t0_; \
            ATL_vmul(t0_, rR_, ATL_VONEPN)); \
            _mm_storeu_pd(p_, _mm_hadd_pd(t0_, rI_)); \
         }
      #else
         #define ATL_cxdot_comb(p_, rR_, rI_) \
         {  __m128d t0_, t1_; \
            ATL_vmul(t0_, rR_, ATL_VONEPN); \
            t1_ = _mm_unpacklo_pd(t0_, rI_); \
            t0_ = _mm_unpackhi_pd(t0_, rI_); \
            ATL_vadd(t0_, t0_, t1_); \
            _mm_storeu_pd(p_, t0_); \
         }
      #endif
#elif defined(ATL_SSE1) && defined(SCPLX)
      #define ATL_cxdot_riswap(rd_, rs_) rd_ = _mm_shuffle_ps(rs_, rs_, 0xB1)
      #if 0  /* would work if intrinsics weren't retarded */
         #define ATL_cxdot_cxldR(r_, p_, n_) \
            r_ = (ATL_VTYPE) _mm_load_sd((void*)(p_))
         #define ATL_cxdot_cxuldR(r_, p_, n_) \
            r_ = (ATL_VTYPE) _mm_loadu_sd((void*)(p_))
      #else
         #define ATL_cxdot_cxldR(r_, p_, n_) \
         { \
            r_ =  _mm_setzero_ps(); \
            r_ = _mm_loadl_pi(r_, (void*)(p_)); \
         }
         #define ATL_cxdot_cxuldR(r_, p_, n_) \
         {  __m128 t_; \
            r_ = _mm_load_ss(p_); \
            t_ = _mm_load_ss((p_)+1); \
            r_ = _mm_unpacklo_ps(r_, t_); \
         }
      #endif
      #ifdef ATL_SSE3
         #define ATL_cxdot_comb(p_, rR_, rI_) \
         {  __m128 t0_; \
            ATL_vmul(t0_, rR_, ATL_VONEPN); \
            t0_ = _mm_hadd_ps(t0_, rI_); \
            t0_ = _mm_hadd_ps(t0_, t0_); \
            _mm_store_ss(p_, t0_); \
            t0_ = _mm_shuffle_ps(t0_, t0_, 0xE1); \
            _mm_store_ss((p_)+1, t0_); \
         }
      #else
         #define ATL_cxdot_comb(p_, rR_, rI_) \
         {  __m128 t0_, t1_; \
            ATL_vmul(t0_, rR_, ATL_VONEPN); \
            t1_ = _mm_unpacklo_ps(t0_, rI_); \
            t0_ = _mm_unpackhi_ps(t0_, rI_); \
            ATL_vadd(t0_, t0_, t1_); \
            t1_ = _mm_movehl_ps(t1_, t0_); \
            ATL_vadd(t0_, t0_, t1_); \
            _mm_store_ss(p_, t0_); \
            t0_ = _mm_shuffle_ps(t0_, t0_, 0xE1); \
            _mm_store_ss((p_)+1, t0_); \
         }
      #endif
#else   /* gnuvec */
   #if ATL_VLEN == 2
      #define ATL_cxdot_cxuldR(r_, p_, n_) r_ = (ATL_VTYPE) {*(p_)}
      #define ATL_cxdot_riswap(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0})
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      { \
         *(p_) = (rR_)[0] - (rR_)[1]; \
         (p_)[1] = (rI_)[0] + (rI_)[1]; \
      }
   #elif  ATL_VLEN == 4
      #define ATL_cxdot_cxuldR(r_, p_, n_) \
      { \
         if (n_ == 1) \
            r_ = (ATL_VTYPE) {*(p_), (p_)[1]}; \
         else \
            r_ = (ATL_VTYPE) {*(p_), (p_)[1], (p_)[2], (p_)[3]}; \
      }
      #define ATL_cxdot_riswap(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2})
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      { \
         *(p_) = (rR_)[0] + (rR_)[2] - (rR_)[1] - (rR_)[3]; \
         (p_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3]; \
      }
   #elif  ATL_VLEN == 8
      #define ATL_cxdot_riswap(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2,5,4,7,6})
      #define ATL_cxdot_cxuldR(r_, p_, n_) \
      { \
         if (n_ == 1) \
            r_ = (ATL_VTYPE) {*(p_), (p_)[1]}; \
         else if (n_ == 2) \
            r_ = (ATL_VTYPE) {*(p_), (p_)[1], (p_)[2], (p_)[3]}; \
         else /* if (n_ == 3) */ \
            r_ = (ATL_VTYPE) {*(p_),(p_)[1],(p_)[2],(p_)[3],(p_)[4],(p_)[5]}; \
      }
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      { \
         *(p_) = (rR_)[0]+(rR_)[2]+(rR_)[4]+(rR_)[6] \
               - (rR_)[1]-(rR_)[3]-(rR_)[5]-(rR_)[7]; \
         (p_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3] \
                 + (rI_)[4] + (rI_)[5] + (rI_)[6] + (rI_)[7]; \
      }
   #elif  ATL_VLEN == 16
   #elif  ATL_VLEN == 32
   #else
      #error "unsupported ATL_VLEN!"
   #endif
   #define ATL_cxdot_cxldR ATL_cxdot_cxuldR
#endif

#endif  /* end multiple inclusion guard */
@ROUT ATL_rk4n4
#include "atlas_misc.h"
#include "atlas_amm.h"
#include "atlas_simd.h"
#if defined(__STDC_VERSION__) && (__STDC_VERSION__/100 >= 1999)
   #ifdef __GNUC__
      #define ATL_SINLINE static __inline__
   #else
      #define ATL_SINLINE static inline
   #endif
#else
   #define ATL_SINLINE static
#endif
#if ATL_VLEN > 1
@define up @@
@whiledef up u
   @define ld @ATL_v@(up)ld@
   @define st @ATL_v@(up)st@
ATL_SINLINE void ATL_rk4n4_@(up)vec
(
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   const SCALAR alpha,
   const TYPE *A0,
   ATL_CSZT lda,
   const TYPE *B0,
   ATL_CSZT ldb,
   TYPE *C0,
   ATL_CSZT ldc
)
{
   ATL_VTYPE b00, b10, b20, b30, b01, b11, b21, b31;
   ATL_VTYPE b02, b12, b22, b32, b03, b13, b23, b33;
   const TYPE *A1=A0+lda, *A2=A1+lda, *A3=A2+lda;
   TYPE *C1=C0+ldc, *C2=C1+ldc, *C3=C2+ldc;
   register int i;
   if (TB == AtlasNoTrans)
   {
      const TYPE *B1=B0+ldb, *B2=B1+ldb, *B3=B2+ldb;
      ATL_vbcast(b00, B0);
      ATL_vbcast(b01, B1);
      ATL_vbcast(b02, B2);
      ATL_vbcast(b03, B3);
      ATL_vbcast(b10, B0+1);
      ATL_vbcast(b11, B1+1);
      ATL_vbcast(b12, B2+1);
      ATL_vbcast(b13, B3+1);
      ATL_vbcast(b20, B0+2);
      ATL_vbcast(b21, B1+2);
      ATL_vbcast(b22, B2+2);
      ATL_vbcast(b23, B3+2);
      ATL_vbcast(b30, B0+3);
      ATL_vbcast(b31, B1+3);
      ATL_vbcast(b32, B2+3);
      ATL_vbcast(b33, B3+3);
   }
   else /* TB == AtlasTrans, B NxK */
   {
      const TYPE *B1=B0+ldb, *B2=B1+ldb, *B3=B2+ldb;
      ATL_vbcast(b00, B0);
      ATL_vbcast(b10, B1);
      ATL_vbcast(b20, B2);
      ATL_vbcast(b30, B3);
      ATL_vbcast(b01, B0+1);
      ATL_vbcast(b11, B1+1);
      ATL_vbcast(b21, B2+1);
      ATL_vbcast(b31, B3+1);
      ATL_vbcast(b02, B0+2);
      ATL_vbcast(b12, B1+2);
      ATL_vbcast(b22, B2+2);
      ATL_vbcast(b32, B3+2);
      ATL_vbcast(b03, B0+3);
      ATL_vbcast(b13, B1+3);
      ATL_vbcast(b23, B2+3);
      ATL_vbcast(b33, B3+3);
   }
   if (alpha != 1.0)
   {
      ATL_VTYPE al;
      ATL_vbcast(al, &alpha);
      ATL_vmul(b00, b00, al);
      ATL_vmul(b10, b10, al);
      ATL_vmul(b20, b20, al);
      ATL_vmul(b30, b30, al);
      ATL_vmul(b01, b01, al);
      ATL_vmul(b11, b11, al);
      ATL_vmul(b21, b21, al);
      ATL_vmul(b31, b31, al);
      ATL_vmul(b02, b02, al);
      ATL_vmul(b12, b12, al);
      ATL_vmul(b22, b22, al);
      ATL_vmul(b32, b32, al);
      ATL_vmul(b03, b03, al);
      ATL_vmul(b13, b13, al);
      ATL_vmul(b23, b23, al);
      ATL_vmul(b33, b33, al);
   }
   for (i=0; i < M; i += ATL_VLEN)
   {
      ATL_VTYPE c0, c1, c2, c3, a0;
      @(ld)(c0, C0+i);
      @(ld)(c1, C1+i);
      @(ld)(c2, C2+i);
      @(ld)(c3, C3+i);

      @(ld)(a0, A0+i);
      ATL_vmac(c0, b00, a0);
      ATL_vmac(c1, b01, a0);
      ATL_vmac(c2, b02, a0);
      ATL_vmac(c3, b03, a0);
      @(ld)(a0, A1+i);
      ATL_vmac(c0, b10, a0);
      ATL_vmac(c1, b11, a0);
      ATL_vmac(c2, b12, a0);
      ATL_vmac(c3, b13, a0);
      @(ld)(a0, A2+i);
      ATL_vmac(c0, b20, a0);
      ATL_vmac(c1, b21, a0);
      ATL_vmac(c2, b22, a0);
      ATL_vmac(c3, b23, a0);
      @(ld)(a0, A3+i);
      ATL_vmac(c0, b30, a0);
      ATL_vmac(c1, b31, a0);
      ATL_vmac(c2, b32, a0);
      ATL_vmac(c3, b33, a0);

      @(st)(C0+i, c0);
      @(st)(C1+i, c1);
      @(st)(C2+i, c2);
      @(st)(C3+i, c3);
   }
}
   @undef ld
   @undef st
@endwhile
#endif

ATL_SINLINE void ATL_rk4n4
(
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   const SCALAR alpha,
   const TYPE *A0,
   ATL_CSZT lda,
   const TYPE *B0,
   ATL_CSZT ldb,
   TYPE *C0,
   ATL_CSZT ldc
)

/*
 * This special-case code used for LU, only called when:
 *   TA=AtlasNoTrans, N == K == 4, beta == 1.0
 */
{
   TYPE b00, b10, b20, b30, b01, b11, b21, b31;
   TYPE b02, b12, b22, b32, b03, b13, b23, b33;
   const TYPE *A1=A0+lda, *A2=A1+lda, *A3=A2+lda;
   TYPE *C1=C0+ldc, *C2=C1+ldc, *C3=C2+ldc;
   register int i;

   if (TB == AtlasNoTrans)
   {
      const TYPE *B1=B0+ldb, *B2=B1+ldb, *B3=B2+ldb;
      b00 = alpha * *B0;
      b01 = alpha * *B1;
      b02 = alpha * *B2;
      b03 = alpha * *B3;
      b10 = alpha * B0[1];
      b11 = alpha * B1[1];
      b12 = alpha * B2[1];
      b13 = alpha * B3[1];
      b20 = alpha * B0[2];
      b21 = alpha * B1[2];
      b22 = alpha * B2[2];
      b23 = alpha * B3[2];
      b30 = alpha * B0[3];
      b31 = alpha * B1[3];
      b32 = alpha * B2[3];
      b33 = alpha * B3[3];
   }
   else  /* B == AtlasTrans; B is NxK */
   {
      const TYPE *B1=B0+ldb, *B2=B1+ldb, *B3=B2+ldb;
      b00 = alpha * *B0;
      b10 = alpha * *B1;
      b20 = alpha * *B2;
      b30 = alpha * *B3;
      b01 = alpha * B0[1];
      b11 = alpha * B1[1];
      b21 = alpha * B2[1];
      b31 = alpha * B3[1];
      b02 = alpha * B0[2];
      b12 = alpha * B1[2];
      b22 = alpha * B2[2];
      b32 = alpha * B3[2];
      b03 = alpha * B0[3];
      b13 = alpha * B1[3];
      b23 = alpha * B2[3];
      b33 = alpha * B3[3];
   }
   for (i=0; i < M; i++)
   {
      const register TYPE a0=A0[i], a1=A1[i], a2=A2[i], a3=A3[i];
      TYPE register c0=C0[i], c1=C1[i], c2=C2[i], c3=C3[i];
      c0 += b00*a0;
      c1 += b01*a0;
      c2 += b02*a0;
      c3 += b03*a0;
      c0 += b10*a1;
      c1 += b11*a1;
      c2 += b12*a1;
      c3 += b13*a1;
      c0 += b20*a2;
      c1 += b21*a2;
      c2 += b22*a2;
      c3 += b23*a2;
      c0 += b30*a3;
      c1 += b31*a3;
      c2 += b32*a3;
      c3 += b33*a3;
      C0[i] = c0;
      C1[i] = c1;
      C2[i] = c2;
      C3[i] = c3;
   }
}

int Mjoin(PATL,rk4n4)
(
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   const SCALAR alpha,
   const TYPE *A0,
   ATL_CSZT lda,
   const TYPE *B0,
   ATL_CSZT ldb,
   TYPE *C0,
   ATL_CSZT ldc
)
{
   #if ATL_VLEN < 2
      ATL_rk4n4(TB, M, alpha, A0, lda, B0, ldb, C0, ldc);
   #else
      const int vmod = (ATL_VLEN-1);
      int Mp=0, Mv, Mr;  /* peel, vector, remainder */
      int ALLALIGN=0;
      if (!((ldc&vmod) | (lda&vmod)))
      {
         const size_t VMOD = ((size_t)(ATL_VLEN-1));
         size_t a0, a1;
         int gap0, gap;
         a0 = (size_t) C0;
         a1 = (size_t) A0;
         a0 = ATL_DivBySize(a0);
         a1 = ATL_DivBySize(a1);
         gap0 = a0 & VMOD;
         gap  = a1 & VMOD;
         if (gap0 == gap)
         {
            ALLALIGN=1;
            if (gap)
            {
               Mp = ATL_VLEN - gap;
               Mp = Mmin(Mp, M);
            }
         }
      }
      Mr = M - Mp;
      Mv = Mr & ~vmod;
      Mr -= Mv;

      if (ALLALIGN)
      {
         if (Mp)
         {
            ATL_rk4n4(TB, Mp, alpha, A0, lda, B0, ldb, C0, ldc);
            A0 += Mp; C0 += Mp;
         }
         if (Mv)
         {
            ATL_rk4n4_vec(TB, Mv, alpha, A0, lda, B0, ldb, C0, ldc);
            A0 += Mv; C0 += Mv;
         }
      }
      else if (Mv)
      {
         ATL_rk4n4_uvec(TB, Mv, alpha, A0, lda, B0, ldb, C0, ldc);
         A0 += Mv; C0 += Mv;
      }
      if (Mr)
         ATL_rk4n4(TB, Mr, alpha, A0, lda, B0, ldb, C0, ldc);
   #endif
   return(0);
}
@ROUT ATL_ammm_rk2
#include "atlas_amm.h"
#include "atlas_misc.h"
#include "atlas_lvl2.h"
#include "atlas_level1.h"
/*
 * This is special-case code that handles rank-2 update by calling GER2
 */
int Mjoin(PATL,ammm_rk2)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef DREAL
      const int MB=512, NB=32;
   #else /* SREAL */
      const int MB=512, NB=64;
   #endif
   void *vp;
   TYPE *x, *y, *w, *z;
   size_t j;
   ATL_CSZT incC = NB*ldc;

/*
 * If beta is one, can handle by one call to ger2
 */
   if (SCALAR_IS_ONE(beta))
   {
      if (TA == AtlasNoTrans)
      {
         if (TB == AtlasNoTrans)
            Mjoin(PATL,ger2)(M, N, alpha, A, 1, B, ldb, alpha, A+lda, 1,
                             B+1, ldb, C, ldc);
         else
            Mjoin(PATL,ger2)(M, N, alpha, A, 1, B, 1, alpha, A+lda, 1,
                             B+ldb, 1, C, ldc);
      }
      else if (TB == AtlasNoTrans)
         Mjoin(PATL,ger2)(M, N, alpha, A, lda, B, ldb, alpha, A+1, lda,
                          B+1, ldb, C, ldc);
      else
         Mjoin(PATL,ger2)(M, N, alpha, A, lda, B, 1, alpha, A+1, lda,
                          B+ldb, 1, C, ldc);
      return(0);
   }
/*
 * Later on, do smart think like copy only MB/NB at a time, and don't copy
 * at all if vectors are contiguous, but right now, always do copy up-front
 * so loop does not have to worry about TA/TB; this is a O(N) cost in N^2 alg
 */
   vp = malloc(2*ATL_MulBySize(M+N)+4*ATL_Cachelen);
   if (!vp)
      return(1);
   x = ATL_AlignPtr(vp);
   y = x + M;
   y = ATL_AlignPtr(y);
   w = y + N;
   w = ATL_AlignPtr(w);
   z = w + M;
   z = ATL_AlignPtr(z);
   if (TA == AtlasNoTrans)
   {
      Mjoin(PATL,copy)(M, A, 1, x, 1);
      Mjoin(PATL,copy)(M, A+lda, 1, w, 1);
   }
   else
   {
      Mjoin(PATL,copy)(M, A, lda, x, 1);
      Mjoin(PATL,copy)(M, A+1, lda, w, 1);
   }
   if (SCALAR_IS_ONE(alpha))
   {
      if (TB == AtlasNoTrans)
      {
         Mjoin(PATL,copy)(N, B, ldb, y, 1);
         Mjoin(PATL,copy)(N, B+1, ldb, z, 1);
      }
      else
      {
         Mjoin(PATL,copy)(N, B, 1, y, 1);
         Mjoin(PATL,copy)(N, B+ldb, 1, z, 1);
      }
   }
   else
   {
      if (TB == AtlasNoTrans)
      {
         Mjoin(PATL,cpsc)(N, alpha, B, ldb, y, 1);
         Mjoin(PATL,cpsc)(N, alpha, B+1, ldb, z, 1);
      }
      else
      {
         Mjoin(PATL,cpsc)(N, alpha, B, 1, y, 1);
         Mjoin(PATL,cpsc)(N, alpha, B+ldb, 1, z, 1);
      }
   }
   for (j=0; j < N; j += NB, C += incC)
   {
      size_t i, nb = N-j;
      nb = (nb >= NB) ? NB : nb;
      for (i=0; i < M; i += MB)
      {
         size_t mb = M-i;
         mb = (mb >= MB) ? MB : mb;
         Mjoin(PATL,gescal)(mb, nb, beta, C+i, ldc);
         Mjoin(PATL,ger2)(mb, nb, ATL_rone, x+i, 1, y+j, 1, ATL_rone, 
                          w+i, 1, z+j, 1, C+i, ldc);
      }
   }
   free(vp);
   return(0);
}
@ROUT ATL_cammm_rk2
#include "atlas_amm.h"
#include "atlas_misc.h"
#include "atlas_lvl2.h"
#include "atlas_level1.h"
/*
 * This is special-case code that handles rank-2 update by calling GER2
 */
int Mjoin(PATL,ammm_rk2)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef DCPLX
      const int MB=512, NB=16;
   #else /* SCPLX */
      const int MB=512, NB=32;
   #endif
   void *vp;
   TYPE *x, *y, *w, *z;
   size_t j;
   const TYPE ONE[2] = {ATL_rone, ATL_rzero};
   ATL_CSZT lda2=lda+lda, ldb2=ldb+ldb, ldc2=ldc+ldc, incC = NB*ldc2;

/*
 * If beta is one, can handle by one call to ger2
 */
   if (SCALAR_IS_ONE(beta) && 0)
   {
      if (TA == AtlasNoTrans)
      {
         if (TB == AtlasNoTrans)
            Mjoin(PATL,ger2u)(M, N, alpha, A, 1, B, ldb, alpha, A+lda2, 1,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasConj)
            Mjoin(PATL,ger2c)(M, N, alpha, A, 1, B, ldb, alpha, A+lda2, 1,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasTrans)
            Mjoin(PATL,ger2u)(M, N, alpha, A, 1, B, 1, alpha, A+lda2, 1,
                              B+ldb2, 1, C, ldc);
         else /* if (TB == AtlasConjTrans) */
            Mjoin(PATL,ger2c)(M, N, alpha, A, 1, B, 1, alpha, A+lda2, 1,
                              B+ldb2, 1, C, ldc);
      }
      else if (TA == AtlasTrans)
      {
         if (TB == AtlasNoTrans)
            Mjoin(PATL,ger2u)(M, N, alpha, A, lda, B, ldb, alpha, A+2, lda,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasConj)
            Mjoin(PATL,ger2c)(M, N, alpha, A, lda, B, ldb, alpha, A+2, lda,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasTrans)
            Mjoin(PATL,ger2u)(M, N, alpha, A, lda, B, 1, alpha, A+2, lda,
                              B+ldb2, 1, C, ldc);
         else if (TB == AtlasConjTrans)
            Mjoin(PATL,ger2c)(M, N, alpha, A, lda, B, 1, alpha, A+2, lda,
                              B+ldb2, 1, C, ldc);
      }
/*
 *    If A must be conjugated, copy it
 */
      else  /* TA == AtlasConj || TA == AtlasConjTrans */
      {
         vp = malloc((ATL_MulBySize(M)+ATL_Cachelen)<<1);
         if (!vp)
           return(2);
         x = ATL_AlignPtr(vp);
         w = x + M + M;
         w = ATL_AlignPtr(w);
         if (SCALAR_IS_ONE(alpha))
         {
            if (TA == AtlasConj)
            {
               Mjoin(PATL,copyConj)(M, A, 1, x, 1);
               Mjoin(PATL,copyConj)(M, A+lda2, 1, w, 1);
            }
            else /* if (TA == AtlasConjTrans) */
            {
               Mjoin(PATL,copyConj)(M, A, lda, x, 1);
               Mjoin(PATL,copyConj)(M, A+2, lda, w, 1);
            }
         }
         else
         {
            if (TA == AtlasConj)
            {
               Mjoin(PATL,moveConj)(M, alpha, A, 1, x, 1);
               Mjoin(PATL,moveConj)(M, alpha, A+lda2, 1, w, 1);
            }
            else /* if (TA == AtlasConjTrans) */
            {
               Mjoin(PATL,moveConj)(M, alpha, A, lda, x, 1);
               Mjoin(PATL,moveConj)(M, alpha, A+2, lda, w, 1);
            }
         }
         if (TB == AtlasNoTrans)
            Mjoin(PATL,ger2u)(M, N, ONE, x, 1, B, ldb, ONE, w, 1,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasConj)
            Mjoin(PATL,ger2c)(M, N, ONE, x, 1, B, ldb, ONE, w, 1,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasTrans)
            Mjoin(PATL,ger2u)(M, N, ONE, x, 1, B, 1, ONE, w, 1,
                              B+ldb2, 1, C, ldc);
         else /* if (TB == AtlasConjTrans) */
            Mjoin(PATL,ger2c)(M, N, ONE, x, 1, B, 1, ONE, w, 1,
                              B+ldb2, 1, C, ldc);
         free(vp);
      }
      return(0);
   }
/*
 * Later on, do smart think like copy only MB/NB at a time, and don't copy
 * at all if vectors are contiguous, but right now, always do copy up-front
 * so loop does not have to worry about TA/TB; this is a O(N) cost in N^2 alg
 */
   vp = malloc(2*ATL_MulBySize(M+N)+4*ATL_Cachelen);
   if (!vp)
      return(1);
   x = ATL_AlignPtr(vp);
   y = x + M + M;
   y = ATL_AlignPtr(y);
   w = y + N + N;
   w = ATL_AlignPtr(w);
   z = w + M + M;
   z = ATL_AlignPtr(z);
   if (TA == AtlasNoTrans)
   {
      Mjoin(PATL,copy)(M, A, 1, x, 1);
      Mjoin(PATL,copy)(M, A+lda2, 1, w, 1);
   }
   else if (TA == AtlasConj)
   {
      Mjoin(PATL,copyConj)(M, A, 1, x, 1);
      Mjoin(PATL,copyConj)(M, A+lda2, 1, w, 1);
   }
   else if (TA == AtlasTrans)
   {
      Mjoin(PATL,copy)(M, A, lda, x, 1);
      Mjoin(PATL,copy)(M, A+2, lda, w, 1);
   }
   else if (TA == AtlasConjTrans)
   {
      Mjoin(PATL,copyConj)(M, A, lda, x, 1);
      Mjoin(PATL,copyConj)(M, A+2, lda, w, 1);
   }
   if (SCALAR_IS_ONE(alpha))
   {
      if (TB == AtlasNoTrans)
      {
         Mjoin(PATL,copy)(N, B, ldb, y, 1);
         Mjoin(PATL,copy)(N, B+2, ldb, z, 1);
      }
      else if (TB == AtlasConj)
      {
         Mjoin(PATL,copyConj)(N, B, ldb, y, 1);
         Mjoin(PATL,copyConj)(N, B+2, ldb, z, 1);
      }
      else if (TB == AtlasTrans)
      {
         Mjoin(PATL,copy)(N, B, 1, y, 1);
         Mjoin(PATL,copy)(N, B+ldb2, 1, z, 1);
      }
      else if (TB == AtlasConjTrans)
      {
         Mjoin(PATL,copyConj)(N, B, 1, y, 1);
         Mjoin(PATL,copyConj)(N, B+ldb2, 1, z, 1);
      }
   }
   else  /* alpha non-one; must apply */
   {
      if (TB == AtlasNoTrans)
      {
         Mjoin(PATL,cpsc)(N, alpha, B, ldb, y, 1);
         Mjoin(PATL,cpsc)(N, alpha, B+2, ldb, z, 1);
      }
      else if (TB == AtlasConj)
      {
         Mjoin(PATL,moveConj)(N, alpha, B, ldb, y, 1);
         Mjoin(PATL,moveConj)(N, alpha, B+2, ldb, z, 1);
      }
      else if (TB == AtlasTrans)
      {
         Mjoin(PATL,cpsc)(N, alpha, B, 1, y, 1);
         Mjoin(PATL,cpsc)(N, alpha, B+ldb2, 1, z, 1);
      }
      else /* if (TB == AtlasConjTrans) */
      {
         Mjoin(PATL,moveConj)(N, alpha, B, 1, y, 1);
         Mjoin(PATL,moveConj)(N, alpha, B+ldb2, 1, z, 1);
      }
   }
   for (j=0; j < N; j += NB, C += incC)
   {
      size_t i, nb = N-j;
      nb = (nb >= NB) ? NB : nb;
      for (i=0; i < M; i += MB)
      {
         size_t mb = M-i;
         mb = (mb >= MB) ? MB : mb;
         Mjoin(PATL,gescal)(mb, nb, beta, C+i+i, ldc);
         Mjoin(PATL,ger2u)(mb, nb, ONE, x+i+i, 1, y+j+j, 1, ONE,
                           w+i+i, 1, z+j+j, 1, C+i+i, ldc);
      }
   }
   free(vp);
   return(0);
}
@ROUT ATL_ammmREC
#include "atlas_misc.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

typedef struct ammrec ammrec_t;
struct ammrec
{
   cm2am_t a2blk, b2blk;
   ablk2cmat_t blk2c;
   ammkern_t amm_b0, amm_b1, amm_k1_b0, amm_k1_b1;
   size_t lda, ldb, ldc, incAm, incAk, incBk, incBn, incCn, incCm;
   TYPE alpA, alpB, alpC, beta;
   int mbkb, kbnb, mbnb, nmu, nnu, nmuF, nnuF;
   int mb, nb, kb, KB0, mr, nr, kr;
};


#define v_kp 1
#define v_np 2
#define v_mp 4
#define v_cpA 8
#define v_cpB 16
#define v_cpC 32
#define v_lwC 64  /* last guy to update C must write it out */
#define v_nmA 128 /* don't move A ptr */
#define v_nmB 256 /* don't move B ptr */
#define v_nmC 512 /* don't move C ptr */

#define b_kp 0
#define b_np 1
#define b_mp 2
#define b_cpA 3
#define b_cpB 4
#define b_cpC 5
#define b_lwC 6 
#define b_nmA 7
#define b_nmB 8
#define b_nmC 9 

@beginskip
static void ammmRECf  /* no partial blocks */
(
   const ammrec_t *pd,
   int nmblks,
   int nnblks,
   int nkblks,
   int flag, /* bits: 0:kp, 1:np, 2:mp, 3:cpA, 4:cpyB, 5:cpyC */
   const TYPE *A,
   const TYPE *B, 
   TYPE *C,
   TYPE *a,
   TYPE *b,
   TYPE *c
)
{
/*
 * If only one block remains, stop and do multiply
 */
   ATL_assert((flag & (v_mp|v_np|v_kp)) == 0)
/*   if ((nmblks|nnblks|nkblks) == 1) */
   if (nmblks == 1 && nnblks == 1 && nkblks == 1)
   {
      TYPE *an = (flag & v_nmA) ? a : a+pd->mbkb;
      TYPE *bn = (flag & v_nmB) ? b : b+pd->kbnb;
      TYPE *cn = (flag & v_nmC) ? c : c+pd->mbnb;
      const ammkern_t amm = (flag & v_cpC) ? pd->amm_b0 : pd->amm_b1;
      if (flag & v_cpA)
         pd->a2blk(pd->kb, pd->mb, pd->alpA, A, pd->lda, a);
      if (flag & v_cpB)
         pd->b2blk(pd->kb, pd->nb, pd->alpB, B, pd->ldb, b);
      amm(pd->nmu, pd->nnu, pd->kb, a, b, c, an, bn, cn);
      if (flag & v_lwC) 
         pd->blk2c(pd->mb, pd->nb, pd->alpC, c, pd->beta, C, pd->ldc);
   }
   else if (nkblks > nmblks && nkblks > nnblks)  /* split K */
   {
      const int nR=(nkblks>>1), nL = nkblks-nR;
      int flg = flag & ~(v_nmA|v_nmB|v_nmC);  /* only one guy doesn't move */
      ammmRECf(pd, nmblks, nnblks, nL, (flag & ~(v_nmA+v_nmB+v_lwC))|v_nmC,
               A, B, C, a, b, c);
      flg = flag & ~v_cpC;
      if (nR == 1)
      {
         if (flag&v_lwC)
            flg |= v_lwC;
         else
            flg &= ~v_lwC;
      }
      ammmRECf(pd, nmblks, nnblks, nR, flg, A+nL*pd->incAk, B+nL*pd->incBk, C,
               a+nL*nmblks*pd->mbkb, b+nL*nnblks*pd->kbnb, c);
   }
   else if (nnblks > nmblks) /* split N */
   {
      const int nR=(nnblks>>1), nL = nnblks-nR;
      ammmRECf(pd, nmblks, nL, nkblks, (flag & ~(v_nmB+v_nmC))|v_nmA, 
               A, B, C, a, b, c);
      ammmRECf(pd, nmblks, nR, nkblks, flag & ~v_cpA,
               A, B+nL*pd->incBn, C+pd->incCn*nL, 
               a, b+nL*nkblks*pd->kbnb, c+nL*nmblks*pd->mbnb);
   }
   else                      /* split M */
   {
      const int nR=(nmblks>>1), nL = nmblks-nR;
      ammmRECf(pd, nL, nnblks, nkblks, (flag & ~(v_nmA+v_nmC))|v_nmB, 
               A, B, C, a, b, c);
      ammmRECf(pd, nR, nnblks, nkblks, flag & ~v_cpB,
               A+nL*pd->incAm, B, C+pd->mb*nL, 
               a+nL*nkblks*pd->mbkb, b, c+nL*nnblks*pd->mbnb);
   }
}
@endskip

static void ammmRECf /* no partial blocks */
(
   const ammrec_t *pd,
   int nmblks,
   int nnblks,
   int nkblks,
   int flag, /* bits: 0:kp, 1:np, 2:mp, 3:cpA, 4:cpyB, 5:cpyC */
   const TYPE *A,
   const TYPE *B,
   TYPE *C,
   TYPE *a,
   TYPE *b,
   TYPE *c
)
{
@skip   ATL_assert((flag & (v_mp|v_np|v_kp)) == 0)
/*
 * Stop recursion and do multiply when only 1 block is left
 */
   if (nmblks == 1 && nnblks == 1 && nkblks == 1)
   {
      TYPE *an = (flag & v_nmA) ? a : a+pd->mbkb;
      TYPE *bn = (flag & v_nmB) ? b : b+pd->kbnb;
      TYPE *cn = (flag & v_nmC) ? c : c+pd->mbnb;
      const ammkern_t amm = (flag & v_cpC) ? pd->amm_b0 : pd->amm_b1;
      if (flag & v_cpA)
         pd->a2blk(pd->kb, pd->mb, pd->alpA, A, pd->lda, a);
      if (flag & v_cpB)
         pd->b2blk(pd->kb, pd->nb, pd->alpB, B, pd->ldb, b);
      amm(pd->nmu, pd->nnu, pd->kb, a, b, c, an, bn, cn);
      if (flag & v_lwC)
         pd->blk2c(pd->mb, pd->nb, pd->alpC, c, pd->beta, C, pd->ldc);
   }
   else if (nnblks >= nkblks && nnblks >= nmblks)   /* recursively divide N */
   {
      const int nR=(nnblks>>1), nL = nnblks-nR;
      ammmRECf(pd, nmblks, nL, nkblks, (flag|v_nmA) & ~(v_nmB+v_nmC), 
               A, B, C, a, b, c);
      ammmRECf(pd, nmblks, nR, nkblks, flag & ~v_cpA,
              A, B+nL*pd->incBn, C+pd->incCn*nL,
              a, b+nL*nkblks*pd->kbnb, c+nL*nmblks*pd->mbnb);
   }
   else if (nmblks >= nkblks)                       /* recursively divide M */
   {
      const int nR=(nmblks>>1), nL = nmblks-nR;
      ammmRECf(pd, nL, nnblks, nkblks, (flag|v_nmB) & ~(v_nmA+v_nmC), 
               A, B, C, a, b, c);
      ammmRECf(pd, nR, nnblks, nkblks, flag & ~v_cpB,
              A+nL*pd->incAm, B, C+pd->mb*nL,
              a+nL*nkblks*pd->mbkb, b, c+nL*nnblks*pd->mbnb);
   }
   else                                             /* recursively divide K */
   {
      const int nR=(nkblks>>1), nL = nkblks-nR;
      ammmRECf(pd, nmblks, nnblks, nL, (flag|v_nmC) & ~(v_nmA+v_nmB+v_lwC), 
               A, B, C, a, b, c);
      ammmRECf(pd, nmblks, nnblks, nR, flag & ~v_cpC, 
               A+nL*pd->incAk, B+nL*pd->incBk, C,
               a+nL*nmblks*pd->mbkb, b+nL*nnblks*pd->kbnb, c);
   }
}

static void ammmREC  /* partial blocks are possible */
(
   const ammrec_t *pd,
   int nmblks,
   int nnblks,
   int nkblks,
   int flag, /* bits: 0:kp, 1:np, 2:mp, 3:cpA, 4:cpyB, 5:cpyC */
   const TYPE *A,
   const TYPE *B,
   TYPE *C,
   TYPE *a,
   TYPE *b,
   TYPE *c
)
{
/*
 * If I only have one possibly partial block left.  Equivalent to:
 * if ( ((nmblks == 1 && !(flag&v_mp)) || nmblks == 0) &&
 *      ((nnblks == 1 && !(flag&v_np)) || nnblks == 0) &&
 *      ((nkblks == 1 && !(flag&v_kp)) || nkblks == 0) )
 */
   if (nmblks < 2 && nnblks < 2 && nkblks < 2 &&
       nmblks != ((flag>>b_mp)&1) &&
       nnblks != ((flag>>b_np)&1) &&
       nkblks != ((flag>>b_kp)&1))
   {
      TYPE *an = (flag & v_nmA) ? a : a+pd->mbkb;
      TYPE *bn = (flag & v_nmB) ? b : b+pd->kbnb;
      TYPE *cn = (flag & v_nmC) ? c : c+pd->mbnb;
/*
 *    If we aren't doing K-cleanup, can always use fastest kernels
 */
      if (!(flag & v_kp))
      {
         const ammkern_t amm = (flag & v_cpC) ? pd->amm_b0 : pd->amm_b1;
         if (!(flag & (v_mp+v_np)))   /* one full block to multiply */
         {
            if (flag & v_cpA)
               pd->a2blk(pd->kb, pd->mb, pd->alpA, A, pd->lda, a);
            if (flag & v_cpB)
               pd->b2blk(pd->kb, pd->nb, pd->alpB, B, pd->ldb, b);
            amm(pd->nmu, pd->nnu, pd->kb, a, b, c, an, bn, cn);
            if (flag & v_lwC)
               pd->blk2c(pd->mb, pd->nb, pd->alpC, c, pd->beta, C, pd->ldc);
         }
         else
         {
            int nmu=pd->nmu, nnu=pd->nnu, m=pd->mb, n=pd->nb, kb=pd->kb;
            if (flag & v_mp)
            {
               nmu = pd->nmuF;
               m = pd->mr;
            }
            if (flag & v_np)
            {
               nnu = pd->nnuF;
               n = pd->nr;
            }
            if (flag & v_cpA)
               pd->a2blk(kb, m, pd->alpA, A, pd->lda, a);
            if (flag & v_cpB)
               pd->b2blk(kb, n, pd->alpB, B, pd->ldb, b);
            amm(nmu, nnu, kb, a, b, c, an, bn, cn);
            if (flag & v_lwC)
               pd->blk2c(m, n, pd->alpC, c, pd->beta, C, pd->ldc);
         }
      }
      else /* if (flag & (v_mp|v_np|v_kp))   partial block to multiply */
      {
         const ammkern_t amm = (flag & v_cpC) ? pd->amm_k1_b0 : pd->amm_k1_b1;
         const int nmu = (nmblks) ? pd->nmu : pd->nmuF;
         const int m = (nmblks) ? pd->mb : pd->mr;
         const int nnu = (nnblks) ? pd->nnu : pd->nnuF;
         const int n = (nnblks) ? pd->nb : pd->nr;
         const int k = (nkblks) ? pd->kb : pd->kr;
         const int KBF = (nkblks) ? k : pd->KB0;

         if (flag & v_cpA)
            pd->a2blk(k, m, pd->alpA, A, pd->lda, a);
         if (flag & v_cpB)
            pd->b2blk(k, n, pd->alpB, B, pd->ldb, b);
         amm(nmu, nnu, KBF, a, b, c, an, bn, cn);
         if (flag & v_lwC)
            pd->blk2c(m, n, pd->alpC, c, pd->beta, C, pd->ldc);
      }
   }
   else if (nnblks >= nkblks && nnblks >= nmblks &&           /* recursively */
            (nnblks > 1 || (flag&v_np)))                      /* divide N    */
   {
      const int nR=(nnblks>>1), nL = nnblks-nR;
      const size_t mblks=(flag&v_mp) ? nmblks+1 : nmblks;
      const size_t kblks=(flag&v_kp) ? nkblks+1 : nkblks;
      const int flg = (flag|v_nmA) & ~(v_np+v_nmB+v_nmC);
      if (flag & (v_mp+v_kp))
         ammmREC(pd, nmblks, nL, nkblks, flg, A, B, C, a, b, c);
      else
         ammmRECf(pd, nmblks, nL, nkblks, flg, A, B, C, a, b, c);
      ammmREC(pd, nmblks, nR, nkblks, flag & ~v_cpA,
              A, B+nL*pd->incBn, C+pd->incCn*nL,
              a, b+nL*kblks*pd->kbnb, c+nL*mblks*pd->mbnb);
   }
   else if (nmblks >= nkblks && (nmblks > 1 || (flag&v_mp)))  /* recursively */
   {                                                          /* divide M    */
      const int nR=(nmblks>>1), nL = nmblks-nR;
      const size_t nblks=(flag&v_np) ? nnblks+1 : nnblks;
      const size_t kblks=(flag&v_kp) ? nkblks+1 : nkblks;
      const int flg = (flag|v_nmB) & ~(v_mp+v_nmA+v_nmC);
      if (flag&(v_np+v_kp))
         ammmREC(pd, nL, nnblks, nkblks, flg, A, B, C, a, b, c);
      else
         ammmRECf(pd, nL, nnblks, nkblks, flg, A, B, C, a, b, c);
      ammmREC(pd, nR, nnblks, nkblks, flag & ~v_cpB,
              A+nL*pd->incAm, B, C+pd->mb*nL,
              a+nL*kblks*pd->mbkb, b, c+nL*nblks*pd->mbnb);
   }
   else                                                       /* recursively */
   {                                                          /* divide K    */
      const int nR=(nkblks>>1), nL = nkblks-nR;
      const size_t mblks=(flag&v_mp) ? nmblks+1 : nmblks;
      const size_t nblks=(flag&v_np) ? nnblks+1 : nnblks;
      const int flg = (flag|v_nmC) & ~(v_kp+v_lwC+v_nmA+v_nmB);
      if (flag & (v_mp+v_np))
         ammmREC(pd, nmblks, nnblks, nL, flg, A, B, C, a, b, c);
      else
         ammmRECf(pd, nmblks, nnblks, nL, flg, A, B, C, a, b, c);
      ammmREC(pd, nmblks, nnblks, nR, flag & ~v_cpC, 
              A+nL*pd->incAk, B+nL*pd->incBk, C,
              a+nL*mblks*pd->mbkb, b+nL*nblks*pd->kbnb, c);
   }
}

int Mjoin(PATL,ammmREC)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   void *vp;
   TYPE *a, *b, *c;
   amminfo_t mminfo;
   ammrec_t pd;
   #if ATL_geAMM_MAXKVEC > 1
      size_t kb0U, KK;
   #else
      #define kb0U kb0
      #define KK K
   #endif
   size_t nmblks, nnblks, nkblks, szA, szB, szC, i, j, k;
   int mb, nb, kb, mu, nu, ku, mr, nr, kr, KB0, flag, appAl;

   pd.alpA = pd.alpB = pd.alpC = ATL_rone;
   appAl = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   pd.mb = mb = mminfo.mb;
   pd.nb = nb = mminfo.nb;
   pd.kb = kb = mminfo.kb;
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   nmblks = M / mb;
   nnblks = N / nb;
   nkblks = K / kb;
   pd.nmu = mb / mu;
   pd.nnu = mb / nu;
   pd.mr = mr = M - nmblks*mb;
   if (mr)
      pd.nmuF = (mr+mu-1)/mu;
   else
      pd.nmuF = pd.nmu;
   pd.nr = nr = N - nnblks*nb;
   if (nr)
      pd.nnuF = (nr+nu-1)/nu;
   else
      pd.nnuF = pd.nnu;
   pd.kr = kr = K - nkblks*kb;
   if (!appAl)
      pd.alpA = alpha;
   else if (appAl == 1)
      pd.alpB = alpha;
   else
      pd.alpC = alpha;
   pd.a2blk = mminfo.a2blk;
   pd.b2blk = mminfo.b2blk;
   pd.blk2c = mminfo.Cblk2cm;
   pd.amm_b0 = mminfo.amm_b0;
   pd.amm_b1 = mminfo.amm_b1;
   if (!kr)
   {
      pd.amm_k1_b0 = mminfo.amm_b0;
      pd.amm_k1_b1 = mminfo.amm_b1;
      KB0 = kb;
   }
/*
 * If last K-block is partial, compute K of gemm (KB0) and K of copy (kr)
 */
   else
   {
/*
 *    K-major require GEMM's K (KB0) to be a mult of ku
 */
      #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kr+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
         {
            pd.amm_k1_b0 = mminfo.amm_b0;
            pd.amm_k1_b1 = mminfo.amm_b1;
         }
         else
         {
            pd.amm_k1_b0 = mminfo.amm_k1_b0;
            pd.amm_k1_b1 = mminfo.amm_k1_b1;
         }
            
      }
      else
      {
      #endif
         KB0 = kr;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && kr == (kr/ku)*ku &&
             kr > mminfo.kbmin)
         {
            pd.amm_k1_b0 = mminfo.amm_b0;
            pd.amm_k1_b1 = mminfo.amm_b1;
         }
         else
         {
            pd.amm_k1_b0 = mminfo.amm_k1_b0;
            pd.amm_k1_b1 = mminfo.amm_k1_b1;
         }
      #if ATL_geAMM_MAXKVEC > 1
      }
      #endif
   }
   pd.mb = mminfo.mb;
   pd.nb = mminfo.nb;
   pd.kb = mminfo.kb;
   pd.mbkb = mminfo.mb * mminfo.kb;
   pd.kbnb = mminfo.kb * mminfo.nb;
   pd.mbnb = mminfo.mb * mminfo.nb;
   pd.lda = lda;
   pd.ldb = ldb;
   pd.ldc = ldc;
   pd.nmu = mminfo.mb / mminfo.mu;
   pd.nnu = mminfo.nb / mminfo.nu;
   pd.beta = beta;
   if (TA == AtlasNoTrans)
   {
      pd.incAm = pd.mb;
      pd.incAk = pd.kb * lda;
   }
   else
   {
      pd.incAm = pd.mb * lda;
      pd.incAk = pd.kb;
   }
   if (TB == AtlasNoTrans)
   {
      pd.incBk = pd.kb;
      pd.incBn = pd.nb * ldb;
   }
   else
   {
      pd.incBk = pd.kb * ldb;
      pd.incBn = pd.nb;
   }
   pd.incCn = nb*ldc;
   pd.incCm = mb;
   pd.KB0 = KB0;
/*
 * Allocate workspace, for now get double amount space required for first
 * recursively divided dimension!
 */
   i = (mr) ? nmblks+1 : nmblks;
   j = (nr) ? nnblks+1 : nnblks;
   k = (kr) ? nkblks+1 : nkblks;
   szA = i*k*pd.mbkb;
   szB = k*j*pd.kbnb;
   szC = i*j*pd.mbnb;
   vp = malloc(ATL_MulBySize(szA+mu + szB+nu + szC+mu*nu) + 3*ATL_Cachelen);
   ATL_assert(vp);
   a = ATL_AlignPtr(vp);
   b = a + szA;
   b = ATL_AlignPtr(b);
   c = b + szB;
   c = ATL_AlignPtr(c);
   flag = (v_cpA | v_cpB | v_cpC | v_nmA | v_nmB | v_nmC | v_lwC);
   if (!(mr|nr|kr))
      ammmRECf(&pd, nmblks, nnblks, nkblks, flag, A, B, C, a, b, c);
   else
   {
      flag |= (mr) ? v_mp : 0;
      flag |= (nr) ? v_np : 0;
      flag |= (kr) ? v_kp : 0;
      ammmREC(&pd, nmblks, nnblks, nkblks, flag, A, B, C, a, b, c);
   }
   free(vp);
}
@ROUT ATL_ammmNMK
#include "atlas_misc.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

int Mjoin(PATL,ammmNMK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   amminfo_t mminfo;
   ATL_INT mb, NB, kb, mu, nu, ku, KRUN;
   #if ATL_geAMM_MAXKVEC > 1
      size_t kb0U, KK;
   #else
      #define kb0U kb0
      #define KK K
   #endif
   size_t nmblks, nnblks, nkblks, mbF, nbF, kb0, nmu, nmuF, MBF, NBF;
   size_t incwA, incAk, incBk, incAk0, incBk0, incAm, incBn, incCn;
   size_t i, j, k, szA, szB, szC, nnu0, nnuF;
   const TYPE *B0 = B;
   TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   TYPE *wA, *wB, *wC, *wA0, *wB0;
   void *vp;
   cm2am_t a2blk, b2blk;
   ablk2cmat_t blk2c;
   ammkern_t amm_b1, amm_b0;
   int appAl;

   appAl = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!appAl)
      alpA = alpha;
   else if (appAl == 1)
      alpB = alpha;
   else
      alpC = alpha;
   mb = mminfo.mb;
   NB = mminfo.nb;
   kb = mminfo.kb;
   KRUN = ATL_AMMFLG_KRUNTIME(mminfo.flag);
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   incwA = mb*kb; 
   nmu = mb / mu;
   amm_b1 = mminfo.amm_b1;
   blk2c = mminfo.Cblk2cm;
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
/*
 * Handle N differently than other dims: since it is outer loop, don't want
 * to peel, so just vary nb inside the main loop.  nnblks therefore includes
 * final block, unlike for M or K.
 */
   if (N >= NB+nu+nu)
   {
      nnblks = N/NB;
      nbF = N - nnblks * NB;
      if (nbF < nu+nu)
         nbF += NB;
      else
         nnblks++;
   }
   else
   {
      nnblks = 1;
      nbF = N;
   }
   nnu0 = NB / nu;
   nnuF = (nbF+nu-1)/nu;
   NBF = nnuF * nu;
/*
 * For M, we must peel the final block to handle any cleanup (can't peel 1st
 * block or we mess up alignment!), so this block is not included in the
 * block count
 */
   if (M >= mb+mu+mu)  /* more than just last block */
   {
      nmblks = M/mb;
      mbF = M - nmblks * mb;
      if (mbF < mu+mu)  /* steal block from main iteration, not enough here! */
      {
         nmblks--;
         mbF += mb;
      }
   }
   else /* put everything in final block */
   {
      mbF = M;
      nmblks = 0;
   }
   nmuF = (mbF+mu-1) / mu;
   MBF = nmuF * mu;
/*
 * For K, we peel the first iteration to set BETA=0, so the nkblks does not
 * include the peeled block
 */
   if (K >= kb)
   {
      nkblks = K/kb;
      kb0 = K - nkblks * kb;
      if (!kb0)
      {
         kb0 = kb;
         nkblks--;
      }
      else
      {
         if (kb0 < 4)
         {
            kb0 += kb;
            nkblks--;
         }
      }
   }
   else /* K < nb */
   {
      kb0 = K;
      nkblks = 0;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KK = ((K+ku-1)/ku)*ku;
         kb0U = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            amm_b0 = mminfo.amm_b0;
         else
            amm_b0 = (mminfo.kb == kb0U) ?  mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
      {
         KK = K;
         kb0U = kb0;
         amm_b0 = (kb0 == mminfo.kb || 
                   (KRUN && kb0 >= mminfo.kbmin && (kb0/ku)*ku == kb0)) ?  
                  mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
   #else
      amm_b0 = (kb0 == mminfo.kb || 
                (KRUN && kb0 >= mminfo.kbmin && (kb0/ku)*ku == kb0)) ?  
               mminfo.amm_b0 : mminfo.amm_k1_b0;
   #endif
   szA = (nmblks*mb+MBF)*KK; /* wrkspc for all of A wt M rounded up to MU*/
   j = Mmax(NB, NBF);
   i = Mmax(MBF, mb);
   szC = i*j;
   szB = KK*j;                     /* workspace for panel of B */

   k = ATL_MulBySize(szA+szB+szC+mu*nu*ku) + 3*ATL_Cachelen;
   if (k > ATL_MaxMalloc)
      return(2);
   vp = malloc(k);
   if (!vp)
      return(1);
   wB0 = wB = ATL_AlignPtr(vp);
   wA = wB + szB;
   wA0 = wA = ATL_AlignPtr(wA);
   wC = wA + szA;
   wC = ATL_AlignPtr(wC);

   if (TA == AtlasNoTrans)
   {
      incAm = mb;
      incAk0 = kb0*lda;
      incAk = kb*lda;
   }
   else
   {
      incAm = mb*lda;
      incAk0 = kb0;
      incAk = kb;
   }
   if (TB == AtlasNoTrans)
   {
      incBk0 = kb0;
      incBk = kb;
      incBn = NB*ldb;
   }
   else
   {
      incBk0 = kb0*ldb;
      incBk = kb*ldb;
      incBn = NB;
   }
   incCn = ldc*NB;

   for (j=0; j < nnblks; j++)
   {
      size_t nb, nbsz, incwB, incwB0, nnu;
      const TYPE *Bn = B+incBn;
      TYPE *Cn = C + incCn;
      if (j != nnblks-1)
      {
         nbsz = nb = NB;
         nnu = nnu0;
      }
      else
      {
         nb = nbF;
         nbsz = NBF;
         nnu = nnuF;
      }
      incwB = nbsz*kb;
      incwB0 = nbsz*kb0U;
/*
 *    Do all M-blocks except final one, which may be of differing size & partial
 */
      for (i=0; i < nmblks; i++)
      {
         TYPE *wAn, *wBn;
         const TYPE *An = A+incAm;
/*
 *       Peel first K it to handle K-cleanup and set BETA=0
 */
         if (!j)
            a2blk(kb0, mb, alpA, A, lda, wA);
         if (!i)
            b2blk(kb0, nb, alpB, B, ldb, wB);
         wAn = wA+mb*kb0U;
         wBn = (nkblks) ? wB+incwB0 : wB;
         amm_b0(nmu, nnu, kb0U, wA, wB, wC, nkblks?wAn:wA, wBn, wC);
         wA = wAn;
         wB = wBn;
         A += incAk0;
         B += incBk0;
/*
 *       If first K-block not the only K-block
 */
         if (nkblks)
         {
            for (k=nkblks-1; k; k--)
            {
               wAn = wA+incwA;
               wBn = wB+incwB;
               if (!j)
                  a2blk(kb, mb, alpA, A, lda, wA);
               if (!i)
                  b2blk(kb, nb, alpB, B, ldb, wB);
               amm_b1(nmu, nnu, kb, wA, wB, wC, wAn, wBn, wC);
               wA = wAn;
               wB = wBn;
               A += incAk;
               B += incBk;
            }
/*
 *          Last K-block peeled to change prefetch pattern
 */
            wAn = wA+incwA;
            if (!j)
               a2blk(kb, mb, alpA, A, lda, wA);
            if (!i)
               b2blk(kb, nb, alpB, B, ldb, wB);
            amm_b1(nmu, nnu, kb, wA, wB, wC, wAn, wB0, wC);
            wA = wAn;
            wB = wB0;
         }
         blk2c(mb, nb, alpC, wC, beta, C, ldc);
         A = An;
         B = B0;
         C += mb;
      }
/*
 *    Do the final peeled M-block, which is of non-constant size mbF
 */
      {
         TYPE *wAn, *wBn;
/*
 *       Peel first K it to handle K-cleanup and set BETA=0
 */
         if (!j)
            a2blk(kb0, mbF, alpA, A, lda, wA);
         if (!i)
            b2blk(kb0, nb, alpB, B, ldb, wB);
         wAn = wA+MBF*kb0U;
         wBn = (nkblks) ? wB+incwB0 : wB;
         amm_b0(nmuF, nnu, kb0U, wA, wB, wC, nkblks?wAn:wA, wBn, wC);
         wA = wAn;
         wB = wBn;
         A += incAk0;
         B += incBk0;
/*
 *       If first K-block not the only K-block
 */
         if (nkblks)
         {
            for (k=nkblks-1; k; k--)
            {
               wAn = wA+MBF*kb;
               wBn = wB+incwB;
               if (!j)
                  a2blk(kb, mbF, alpA, A, lda, wA);
               if (!i)
                  b2blk(kb, nb, alpB, B, ldb, wB);
               amm_b1(nmuF, nnu, kb, wA, wB, wC, wAn, wBn, wC);
               wA += MBF*kb;
               wB = wBn;
               A += incAk;
               B += incBk;
            }
/*
 *          Last K-block peeled to change prefetch pattern
 */
            if (!j)
               a2blk(kb, mbF, alpA, A, lda, wA);
            if (!i)
               b2blk(kb, nb, alpB, B, ldb, wB);
            amm_b1(nmuF, nnu, kb, wA, wB, wC, wA0, wB0, wC);
            wA = wA0;
            wB = wB0;
         }
         blk2c(mbF, nb, alpC, wC, beta, C, ldc);
      }  /* end M-peel */
      wA = wA0;
      B = B0 = Bn;
      C = Cn;
   }
   free(vp);
   return(0);
}
@ROUT ATL_cammmNMK
#include "atlas_misc.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

int Mjoin(PATL,ammmNMK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   amminfo_t mminfo;
   ATL_INT mb, NB, kb, mu, nu, ku, KRUN;
   #if ATL_geAMM_MAXKVEC > 1
      size_t kb0U, KK;
   #else
      #define kb0U kb0
      #define KK K
   #endif
   size_t nmblks, nnblks, nkblks, mbF, nbF, kb0, nmu, nmuF, MBF, NBF;
   size_t incwA, incAk, incBk, incAk0, incBk0, incAm, incBn, incCn;
   size_t i, j, k, szA, szB, szC, nnu0, nnuF;
   const TYPE *B0 = B;
   const TYPE one[2] = {ATL_rone, ATL_rzero};
   const TYPE *alpA=one, *alpB=one, *alpC=one;
   TYPE *wA, *wB, *wC, *rC, *wA0, *wB0;
   void *vp;
   cm2am_t a2blk, b2blk;
   ablk2cmat_t blk2c;
   ammkern_t amm_b1, amm_b0, amm_bn, amm_b1K, amm_bnK;
   int appAl;

   appAl = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!appAl)
      alpA = alpha;
   else if (appAl == 1)
      alpB = alpha;
   else
      alpC = alpha;
   mb = mminfo.mb;
   NB = mminfo.nb;
   kb = mminfo.kb;
   KRUN = ATL_AMMFLG_KRUNTIME(mminfo.flag);
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   incwA = mb*kb; 
   nmu = mb / mu;
   amm_b1 = mminfo.amm_b1;
   amm_bn = mminfo.amm_bn;
   blk2c = mminfo.Cblk2cm;
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
/*
 * Handle N differently than other dims: since it is outer loop, don't want
 * to peel, so just vary nb inside the main loop.  nnblks therefore includes
 * final block, unlike for M or K.
 */
   if (N >= NB+nu+nu)
   {
      nnblks = N/NB;
      nbF = N - nnblks * NB;
      if (nbF < nu+nu)
         nbF += NB;
      else
         nnblks++;
   }
   else
   {
      nnblks = 1;
      nbF = N;
   }
   nnu0 = NB / nu;
   nnuF = (nbF+nu-1)/nu;
   NBF = nnuF * nu;
/*
 * For M, we must peel the final block to handle any cleanup (can't peel 1st
 * block or we mess up alignment!), so this block is not included in the
 * block count
 */
   if (M >= mb+mu+mu)  /* more than just last block */
   {
      nmblks = M/mb;
      mbF = M - nmblks * mb;
      if (mbF < mu+mu)  /* steal block from main iteration, not enough here! */
      {
         nmblks--;
         mbF += mb;
      }
   }
   else /* put everything in final block */
   {
      mbF = M;
      nmblks = 0;
   }
   nmuF = (mbF+mu-1) / mu;
   MBF = nmuF * mu;
/*
 * For K, we peel the first iteration to set BETA=0, so the nkblks does not
 * include the peeled block
 */
   if (K >= kb)
   {
      nkblks = K/kb;
      kb0 = K - nkblks * kb;
      if (!kb0)
      {
         kb0 = kb;
         nkblks--;
      }
      else
      {
         if (kb0 < 4)
         {
            kb0 += kb;
            nkblks--;
         }
      }
   }
   else /* K < nb */
   {
      kb0 = K;
      nkblks = 0;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KK = ((K+ku-1)/ku)*ku;
         kb0U = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            amm_b0 = mminfo.amm_b0;
         else
            amm_b0 = (mminfo.kb == kb0U) ?  mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
      {
         KK = K;
         kb0U = kb0;
         amm_b0 = (kb0 == mminfo.kb || 
                   (KRUN && kb0 >= mminfo.kbmin && (kb0/ku)*ku == kb0)) ?  
                  mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
   #else
      amm_b0 = (kb0 == mminfo.kb || 
                (KRUN && kb0 >= mminfo.kbmin && (kb0/ku)*ku == kb0)) ?  
               mminfo.amm_b0 : mminfo.amm_k1_b0;
   #endif
   if (amm_b0 == mminfo.amm_b0)
   {
      amm_b1K = amm_b1;
      amm_bnK = amm_bn;
   }
   else
   {
      amm_b1K = mminfo.amm_k1_b1;
      amm_bnK = mminfo.amm_k1_bn;
   }
   szA = (nmblks*mb+MBF)*KK; /* wrkspc for all of A wt M rounded up to MU*/
   j = Mmax(NB, NBF);
   i = Mmax(MBF, mb);
   szC = i*j;
   szB = KK*j;                     /* workspace for panel of B */

   k = ATL_MulBySize(szA+szB+szC+mu*nu*ku) + 3*ATL_Cachelen;
   if (k > ATL_MaxMalloc)
      return(2);
   vp = malloc(k);
   if (!vp)
      return(1);
   wB0 = wB = ATL_AlignPtr(vp);
   wA = wB + szB + szB;
   wA0 = wA = ATL_AlignPtr(wA);
   wC = wA + szA + szA;
   wC = ATL_AlignPtr(wC);
   rC = wC + szC;

   if (TA == AtlasNoTrans)
   {
      incAm = mb SHIFT;
      incAk0 = kb0*lda SHIFT;
      incAk = kb*lda SHIFT;
   }
   else
   {
      incAm = mb*lda SHIFT;
      incAk0 = kb0 SHIFT;
      incAk = kb SHIFT;
   }
   if (TB == AtlasNoTrans)
   {
      incBk0 = kb0 SHIFT;
      incBk = kb SHIFT;
      incBn = NB*ldb SHIFT;
   }
   else
   {
      incBk0 = kb0*ldb SHIFT;
      incBk = kb*ldb SHIFT;
      incBn = NB SHIFT;
   }
   incCn = ldc*NB SHIFT;

   for (j=0; j < nnblks; j++)
   {
      size_t nb, nbsz, incwB, incwB0, nnu;
      const TYPE *Bn = B+incBn;
      TYPE *Cn = C + incCn;
      if (j != nnblks-1)
      {
         nbsz = nb = NB;
         nnu = nnu0;
      }
      else
      {
         nb = nbF;
         nbsz = NBF;
         nnu = nnuF;
      }
      incwB = nbsz*kb;
      incwB0 = nbsz*kb0U;
/*
 *    Do all M-blocks except final one, which may be of differing size & partial
 */
      for (i=0; i < nmblks; i++)
      {
         TYPE *wAn, *wBn;
         const TYPE *An = A+incAm;
/*
 *       Peel first K it to handle K-cleanup and set BETA=0
 */
         wAn = wA+mb*kb0U;
         wBn = wB+incwB0;
         if (!j)
            a2blk(kb0, mb, alpA, A, lda, wAn, wA);
         if (!i)
            b2blk(kb0, nb, alpB, B, ldb, wBn, wB);
         amm_b0(nmu, nnu, kb0U, wA, wB, rC, wAn, wB, wC);
         amm_b0(nmu, nnu, kb0U, wAn, wB, wC, wAn, wBn, rC);
         amm_bnK(nmu, nnu, kb0U, wAn, wBn, rC, wA, wBn, wC);
         wB = wBn+incwB0;
         wAn += mb*kb0U;
         amm_b1K(nmu, nnu, kb0U, wA, wBn, wC, wAn, wB, rC);
         wA = wAn;
         A += incAk0;
         B += incBk0;
/*
 *       If first K-block not the only K-block
 */
         if (nkblks)
         {
            for (k=nkblks-1; k; k--)
            {
               wAn = wA+incwA;
               wBn = wB+incwB;
               if (!j)
                  a2blk(kb, mb, alpA, A, lda, wAn, wA);
               if (!i)
                  b2blk(kb, nb, alpB, B, ldb, wBn, wB);
               amm_bn(nmu, nnu, kb, wA, wB, rC, wAn, wB, wC);
               amm_b1(nmu, nnu, kb, wAn, wB, wC, wAn, wBn, rC);
               amm_bn(nmu, nnu, kb, wAn, wBn, rC, wAn, wB, wC);
               wAn += incwA;
               wB = wBn + incwB;
               amm_b1(nmu, nnu, kb, wA, wBn, wC, wAn, wB, rC);
               wA = wAn;
               A += incAk;
               B += incBk;
            }
/*
 *          Last K-block peeled to change prefetch pattern
 */
            wAn = wA+incwA;
            wBn = wB+incwB;
            if (!j)
               a2blk(kb, mb, alpA, A, lda, wAn, wA);
            if (!i)
               b2blk(kb, nb, alpB, B, ldb, wBn, wB);
            amm_bn(nmu, nnu, kb, wA, wB, rC, wAn, wB, wC);
            amm_b1(nmu, nnu, kb, wAn, wB, wC, wAn, wBn, rC);
            amm_bn(nmu, nnu, kb, wAn, wBn, rC, wAn, wB, wC);
            wAn += incwA;
            amm_b1(nmu, nnu, kb, wA, wBn, wC, wAn, wB0, rC);
            wA = wAn;
            wB = wB0;
         }
         blk2c(mb, nb, alpC, rC, wC, beta, C, ldc);
         A = An;
         B = B0;
         wB = wB0;
         C += mb+mb;
      }
/*
 *    Do the final peeled M-block, which is of non-constant size mbF
 */
      {
         TYPE *wAn, *wBn;
/*
 *       Peel first K it to handle K-cleanup and set BETA=0
 */
         wAn = wA+MBF*kb0U;
         wBn = wB+incwB0;
         if (!j)
            a2blk(kb0, mbF, alpA, A, lda, wAn, wA);
         if (!i)
            b2blk(kb0, nb, alpB, B, ldb, wBn, wB);
         amm_b0(nmuF, nnu, kb0U, wA, wB, rC, wAn, wB, wC);
         amm_b0(nmuF, nnu, kb0U, wAn, wB, wC, wAn, wBn, rC);
         amm_bnK(nmuF, nnu, kb0U, wAn, wBn, rC, wAn, wB, wC);
         wAn += MBF*kb0U;
         wB = wBn + incwB0;
         amm_b1K(nmuF, nnu, kb0U, wA, wBn, wC, nkblks?wAn:wA, wB, rC);
         wA = wAn;
         A += incAk0;
         B += incBk0;
/*
 *       If first K-block not the only K-block
 */
         if (nkblks)
         {
            for (k=nkblks-1; k; k--)
            {
               wAn = wA+MBF*kb;
               wBn = wB+incwB;
               if (!j)
                  a2blk(kb, mbF, alpA, A, lda, wAn, wA);
               if (!i)
                  b2blk(kb, nb, alpB, B, ldb, wBn, wB);
               amm_bn(nmuF, nnu, kb, wA, wB, rC, wAn, wB, wC);
               amm_b1(nmuF, nnu, kb, wAn, wB, wC, wAn, wBn, rC);
               amm_bn(nmuF, nnu, kb, wAn, wBn, rC, wAn, wB, wC);
               wAn += MBF*kb;
               wB = wBn + incwB;
               amm_b1(nmuF, nnu, kb, wA, wBn, wC, wAn, wB, rC);
               wA = wAn;
               A += incAk;
               B += incBk;
            }
/*
 *          Last K-block peeled to change prefetch pattern
 */
            wAn = wA+MBF*kb;
            wBn = wB+incwB;
            if (!j)
               a2blk(kb, mbF, alpA, A, lda, wAn, wA);
            if (!i)
               b2blk(kb, nb, alpB, B, ldb, wBn, wB);
            amm_bn(nmuF, nnu, kb, wA, wB, rC, wAn, wB, wC);
            amm_b1(nmuF, nnu, kb, wAn, wB, wC, wAn, wBn, rC);
            amm_bn(nmuF, nnu, kb, wAn, wBn, rC, wAn, wB, wC);
            amm_b1(nmuF, nnu, kb, wA, wBn, wC, wA0, wB0, rC);
            wA = wA0;
            wB = wB0;
         }
         blk2c(mbF, nb, alpC, rC, wC, beta, C, ldc);
      }  /* end M-peel */
      wA = wA0;
      wB = wB0;
      B = B0 = Bn;
      C = Cn;
   }
   free(vp);
   return(0);
}
@ROUT peaktim
#include "atlas_misc.h"
#include <assert.h>

void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -n <spclen>: workspace to pass\n");
   fprintf(stderr, "   -I <its> : iterations to pass\n");
   fprintf(stderr, "   -# <ntimes> : set # of times to time kernel\n");
   exit(ierr ? ierr : -1);
}
size_t GetFlags(int nargs, char **args, size_t *N, int *NREP)
{
   size_t nits = 10000;
   int i;

   *N = 128;
   *NREP = 3;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);
      switch(args[i][1])
      {
      case 'I':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         nits = atoll(args[i]);
         break;
      case 'n':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *N = atoll(args[i]);
         break;
      case '#':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *NREP = atoi(args[i]);
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   return(nits);
}

double ATL_walltime(void);
void RunKern(size_t nits, void *vp);

int main (int nargs, char **args)
{
   size_t n, nits, i, ifl;
   double t0, mf, mfB;
   void *vp;
   char *cp;
   size_t *lp;
   int nrep;

   nits = GetFlags(nargs, args, &n, &nrep);
   vp = malloc(n+32);
   cp = ATL_AlignPtr(vp);
   lp = (size_t*)cp;
   for (i=0; i < n; i++)
      cp[i] = 0;

   mfB=0;
   for (i=0; i < nrep; i++)
   {
      t0 = ATL_walltime();
      RunKern(nits, (void*)cp);
      t0 = ATL_walltime() - t0;
      ifl = lp[0];
      mf = (((double)ifl)*nits) / (t0 * 1.0e6);
      if (mf > mfB)
         mfB = mf;
      printf("MFLOPS=%.2f\n", mf);
   }
   printf("\nBEST = %.2f\n\n", mfB);

   free(vp);
   return(0);
}
@ROUT cm2amtst
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
#include <string.h>
#include "atlas_misc.h"

void cm2am_tst
(
   ATL_CSZT K,          /* number of rows in A */
   ATL_CSZT N,          /* number of columns in A */
   const SCALAR alpha,  /* scalar for A */
   const TYPE *A,       /* matrix to be copied to access-major format */
   ATL_CSZT lda,        /* stride between row elements */
   TYPE *pA,            /* OUTPUT: access-major block holding real(A) */
   int nu
)
{
   ATL_CINT nfblks = (N/nu), NNU=nfblks*nu, nr = N-NNU;
   for (j=0; j < NNU; j += nu)
   {
      for (k=0; k < k++)
      {
         for (i=0; i < nu; i++)
            *pA++ = A[(j+i)*lda+k]
      }
   }
   for (; j < N; j++)
   {
      for (k=0; k < k++)
      {
         for (i=0; i < nr; i++)
            *pA++ = A[(j+i)*lda+k]
         for (; i < nu; i++)
            *pA++ = ATL_rzero;
      }
   }
}

void InitEntryArray(int M, int N, TYPE *A, int lda)
{
   int i, j;
   for (j=0; j < N; j++)
   {
      for (i=0; i < lda; i++)
         A[i] = lda*j+i;
   }
   
}

main(int nargs, char **args)
{
   int M=12, N=10, lda=14, align=16, maxalign=32, mu=5, k, ierr=0;
   TYPE *A, *pA0, *pA1;
   TYPE alpha = 1.0;
   A = malloc(((2*M+lda)*N + 2*maxalign);
   assert(A);
   pA0 = A + lda*N;
   pA1 = pA0 + M*N;
   assert(maxalign > align);
   pA1 = (TYPE*)((((size_t)pA1)+maxalign-1)/maxalign)*maxalign;
   if (align)
      pA1 = (TYPE*)((size_t)pA1 + align);
   cm2am_tst(N, M, alpha, A, lda, pA0, mu);
   ATL_UCM2AM(N, M, alpha, A, lda, pA1);
   for (k=0; k < M*N; k++)
   {
      if (pA0[i] != pA1[i])
      {
         int i, j, jmu;
         jmu = k / (M*mu);
         j = k - (jmu*M*mu);
         i = j / mu;
         j = j % mu;
         if (pA0[i] != alpha*A[j*lda+i])
         {
            printf(
               "TEST COPY OR INDEX CALC WRONG: pA0[%d] != A[%d,%d] (%g, %g)\n"
                   k, i, j, pA0[i] != A[j*lda+i]);
            return(k+1);
         }
         printf("pA[%d] ([%d,%d] of matrix): expected=%g (%g), got=%g\n",
                i, i, j, pA0[i], A[j*lda+i], pA1[i]);
         ierr++;
      }
   }
   if (!ierr)
      printf("PASSED.\n");
   else
      printf("FAILED: %d\n", ierr);
   return(ierr);
}

@ROUT ATL_GetAmmAlg.c
#include "atlas_amm.h"
#include Mstr(Mjoin(ATLAS_PRE,geamm_blk.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_ablk2cmat.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_aX.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,geamm_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_kern.h))

void GetAmmNMKDetails
(
/*
 * Input parameters describing problem; for now, don't use A/B/C, but might
 * be important to find aliasing later!
 */
   const enum ATLAS_TRANS TA,
   const enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   const TYPE *C,
   ATL_CSZT ldc
/*
 * Output params
 */
   ATL_SZT *mb, ATL_SZT *nb, ATL_SZT *kb,
   int *mu, int *nu, int *ku,
   ammkern_t *amm_b0, ammkern_t *amm_b1, ammkern_t *amm_bn, 
   cm2am_t *a2blk, *b2blk, ablk2cmat_t *blk2c
)
{

   if (SCALAR_IS_ONE(alpha))
   {
      if (SCALAR_IS_ONE(beta))
         *blk2c = ATL_AMM_BLK2C_a1_b1[IK];
      else if (SCALAR_IS_NONE(beta))
         *blk2c = ATL_AMM_BLK2C_a1_bn[IK];
      else if (SCALAR_IS_ZERO(beta))
         *blk2c = ATL_AMM_BLK2C_a1_b0[IK];
      else
         *blk2c = ATL_AMM_BLK2C_a1_bX[IK];
   }
   else if (alpha == ATL_rnone)
   {
      if (SCALAR_IS_ONE(beta))
         *blk2c = ATL_AMM_BLK2C_an_b1[IK];
      else if (SCALAR_IS_NONE(beta))
         *blk2c = ATL_AMM_BLK2C_an_bn[IK];
      else if (SCALAR_IS_ZERO(beta))
         *blk2c = ATL_AMM_BLK2C_an_b0[IK];
      else
         *blk2c = ATL_AMM_BLK2C_an_bX[IK];
   }
   else
   {
      if (beta == ATL_rone)
         *blk2c = ATL_AMM_BLK2C_aX_b1[IK];
      else if (beta == ATL_rnone)
         *blk2c = ATL_AMM_BLK2C_aX_bn[IK];
      else if (beta == ATL_rzero)
         *blk2c = ATL_AMM_BLK2C_aX_b0[IK];
      else
         *blk2c = ATL_AMM_BLK2C_aX_bX[IK];
   }
}
enum ATL_AMMALG ATL_GetAmmAlg
(
   const enum ATLAS_TRANS TA,
   const enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   const TYPE *C,
   ATL_CSZT ldc
{
   enum ATL_AMMALG ret=ATL_NMK;

   if (M <= ATL_geAMM_LASTMB && N <= ATL_geAMM_LASTNB && K <= ATL_geAMM_LASTKB)
      ret = ATL_amm1b;
   else if (K <= ATL_rkAMM_LASTKB)  /* must create this! */
      ret = ATL_ammrkK;
   return(ret);
}
@ROUT genMM
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <assert.h>
enum VECEXT {VEC_None=0, VEC_VSX, VEC_AV, VEC_AVXMAC, VEC_AVXFMA4, VEC_AVX, 
             VEC_SSE3, VEC_SSE2, VEC_SSE1}
typedef enum VECEXT vec_t;
enum STRG {bcastB=0, kmaj};
typedef enum STRG strg_t;

char *typ = "double", *vtyp, *bcast, *mul, *add, *sub, *vld, *vst;
int VLEN, CL;
strg_t STRG=bcastB;

int GetVeclen(char pre, vec_t vec)
{
   int vlen;
   switch(vec)
   {
   case VEC_AVXMAC:
   case VEC_AVXFMA4:
   case VEC_AVX:
      vlen = 8;
      break;
   case VEC_VSX:
   case VEC_AV:
   case VEC_SSE3:
   case VEC_SSE2:
   case VEC_SSE1:
      vlen = 4;
      break;
   default:
      vlen = 1;
   }
   if (pre == 'd' && vlen > 1)
      vlen >>= 1;
}
void SetVecInfo(char pre, vec_t vec)
{
   VLEN = GetVeclen(pre, vec);
   if (pre == 'd')
   {
      switch(vec)
      {
      case VEC_AVXMAC:
      case VEC_AVXFMA4:
      case VEC_AVX:
         vtyp = "__m256d";
         bcast = "_mm256_broadcast_sd";
         mul = "_mm256_mul_pd";
         add = "_mm256_add_pd";
         sub = "_mm256_sub_pd";
         vld = "_mm256_load_pd";
         vst = "_mm256_store_pd";
         vlen = 4;
         break;
      case VEC_VSX:
      case VEC_AV:
      case VEC_SSE3:
      case VEC_SSE2:
      case VEC_SSE1:
         vlen = 4;
         break;
      default:
         vlen = 1;
      }
   }
   else
   {
   }
}
void PrintDecl(FILE *fp)
{
   fprintf(fp, "void ATL_USERMM(ATL_CSZT nmus, ATL_CSZT nnus, ATL_CSZT K,\n");
   fprintf(fp, "                const %s *pA, const %s *pB, %s *pC,\n",
           typ, typ, typ);
   fprintf(fp, "                const %s *pAn, const %s *pBn, const %s *pCn)\n",
           typ, typ, typ);
}
void DoKloop(FILE *fp, char pre, vec_t vec, int kmaj, int kb, 
             int mu, int nu, int ku)
{
   if (kmaj)
   {
      assert(kmaj == VLEN)
      assert(ku%kmaj == 0);
   }
   if (kb)
   {
      assert(kb%ku == 0);
      if (kb > ku)
         fprintf(fp, "      for (k=%d; k < %d; k += %d\n", ku, kb, ku);
   }
   else
      fprintf(fp, "      for (k=%d; k < K; k += %d\n", ku, ku);
   fprintf(fp,    "      {\n");
   fprintf(fp,    "      } /* end of K-loop */ \n");
}
void genMM(FILE *fp, char pre, vec_t vec, int kmaj, int kb, 
           int mu, int nu, int ku)
{
   int i, j;
   int incb = (kmaj) ? kmaj : 1;
   int ia=0, ib=0;
   char *Bld = (kmaj) ? "vld" : "bcast";

   if (kb && ku+ku >= kb)
      ku = kb;
   else
      ku = 0;

   fprintf(fp, "#include <atlas_simd.h>\n\n");
   PrintDecl(fp);
   fprintf(fp, "/*\n");
   fprintf(fp, 
" * Access-major matmul with: pre=%c, KMAJ=%d, kb=%d, mu=%d, nu=%d\n",
           pre, kmaj, kb, mu, nu);
   fprintf(fp, " */\n");
   fprintf(fp, "{\n");
   fprintf(fp, "   size_t i, j, k, incPF\n");
   if (kb)
      fprintf(fp, "   #define incA %d\n", mu*kb);
   else
      fprintf(fp, "   const size_t incA = K*%d\n", mu);
   fprintf(fp, "   const %s *pB0=pB;\n", typ);
   fprintf(fp, "   register ATL_VTYP rA0");
   for (j=1; j < nu; j++)
      fprintf(fp, ", rA%d", j);
   fprintf(fp, ";\n");
   fprintf(fp, "   register ATL_VTYP rB0");
   for (j=1; j < mu; j++)
      fprintf(fp, ", rB%d", j);
   fprintf(fp, ";\n");
   fprintf(fp, "   register ATL_VTYP rC0_0");
   for (j=0; j < nu; j++)
      for (i=0; i < mu; i++)
         if (i | j)
            fprintf(fp, ", rC%d_%d", i, j);
   fprintf(fp, ";\n");
   fprintf(fp, "\n");
   fprintf(fp, "   for (i=0; i < nmus; i++, pA += incA)\n   {\n");
   fprintf(fp, "      const %s *a=pA;\n");
   fprintf(fp, "      for (j=0; j < nnus; j++)\n      {\n");
/*
 * Rewrite to peel X its in order to schedule loads & prefetches, then
 * start loop; will have specialized routines for each case
 */
   fprintf(fp, "/*\n *         K=0 it peeled to zero rCx_x\n */\n");
   for (j=0; j < nu; j++)
      fprintf(fp, "         ATL_v%s(rB%d, pB+%d);\n", Bld, j, j*incb);
   if (!ku)
      fprintf(fp, "         pB += %d;\n", nu*incb);
   else 
      ib += nu*incb;
   for (i=0; i < mu; i++)
      fprintf(fp, "         ATL_vld(rA%d, a+%d);\n", i, i*VLEN);
   if (!ku)
      fprintf(fp, "         pA += %d;\n", VLEN*mu);
   else 
      ia += VLEN*mu;

   for (j=0; j < nu; j++)
   {
      for (i=0; i < mu; i++)
      {
         fprintf(fp, "         ATL_vmul(rC%d_%d, rA%d, rB%d);\n",
                 i, j, i, j);
         if (j==nu-1)
            fprintf(fp, "         ATL_vld(rA%d, a+%d);\n", i, ia+i*VLEN);
      }
      if (j != nu-1)
         fprintf(fp, "         ATL_v%s(rB%d, pB+%d);\n", Bld, j, ib+j*incb);
   }
   if (kb && ku+ku > kb) /* fully unrolled K loop */
   {
      fprintf(fp, "         ATL_v%s(rB0, pB+%d);\n", Bld, nu*incb);
      for (k=VLEN; k < kb; k += VLEN)
      {
         fprintf(fp, "/*\n *         K=%d iteration\n */\n");
      }
   }
   else
   {
      if (kmaj)
      {
         if (kb)
            fprintf(fp, "         for (k=%d; k < %d; k += %d)\n         {\n",
                    VLEN, kb, VLEN);
         else
            fprintf(fp, "         for (k=%d; k < K; k += %d)\n         {\n",
                    VLEN, VLEN);
      }
      else
      {
         fprintf(fp, "         for (k=1; k < K; k++)\n         {\n");
      }
      fprintf(fp, "         }  /* end K-loop */\n");
   }
   fprintf(fp, "         a += %d;\n", mu*VLEN);
   fprintf(fp, "         pB += %d;\n", nu*incb);

   fprintf(fp, "      } /* end j-loop */\n");
   fprintf(fp, "      pB = pB0;\n");
   fprintf(fp, "   } /* end i-loop */\n");

   
   fprintf(fp, "}\n");
   if (kb)
      fprintf(fp, "#undef incA\n");
}
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr, 
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
   fprintf(stderr, "   -o <outfile>: path & file to generate\n");
   fprintf(stderr, "   -U[m,n,k]: set unrolling factor\n");
   fprintf(stderr, "   -V [sse1,sse2,sse3,avx,fma3,fma4,ppcav,vsx]\n");
   fprintf(stderr, "   -K # : non-zero number is fixed K loop\n");
   fprintf(stderr, "   -S [B,K]: storage bcastB/KU-major\n");
}

FILE *GetFlags(char *PRE, vec_t *VEC, int *KMAJ, int *KB, 
               int *MU, int *NU, int *KU)
{
   FILE *fpout=stdout;
   *PRE = 'd';
   *VEC = VEC_SSE3;
   *KMAJ = *KB = 0;
   *MU = *NU = 3;
   *KU = 1;
}
int main(int nargs, char **args)
{
   char pre='d';
   int mu, nu, ku, kb;
   FILE *fpout;
   vec_t vec;
   
   fpout = GetFlags(&pre, &vec, &kb, &kmaj, &mu, &nu, &ku);
   if (pre == 's')
      typ = "float";
   genMM(pre, vec, kmaj, kb, mu, nu, ku);
}
@ROUT ATL_GetRankKInfo
#define ATL_NOAMM 1
#include "atlas_misc.h"
#undef ATL_NOAMM
#include Mstr(Mjoin(ATLAS_PRE,rkamm_kern.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_blk.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,rkamm_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_perf.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_cm2am_aX.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_ablk2cmat.h))
@ROUT ATL_GetAmmmInfoSQ
#include "atlas_misc.h"
#include Mstr(Mjoin(ATLAS_PRE,opsq_blk.h))
#include Mstr(Mjoin(ATLAS_PRE,opsq_ablk2cmat.h))
#include Mstr(Mjoin(ATLAS_PRE,opsq_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,opsq_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,opsq_cm2am_aX.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,opsq_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,opsq_kern.h))
#include Mstr(Mjoin(ATLAS_PRE,opsq_perf.h))
#include Mstr(Mjoin(ATLAS_PRE,skamm_perf.h))

#ifdef ATL_CAMM_MAXINDX
   #define ATL_MAXIDX ATL_CAMM_MAXINDX
#elif defined(ATL_sqAMM_98IDX) && !defined(ATL_sqAMM_66IDX)
   #define ATL_MAXIDX ATL_sqAMM_98IDX
#endif
#ifndef ATL_MAXIDX
   #define ATL_MAXIDX ATL_sqAMM_NCASES-1
#endif

static INLINE void FillInInfo(amminfo_t *out, int id)
{
   out->IDX = id;
   out->nb = out->kb = out->mb = ATL_AMM_KBs[id];
   out->mu = ATL_AMM_MUs[id];
   out->nu = ATL_AMM_NUs[id];
   out->ku = ATL_AMM_KUs[id];
   out->kbmin = ATL_AMM_KBMINs[id];
   out->kbmax = ATL_AMM_KBMAXs[id];
   out->vlen = ATL_AMM_VLENs[id];
   out->flag = ATL_AMM_KFLAG[id];
   out->amm_b0 = ATL_AMM_KERN_b0[id];
   out->amm_b1 = ATL_AMM_KERN_b1[id];
   out->amm_bn = ATL_AMM_KERN_bn[id];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[id];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[id];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[id];
}

@ROUT ATL_GetAmmmInfo
#include "atlas_misc.h"
#include Mstr(Mjoin(ATLAS_PRE,geamm_blk.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_ablk2cmat.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_aX.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,geamm_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_kern.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_perf.h))

@ROUT ATL_GetAmmmInfo  ATL_GetAmmmInfoSQ ATL_GetRankKInfo
static INLINE ablk2cmat_t GetBlk2C(int id, int ialp, int ibet)
{
   if (ialp == 1)
   {
      if (ibet == 1)
         return(ATL_AMM_BLK2C_a1_b1[id]);
      else if (!ibet)
         return(ATL_AMM_BLK2C_a1_b0[id]);
      else if (ibet == -1)
         return(ATL_AMM_BLK2C_a1_bn[id]);
      return(ATL_AMM_BLK2C_a1_bX[id]);
   }
   else if (ialp == -1)
   {
      if (ibet == 1)
         return(ATL_AMM_BLK2C_an_b1[id]);
      else if (!ibet)
         return(ATL_AMM_BLK2C_an_b0[id]);
      else if (ibet == -1)
         return(ATL_AMM_BLK2C_an_bn[id]);
      return(ATL_AMM_BLK2C_an_bX[id]);
   }
   else
   {
      if (ibet == 1)
         return(ATL_AMM_BLK2C_aX_b1[id]);
      else if (!ibet)
         return(ATL_AMM_BLK2C_aX_b0[id]);
      else if (ibet == -1)
         return(ATL_AMM_BLK2C_aX_bn[id]);
      return(ATL_AMM_BLK2C_aX_bX[id]);
   }
}
@ROUT ATL_GetAmmmInfoSQ

#define SyrkTime Mjoin(PATL,sSyrkTimeEst)
double SyrkTime(int id, unsigned int flg, size_t N, size_t K, double symul)
{
   double tot, kfrac;
   size_t nfnblks, nondiag, nfkblks;
   unsigned int nb, kr;

   if (symul > 1.0)  /* <=1.0 means using GEMM for diag blks, not SYRK */
      symul *= 0.5;  /* syrk does half as many flops */
   nb = ATL_AMM_KBs[id];
   nfkblks = K / nb;
   kr = K - nfkblks*nb;
   kfrac = (double)kr / (double)nb;
   nfnblks = N/nb;
   nondiag = (((nfnblks+1)*nfnblks)>>1) - nfnblks;
/*
 * Find total time to compute full GEMM & SYRK blocks
 */
   tot = nondiag * ATL_sqAMM_TIME[id] * (nfkblks + kfrac/ATL_sqAMM_K1RATIO[id]);
   tot += symul * nfnblks * ATL_skAMM_TIME[id] * (nfkblks + kfrac);
   kr = N - nfnblks*nb;
   if (kr)  /* have partial GEMM panel & SYRK block */
   {
      size_t nkb, nnb;
      int i;
      double pen;
      const unsigned int U = (flg) ? ATL_AMM_NUs[id] :ATL_AMM_MUs[id];
      const unsigned int NR = ((kr+U-1)/U)*U;
/*
 *    pen: penalty for doing useless flops
 */
      pen = (double)NR / (double)kr;
      pen *= pen;
/*
 *    Try to find similar size to estimate speed for cleanup dim
 */
      for (i=0; i < ATL_sqAMM_NCASES-1 && ATL_AMM_KBs[i] < NR; i++);
      if (i && ATL_AMM_KBs[i] > NR)
         i--;
      nb = ATL_AMM_KBs[i];
      nkb = (K+nb-1) / nb;
      nnb = (N+nb-1) / nb;
      tot += symul*nkb*ATL_skAMM_TIME[i]; /* SYRK cleanup */
      tot += nkb*pen*nnb*ATL_sqAMM_TIME[i];
   }

#if 0
printf("   D%03d=(%d,%d:%d), time=%e, mf=%.0f\n", 
       id, N, K, nb, tot, 1.0e-6*N*N*K / tot);
#endif
   return(tot);
}

int Mjoin(PATL,GetSyrkIdx) /* returns square amm index to use */
(
   unsigned int flg,     /* bit 0 set: Upper, else Lower */
   ATL_CSZT N,           /* size of triangular matrix */
   ATL_CSZT K,           /* K dim of A/A^T */
   double symul         /* <= 1: use gemm, else syrk/gemm speed (>1) */
@skip   int *NB               /* OUTPUT: suggested nb */
)
{
   double timB;
   int i, iB=0;

   #if 0
   if (K >=  ATL_pmnAMM_MAXKB)
   {
      int *ip = ATL_AMM_NBs;
      if (N >= ATL_pmnAMM_MAXNB)
      for (i=0; i < ATL_pmnAMM_NCASES && ip[i] < N; i++)
   }
   #endif
   timB = SyrkTime(0, flg, N, K, symul);
   for (i=1; i < ATL_sqAMM_NCASES; i++)
   {
      double tim;
      if (ATL_AMM_KBs[i] > K)
         break;
      tim = SyrkTime(i, flg, N, K, symul);
      if (tim < timB)
      {
         timB = tim;
         iB = i;
      }
   }
/*   printf("IDX=%d, NB=%d, tim=%e, mf=%.0f\n", iB, ATL_AMM_KBs[iB], timB, 1.0e-6*N*N*K / timB);  */
   return(iB);
}

int Mjoin(PATL,GetSyrkInfo)  /* returns nb */
(
   amminfo_t *out,
   int ialp,             /* 1:alpha=1.0, -1:-1.0, else alpha=X */
   enum ATLAS_TRANS TA,
   ATL_CSZT N,           /* size of triangular matrix */
   ATL_CSZT K,           /* K dim of A/A^T */
   int ibet              /* 0:beta=0.0 1:beta=1.0, -1:-1.0, else beta=X */
)
{
   int id=0, nb, ibest=0;
   double timB = ((double)N)*N*K*ATL_sqAMM_TIME[0];
   for (id=0; id < ATL_sqAMM_NCASES; id++)
   {
      double tim;
      const int nb=ATL_AMM_KBs[id];
      ATL_SZT ndiag, ncblks;
      ATL_CSZT nnblks=N/nb, nkblks=K/nb;
      const int nr=N-nnblks*nb, kr=K-nkblks*nb;
      if (nb+nb > K)
         break;
      tim = nkblks*ATL_sqAMM_TIME[id];
      if (kr)
      {
         int i;
         double d;
         for (i=id; i > 0; i--)         /* find kb closest to kr to */
            if (ATL_AMM_KBs[i] <= kr)   /* estimate K-clean speed */
               break;
         d = nb;
         d /= (double)ATL_AMM_KBs[i];
         tim += d*ATL_sqAMM_TIME[i]*d*d;
      }
      ndiag = (nr) ? nnblks+1 : nnblks;
      ncblks = ((ndiag-1)*ndiag)>>1;
      tim *= (ndiag+ncblks);
      if (tim < timB)
      {
         timB = tim;
         ibest = id;
      }
   }
   id = ibest;

   FillInInfo(out, id);
/* printf("IDX=%d, B=%d, U=(%d,%d,%d)\n", id, out->nb, out->mu,out->nu,out->ku);*/
   nb = out->nb;
   out->Cblk2cm = GetBlk2C(id, 1, ibet);
   out->Cblk2cm_b1 = ATL_AMM_BLK2C_a1_b0[id]; /* _b1 is really _b0 for SYRK! */
   if (TA == AtlasNoTrans)
   {
      out->a2blk = ATL_AMM_AT2BLK_a1[id];
      if (ialp == 1)
         out->b2blk = ATL_AMM_BT2BLK_a1[id];
      else
         out->b2blk = (ialp == -1)?ATL_AMM_BT2BLK_an[id]:ATL_AMM_BT2BLK_aX[id];
   }
   #ifdef TCPLX
   else if (TA == AtlasConj)  /* means HERK, noTrans */
   {
      out->a2blk = ATL_AMM_AT2BLK_a1[id];
      if (ialp == 1)
         out->b2blk = ATL_AMM_BH2BLK_a1[id];
      else
         out->b2blk = (ialp == -1)?ATL_AMM_BH2BLK_an[id]:ATL_AMM_BH2BLK_aX[id];
   }
   else if (TA == AtlasConjTrans)  /* Means HERK, HermTrans */
   {
      out->a2blk = ATL_AMM_AC2BLK_a1[id];
      if (ialp == 1)
         out->b2blk = ATL_AMM_BN2BLK_a1[id];
      else
         out->b2blk = (ialp == -1)?ATL_AMM_BN2BLK_an[id]:ATL_AMM_BN2BLK_aX[id];
   }
   #endif
   else  /* TA == AtlasTrans */
   {
      out->a2blk = ATL_AMM_AN2BLK_a1[id];
      if (ialp == 1)
         out->b2blk = ATL_AMM_BN2BLK_a1[id];
      else
         out->b2blk = (ialp == -1)?ATL_AMM_BN2BLK_an[id]:ATL_AMM_BN2BLK_aX[id];
   }
   return(nb);
}
#ifdef TREAL
/*
 * For TRSM, we need a kernel with mb == kb, but nb can differ.
 * Alpha for A will be -1, for B it will 1,  and Cblk2cm will be for beta=alpha,
 * while Cbk2cm_b1 will be for beta=1.0.
 * RETURNS: mb to use, 0 if ATL_trsmKL_rk4 should be called instead.
 */
#include "atlas_ttypes.h"
#include Mstr(Mjoin(ATLAS_PRE,tsamm_perf.h))
int Mjoin(PATL,GetTrsmInfo)
(
   amminfo_t *out,
   int ialp,            /* 0 alpha=0.0, 1:alpha=1.0, -1:-1.0, else alpha=X */
   enum ATLAS_TRANS TA,
   ATL_CSZT M,           /* size of triangular matrix */
   ATL_CSZT N,           /* NRHS */
   const SCALAR beta
)
{
   #define MAXIDX ATL_tsAMM_NCASES-1
   int ik = MAXIDX;
   int mu, nu, ku, nb, nnblks, mb, nmblks, mb0, ibest, bbest;
   double tslv;   /* predicted time to solve whole prob wt trsmK */
   double tbest;  /* start it at time using nb=4 (ik=0) */

/*
 * First, find speed of trsmK by taking MB closest to M
 */
   if (M >= ATL_sqAMM_LASTKB)
      tslv = ATL_tsAMM_TIME[MAXIDX];
   else
   {
      int i;
      for (i=MAXIDX; i > 0; i--)
         if (ATL_AMM_KBs[i] <= M)
            break;
      tslv = ATL_tsAMM_TIME[i];
   }
   tslv = ((1.0*M)*M*N) * tslv;
   tbest = tslv;
   ibest = -1;
   bbest = -1;
/*
 * Now loop over all square block factors, and find the best predicted perf
 */
   for (ik=0; ik < ATL_tsAMM_NCASES; ik++)
   {
      const int kb = ATL_AMM_KBs[ik];
      int mb, ndi, nsq;
      double tim, tfl;
      if (kb+kb >= M)  /* don't use blks leading to little amm */
         break;
      ndi = M/kb;              /* # of full diagonal blocks */
      nsq = ((ndi-1)*ndi)>>1; /* # of full amm blks */
      mb = M - ndi*kb;         /* partial block at beginning */
      tfl = kb;                /* triangular flops are half  */
      tfl = tfl*kb*N;          /* of amm flops for same kb */
/*
 *    Compute time to do full blocks portion of algorithm
 */
      tim = (ndi*tfl)*ATL_tsAMM_TIME[ik] +             /* slv time */
            (nsq*(tfl+tfl))*ATL_sqAMM_TIME[ik];        /* amm time */
      if (mb) /* need to find perf of partial block */
      {
         int i;
         const double pfl=(1.0*mb)*kb*N, mmfl=(2.0*ndi)*ndi*N;

         for (i=ik; i > 0; i--)
            if (ATL_AMM_KBs[ik] <= mb)
               break;
         tim += pfl * ATL_tsAMM_TIME[i];   /* extra slvtime */
         tim += mmfl * ATL_sqAMM_TIME[i];  /* extra mmtime */
      }
/*    printf("idx=%d, kb=%d(%d), spdup=%e\n", ik, kb, ATL_AMM_KBs[ik], 
             trk4/tim); */
      if (tim <= tbest)
      {
         tbest = tim;
         ibest = ik;
         bbest = kb;
      }
   }
/* best=0; */   /* FOR TESTING!!!!! */
   if (ibest < 0)
      return(0);
   ik = ibest;

   out->IDX = ik;
   out->mb = mb = out->kb = bbest;
   out->nb = nb = ATL_AMM_NBs[ik];
   out->mu = mu = ATL_AMM_MUs[ik];
   out->nu = nu = ATL_AMM_NUs[ik];
   out->ku = ku = ATL_AMM_KUs[ik];
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->kbmax = ATL_AMM_KBMAXs[ik];
   out->vlen = ATL_AMM_VLENs[ik];
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
   out->a2blk = (TA == AtlasNoTrans) ? 
                ATL_AMM_AT2BLK_an[ik]:ATL_AMM_AN2BLK_an[ik];
   out->b2blk = ATL_AMM_BN2BLK_a1[ik];
   if (ialp == 1)
      out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
   else if (ialp == -1)
      out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
   else
      out->Cblk2cm = (ialp) ? ATL_AMM_BLK2C_a1_bX[ik]:ATL_AMM_BLK2C_a1_b0[ik];
   out->Cblk2cm_b1 = ATL_AMM_BLK2C_a1_b1[ik];
   out->cm2Cblk = NULL;
   printf("ik=%d, mb=%d(%d), nb=%d, pred spdup=%.2f\n", ik, out->mb, mb, 
          out->nb, tslv/tbest);
   return(mb);
}

/*
 * For TRSM, we're going to get our main parellelism from the N dimension
 * We know that mb==kb, but nb is independent.  alpha for A will be -1,
 * and for B it will 1.  Cblk2cm will be beta=0, while Cbk2cm_b1 will be 1.
 * RETURNS: upper bound on useful nthreads to use
 */
#include "atlas_ttypes.h"
int Mjoin(PATL,tGetTrsmInfo)
(
   ATL_ttrsm_amm_t *pd,
   int P,
   enum ATLAS_TRANS TA,
   ATL_CSZT M,
   ATL_CSZT N,
   const SCALAR beta
)
{
   #ifdef ATL_CAMM_MAXINDX
      int ik = ATL_CAMM_MAXINDX;
   #else
      int ik = ATL_tsAMM_NCASES-1;
   #endif
   int mu, nu, ku, nb, nnblks, mb, nmblks, mb0;

@beginskip
   #ifdef TREAL
      nb = ATL_AMM_NBs[ik];
      nnblks = N / nb;
      if (nnblks > P && ik > ATL_AMM_98IDX)
      {
         ik = ATL_AMM_98IDX;
      }
   #endif
@endskip
/*
 * Get a KB smaller than M
 */
   for (; ik > 0 && ATL_AMM_KBs[ik] > M; ik--);

/*
 * Find a kernel where mb can be set to kb; we know these exist, since we insist
 * on square problems of moderate size
 */
   for (; ik > 0; ik--)
   {
      mu = ATL_AMM_MUs[ik];
      mb = ATL_AMM_KBs[ik];
      if (mb > M)
         continue;
/*
 *    Any kernel can be used if it can be called with MB = KB
 */
      if ((mb/mu)*mu == mb)       /* it is legal to call wt MB=KB */
         break;                   /* so use this kernel */
/*
 *    KRUNTIME kernels can vary their KB, and thus be made legal
 */
      if (ATL_AMM_KRUNTIME(ATL_AMM_KFLAG[ik]))
      {
         ku = ATL_AMM_KUs[ik];
         ku = ATL_lcm(ku, mu);
         mb = (mb/ku)*ku;
         if (mb)
            break;
      }
   }
/* ik=0; */   /* FOR TESTING!!!!! */
   pd->mb = mb = ATL_AMM_KBs[ik];
   nb = ATL_AMM_NBs[ik];
   nu = ATL_AMM_NUs[ik];
@beginskip
/*
 * Restrict either nb or P in order to split up RHS
 */
   if (nb*P > N)
   {
      if (nb > (nu<<2))  /* try reducing large NB to 4*nu,  */
      {                  /* still allows A reuse by factor 4 */
         int k = N / (nu<<2);
         if (k <= P)
         {
            nb = (nu<<2);
            P = (k*nb != N) ? k+1 : k;
         }
      }
      else
         P = (N+nb-1) / nb;
   }
@endskip
   if (P*nb > N)
      P = (N+nb-1)/nb;
   pd->nb = nb;
   mu = ATL_AMM_MUs[ik];
   ku = ATL_AMM_KUs[ik];
   pd->nmu = mb / mu;
   pd->nnu = nb / nu;
   nnblks = N / nb;
   pd->nbf = N - nb*nnblks;
   if (!pd->nbf)
   {
      pd->nbf = nb;
      pd->nnuf = pd->nnu;
   }
   else
   {
      nnblks++;
      pd->nnuf = (pd->nbf+nu-1)/nu;
   }
   pd->nnblks = nnblks;
   pd->amm_b0 = ATL_AMM_KERN_b0[ik];
   pd->amm_b1 = ATL_AMM_KERN_b1[ik];
   nmblks = M/mb;
   mb0 = (M - nmblks*mb);
   if (!mb0)
   {
      pd->MB0 = mb0 = mb;
      pd->nmu0 = pd->nmu;
   }
   else
   {
      nmblks++;
      if (ATL_AMM_KMAJOR(ik))
      {
         pd->MB0 = ((mb0+ku-1)/ku)*ku;
         if (!ATL_AMM_KRUNTIME(ik))
            pd->amm_b0 = ATL_AMM_KERN_K1_b0[ik];
      }
      else if (!ATL_AMM_KRUNTIME(ik) || mb0 != (mb0/ku)*ku ||
               mb0 < ATL_AMM_KBMINs[ik])
      {
         pd->amm_b0 = ATL_AMM_KERN_K1_b0[ik];
         pd->MB0 = mb0;
      }
      else
         pd->MB0 = mb0;
      pd->nmu0 = (mb0+mu-1)/mu;
   }
   pd->mb0 = mb0;
   pd->nmblks = nmblks;
   pd->nxblks = nnblks * nmblks;
   if (P > pd->nxblks)
      P = pd->nxblks;
   pd->mu = mu;
   pd->nu = nu;
   pd->ku = ATL_AMM_KUs[ik];
   #ifdef TCPLX
      if (TA == AtlasConjTrans)
         pd->a2blk = ATL_AMM_AC2BLK_an[ik];
      else if (TA == AtlasConj)
         pd->a2blk = ATL_AMM_AH2BLK_an[ik];
      else
   #endif
   pd->a2blk = (TA == AtlasNoTrans) ? 
               ATL_AMM_AT2BLK_an[ik] : ATL_AMM_AN2BLK_an[ik];
   pd->b2blk = ATL_AMM_BN2BLK_a1[ik];
/*
 * beta != 0, because then trsm simply zeros X and returns
 */
   if (SCALAR_IS_ONE(beta))
      pd->blk2c = ATL_AMM_BLK2C_a1_b1[ik];
   else if (SCALAR_IS_NONE(beta))
      pd->blk2c = ATL_AMM_BLK2C_a1_bn[ik];
   else
      pd->blk2c = ATL_AMM_BLK2C_a1_bX[ik];
/* printf("ik=%d, mb=%d(%d), nb=%d(%d), MB0=%d\n", ik, pd->mb, pd->mb0, pd->nb, pd->nbf, pd->MB0); */
   return(P);
}

ablk2cmat_t Mjoin(PATL,tGetSyammInfo)
(
   amminfo_t *out,
   const int P,          /* scale you want to use */
   enum ATLAS_TRANS TA,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   ablk2cmat_t dblk2cmat;
   int ik = ATL_MAXIDX;
   int nb, k;
   if (K < ATL_sqAMM_LASTKB)  
   {
      for (ik=0; ik <= ATL_MAXIDX && ATL_AMM_KBs[ik] < K; ik++);
   }
   nb = ATL_AMM_MBs[ik];
   #ifdef ATL_sqAMM_66IDX
      while (ik > ATL_sqAMM_66IDX)
      {
         k = N / nb;
         k = ((k-1)*k)>>1;
         if (k >= P)
            break;
         nb = ATL_AMM_MBs[--ik];
      }
   #endif
   out->IDX = ik;
   nb = Mmax(nb, ATL_AMM_NBs[ik]);
   if (nb > N)
      nb = N;
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   k = ATL_lcm(out->mu, out->nu);
   nb = (nb > k) ? (nb/k)*k : k;
   out->nb = out->mb = nb;
   out->kb = ATL_AMM_KBs[ik];
/*   printf("tGetSyAMM, nb=%d, kb=%d, ik=%d\n", nb, out->kb, ik); */
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->kbmax = ATL_AMM_KBMAXs[ik];
   out->vlen = ATL_AMM_VLENs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
   if (TA == AtlasNoTrans)
   {
      out->a2blk = ATL_AMM_AT2BLK_a1[ik];
      out->b2blk =  ATL_AMM_BT2BLK_a1[ik];
   }
   else
   {
      out->a2blk = ATL_AMM_AN2BLK_a1[ik];
      out->b2blk =  ATL_AMM_BN2BLK_a1[ik];
   }
   if (SCALAR_IS_ONE(alpha))
   {
      dblk2cmat = ATL_AMM_BLK2C_a1_b0[ik];
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
   }
   else if (SCALAR_IS_NONE(alpha))
   {
      dblk2cmat = ATL_AMM_BLK2C_an_b0[ik];
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_an_b1[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_an_bn[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_an_b0[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_an_bX[ik];
   }
   else  /* alpha = X */
   {
      dblk2cmat = ATL_AMM_BLK2C_aX_b0[ik];
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_aX_b1[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_aX_bn[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_aX_b0[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_aX_bX[ik];
   }
   return(dblk2cmat);
}
/*
 * returns cblk2c_b0, cblk2c_b1 is in structure
 */
ablk2cmat_t Mjoin(PATL,tGetSyammInfo_K)
(
   amminfo_t *out,
   const int P,          /* scale you want to use */
   enum ATLAS_TRANS TA,
   ATL_CSZT N,
   ATL_CSZT K
)
{
   ablk2cmat_t dblk2cmat;
   int ik = ATL_sqAMM_NCASES-1;
   int mb, nb, k, mu, nu;

   if (K < ATL_sqAMM_LASTKB)  
      for (ik=0; ik < ATL_sqAMM_NCASES-1 && ATL_AMM_KBs[ik] < K; ik++);
   out->IDX = ik;
   mu = out->mu = ATL_AMM_MUs[ik];
   nu = out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->mb = ((N+mu-1)/mu)*mu;
   out->nb = ((N+nu-1)/nu)*nu;
   out->kb = ATL_AMM_KBs[ik];
/*  printf("tGetSyAMM_K, mb=%d, nb=%d, kb=%d, ik=%d\n", mb, nb, out->kb, ik); */
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->kbmax = ATL_AMM_KBMAXs[ik];
   out->vlen = ATL_AMM_VLENs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
   if (TA == AtlasNoTrans)
   {
      out->a2blk = ATL_AMM_AT2BLK_a1[ik];
      out->b2blk =  ATL_AMM_BT2BLK_a1[ik];
   }
   else
   {
      out->a2blk = ATL_AMM_AN2BLK_a1[ik];
      out->b2blk =  ATL_AMM_BN2BLK_a1[ik];
   }
   out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
   return(ATL_AMM_BLK2C_a1_b0[ik]);
}
#endif
@ROUT ATL_GetRankKInfo
int Mjoin(PATL,GetRankKInfo)
(
   amminfo_t *out,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   const int ik = K-3;
   int appAl;  /* 0:A, 1:B */
   ATL_assert(K > 2 && K <= ATL_rkAMM_LASTKB);
@ROUT ATL_GetAmmmInfo
int Mjoin(PATL,GetAmmmInfo)
(
   amminfo_t *out,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   #ifdef ATL_CAMM_MAXINDX
      int ik=ATL_CAMM_MAXINDX;
   #else
      int ik=ATL_AMM_NCASES-1; 
   #endif
   int appAl;  /* 0:A, 1:B, 2:C */
/*
 * For rank-K update, choose smallest KB that contains required K
 */
   if (K < ATL_geAMM_LASTKB)  
   {
      for (ik=0; ik < ATL_AMM_NCASES && ATL_AMM_KBs[ik] < K; ik++);
   }
@ROUT ATL_GetAmmmInfo ATL_GetRankKInfo
   out->IDX = ik;
   out->mb = ATL_AMM_MBs[ik];
   out->nb = ATL_AMM_NBs[ik];
   out->kb = ATL_AMM_KBs[ik];
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->kbmax = ATL_AMM_KBMAXs[ik];
   out->vlen = ATL_AMM_VLENs[ik];
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
@ROUT ATL_GetAmmmInfo
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
   @define pf @ATL_AMM_@
@ROUT ATL_GetRankKInfo
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   @define pf @ATL_AMM_@
@ROUT ATL_GetAmmmInfo ATL_GetRankKInfo
/*
 * Apply alpha to smallest matrix, and use alpha/beta to pick copy routines
 */
   if (SCALAR_IS_ONE(alpha))
   {
      appAl = 0;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = @(pf)AT2BLK_a1[ik];
         else if (TA == AtlasTrans)
            out->a2blk = @(pf)AN2BLK_a1[ik];
         else if (TA == AtlasConjTrans)
            out->a2blk = @(pf)AC2BLK_a1[ik];
         else
            out->a2blk = @(pf)AH2BLK_a1[ik];
         if (TB == AtlasNoTrans)
             out->b2blk = @(pf)BN2BLK_a1[ik];
         else if (TB == AtlasTrans)
             out->b2blk = @(pf)BT2BLK_a1[ik];
         else if (TB == AtlasConjTrans)
             out->b2blk = @(pf)BH2BLK_a1[ik];
         else
             out->b2blk = @(pf)BC2BLK_a1[ik];
      #else
         out->a2blk = (TA == AtlasNoTrans) ?
            @(pf)AT2BLK_a1[ik]:@(pf)AN2BLK_a1[ik];
         out->b2blk = (TB == AtlasNoTrans) ?
            @(pf)BN2BLK_a1[ik]:@(pf)BT2BLK_a1[ik];
      #endif
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_b1[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_b0[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_bn[ik];
      else
         out->Cblk2cm = @(pf)BLK2C_a1_bX[ik];
   }
   else  /* alpha is not one */
   {
@ROUT ATL_GetRankKInfo
      appAl = (M >= N) ? 1:0;
@ROUT ATL_GetAmmmInfo
      if (M >= N)                  /* A is larger than B, put alpha on C or B */
         appAl = (M >= K) ? 1 : 2;
      else                         /* B is larger than A, put alpha on C or A */
         appAl = (N >= K) ? 0 : 2;
      if (appAl == 2)  /* apply alpha to C */
      {
         #ifdef TCPLX
            if (TA == AtlasNoTrans)
               out->a2blk = @(pf)AT2BLK_a1[ik];
            else if (TA == AtlasTrans)
               out->a2blk = @(pf)AN2BLK_a1[ik];
            else if (TA == AtlasConjTrans)
               out->a2blk = @(pf)AC2BLK_a1[ik];
            else
               out->a2blk = @(pf)AH2BLK_a1[ik];
            if (TB == AtlasNoTrans)
                out->b2blk = @(pf)BN2BLK_a1[ik];
            else if (TB == AtlasTrans)
                out->b2blk = @(pf)BT2BLK_a1[ik];
            else if (TB == AtlasConjTrans)
                out->b2blk = @(pf)BH2BLK_a1[ik];
            else
                out->b2blk = @(pf)BC2BLK_a1[ik];
         #else
            out->a2blk = (TA == AtlasNoTrans) ?
                         @(pf)AT2BLK_a1[ik] : @(pf)AN2BLK_a1[ik];
            out->b2blk = (TB == AtlasNoTrans) ?
                         @(pf)BN2BLK_a1[ik] : @(pf)BT2BLK_a1[ik];
         #endif
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           @(pf)BLK2C_an_b1[ik] : @(pf)BLK2C_aX_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           @(pf)BLK2C_an_b0[ik] : @(pf)BLK2C_aX_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           @(pf)BLK2C_an_bn[ik] : @(pf)BLK2C_aX_bn[ik];
         else
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           @(pf)BLK2C_an_bX[ik] : @(pf)BLK2C_aX_bX[ik];
      }
      else  /* not applying alpha to C */
      {
      @beginindent 1 3
@ROUT ATL_GetAmmmInfo ATL_GetRankKInfo
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_b1[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_b0[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_bn[ik];
      else
         out->Cblk2cm = @(pf)BLK2C_a1_bX[ik];
      if (!appAl)  /* apply to alpha to A */
      {
         #ifdef TCPLX
            if (TB == AtlasNoTrans)
                out->b2blk = @(pf)BN2BLK_a1[ik];
            else if (TB == AtlasTrans)
                out->b2blk = @(pf)BT2BLK_a1[ik];
            else if (TB == AtlasConjTrans)
                out->b2blk = @(pf)BH2BLK_a1[ik];
            else
                out->b2blk = @(pf)BC2BLK_a1[ik];
            if (SCALAR_IS_NONE(alpha))
            {
               if (TA == AtlasNoTrans)
                  out->a2blk = @(pf)AT2BLK_an[ik];
               else if (TA == AtlasTrans)
                  out->a2blk = @(pf)AN2BLK_an[ik];
               else if (TA == AtlasConjTrans)
                  out->a2blk = @(pf)AC2BLK_an[ik];
               else
                  out->a2blk = @(pf)AH2BLK_an[ik];
            }
            else
            {
               if (TA == AtlasNoTrans)
                  out->a2blk = @(pf)AT2BLK_aX[ik];
               else if (TA == AtlasTrans)
                  out->a2blk = @(pf)AN2BLK_aX[ik];
               else if (TA == AtlasConjTrans)
                  out->a2blk = @(pf)AC2BLK_aX[ik];
               else
                  out->a2blk = @(pf)AH2BLK_aX[ik];
            }
         #else
            if (SCALAR_IS_NONE(alpha))
               out->a2blk = (TA == AtlasNoTrans) ?
                            @(pf)AT2BLK_an[ik] : @(pf)AN2BLK_an[ik];
            else
               out->a2blk = (TA == AtlasNoTrans) ?
                            @(pf)AT2BLK_aX[ik] : @(pf)AN2BLK_aX[ik];
            out->b2blk = (TB == AtlasNoTrans) ?
                         @(pf)BN2BLK_a1[ik] : @(pf)BT2BLK_a1[ik];
         #endif
      }
      else /* apply alpha to B */
      {
         #ifdef TCPLX
            if (TA == AtlasNoTrans)
               out->a2blk = @(pf)AT2BLK_a1[ik];
            else if (TA == AtlasTrans)
               out->a2blk = @(pf)AN2BLK_a1[ik];
            else if (TA == AtlasConjTrans)
               out->a2blk = @(pf)AC2BLK_a1[ik];
            else
               out->a2blk = @(pf)AH2BLK_a1[ik];
            if (SCALAR_IS_NONE(alpha))
            {
               if (TB == AtlasNoTrans)
                   out->b2blk = @(pf)BN2BLK_an[ik];
               else if (TB == AtlasTrans)
                   out->b2blk = @(pf)BT2BLK_an[ik];
               else if (TB == AtlasConjTrans)
                   out->b2blk = @(pf)BH2BLK_an[ik];
               else
                   out->b2blk = @(pf)BC2BLK_an[ik];
            }
            else
            {
               if (TB == AtlasNoTrans)
                   out->b2blk = @(pf)BN2BLK_aX[ik];
               else if (TB == AtlasTrans)
                   out->b2blk = @(pf)BT2BLK_aX[ik];
               else if (TB == AtlasConjTrans)
                   out->b2blk = @(pf)BH2BLK_aX[ik];
               else
                   out->b2blk = @(pf)BC2BLK_aX[ik];
            }
         #else
            out->a2blk = (TA == AtlasNoTrans) ?
                         @(pf)AT2BLK_a1[ik] : @(pf)AN2BLK_a1[ik];
            if (SCALAR_IS_NONE(alpha))
               out->b2blk = (TB == AtlasNoTrans) ?
                            @(pf)BN2BLK_an[ik] : @(pf)BT2BLK_an[ik];
            else
               out->b2blk = (TB == AtlasNoTrans) ?
                            @(pf)BN2BLK_aX[ik] : @(pf)BT2BLK_aX[ik];
         #endif
      }
@ROUT ATL_GetAmmmInfo 
      @endindent
      }
@ROUT ATL_GetAmmmInfo  ATL_GetRankKInfo 
   }
   return(appAl);
}

@ROUT ATL_GetAmmmInfo 
/*
 * Following routines help pick NB for parallel routines
 */
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
#ifndef ATL_MAXIDX
   #define ATL_MAXIDX ATL_AMM_NCASES-1
#endif

int Mjoin(PATL,tGetAmmmInfo)
(
   amminfo_t *out,
   const unsigned int P,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   int ik=ATL_MAXIDX, mb, nb, nmblks, nnblks, ncblks;
   int appAl;  /* 0:A, 1:B, 2:C */
/*
 * For rank-K update, choose smallest KB that contains required K
 */
   if (K < ATL_geAMM_LASTKB)
   {
      for (ik=0; ik < ATL_AMM_NCASES && ATL_AMM_KBs[ik] < K; ik++);
   }
   ik++;
   do
   {
      ik--;
      mb = ATL_AMM_MBs[ik];
      nb = ATL_AMM_NBs[ik];
      nmblks = M / mb;
      nnblks = N / nb;
      ncblks = nmblks * nnblks;
   }
   while (ik >= ATL_geAMM_66IDX && ncblks < P);
   out->IDX = ik;
   out->mb = mb;
   out->nb = nb;
   out->kb = ATL_AMM_KBs[ik];
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->kbmax = ATL_AMM_KBMAXs[ik];
   out->vlen = ATL_AMM_VLENs[ik];
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
/*
 * Apply alpha to smallest matrix, and use alpha/beta to pick copy routines
 */
   if (SCALAR_IS_ONE(alpha))
   {
      appAl = 0;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = ATL_AMM_AT2BLK_a1[ik];
         else if (TA == AtlasTrans)
            out->a2blk = ATL_AMM_AN2BLK_a1[ik];
         else if (TA == AtlasConjTrans)
            out->a2blk = ATL_AMM_AC2BLK_a1[ik];
         else
            out->a2blk = ATL_AMM_AH2BLK_a1[ik];
         if (TB == AtlasNoTrans)
             out->b2blk = ATL_AMM_BN2BLK_a1[ik];
         else if (TB == AtlasTrans)
             out->b2blk = ATL_AMM_BT2BLK_a1[ik];
         else if (TB == AtlasConjTrans)
             out->b2blk = ATL_AMM_BH2BLK_a1[ik];
         else
             out->b2blk = ATL_AMM_BC2BLK_a1[ik];
      #else
         out->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_a1[ik]:ATL_AMM_AN2BLK_a1[ik];
         out->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_a1[ik]:ATL_AMM_BT2BLK_a1[ik];
      #endif
      out->Cblk2cm_b1 = ATL_AMM_BLK2C_a1_b1[ik];
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
   }
   else  /* alpha is not one */
   {
      if (M >= N)                  /* A is larger than B, put alpha on C or B */
         appAl = (M >= K) ? 1 : 2;
      else                         /* B is larger than A, put alpha on C or A */
         appAl = (N >= K) ? 0 : 2;
      if (appAl == 2)  /* apply alpha to C */
      {
         #ifdef TCPLX
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_a1[ik];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_a1[ik];
            else if (TA == AtlasConjTrans)
               out->a2blk = ATL_AMM_AC2BLK_a1[ik];
            else
               out->a2blk = ATL_AMM_AH2BLK_a1[ik];
            if (TB == AtlasNoTrans)
                out->b2blk = ATL_AMM_BN2BLK_a1[ik];
            else if (TB == AtlasTrans)
                out->b2blk = ATL_AMM_BT2BLK_a1[ik];
            else if (TB == AtlasConjTrans)
                out->b2blk = ATL_AMM_BH2BLK_a1[ik];
            else
                out->b2blk = ATL_AMM_BC2BLK_a1[ik];
         #else
            out->a2blk = (TA == AtlasNoTrans) ?
                         ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
            out->b2blk = (TB == AtlasNoTrans) ?
                         ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
         #endif
         out->Cblk2cm_b1 = SCALAR_IS_NONE(alpha) ?
                        ATL_AMM_BLK2C_an_b1[ik] : ATL_AMM_BLK2C_aX_b1[ik];
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b1[ik] : ATL_AMM_BLK2C_aX_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b0[ik] : ATL_AMM_BLK2C_aX_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bn[ik] : ATL_AMM_BLK2C_aX_bn[ik];
         else
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bX[ik] : ATL_AMM_BLK2C_aX_bX[ik];
      }
      else  /* not applying alpha to C */
      {
         out->Cblk2cm_b1 = ATL_AMM_BLK2C_a1_b1[ik];
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
         else
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
         if (!appAl)  /* apply to alpha to A */
         {
            #ifdef TCPLX
               if (TB == AtlasNoTrans)
                   out->b2blk = ATL_AMM_BN2BLK_a1[ik];
               else if (TB == AtlasTrans)
                   out->b2blk = ATL_AMM_BT2BLK_a1[ik];
               else if (TB == AtlasConjTrans)
                   out->b2blk = ATL_AMM_BH2BLK_a1[ik];
               else
                   out->b2blk = ATL_AMM_BC2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_an[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_an[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_an[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_an[ik];
               }
               else
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_aX[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_aX[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_aX[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_aX[ik];
               }
            #else
               if (SCALAR_IS_NONE(alpha))
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_an[ik] : ATL_AMM_AN2BLK_an[ik];
               else
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_aX[ik] : ATL_AMM_AN2BLK_aX[ik];
               out->b2blk = (TB == AtlasNoTrans) ?
                            ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
            #endif
         }
         else /* apply alpha to B */
         {
            #ifdef TCPLX
               if (TA == AtlasNoTrans)
                  out->a2blk = ATL_AMM_AT2BLK_a1[ik];
               else if (TA == AtlasTrans)
                  out->a2blk = ATL_AMM_AN2BLK_a1[ik];
               else if (TA == AtlasConjTrans)
                  out->a2blk = ATL_AMM_AC2BLK_a1[ik];
               else
                  out->a2blk = ATL_AMM_AH2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_an[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_an[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_an[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_an[ik];
               }
               else
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_aX[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_aX[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_aX[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_aX[ik];
               }
            #else
               out->a2blk = (TA == AtlasNoTrans) ?
                            ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_an[ik] : ATL_AMM_BT2BLK_an[ik];
               else
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_aX[ik] : ATL_AMM_BT2BLK_aX[ik];
            #endif
         }
      }
   }
   return(appAl);
}

@ROUT ATL_GetAmmmInfo  ATL_GetAmmmInfoSQ ATL_GetRankKInfo
static INLINE int ATL_CompBlkPart
   (size_t D, ATL_UINT maxB, ATL_UINT b, ATL_UINT u, 
    ATL_UINT *BS, size_t *NS, size_t *NL)
/*
 * Given dim D, and a blocking that is presently b (b <= maxB), and can be
 * maximally ncreased to maxB, find two blocking factors such that
 *    bL*nL + bS*nS = CEIL(D/u),   bS < bL < maxB
 * --> For D with a lot of blocks, bL = bS + nu.
 * --> For D with low nblocks, small block will just be remainder
 */
{
   size_t nL, nS, bL, bS;  /* # of small/large blks, blksz for lg/sm */
   size_t i; 
   int NU;
   
/*
 * If entire dim fits in max block, just use one block
 */
   NU = (b+u-1)/u;       /* ceiling of number of unrollings in b */
   bL = NU*u;            /* blocking must be a multiple of unrolling */
   i = (((D+u-1)/u)*u);  /* aiming for CEIL(D/u)*u */
   if (i < b+b && i <= maxB)
   {
      nS = bS = 0;
      nL = 1;
      bL = i;
   }
   else  /* have at least two blocks at initial b */
   {
      int r;
      nL = D / bL;    /* number of blocks w/o changing b */
      r = i - nL*bL;
      if (r)          /* if block does not evenly divide D */
      {               /* find 2 block sizes that get us CEIL(D/u)*u */
         if (bL+u <= maxB)          /* increase b to find partition */
         {
            ATL_CUINT nu=(r+u-1)/u; /* CEIL of # of unrollings in remndr */
            if (nL >= nu)           /* can just add u to first nu blks */
            {
               nS = nL - nu;
               nL = nu;
               bS = b;
               bL += u;
            }
            else                   /* otherwise, just dump remndr to small b */
            {
               nS = 1;
               bS = ((r+u-1)/u)*u;
            }
         }
         else                       /* decrease b to find partition */
         {
            ATL_UINT nu;
            bS = bL - u;
            nS = D/bS;
            r = i - bS*nS;
            nu=(r+u-1)/u; /* CEIL of # of unrollings in remndr */
            if (nS >= nu)           /* can just add u to first nu blks */
            {
               nS -= nu;
               nL = nu;
            }
            else                   /* otherwise, just dump remndr to small b */
            {
               nS = 1;
               r = i - nL*bL;
               bS = ((r+u-1)/u)*u;
            }
         }
      }
      else  /* no remainder, means no small blocks, D a mul of orig b */
         bS = nS = 0;
   }
   *BS = bS;
   *NS = nS;
   *NL = nL;
   #ifdef DEBUG
      printf("nS*bS + nL*bL = %d*%d + %d*%d = %d (D=%d, Du=%d)\n", (int)nS, bS,
             (int)nL, bL, (int)(nS*bS+nL*bL), (int)D, (int)(((D+u-1)/u)*u));
      ATL_assert(bS*nS + bL*nL == i);
   #endif
   return(bL);
}

@ROUT ATL_GetAmmmInfoSQ
   @define sh @sq@
@ROUT ATL_GetAmmmInfo
   @define sh @ge@
@ROUT ATL_GetRankKInfo
   @define sh @rk@
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ ATL_GetRankKInfo
double Mjoin(PATL,@(sh)GetAmmInfoDbl)(char wh, int idx)
{
   ATL_assert(idx >= 0 && idx < ATL_@(sh)AMM_NCASES);
   switch(wh)
   {
   case 'P':
      return(ATL_@(sh)AMM_PERF[idx]);
   case 'T':
      return(ATL_@(sh)AMM_TIME[idx]);
   case '1':
@ROUT ATL_GetRankKInfo
      return(1.0);
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
      return(ATL_@(sh)AMM_K1RATIO[idx]);
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ ATL_GetRankKInfo
   default:
      fprintf(stderr, "unknown what='%c'!\n", wh);
      ATL_assert(0);
   }
   return(0.0);
}

int Mjoin(PATL,@(sh)GetAmmInfoInt)(char wh, int idx)
{
   ATL_assert(idx >= 0 && idx < ATL_@(sh)AMM_NCASES);
   switch(wh)
   {
   case 'M':
      return(ATL_AMM_MBs[idx]);
   case 'N':
      return(ATL_AMM_NBs[idx]);
   case 'K':
      return(ATL_AMM_KBs[idx]);
   case 'm':
      return(ATL_AMM_MUs[idx]);
   case 'n':
      return(ATL_AMM_NUs[idx]);
   case 'k':
      return(ATL_AMM_KUs[idx]);
   case 'F':
      return(ATL_AMM_KFLAG[idx]);
   case '>':
      return(ATL_AMM_KBMAXs[idx]);
   case '<':
      return(ATL_AMM_KBMINs[idx]);
   default:
      fprintf(stderr, "unknown what='%c'!\n", wh);
      ATL_assert(0);
   }
   return(0);
}
void *Mjoin(PATL,@(sh)GetAmmInfoPtr)(int idx, int what, int alp, int bet)
{
   void *vp;
   if (!what) /* amm */
   {
      if (bet == 0)
         vp = ATL_AMM_KERN_b0[idx];
      else
         vp = (bet == 1) ? ATL_AMM_KERN_b1[idx] : ATL_AMM_KERN_bn[idx];
   }
   else if (what == 1)  /* blk2c */
      vp = GetBlk2C(idx, alp, bet);
   else if (what == 2)  /* a2blk, beta = trans */
   {
      if (bet == AtlasNoTrans)
      {
         if (alp == -1)
            vp = ATL_AMM_AN2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_AN2BLK_a1[idx] : ATL_AMM_AN2BLK_aX[idx];
      }
      #ifdef TCPLX
      else if (bet == AtlasConjTrans)
      {
         if (alp == -1)
            vp = ATL_AMM_AH2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_AH2BLK_a1[idx] : ATL_AMM_AH2BLK_aX[idx];
      }
      else if (bet == AtlasConj)
      {
         if (alp == -1)
            vp = ATL_AMM_AC2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_AC2BLK_a1[idx] : ATL_AMM_AC2BLK_aX[idx];
      }
      #endif
      else /* AtlasTrans */
      {
         if (alp == -1)
            vp = ATL_AMM_AT2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AT2BLK_aX[idx];
      }
   }
   else /* if (what == 3) */  /* b2blk */
   {
      if (bet == AtlasNoTrans)
      {
         if (alp == -1)
            vp = ATL_AMM_BN2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BN2BLK_aX[idx];
      }
      #ifdef TCPLX
      else if (bet == AtlasConjTrans)
      {
         if (alp == -1)
            vp = ATL_AMM_BH2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_BH2BLK_a1[idx] : ATL_AMM_BH2BLK_aX[idx];
      }
      else if (bet == AtlasConj)
      {
         if (alp == -1)
            vp = ATL_AMM_BC2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_BC2BLK_a1[idx] : ATL_AMM_BC2BLK_aX[idx];
      }
      #endif
      else /* AtlasTrans */
      {
         if (alp == -1)
            vp = ATL_AMM_BT2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_BT2BLK_a1[idx] : ATL_AMM_BT2BLK_aX[idx];
      }
   }
   return(vp);
}
@ROUT ATL_GetAmmmInfoSQ
/*
 * Designed for parallelism mainly on C blocks, K > LASTKB (ipinfo, not opinfo)
 * C is known to be Upper or Lower.  Fills in only M/N blocking info in ipinfo.
 */
int Mjoin(PATL,tGetParTriCIndx)(int P, int flg, size_t N, size_t K, int *NB)
{
   unsigned int ik=ATL_sqAMM_NCASES-1, nb, mu, nu, U;
@skip   size_t nmblks, nnblks, ncblks;

   if (K < ATL_@(sh)AMM_LASTKB)
      for (ik=0; ik < ATL_sqAMM_NCASES && ATL_AMM_KBs[ik] < K; ik++);
/*   ik = Mjoin(PATL,GetSyrkIdx)(flg, N, K); */
   nb = ATL_AMM_NBs[ik];
@skip   mu = ATL_AMM_MUs[ik];
@skip   nu = ATL_AMM_NUs[ik];
   U = ATL_lcm(ATL_AMM_MUs[ik],ATL_AMM_NUs[ik]);
   if (N < ATL_sqAMM_LASTNB || 
       (N < ATL_sqAMM_LASTNB+U && K >= P*nb) )
      nb = ((N+U-1)/U)*U;  /* for large U, small N, could be bad! */
@skip   nb0 = nb;
   *NB = nb;
   return(ik);
@BEGINSKIP
   #if 0
/*
 * If blocking tuned to KB provides enough parallelism, just use it
 */
   nnblks = N/nb;
   ncblks = (((nnblks-1)*nnblks)>>1) + nnblks;
   if (ncblks >= P)  /* standard blocking provides enough parallelism */
   {
      *NB = nb;
      return(ik);
   }
/*
 * If we reach here, must reduce nb for parallelism, but don't go below
 * NB that gets 66% of original perf (better to reduce P)
 */
   if (N <= ATL_sqAMM_66NB)
      nb = U*((N+U-1)/U);
   else if (ATL_sqAMM_66NB <= ATL_sqAMM_50NB + U)
      nb = U*((ATL_sqAMM_66NB+U-1)/U);
   else
      nb = U*(ATL_sqAMM_66NB/U);
   #endif
   nnblks = N/nb;
   ncblks = (((nnblks-1)*nnblks)>>1 + nnblks);
   if (ncblks < P)  /* nb at min, so reduce parallelism */
   {
      *NB = nb;
      return(ik);
   }
/*
 * If we get to here, present setting using minimal nb gives enough
 * parallelism, so look at increasing nb towards nb0 until we reach P limit.
 * The idea is that once we have the required parallelism, we want
 * to increase block performance back up towards maximum for KB.
 */
   if (nb0 > N)
      nb0 = ((N+U-1)/U)*U;
   while (1)
   {
      unsigned int nbN=nb;
      size_t cblks, nblks;
      if (nb < nb0)
      {
         nbN += U;
         nblks = N / nbN;
         cblks = ((nblks-1)*nblks)>>1 + nblks;
         if (cblks < P)
            break;
         nnblks = nblks;
      }
      else
         break;
      nb = nbN;
      ncblks = cblks;
   }
   *NB = nb;
   return(ik);
@ENDSKIP
}
@ROUT ATL_GetAmmmInfo
/*
 * Designed for parallelism mainly on C blocks, K > LASTKB (ipinfo, not opinfo)
 * Fills in only M & N blocking info in ipinfo.
 */
int Mjoin(PATL,tGetParCIndx)(ipinfo_t *ip, int P, size_t M, size_t N, size_t K)
{
   unsigned int ik=ATL_AMM_NCASES-1, mb0, mb, nb0, nb, mu, nu;
   size_t nmblks, nnblks, ncblks;
   if (K < ATL_@(sh)AMM_LASTKB)
      for (ik=0; ik < ATL_AMM_NCASES && ATL_AMM_KBs[ik] < K; ik++);
   mu = ATL_AMM_MUs[ik];
   nu = ATL_AMM_NUs[ik];
   mb0 = mb = ATL_AMM_MBs[ik];
   nb0 = nb = ATL_AMM_NBs[ik];
/*
 * If blocking tuned to KB provides enough parallelism, just use it
 */
   nmblks = M/mb;
   nnblks = N/nb;
   ncblks = nmblks*nnblks;
   if (ncblks >= P)  /* standard blocking provides enough parallelism */
   {
      unsigned int n;
      n = M - mb*nmblks;
      if (n)
      {
         ip->nfmblks = nmblks;
         ip->npmblks = 1;
         ip->mb = mb;
         ip->pmb = ((n+mu-1)/mu)*mu;
      }
      else
      {
         ip->nfmblks = nmblks;
         ip->npmblks = 0;
         ip->mb = ip->pmb = mb;
      }
      n = N - nb*nnblks;
      if (n)
      {
         ip->nfnblks = nnblks;
         ip->npnblks = 1;
         ip->nb = nb;
         ip->pnb = ((n+nu-1)/nu)*nu;
      }
      else
      {
         ip->nfnblks = nnblks;
         ip->npnblks = 0;
         ip->nb = ip->pnb = nb;
      }
      return(ik);
   }
/*
 * If we reach here, must reduce mb/nb for parallelism, but don't go below
 * MB&NB that get 66% of original perf (better to reduce P)
 */
   if (M <= ATL_geAMM_66MB)
      mb = mu*((M+mu-1)/mu);
   else if (ATL_geAMM_66MB <= mu || ATL_geAMM_66MB - mu <= ATL_geAMM_50MB)
      mb = mu*((ATL_geAMM_66MB+mu-1)/mu);
   else
      mb = mu*(ATL_geAMM_66MB/mu);
   if (N <= ATL_geAMM_66NB)
      nb = nu*((N+nu-1)/nu);
   else if (ATL_geAMM_66NB <= nu || ATL_geAMM_66NB - nu <= ATL_geAMM_50NB)
      nb = nu*((ATL_geAMM_66NB+nu-1)/nu);
   else
      nb = nu*(ATL_geAMM_66NB/nu);
   nmblks = M/mb;
   nnblks = N/nb;
   if (nmblks*nnblks < P)  /* mb/nb at min, so reduce parallelism */
   {
      unsigned int n;
      n = M - mb*nmblks;
      if (!n)
      {
         ip->pmb = ip->mb = mb;
         ip->npmblks = 0;
         ip->nfmblks = nmblks;
      }
      else if (n < mu || n+mb <= mb0)
      {
         ip->mb = mb + ((n+mu-1)/mu)*mu;
         ip->pmb = mb;
         ip->nfmblks = 1;
         ip->npmblks = (nmblks) ? nmblks-1 : 0;
      }
      else
      {
         ip->mb = mb;
         ip->nfmblks = nmblks;
         ip->npmblks = 1;
         ip->pmb = n;
      }
      n = N - nb*nnblks;
      if (!n)
      {
         ip->pnb = ip->nb = nb;
         ip->npnblks = 0;
         ip->nfnblks = nnblks;
      }
      else if (n < nu || n+nb <= nb0)
      {
         ip->nb = nb + ((n+nu-1)/nu)*nu;
         ip->pnb = nb;
         ip->nfnblks = 1;
         ip->npnblks = (nnblks) ? nnblks - 1 : 0;
      }
      else
      {
         ip->nb = nb;
         ip->nfnblks = nnblks;
         ip->npnblks = 1;
         ip->pnb = n;
      }
      return(ik);
   }
/*
 * If we get to here, present setting using minimal mb/nb gives enough
 * parallelism, so look at increasing mb/nb towards mb0/nb0 until we reach
 * P limit.  The idea is that once we have the required parallelism, we want
 * to increase block performance back up towards maximum for KB.
 */
   if (mb0 > M)
      mb0 = ((M+mu-1)/mu)*mu;
   if (nb0 > N)
      nb0 = ((N+nu-1)/nu)*nu;
   while (1)
   {
      unsigned int mbN=mb, nbN=nb;
      size_t cblks, nblks;
      if (nb < nb0 && (nb <= mb || mb >= mb0))
      {
         nbN += nu;
         nblks = N / nbN;
         cblks = nblks * nmblks;
         if (cblks < P)
            break;
         nnblks = nblks;
      }
      else if (mb < mb0)
      {
         mbN += mu;
         nblks = M / mbN;
         cblks = nblks * nnblks;
         if (cblks < P)
            break;
         nmblks = nblks;
      }
      else
         break;
      mb = mbN;
      nb = nbN;
      ncblks = cblks;
   }
   mb0 = M - nmblks * mb;
   if (mb0 > mu)
   {
      ip->nfmblks = nmblks;
      ip->npmblks = 1;
      ip->mb = mb;
      ip->pmb = ((mb0+mu-1)/mu)*mu;
   }
   else if (!mb0)
   {
      ip->nfmblks = nmblks;
      ip->npmblks = 0;
      ip->pmb = ip->mb = mb;
   }
   else  /* M%mb <= mu */
   {
      ip->nfmblks = 1;
      ip->npmblks = (nmblks) ? nmblks-1 : 0;
      ip->mb = mb+mu;
      ip->pmb = mb;
   }
   nb0 = N - nnblks * nb;
   if (nb0 > nu)
   {
      ip->nfnblks = nnblks;
      ip->npnblks = 1;
      ip->nb = nb;
      ip->pnb = ((nb0+nu-1)/nu)*nu;
   }
   else if (!nb0)
   {
      ip->nfnblks = nnblks;
      ip->npnblks = 0;
      ip->pnb = ip->nb = nb;
   }
   else  /* N%nb <= nu */
   {
      ip->nfnblks = 1;
      ip->npnblks = (nnblks) ? nnblks-1 : 0;
      ip->nb = nb+nu;
      ip->pnb = nb;
   }
   return(ik);
}
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ ATL_GetRankKInfo
int Mjoin(PATL,@(sh)GetAmmmIndx)(size_t M, size_t N, size_t K)
{
   int idx=ATL_@(sh)AMM_NCASES-1;
/*
 * This shouldn't happen, but allow for debugging.
 */
/* return(0); */
   if (K < ATL_@(sh)AMM_LASTKB)
   {
      for (idx=0; ATL_AMM_KBs[idx] < K; idx++);
      ATL_assert(ATL_AMM_KBs[idx] == K);
   }
   else if (M <= ATL_@(sh)AMM_LASTMB && N <= ATL_@(sh)AMM_LASTNB) 
   {  /* inner product */
      size_t NN, MM;
      int i, nu, mu;
      double mfB;
      mu = ATL_AMM_MUs[idx];
      nu = ATL_AMM_NUs[idx];
      MM = ((M+mu-1)/mu)*mu;
      NN = ((N+nu-1)/nu)*nu;
      mfB = (((double)(NN))*MM) / (((double)(NN-N))*(MM-M));
      mfB *= ATL_@(sh)AMM_PERF[idx];
      for (i=idx-1; i >=0; i++)
      {
         double mf, scal;
         mf = ATL_@(sh)AMM_PERF[i];
         if (mf <= mfB)
            break;
         mu = ATL_AMM_MUs[idx];
         nu = ATL_AMM_NUs[i];
         MM = ((M+mu-1)/mu)*mu;
         NN = ((N+nu-1)/nu)*nu;
         scal = (((double)(NN))*MM) / (((double)(NN-N))*(MM-M));
         mf *= scal;
         if (mf > mfB)
         {
            idx = i;
            mfB = mf;
         }
      }
   }
   else if (N <= ATL_@(sh)AMM_LASTNB)  /* only one col panel */
   {
      size_t NN;
      int i, nu;
      double mfB;
      nu = ATL_AMM_NUs[idx];
      NN = ((N+nu-1)/nu)*nu;
      mfB = (double)(NN) / (double)(NN-N);
      mfB *= ATL_@(sh)AMM_PERF[idx];
      for (i=idx-1; i >=0; i++)
      {
         double mf, scal;
         mf = ATL_@(sh)AMM_PERF[i];
         if (mf <= mfB)
            break;
         nu = ATL_AMM_NUs[i];
         NN = ((N+nu-1)/nu)*nu;
         scal = (double)(NN) / (double)(NN-N);
         mf *= scal;
         if (mf > mfB)
         {
            idx = i;
            mfB = mf;
         }
      }
   }
   else /* no degenerate dim */
   {    /* for now, just return max case, tune for cleanup later */
   }
   #ifdef DEBUG
      printf("idx=%d, B=(%d,%d,%d)\n", idx, 
             ATL_AMM_MBs[idx], ATL_AMM_NBs[idx], ATL_AMM_KBs[idx]);
   #endif
   return(idx);
}
@ROUT ATL_GetAmmmInfoSQ `@define mb @nb@`
@ROUT ATL_GetAmmmInfo `@define mb @mb@`
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
void Mjoin(PATL,@(sh)FillInIPInfo)
(
   ipinfo_t *ip,        /* output */
   int idx,             /* what amm kernel index to use */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   size_t M, 
   size_t N, 
   size_t K, 
   size_t lda,
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta,
@ROUT ATL_GetAmmmInfo
   size_t nfmblks,
   size_t npmblks,
   ATL_UINT mb,
   ATL_UINT pmb,
   size_t nfnblks,
   size_t npnblks,
   ATL_UINT nb,
   ATL_UINT pnb
@ROUT ATL_GetAmmmInfoSQ
   ATL_UINT nb
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
)
{
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      #define CONE ATL_rone
   #endif
   ATL_UINT vlen, mu, nu, ku, kb, nkblks, KB0, kb0, szC;

   ip->mu = mu = ATL_AMM_MUs[idx];
   ip->nu = nu = ATL_AMM_NUs[idx];
   ip->ku = ku = ATL_AMM_KUs[idx];
   ip->kb = kb = ATL_AMM_KBs[idx];
   ip->vlen = vlen = ATL_AMM_VLENs[idx];
   ip->lda = lda;
   ip->ldb = ldb;
   ip->ldc = ldc;

@ROUT ATL_GetAmmmInfo
   ip->mb = mb;
   ip->pmb = pmb;
   ip->nmu = mb / mu;
   ip->pnmu = pmb / mu;
   if (npmblks)
      ip->mF = M - nfmblks*mb - (npmblks-1)*pmb;
   else
      ip->mF = M - (nfmblks-1)*mb;
   ip->nmuF = (ip->mF+mu-1) / mu;

   ip->nb = nb;
   ip->pnb = pnb;
   ip->nnu = nb / nu;
   ip->pnnu = pnb / nu;
   if (npnblks)
      ip->nF = N - nfnblks*nb - (npnblks-1)*pnb;
   else
      ip->nF = N - (nfnblks-1)*nb;
   ip->nnuF = (ip->nF+nu-1) / nu;
@ROUT ATL_GetAmmmInfoSQ
   ip->mF = ip->nF = ip->mb = ip->nb = nb;
   ip->nfmblks = M / nb;
   ip->nfnblks = N / nb;
   ip->nnu = nb / nu;
   ip->nmu = nb / mu;
   kb0 = M - ip->nfmblks * nb;
   if (kb0)
   {
      ip->mF = kb0;
      ip->nmuF = ip->pnmu = (kb0+mu-1) / mu;
      ip->pmb = ip->pnmu * mu;
      ip->npmblks = 1;
   }
   else
   {
      ip->nmuF = ip->nmu;
      ip->pnmu = ip->pmb = ip->npmblks = 0;
   }
   kb0 = N - ip->nfnblks * nb;
   if (kb0)
   {
      ip->nF = kb0;
      ip->nnuF = ip->pnnu = (kb0+nu-1) / nu;
      ip->pnb = ip->pnnu * nu;
      ip->npnblks = 1;
   }
   else
   {
      ip->nnuF = ip->nnu;
      ip->pnnu = ip->pnb = ip->npnblks = 0;
   }

@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ

/*
 * Compute K remainder block, and how it affects kernel to use
 */
   nkblks = K / kb;
   KB0 = kb0 = K - nkblks*kb;
   ip->ammK1_b1 = ip->amm_b1 = ATL_AMM_KERN_b1[idx];
   ip->ammK1_b0 = ip->amm_b0 = ATL_AMM_KERN_b0[idx];  /* default case */
   #ifdef TCPLX
      ip->ONE = CONE;
      ip->ammK1_b1 = ip->amm_b1;
      ip->ammK1_bn = ip->amm_bn = ATL_AMM_KERN_bn[idx];
   #endif
   if (kb0)  /* K not a multiple of kb, need initial block */
   {
      if (ATL_AMM_KMAJOR(idx))
      {
         KB0 = ((kb0+vlen-1)/vlen)*vlen;
         if (KB0 != kb)
         {
            if (ATL_AMM_KRUNTIME(idx))
            {
               ATL_CUINT min=ATL_AMM_KBMINs[idx];
               if ((min && KB0 < min) || (KB0/ku)*ku != KB0)
                  ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
            }
            else
               ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
         }
      }
      else if (ATL_AMM_KRUNTIME(idx))
      {
         ATL_CUINT min=ATL_AMM_KBMINs[idx];
         if ((min && kb0 < min) || (kb0/ku)*ku != kb0 )
            ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
      }
      else if (kb0 != kb) /* compile-time K only works if kb=kb0 */
         ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];

      if (ip->ammK1_b0 != ip->amm_b0)
      {
         ip->ammK1_b1 = ATL_AMM_KERN_K1_b1[idx];
         #ifdef TCPLX
            ip->ammK1_bn = ATL_AMM_KERN_K1_bn[idx];
         #endif
      }
   }
   else
   {
      kb0 = KB0 = kb;
      nkblks--;
      ATL_assert(nkblks >= 0);
   }
   ip->KB0 = KB0;
   ip->kb0 = kb0;
   szC = ((mu*nu+vlen-1)/vlen)*vlen;
   szC *= ip->nnu * ip->nmu;
   ip->szC = szC;


   ip->alpA = ip->alpB = ip->alpC = CONE;
   if (M < N)  /* alpha goes on A or C */
   {
      if (M < K)
         ip->alpC = alpha;
      else
         ip->alpA = alpha;
   }
   else if (N < K)
      ip->alpC = alpha;
   else
      ip->alpB = alpha;
   if (SCALAR_IS_NONE(ip->alpA))
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_an[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_an[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_an[idx] : ATL_AMM_AN2BLK_an[idx];
   }
   else if (SCALAR_IS_ONE(ip->alpA))
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_a1[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_a1[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
   }
   else  /* alphaA = X */
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_aX[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_aX[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_aX[idx] : ATL_AMM_AN2BLK_aX[idx];
   }

   if (SCALAR_IS_NONE(ip->alpB))
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_an[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_an[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_an[idx] : ATL_AMM_BT2BLK_an[idx];
   }
   else if (SCALAR_IS_ONE(ip->alpB))
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_a1[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_a1[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
   }
   else  /* alphaB = X */
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_aX[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_aX[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_aX[idx] : ATL_AMM_BT2BLK_aX[idx];
   }

   if (SCALAR_IS_ONE(ip->alpC))
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_a1_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_a1_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ?
            ATL_AMM_BLK2C_a1_b0[idx] : ATL_AMM_BLK2C_a1_bX[idx];
   }
   else if (SCALAR_IS_NONE(ip->alpC))
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_an_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_an_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ?
            ATL_AMM_BLK2C_an_b0[idx] : ATL_AMM_BLK2C_an_bX[idx];
   }
   else /* alphaC = X */
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_aX_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_aX_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ?
            ATL_AMM_BLK2C_aX_b0[idx] : ATL_AMM_BLK2C_aX_bX[idx];
   }

   ip->nfkblks = nkblks;
   if (IS_COLMAJ(TA))
   {
      ip->incAk  = (kb SHIFT)*lda;
      ip->incAm  = (@(mb) SHIFT);
@ROUT ATL_GetAmmmInfo `      ip->pincAm = (p@(mb) SHIFT);`
@ROUT ATL_GetAmmmInfoSQ `      ip->pincAm = 0;`
   }
   else
   {
      ip->incAk  = (kb SHIFT);
      ip->incAm  = (@(mb) SHIFT)*lda;
@ROUT ATL_GetAmmmInfo `      ip->pincAm = (p@(mb) SHIFT)*lda;`
@ROUT ATL_GetAmmmInfoSQ `      ip->pincAm = 0;`
   }
   if (IS_COLMAJ(TB))
   {
      ip->incBk  = (kb SHIFT);
      ip->incBn  = (nb SHIFT)*ldb;
@ROUT ATL_GetAmmmInfo `      ip->pincBn = (pnb SHIFT)*ldb;`
@ROUT ATL_GetAmmmInfoSQ `      ip->pincBn = 0;`
   }
   else
   {
      ip->incBk  = (kb SHIFT)*ldb;
      ip->incBn  = (nb SHIFT);
@ROUT ATL_GetAmmmInfo `      ip->pincBn = (pnb SHIFT);`
@ROUT ATL_GetAmmmInfoSQ `      ip->pincBn = 0;`
   }
   ip->szA = @(mb)*kb;
   ip->szB = kb*nb;
@ROUT ATL_GetAmmmInfoSQ
   ip->pszA = ip->pmb*kb;
   ip->pszB = kb*ip->pnb;
@ROUT ATL_GetAmmmInfo
   ip->pszA = p@(mb)*kb;
   ip->pszB = kb*pnb;
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
}
#ifndef TCPLX
   #undef ONE
#endif

@ROUT ATL_GetAmmmInfo
int Mjoin(PATL,tGetIPInfo_tMN)
   (ipinfo_t *ip, int P, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, 
    size_t M, size_t N, size_t K, const SCALAR alpha, size_t lda, size_t ldb, 
    const SCALAR beta, size_t ldc)
{
   ATL_UINT idx, mb, nb, kb, mu, nu, nkblks;
/*
 * Eventually, scope all block factors, and find best predicted perf 
 * when scoping mu/nu cleanup.  Will be imprecise since diff kerns for diff
 * blockings, but better than present.  For now, assume large M/N, so use
 * largest kern.
 */
   idx = ATL_geAMM_NCASES-1;
/*   idx = 0; */   /* just for debugging */
   kb = ATL_AMM_KBs[idx];
   mu = ATL_AMM_MUs[idx];
   mb = ((M+mu-1)/mu)*mu;
   nu = ATL_AMM_NUs[idx];
   nb = ((N+nu-1)/nu)*nu;

   Mjoin(PATL,geFillInIPInfo)(ip, idx, TA, TB, M, N, K, lda, ldb, ldc,
                              alpha, beta, 1, 0, mb, 0, 1, 0, nb, 0);
   nb = ip->nfkblks + 1;
   P = Mmin(P, nb);
   #ifdef TREAL
      ATL_assert(ip->alpC == alpha);
   #else
      ATL_assert(ip->alpC[0] == alpha[0] && ip->alpC[1] == alpha[1]);
   #endif
   return(P);
}
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
/*
 * Given a selected amm index, fill in ipinfo for using inner-product based
 * amm loops
 */
void Mjoin(PATL,@(sh)ComputeIPInfo)
(
   ipinfo_t *ip,
   int idx,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   size_t M, 
   size_t N, 
   size_t K, 
   size_t lda,
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta 
)
{
   size_t npmblks, nmblks, npnblks, nnblks;
   ATL_UINT MB, NB, mb, nb, kb, mu, nu; 
@ROUT ATL_GetAmmmInfoSQ `   ATL_UINT U;`
   ATL_UINT maxMB=ATL_@(sh)AMM_LASTMB, maxNB=ATL_@(sh)AMM_LASTNB;

   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
@ROUT ATL_GetAmmmInfoSQ
   U = ATL_lcm(mu, nu);
   NB = nb = ATL_AMM_KBs[idx];
   Mjoin(PATL,sqFillInIPInfo)(ip, idx, TA, TB, M, N, K, lda, ldb, ldc, 
                              alpha, beta, nb);
/*
 * Eventually, we want ability to expand MB/NB past kb (kb fixed by idx)
 * when operands don't even fill L1, but don't do this now;  Some square
 * routines may need KB=MB, and then this would fail
 */
   #if 0
   if (nb*nb < ATL_L1elts)   /* one operand fits in L1 */
   {                         /* expand to fill L1 */
      if ((nb+nb)*nb < ATL_L1elts)  /* fitting A & B into L1 */
         NB = (ATL_L1elts/nb)>>1;
      else
         NB = (ATL_l1elts/nb);
   }
   #endif

@ROUT ATL_GetAmmmInfo
   mb = ATL_AMM_MBs[idx];
   nb = ATL_AMM_NBs[idx];
   kb = ATL_AMM_KBs[idx];
/*
 * Compute M and N blocking factors to use
 */
   if ((mb+nb)*kb < ATL_L1elts)  /* fitting A & B into L1 */
      maxNB = maxMB = (ATL_L1elts/kb)>>1;
   else if (nb*kb < ATL_L1elts)  /* fitting only B */
   {
      maxMB = mb;
      maxNB = ATL_L1elts / kb;
   }

   MB = ATL_CompBlkPart(M, maxMB, mb, mu, &mb, &npmblks, &nmblks);
   NB = ATL_CompBlkPart(N, maxNB, nb, nu, &nb, &npnblks, &nnblks);
   ip->npmblks = npmblks;
   ip->nfmblks = nmblks;
   ip->npnblks = npnblks;
   ip->nfnblks = nnblks;
   if (!nmblks)  /* all blks small */
      MB = mb;
   if (!nnblks) /* all blks small */
      NB = nb;
   Mjoin(PATL,@(sh)FillInIPInfo)(ip, idx, TA, TB, M, N, K, lda, ldb, ldc,
                            alpha, beta, nmblks, npmblks, MB, mb, 
                            nnblks, npnblks, NB, nb);
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
}

@beginskip
{
   ATL_UINT ku, kb, kb0, KB0, MB, NB, mb, nb, mu, nu, vlen;
   size_t k, nkblks, npmblks, nmblks, npnblks, nnblks;
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else 
      #define CONE ATL_rone
   #endif
   int szC, maxNB=ATL_@(sh)AMM_LASTNB, maxMB=ATL_@(sh)AMM_LASTMB;
   
@ROUT ATL_GetAmmmInfoSQ
   ip->kb = mb = nb = kb = ATL_AMM_KBs[idx];
@ROUT ATL_GetAmmmInfo
   mb = ATL_AMM_MBs[idx];
   nb = ATL_AMM_NBs[idx];
@skip   ip->kb = kb = ATL_AMM_KBs[idx];
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
   ip->mu = mu = ATL_AMM_MUs[idx];
   ip->nu = nu = ATL_AMM_NUs[idx];
   ip->ku = ku = ATL_AMM_KUs[idx];
   vlen = ip->vlen = ATL_AMM_VLENs[idx];
   ip->lda = lda;
   ip->ldb = ldb;
   ip->ldc = ldc;
/*
 * Compute K remainder block, and how it affects kernel to use
 */
   nkblks = K / kb;
   KB0 = kb0 = K - nkblks*kb;
   ip->amm_b1 = ATL_AMM_KERN_b1[idx];
   ip->ammK1_b0 = ATL_AMM_KERN_b0[idx];  /* default case */
   #ifdef TCPLX
      ip->ONE = CONE;
      ip->amm_b0 = ip->ammK1_b0;
      ip->ammK1_b1 = ip->amm_b1;
      ip->ammK1_bn = ip->amm_bn = ATL_AMM_KERN_bn[idx];
   #endif
   if (kb0)  /* K not a multiple of kb, need initial block */
   {
      if (ATL_AMM_KMAJOR(idx))
      {
         KB0 = ((kb0+vlen-1)/vlen)*vlen;
         if (KB0 != kb)
         {
            if (ATL_AMM_KRUNTIME(idx))
            {
               ATL_CUINT min=ATL_AMM_KBMINs[idx];
               if ((min && KB0 < min) || (KB0/ku)*ku != KB0)
                  ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
            }
            else
               ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
         }
      }
      else if (ATL_AMM_KRUNTIME(idx))
      {
         ATL_CUINT min=ATL_AMM_KBMINs[idx];
         if ((min && kb0 < min) || (kb0/ku)*ku != kb0 )
            ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
      }
      else if (kb0 != kb) /* compile-time K only works if kb=kb0 */
         ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];

   #ifdef TCPLX
      if (ip->ammK1_b0 != ip->amm_b0)
      {
         ip->ammK1_b1 = ATL_AMM_KERN_K1_b1[idx];
         ip->ammK1_bn = ATL_AMM_KERN_K1_bn[idx];
      }
   #endif
   }
   else
   {
      kb0 = KB0 = kb;
      nkblks--;
      ATL_assert(nkblks >= 0);
   }
   ip->KB0 = KB0;
   ip->kb0 = kb0;
/*
 * Compute M and N blocking factors to use
 */
   if ((mb+nb)*kb < ATL_L1elts)  /* fitting A & B into L1 */
      maxNB = maxMB = (ATL_L1elts/kb)>>1;
   else if (nb*kb < ATL_L1elts)  /* fitting only B */
   {
      maxMB = mb;
      maxNB = ATL_L1elts / kb;
   }

@ROUT ATL_GetAmmmInfoSQ
   if (!M)      /* requires N=M  (SYRK/SYR2K) */
   {
      if (mu == nu)
      {
         MB = NB = ATL_CompBlkPart(N, maxNB, nb, nu, &nb, &npnblks, &nnblks);
         npmblks = npnblks;
         nmblks = nnblks;
      }
      else
      {
         NB = nb;
         nnblks = (N/nb);
         nb = N - nnblks*nb;
         npnblks = (nb) ? 1 : 0;
      }
   }
   else if (!K) /* requires N=K  (TRSM/TRMM/SYMM, 'Right' */
   {
      MB = ATL_CompBlkPart(M, maxMB, mb, mu, &mb, &npmblks, &nmblks);
      npnblks = (kb0 != kb);
      nnblks = nkblks + 1 - npnblks;
      NB = kb;
      nb = kb0;
   }
   else if (!N) /* requires M=K  (TRSM/TRMM/SYMM, 'Left' */
   {
      NB = ATL_CompBlkPart(N, maxNB, nb, nu, &nb, &npnblks, &nnblks);
      npmblks = (kb0 != kb);
      nmblks = nkblks + 1 - npmblks;
      MB = kb;
      mb = kb0;
   }
@ROUT ATL_GetAmmmInfo
   MB = ATL_CompBlkPart(M, maxMB, mb, mu, &mb, &npmblks, &nmblks);
   NB = ATL_CompBlkPart(N, maxNB, nb, nu, &nb, &npnblks, &nnblks);
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
   ip->npmblks = npmblks;
   ip->nfmblks = nmblks;
   ip->npnblks = npnblks;
   ip->nfnblks = nnblks;
   if (!nmblks)  /* all blks small */
   {
      ip->mb = ip->pmb = MB = mb;
      ip->nmu = ip->pnmu = mb / mu;
      ip->mF = M - (npmblks-1)*mb;
   }
   else
   {
      int b;
      ip->mb  = MB;
      ip->pmb = mb;
      ip->nmu = MB / mu;
      ip->pnmu = mb / mu;
      b = (npmblks) ? mb : MB;
      ip->mF = M + b - nmblks*MB - npmblks*mb;
   }
   ip->nmuF = ((ip->mF+mu-1)/mu);
   if (!nnblks) /* all blks small */
   {
      ip->nb = ip->pnb = NB = nb;
      ip->nnu = ip->pnnu = nb / nu;
      ip->nF = N - (npnblks-1)*nb;
   }
   else
   {
      int b;
      ip->nb  = NB;
      ip->nnu = NB / nu;
      ip->pnb = nb;
      ip->pnnu = nb / nu;
      b = (npnblks) ? nb : NB;
      ip->nF = N + b - nnblks*NB - npnblks*nb;
   }
   ip->nnuF = ((ip->nF+nu-1)/nu);
   szC = ((mu*nu+vlen-1)/vlen)*vlen;
   szC *= ip->nnu * ip->nmu;
   ip->szC = szC;


   ip->alpA = ip->alpB = ip->alpC = CONE;
   if (M < N)  /* alpha goes on A or C */
   {
      if (M < K)
         ip->alpC = alpha;
      else
         ip->alpA = alpha;
   }
   else if (N < K)
      ip->alpC = alpha;
   else 
      ip->alpB = alpha;
   if (SCALAR_IS_NONE(ip->alpA))
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_an[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_an[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ? 
            ATL_AMM_AT2BLK_an[idx] : ATL_AMM_AN2BLK_an[idx];
   }
   else if (SCALAR_IS_ONE(ip->alpA))
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_a1[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_a1[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ? 
            ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
   }
   else  /* alphaA = X */
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_aX[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_aX[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ? 
            ATL_AMM_AT2BLK_aX[idx] : ATL_AMM_AN2BLK_aX[idx];
   }

   if (SCALAR_IS_NONE(ip->alpB))
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_an[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_an[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ? 
            ATL_AMM_BN2BLK_an[idx] : ATL_AMM_BT2BLK_an[idx];
   }
   else if (SCALAR_IS_ONE(ip->alpB))
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_a1[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_a1[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ? 
            ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
   }
   else  /* alphaB = X */
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_aX[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_aX[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ? 
            ATL_AMM_BN2BLK_aX[idx] : ATL_AMM_BT2BLK_aX[idx];
   }

   if (SCALAR_IS_ONE(ip->alpC))
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_a1_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_a1_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ? 
            ATL_AMM_BLK2C_a1_b0[idx] : ATL_AMM_BLK2C_a1_bX[idx];
   }
   else if (SCALAR_IS_NONE(ip->alpC))
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_an_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_an_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ? 
            ATL_AMM_BLK2C_an_b0[idx] : ATL_AMM_BLK2C_an_bX[idx];
   }
   else /* alphaC = X */
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_aX_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_aX_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ? 
            ATL_AMM_BLK2C_aX_b0[idx] : ATL_AMM_BLK2C_aX_bX[idx];
   }

   ip->nfkblks = nkblks;
   if (IS_COLMAJ(TA))
   {
      ip->incAk  = (kb SHIFT)*lda;
      ip->incAm  = (MB SHIFT);
      ip->pincAm = (mb SHIFT);
   }
   else
   {
      ip->incAk  = (kb SHIFT);
      ip->incAm  = (MB SHIFT)*lda;
      ip->pincAm = (mb SHIFT)*lda;
   }
   if (IS_COLMAJ(TB))
   {
      ip->incBk  = (kb SHIFT);
      ip->incBn  = (NB SHIFT)*ldb;
      ip->pincBn = (nb SHIFT)*ldb;
   }
   else
   {
      ip->incBk  = (kb SHIFT)*ldb;
      ip->incBn  = (NB SHIFT);
      ip->pincBn = (nb SHIFT);
   }
   ip->pszA = mb*kb;
   ip->szA = MB*kb;
   ip->pszB = kb*nb;
   ip->szB = kb*NB;
}
#ifndef TCPLX
   #undef ONE
#endif
@endskip

@ROUT ATL_GetAmmmInfo
@beginskip
#define NOPERF 1
#include "atlas_dpmnamm_degen.h"
#undef NOPERF
static double SyrkTimeKpan
   (int id, ATL_UINT flg, size_t N, size_t K, double symul)
/* 
 * NOTE: replace symul wt timings eventually
 */
{
}

int Mjoin(PATL,GetSyrkInfo)  /* returns nb */
(
   amminfo_t *out,
   int ialp,             /* 1:alpha=1.0, -1:-1.0, else alpha=X */
   enum ATLAS_TRANS TA,
   ATL_CSZT N,           /* size of triangular matrix */
   ATL_CSZT K,           /* K dim of A/A^T */
   int ibet              /* 0:beta=0.0 1:beta=1.0, -1:-1.0, else beta=X */
)
{
   unsigned int kb, nb, idx = ATL_pmnAMM_NCASES-1, gidx;
   if (K < ATL_pmnAMM_MAXKB) /* handled by outprod view eventually */
   {                         /* for now, accept any kern that works */
      for (i=ATL_pmnAMM_NCASES-1; i >= 0; i--)
      {
         idx = i;
         if (ATL_pmnAMM_KBs[i] <= K)
            break;
      }
      kb = ATL_pmnAMM_KBs[i];
      if (N < ATL_pmnAMM_NBs[i])
      {
         unsigned int U;
         gidx = ATL_AMM_KIDX[i];
         U = ATL_lcm(ATL_AMM_MUs[gidx], ATL_AMM_MUs[gidx]);
         nb = ((N+U-1)/U)*U;
      }
   }
   else  /* choose kern to use by N, not K */
   {
      for (i=0; i < ATL_pmnAMM_NCASES;
      kb = ATL_pmnAMM_KBs[idx];
   }
}
int Mjoin(PATL,tGetSyrkInfo)
/*
 * RETURNS: bitvec: 0:use PRV ac; 1:use PUB ac,
 */
(
   amminfo_t *out,
   int ialp,             /* 1:alpha=1.0, -1:-1.0, else alpha=X */
   enum ATLAS_TRANS TA,
   ATL_CSZT N,           /* size of triangular matrix */
   ATL_CSZT K,           /* K dim of A/A^T */
   int ibet,             /* 0:beta=0.0 1:beta=1.0, -1:-1.0, else beta=X */
   int *P0,              /* number of threads to use */
   int *NKSHAR,
)
{
   unsigned int idx=ATL_pmnAMM_NCASES-1; /* not amm idx yet */
   unsigned int P=*P0, nkshar=0, i;

   if (K < ATL_pmnAMM_MAXKB) /* handled by outprod view eventually */
   {                         /* for now, accept any kern that works */
       for (i=ATL_pmnAMM_NCASES-1; i >= 0; i--)
       {
          idx = ATL_AMM_KIDX[i];
          if (ATL_pmnAMM_KBs[i] 
       }
   }
   if (P*(size_t)ATL_pmnAMM_MAXNB > N) /* N may not provide full scale */
   {
      if (P*(size_t)ATL_pmnAMM_MAXKB
   }

   *P0 = P;
   *NKSHAR = nkshar;
}
@endskip
@ROUT ATL_GetRankKInfo
@beginskip
static INLINE int ATL_ComputeB   /* RETURNS: selected blocking */
(
   size_t N,   /* problem dimension */
   int nu,     /* unrolling by kernel on this dim */
   int nb,     /* IN: large-case blocking */
   size_t *NS, /* OUT: # of blks of size NB-nu to perform */
   size_t *NT  /* OUT: # of blks to perform */
)
{
   size_t ns, nt, nblks, NN;
/*
 * If the entire problem is less than or equal to the unrolling, choose a block
 * of the ceiling of the unrolling and only do one
 */
   NN=((N+nu-1)/nu)*nu;  /* ceiling of number of unrollings in N */
   if (NN <= nu)
   {
      *NS = 0;
      *NT = 1;
      return(NN);
   }
/*
 * If suggested block size is smaller or same as unrolling, then the blocking
 * size is the unrolling, and we don't have an NB-nu sized-blocks, since that
 * would be zero sized
 */
   if (nb <= nu)
   {
      *NS = 0;
      *NT = NN/nu;
      return(nu);
   }

   nb = (nb/nu)*nu;      /* floor of number of unrollings in a block*/
/*
 * If 1 block is within NU of covering the entire dim, just make the
 * block size the entire dim
 */
   if (nb+nu >= NN)
   {
      *NS = 0;
      *NT = 1;
      return(NN);
   }
/*
 * Otherwise, compute how many blocks we need of each type
 */
   while(1)
   {
      nblks = (N+nb-1)/nb;
      ns = (nblks*nb - NN)/nu;
      if (ns < nblks)
         break;
      nb -= nu;
   }

   *NS = ns;
   *NT = nblks;
   return(nb);
}
@endskip

#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
static INLINE void FillInRankKInf
   (opinfo_t *out, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, 
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta, 
    size_t nfmblks, size_t npmblks, int mb, int pmb,
    size_t nfnblks, size_t npnblks, int nb, int pnb)
{

   #if ATL_rkAMM_MAXKVEC == 0
      const unsigned int kb = K;
   #else
      int unsigned kb = K;
   #endif
   const unsigned int mu=ATL_AMM_MUs[idx], nu=ATL_AMM_NUs[idx];
   const unsigned int ku=ATL_AMM_KUs[idx], vlen=ATL_AMM_VLENs[idx];
   unsigned int sz, nmu, nnu;
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      #define CONE ATL_rone
   #endif

   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   out->nfmblks = nfmblks;
   out->npmblks = npmblks;
   out->mb = mb;
   out->pmb = pmb;
   out->nfnblks = nfnblks;
   out->npnblks = npnblks;
   out->nb = nb;
   out->pnb = pnb;
   out->mu = mu;
   out->nu = nu;
   out->ku = ku;
   out->vlen = vlen;
   out->lda = lda;
   out->ldb = ldb;
   out->ldc = ldc;

   out->nmu = mb / mu;
   out->pnmu = pmb / mu;
   out->nnu = nb / nu;
   out->pnnu = pnb / nu;
   if (npmblks)
   {
      out->mF = M - nfmblks*mb - (npmblks-1)*pmb;
      out->nmuF = (out->mF+mu-1) / mu;
   }
   else
      out->nmuF = out->mF = 0;
   if (npnblks)
   {
      out->nF = N - nfnblks*nb - (npnblks-1)*pnb;
      out->nnuF = (out->nF+nu-1) / nu;
   }
   else
      out->nnuF = out->nF = 0;
   sz = ((mu*nu+vlen-1)/vlen)*vlen;
   sz *= (out->nmu) ? out->nmu : out->pnmu;
   sz *= (out->nnu) ? out->nnu : out->pnnu;
   out->szC = sz;
   out->idx = idx;
   out->amm_b0 = ATL_AMM_KERN_b0[idx];
   #ifdef TCPLX
      out->amm_b1 = ATL_AMM_KERN_b1[idx];
      out->amm_bn = ATL_AMM_KERN_bn[idx];
   #endif
   out->kb = K;
   out->KB = kb;
   out->lda = lda;
   out->ldb = ldb;
   out->ldc = ldc;
   out->pszA = pmb*kb;
   out->szA = kb * ((mb) ? mb:pmb);
   out->pszB = kb*pnb;
   out->szB = kb * ((nb) ? nb:pnb);
   out->alpA = out->alpB = CONE;
   out->beta = beta;
   #ifdef TCPLX
      out->ONE = CONE;
   if (TA == AtlasNoTrans || TA == AtlasConj)
   #else
   if (TA == AtlasNoTrans)
   #endif
   {
      out->incAm  = mb SHIFT;
      out->pincAm = pmb SHIFT;
   }
   else
   {
      out->incAm = lda*(mb SHIFT);
      out->pincAm = lda*(pmb SHIFT);
   }
   #ifdef TCPLX
   if (TB == AtlasNoTrans || TB == AtlasConj)
   #else
   if (TB == AtlasNoTrans)
   #endif
   {
      out->incBn = ldb*(nb SHIFT);
      out->pincBn = ldb*(pnb SHIFT);
   }
   else
   {
      out->incBn  = nb SHIFT;
      out->pincBn = pnb SHIFT;
   }
/*
 * Once we have ATL_ammmN written, put alpha on A if there's only 1 blk of
 * of B.  For now, always put on B and use ATL_ammmM
 */
   #if 0
   if (nnblks > 1 && nmblks < 2) /* If we only have row panel of C */
   {                             /* apply alpha to A */
      #ifdef TCPLX
         if (TB == AtlasNoTrans)
            out->b2blk = ATL_AMM_BN2BLK_a1[idx];
         else if (TB == AtlasTrans)
            out->b2blk = ATL_AMM_BT2BLK_a1[idx];
         else
            out->b2blk = (TB == AtlasConjTrans) ?
               ATL_AMM_BH2BLK_a1[idx] : ATL_AMM_BC2BLK_a1[idx];

         if (SCALAR_IS_ONE(alpha))
         {
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_a1[idx];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_a1[idx];
            else
               out->a2blk = (TA == AtlasConjTrans) ?
                  ATL_AMM_AC2BLK_a1[idx] : ATL_AMM_AH2BLK_a1[idx];
         }
         else if (SCALAR_IS_NONE(alpha))
         {
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_an[idx];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_an[idx];
            else
               out->a2blk = (TA == AtlasConjTrans) ?
                  ATL_AMM_AC2BLK_an[idx] : ATL_AMM_AH2BLK_an[idx];
         }
         else
         {
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_aX[idx];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_aX[idx];
            else
               out->a2blk = (TA == AtlasConjTrans) ?
                  ATL_AMM_AC2BLK_aX[idx] : ATL_AMM_AH2BLK_aX[idx];
         }
      #else
         out->b2blk = (TB == AtlasNoTrans) ?
                      ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
         if (SCALAR_IS_ONE(alpha))
            out->a2blk = (TA == AtlasNoTrans) ?
                      ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
         else if (SCALAR_IS_NONE(alpha))
            out->a2blk = (TA == AtlasNoTrans) ?
                      ATL_AMM_AT2BLK_an[idx] : ATL_AMM_AN2BLK_an[idx];
         else
            out->a2blk = (TA == AtlasNoTrans) ?
                      ATL_AMM_AT2BLK_aX[idx] : ATL_AMM_AN2BLK_aX[idx];
      #endif
   }
   else  /* apply alpha to B */
   #endif
   {
      out->alpB = alpha;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = ATL_AMM_AT2BLK_a1[idx];
         else if (TA == AtlasTrans)
            out->a2blk = ATL_AMM_AN2BLK_a1[idx];
         else
            out->a2blk = (TA == AtlasConjTrans) ?
               ATL_AMM_AC2BLK_a1[idx] : ATL_AMM_AH2BLK_a1[idx];

         if (SCALAR_IS_ONE(alpha))
         {
            if (TB == AtlasNoTrans)
               out->b2blk = ATL_AMM_BN2BLK_a1[idx];
            else if (TB == AtlasTrans)
               out->b2blk = ATL_AMM_BT2BLK_a1[idx];
            else
               out->b2blk = (TB == AtlasConjTrans) ?
                  ATL_AMM_BH2BLK_a1[idx] : ATL_AMM_BC2BLK_a1[idx];
         }
         else if (SCALAR_IS_NONE(alpha))
         {
            if (TB == AtlasNoTrans)
               out->b2blk = ATL_AMM_BN2BLK_an[idx];
            else if (TB == AtlasTrans)
               out->b2blk = ATL_AMM_BT2BLK_an[idx];
            else
               out->b2blk = (TB == AtlasConjTrans) ?
                  ATL_AMM_BH2BLK_an[idx] : ATL_AMM_BC2BLK_an[idx];
         }
         else
         {
            if (TB == AtlasNoTrans)
               out->b2blk = ATL_AMM_BN2BLK_aX[idx];
            else if (TB == AtlasTrans)
               out->b2blk = ATL_AMM_BT2BLK_aX[idx];
            else
               out->b2blk = (TB == AtlasConjTrans) ?
                  ATL_AMM_BH2BLK_aX[idx] : ATL_AMM_BC2BLK_aX[idx];
         }
      #else
         out->a2blk = (TA == AtlasNoTrans) ?
                      ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
         if (SCALAR_IS_ONE(alpha))
            out->b2blk = (TB == AtlasNoTrans) ?
                      ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
         else if (SCALAR_IS_NONE(alpha))
            out->b2blk = (TB == AtlasNoTrans) ?
                      ATL_AMM_BN2BLK_an[idx] : ATL_AMM_BT2BLK_an[idx];
         else
            out->b2blk = (TB == AtlasNoTrans) ?
                      ATL_AMM_BN2BLK_aX[idx] : ATL_AMM_BT2BLK_aX[idx];
      #endif
   }
   if (SCALAR_IS_NONE(beta))
      out->blk2C = ATL_AMM_BLK2C_a1_bn[idx];
   else if (SCALAR_IS_ONE(beta))
      out->blk2C = ATL_AMM_BLK2C_a1_b1[idx];
   else
      out->blk2C = (SCALAR_IS_ZERO(beta)) ?
         ATL_AMM_BLK2C_a1_b0[idx] : ATL_AMM_BLK2C_a1_bX[idx];
}

int Mjoin(PATL,tGetopinfo_tK)
(
   opinfo_t *out,
   int P,                   /* max number of cores to use */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   size_t lda, 
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
{
   #if ATL_rkAMM_MAXKVEC == 0
      const int kb = K;
   #else
      int kb=K;
   #endif
   ATL_UINT idx, mb, nb, MB, NB, mu, nu, ku, vlen, szC;
   size_t npmblks, nfmblks, npnblks, nfnblks;

   ATL_assert(K <= ATL_rkAMM_LASTKB && K > 2);
   idx = K-3;
   ku = ATL_AMM_KUs[idx];
   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   mb = ATL_AMM_MBs[idx];
   nb = ATL_AMM_NBs[idx];
   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
/*
 * Calculate M blocking; for now, just use default mb/nb, assume full ||
 */
   nfmblks = M / mb;
   MB = mb;
   if (nfmblks)
   {
      mb = M - nfmblks*MB;
      if (mb)
      {
         npmblks = 1;
         mb = ((mb+mu-1)/mu)*mu;
      }
      else
         npmblks = 0;
   }
   else
   {
      MB = 0;
      mb = ((M+mu-1)/mu)*mu;
      npmblks = 1;
   }
   nfnblks = N / nb;
   NB = nb;
   if (nfnblks)
   {
      nb = N - nfnblks*NB;
      if (nb)
      {
         npnblks = 1;
         nb = ((nb+nu-1)/nu)*nu;
      }
      else
         npnblks = 0;
   }
   else
   {
      NB = 0;
      nb = ((N+nu-1)/nu)*nu;
      npnblks = 1;
   }
   FillInRankKInf(out, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta,
                  nfmblks, npmblks, MB, mb, nfnblks, npnblks, NB, nb);
   {
      double flwant, flgot;
      size_t nblks;

      nblks = nfmblks * nfnblks;
      P = Mmin(P, nblks);
      flwant = (((double)ATL_rkAMM_66MB)*ATL_rkAMM_66NB)*ATL_rkAMM_66KB;
      flgot = ((((double)M)*N)*K);
      nblks = flgot / flwant;
      P = Mmin(P, nblks);
   }
   return(P);
}
int Mjoin(PATL,tGetopinfo_tNK)
(
   opinfo_t *out,
   int P,                   /* max number of cores to use */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   size_t lda, 
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
{
   #if ATL_rkAMM_MAXKVEC == 0
      const int kb = K;
   #else
      int kb=K;
   #endif
   ATL_UINT idx, mb, nb, MB, NB, mu, nu, ku, vlen, szC;
   size_t npmblks, nfmblks, npnblks, nfnblks;

   ATL_assert(K <= ATL_rkAMM_LASTKB && K > 2);
   idx = K-3;
   ku = ATL_AMM_KUs[idx];
   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   mb = ATL_AMM_MBs[idx];
   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
   nb = ((N+nu-1)/nu)*nu;
   if (nb != N)
   {
      NB = nfnblks = 0;
      npnblks = 1;
   }
   else
   {
      NB = nb;
      nfnblks = 1;
      nb = npnblks = 0;
   }
   nfmblks = M / mb;
   if (nfmblks < P) /* scope reducing mb for greater parallelism */
   {
      P = nfmblks;  /* for now, just reduce parallelism */
   }
   #if 0  /* don't adjust mb until initial debug is done */
/*
 * If there's enough parallelism, consider increasing mb
 */
   else if (nfmblks >= P+P && mb < ATL_rkAMM_LASTMB)
   {
      if (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts) /* keep it in L1 */
      {                                           /* if it presently fits */
         do 
         {
            mb += mu;
         }
         while (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts);
         mb -= mu;
      }
      else  /* if L1 exceeded, maximize MB to min # of times B is flushed */
         mb = ((ATL_rkAMM_LASTMB+mu-1)/mu)*mu;
   }
   #endif
   MB = mb;
   nfmblks = M / MB;
   if (nfmblks)
   {
      mb = M - nfmblks*MB;
      if (mb)
      {
         npmblks = 1;
         mb = ((mb+mu-1)/mu)*mu;
      }
      else
         npmblks = 0;
   }
   else
   {
      MB = 0;
      mb = ((M+mu-1)/mu)*mu;
      npmblks = 1;
   }
   FillInRankKInf(out, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta,
                  nfmblks, npmblks, MB, mb, nfnblks, npnblks, NB, nb);
   return(P);
}

void Mjoin(PATL,GetSyrkOP)
(
   opinfo_t *out,           /* what to use for K-cleanup */
   int flag,                /* bit 0: if set, only block & remainder */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT N,
   ATL_CSZT K,
   size_t lda, 
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
{
   size_t nfnblks, npnblks;
   int idx=K-3, mu, nu, ku, nb, pnb, pmb, kb, Umn, nr;

/*
 * if we've only got one block of C, entire problem will be done by SYRK,
 * so just return bogus info so it works
 */
   if (N < Mmin(ATL_rkAMM_LASTNB,ATL_rkAMM_LASTMB))
   {
      FillInRankKInf(out, 0, TA, TB, N, N, K, lda, lda, ldc, alpha, beta,
                     0, 1, 0, N, 0, 1, 0, N);
      return;
   }
   ATL_assert(K <= ATL_rkAMM_LASTKB && K > 2);
   ku = ATL_AMM_KUs[idx];
   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
   Umn = ATL_lcm(mu, nu);
   nb = ((K+Umn-1)/Umn)*Umn;
   if (nb > Mmin(ATL_rkAMM_LASTNB,ATL_rkAMM_LASTMB) && nb > Umn)
      nb -= Umn;
   nfnblks = N / nb;
   nr = N - nfnblks*nb;
   if (nr)
   {
      npnblks = 1;
      pmb = ((nr+mu-1)/mu)*mu;
      pnb = ((nr+nu-1)/nu)*nu;
   }
   else 
      pmb = pnb = npnblks = 0;
   FillInRankKInf(out, idx, TA, TB, N, N, K, lda, lda, ldc, alpha, beta,
                  nfnblks, npnblks, nb, pmb, nfnblks, npnblks, nb, pnb);
}
void Mjoin(PATL,GetRKInfo)
(
   opinfo_t *out,           /* what to use for K-cleanup */
   int flag,                /* bit 0: if set, only block & remainder */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   size_t lda, 
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
{
   #if ATL_rkAMM_MAXKVEC == 0
      const int kb = K;
   #else
      int kb=K;
   #endif
   ATL_UINT idx, mb, nb, MB, NB, NMU, NNU, nmu, nnu, mu, nu, ku, vlen, szC;
   size_t npmblks, nfmblks, npnblks, nfnblks;

   ATL_assert(K <= ATL_rkAMM_LASTKB && K > 2);
   idx = K-3;
   out->ku = ku = ATL_AMM_KUs[idx];
   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   mb = ATL_AMM_MBs[idx];
   nb = ATL_AMM_NBs[idx];
   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
/*
 * If 4 operands (C, wC, A, B) all fit in L1, use small, near-square shapes.
 * otherwise, use MB/NB from largest KB, which we know fits in some level
 * of cache.  Using larger M/N will tend to minimize function call overhead,
 * and shouldn't have much negative effect once L1 is overflowed.
 */
   if (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts)
   {
      MB = mb;
      NB = nb;
      while (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts && (mb < M || nb < N))
      {
         MB = mb;
         NB = nb;
         if (nb >= N || (mb <= nb && mb < M))
            mb += mu;
         else if (nb < N)
            nb += nu;
      }
      nfmblks = M / MB;
      if (nfmblks)
      {
         mb = ((M - MB*nfmblks + mu-1)/mu)*mu;
         npmblks = (mb) ? 1 : 0;
      }
      else
      {
         MB = 0;
         mb = ((M+mu-1)/mu)*mu;
         npmblks = 1;
      }
      nfnblks = N / NB;
      if (nfnblks)
      {
         nb = ((N - NB*nfnblks + nu-1)/nu)*nu;
         npnblks = (nb) ? 1 : 0;
      }
      else
      {
         NB = 0;
         nb = ((N+nu-1)/nu)*nu;
         npnblks = 1;
      }
   }
/*
 * If we don't fit in cache, start with assumption we'll use largest M/N blk,
 * but if the remainder block is very small, while the initial blks are large,
 * try to rebalance (if allowed by flag).
 */
   else
   {
      if (ATL_rkAMM_LASTMB > M)  /* only 1 blk in M dim */
      {
         nmu = (M+mu-1)/mu;
         mb = nmu*mu;
         if (mb == M)
         {
            MB = mb;
            nfmblks = 1;
            npmblks = mb = 0;
         }
         else
         {
            MB = nfmblks = 0;
            npmblks = 1;
         }
      }
      else                      /* at least one M blk */
      {
         NMU = ATL_rkAMM_LASTMB / mu;
         MB = NMU*mu;
         nfmblks = M / MB;
         mb = M - nfmblks*MB;
         if (mb)
         {
            int b = ATL_AMM_MBs[idx];
            nmu = (mb+mu-1)/mu;
            if (nmu < 4 && b >= nmu*mu && (flag&1)==0 && NMU > 5)
            {
               MB = ATL_CompBlkPart(M, MB, b, mu, &mb, &npmblks, &nfmblks);
               if (!npmblks && M != nfmblks*MB)
               {
                  MB = (--nfmblks) ? MB : 0;
                  npmblks = 1;
                  mb = ((M - nfmblks*MB + mu-1)/mu)*mu;
               }
            }
            else
            {
               npmblks = 1;
               mb = nmu*mu;
            }
         }
         else
            npmblks = 0;

      }
      if (ATL_rkAMM_LASTNB > N)  /* only 1 blk in N dim */
      {
         nnu = (N+nu-1)/nu;
         nb = nnu*nu;
         if (nb == N)
         {
            NB = nb;
            nfnblks = 1;
            npnblks = nb = 0;
         }
         else
         {
            NB = nfnblks = 0;
            npnblks = 1;
         }
      }
      else                      /* at least one M blk */
      {
         NNU = ATL_rkAMM_LASTNB / nu;
         NB = NNU*nu;
         nfnblks = N / NB;
         nb = N - nfnblks*NB;
         if (nb)
         {
            int b = ATL_AMM_NBs[idx];
            nnu = (nb+nu-1)/nu;
            if (nnu < 4 && b >= nnu*nu && (flag&1)==0 && NNU > 5)
            {
               NB = ATL_CompBlkPart(N, NB, b, nu, &nb, &npnblks, &nfnblks);
               if (!npnblks && N != nfnblks*NB)
               {
                  NB = (--nfnblks) ? NB : 0;
                  npnblks = 1;
                  nb = ((N - nfnblks*NB + nu-1)/nu)*nu;
               }
            }
            else
            {
               npnblks = 1;
               nb = nnu*nu;
            }
         }
         else
            npnblks = 0;
      }
   }
   FillInRankKInf(out, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta, 
                  nfmblks, npmblks, MB, mb, nfnblks, npnblks, NB, nb);
@beginskip
   ATL_UINT maxMB=ATL_rkAMM_LASTMB, maxNB=ATL_rkAMM_LASTNB;
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      #define CONE ATL_rone
   #endif

   ATL_assert(K <= ATL_rkAMM_LASTKB && K > 2);
   idx = K-3;
   out->ku = ku = ATL_AMM_KUs[idx];
   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
/*
 * If 4 operands (C, wC, A, B) all fit in L1, use small, near-square shapes.
 * otherwise, use MB/NB from largest KB, which we know fits in some level
 * of cache.  Using larger M/N will tend to minimize function call overhead,
 * and shouldn't have much negative effect when in-cache.
 */
   mb = ATL_AMM_MBs[idx];
   nb = ATL_AMM_NBs[idx];
   out->mu = mu = ATL_AMM_MUs[idx];
   out->nu = nu = ATL_AMM_NUs[idx];
   if (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts)
   {
      MB = mb;
      NB = nb;
      while (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts && (mb < M || nb < N))
      {
         MB = mb;
         NB = nb;
         if (nb >= N || (mb <= nb && mb < M)) 
            mb += mu;
         else if (nb < N)
            nb += nu;
      }
   }
   else
   {
      MB = ATL_rkAMM_LASTMB;
      NB = ATL_rkAMM_LASTNB;
   }
   if (MB >= M)
   {
      mb = 0;
      npmblks = 0;
      nmblks = 1;
      NMU = (M+mu-1)/mu; 
      MB = NMU*mu;
   }
   else
   {
      NMU = MB/mu; 
      MB = NMU*mu;
      nmblks = M/MB;
      mb = M - nmblks*MB;
      if (mb)
      {
         npmblks = 1;
         nmu = (mb+mu-1)/mu;
      }
      else
         nmu = npmblks = 0;
      if (nmu < 4 && (flag&1)==0 && NMU > 4)
      {
         MB = ATL_CompBlkPart(M, maxMB, ATL_AMM_MBs[idx], mu, 
                              &mb, &npmblks, &nmblks);
         NMU = MB / mu;
         if (!nmblks)
         {
            nmblks = npmblks;
            npmblks = 0;
            MB = mb;
            nmu = NMU = mb / mu;
         }
         else
            nmu = mb / mu;
      }
      mb = nmu*mu;
   }
   out->nfmblks = nmblks;
   out->npmblks = npmblks;
   out->mb = MB;
   out->pmb = mb;
   out->nmu = NMU;
   out->pnmu = mb / mu;
   out->mF = M + ((npmblks)?mb:MB) - nmblks*MB - npmblks*mb;
   if (NB >= N)
   {
      nb = 0;
      npnblks = 0;
      nnblks = 1;
      NNU = (N+nu-1)/nu; 
      out->nF = NB = NNU*nu;
   }
   else
   {
      NNU = NB/nu; 
      NB = NNU*nu;
      nnblks = N/NB;
      nb = N - nnblks*NB;
      if (nb)
      {
         nnu = (nb+nu-1)/nu;
         npnblks = 1;
      }
      else
         nnu = npnblks = 0;
      if (nnu < 4 && (flag&1)==0 && NNU > 4)
      {
         NB = ATL_CompBlkPart(N, maxNB, ATL_AMM_NBs[idx], nu, 
                              &nb, &npnblks, &nnblks);
         NNU = NB / nu;
         if (!nnblks)
         {
            nnblks = npnblks;
            npnblks = 0;
            NB = nb;
            nnu = NNU = nb / nu;
         }
         else
            nnu = nb / nu;
      }
      nb = nnu*nu;
   }
   out->nfnblks = nnblks;
   out->npnblks = npnblks;
   out->nb = NB;
   out->pnb = nb;
   out->nnu = NNU;
   out->pnnu = nb / nu;
   out->nF = N + ((npnblks)?nb:NB) - nnblks*NB - npnblks*nb;
   out->vlen = vlen = ATL_AMM_VLENs[idx];
   szC = ((mu*nu+vlen-1)/vlen)*vlen;
   szC *= NMU*NNU;
   out->szC = szC;
   out->idx = idx;
   out->amm_b0 = ATL_AMM_KERN_b0[idx];
   #ifdef TCPLX
      out->amm_b1 = ATL_AMM_KERN_b1[idx];
      out->amm_bn = ATL_AMM_KERN_bn[idx];
   #endif
   out->kb = K;
   out->KB = kb;
   out->lda = lda;
   out->ldb = ldb;
   out->ldc = ldc;
   out->pszA = mb*kb;
   out->szA = MB*kb;
   out->pszB = kb*nb;
   out->szB = kb*NB;
   out->alpA = out->alpB = CONE;
   out->beta = beta;
   #ifdef TCPLX
   out->ONE = CONE;
   if (TA == AtlasNoTrans || TA == AtlasConj)
   #else
   if (TA == AtlasNoTrans)
   #endif
   {
      out->incAm  = MB SHIFT;
      out->pincAm = mb SHIFT;
   }
   else
   {
      out->incAm = lda*(MB SHIFT);
      out->pincAm = lda*(mb SHIFT);
   }
   #ifdef TCPLX
   if (TB == AtlasNoTrans || TB == AtlasConj)
   #else
   if (TB == AtlasNoTrans)
   #endif
   {
      out->incBn = ldb*(NB SHIFT);
      out->pincBn = ldb*(nb SHIFT);
   }
   else
   {
      out->incBn  = NB SHIFT;
      out->pincBn = nb SHIFT;
   }
/*
 * Once we have ATL_ammmN written, put alpha on A if there's only 1 blk of
 * of B.  For now, always put on B and use ATL_ammmM
 */
   #if 0
   if (nnblks > 1 && nmblks < 2) /* If we only have row panel of C */
   {                             /* apply alpha to A */
      #ifdef TCPLX
         if (TB == AtlasNoTrans)
            out->b2blk = ATL_AMM_BN2BLK_a1[idx];
         else if (TB == AtlasTrans)
            out->b2blk = ATL_AMM_BT2BLK_a1[idx];
         else
            out->b2blk = (TB == AtlasConjTrans) ?
               ATL_AMM_BH2BLK_a1[idx] : ATL_AMM_BC2BLK_a1[idx];

   @define else @@
   @multidef at NONE ONE
   @whiledef an X n 1
      @ifdef ! at
         else
      @endifdef
      @ifdef at
         @(else)if (SCALAR_IS_@(at)(alpha))
         @undef at
      @endifdef
      @undef else
      @define else @else @
         {
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_a@(an)[idx];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_a@(an)[idx];
            else
               out->a2blk = (TA == AtlasConjTrans) ?
                  ATL_AMM_AC2BLK_a@(an)[idx] : ATL_AMM_AH2BLK_a@(an)[idx];
         }
   @endwhile
   @undef else
      #else
         out->b2blk = (TB == AtlasNoTrans) ? 
                      ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
         if (SCALAR_IS_ONE(alpha))
            out->a2blk = (TA == AtlasNoTrans) ? 
                      ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
         else if (SCALAR_IS_NONE(alpha))
            out->a2blk = (TA == AtlasNoTrans) ? 
                      ATL_AMM_AT2BLK_an[idx] : ATL_AMM_AN2BLK_an[idx];
         else
            out->a2blk = (TA == AtlasNoTrans) ? 
                      ATL_AMM_AT2BLK_aX[idx] : ATL_AMM_AN2BLK_aX[idx];
      #endif
   }
   else  /* apply alpha to B */
   #endif
   {
      out->alpB = alpha;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = ATL_AMM_AT2BLK_a1[idx];
         else if (TA == AtlasTrans)
            out->a2blk = ATL_AMM_AN2BLK_a1[idx];
         else
            out->a2blk = (TA == AtlasConjTrans) ?
               ATL_AMM_AC2BLK_a1[idx] : ATL_AMM_AH2BLK_a1[idx];

   @define else @@
   @multidef at NONE ONE
   @whiledef an X n 1
      @ifdef ! at
         else
      @endifdef
      @ifdef at
         @(else)if (SCALAR_IS_@(at)(alpha))
         @undef at
      @endifdef
      @undef else
      @define else @else @
         {
            if (TB == AtlasNoTrans)
               out->b2blk = ATL_AMM_BN2BLK_a@(an)[idx];
            else if (TB == AtlasTrans)
               out->b2blk = ATL_AMM_BT2BLK_a@(an)[idx];
            else
               out->b2blk = (TB == AtlasConjTrans) ?
                  ATL_AMM_BH2BLK_a@(an)[idx] : ATL_AMM_BC2BLK_a@(an)[idx];
         }
   @endwhile
   @undef else
      #else
         out->a2blk = (TA == AtlasNoTrans) ? 
                      ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
         if (SCALAR_IS_ONE(alpha))
            out->b2blk = (TB == AtlasNoTrans) ? 
                      ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
         else if (SCALAR_IS_NONE(alpha))
            out->b2blk = (TB == AtlasNoTrans) ? 
                      ATL_AMM_BN2BLK_an[idx] : ATL_AMM_BT2BLK_an[idx];
         else
            out->b2blk = (TB == AtlasNoTrans) ? 
                      ATL_AMM_BN2BLK_aX[idx] : ATL_AMM_BT2BLK_aX[idx];
      #endif
   }
   if (SCALAR_IS_NONE(beta))
      out->blk2C = ATL_AMM_BLK2C_a1_bn[idx];
   else if (SCALAR_IS_ONE(beta))
      out->blk2C = ATL_AMM_BLK2C_a1_b1[idx];
   else
      out->blk2C = (SCALAR_IS_ZERO(beta)) ? 
         ATL_AMM_BLK2C_a1_b0[idx] : ATL_AMM_BLK2C_a1_bX[idx];
@endskip
@skip   printf("IDR=%d, B=(%d,%d,%d), U=(%d,%d,%d)\n",
@skip          idx, out->mb, out->nb, out->kb, out->mu, out->nu, ku);
}

@beginskip
void Mjoin(PATL,GetBestKBInfo)
(
   opinfo_t *out,            /* what to use for full-KB blocks */
   opinfo_t *outR,           /* what to use for K-cleanup */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   size_t lda, 
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
{
   int idx;        /* amm index to use for full kb calls */
   int idr=(-1);   /* amm index for final colpan (-1: use ger1/2) */
   int KR;         /* K%kb */
   int i;

   #if 1
   if (K <= ATL_rkAMM_LASTKB)
   {
      idx = -1;
      idr = (K > 2) ? K-3 : -1;
      KR = K;
   }
   else
   #endif
   {
      int ibest=0;
      double timB=M*N*K*ATL_rkAMM_TIME[0];
      for (i=0; i < ATL_rkAMM_NCASES; i++)
      {
         ATL_CINT kb=ATL_AMM_KBs[i], nkb=K/kb, kr=K-nkb*kb;
         ATL_CINT mb=ATL_AMM_MBs[i], nb=ATL_AMM_MBs[i], nmb=M/mb, nnb=N/nb;
         ATL_CINT mu = ATL_AMM_MUs[i], mr = M-nmb*mb;
         ATL_CINT nu = ATL_AMM_NUs[i], nr = N-nnb*nb;
         double nfcblks, tkr, tpan, tim;

         nfcblks = nmb;
         nfcblks *= nnb;
         if (kr > 2)
         {
            idr = kr-3;
            tkr = ATL_rkAMM_TIME[idr];
            tkr /= ((double)ATL_AMM_KBs[idr])*ATL_AMM_MBs[idr]*ATL_AMM_KBs[idr];
            tkr *= ((double)mb)*nb*kb;
         }
         else if (!kr)
         {
            idr = -2;
            tkr = 0.0;
         }
/*
 *       Strongly penalize kr==1,2, since they require double write of C
 */
         else
         {
            if (kr == 1)
               tkr = ATL_rkAMM_TIME[0] * 8.0;
            else 
               tkr = ATL_rkAMM_TIME[0] * 6.0;
            tkr *= (0.015625*mb)*nb*kb;  /* b^3/4^3 */
         }
         tpan = nkb*ATL_rkAMM_TIME[i] + tkr;
         tim = nfcblks*tpan;
/*
 *       Rank-K perf not much affected by MB, so M cleanup only reduced
 *       by extra computation
 */
         if (mr)
            tim += nmb*tpan*mr / (double)mb;
#if 1
/*
 *       Small N drastically affects rank-K perf, so estimate it's speed
 *       as being equal to the mininum of rank-K or rank-nr
 *       We ignore kr for this, shouldn't be a big deal.
 */
         if (nr)
         {
            if (nr < K)
            {
               const int kk = (nr >= 3) ? nr-3 : 0;
               double tpe = ATL_rkAMM_TIME[kk];        /* time per element */
               tpe /= ((double)ATL_AMM_MBs[kk])*ATL_AMM_NBs[kk]*ATL_AMM_KBs[kk];
               tpe *= ((double)mb)*nr*kb;
               tim += tpe*nmb;
            }
            else
               tim += tpan;
         }
#endif
         if (tim < timB)
         {
            timB = tim;
            ibest = i;
            KR = kr;
         }
      }
#if 0
      ibest = 1;
      KR = K%4;
#elif 0
      ibest = 17;
      KR = K%20;
#endif
      idx = ibest;
      if (KR > 2)
         idr = KR-3;
      else
         idr = (KR == 0) ? -2 : -1;
   }
   out->idx = idx;
   if (idx != -1)
      FillInRankKInf(out, idx, TA, TB, M, N, K, lda, ldb, ldc,alpha,beta,0,0);
   outR->idx = idr;
   if (idr != -2)
   {
      const int mu=out->mu, nu=out->nu;
      int GOLOOK=(idr == -1);  /* should we look for kern wt same MU/NU? */

      if (!GOLOOK)
         GOLOOK = (mu != ATL_AMM_MUs[idr] || nu != ATL_AMM_NUs[idr]);
/*
 *    If present K-clean candidate doesn't have same C format, search
 *    for one that does
 */
      if (idx != -1 && GOLOOK)
      {
         int kbmin = ATL_AMM_KBMINs[idx];
/*
 *       See if present kernel can perform K-cleanup itself
 */
         if (ATL_AMM_KRUNTIME(idx) && ATL_AMM_KBMINs[idx] <= KR)
            idr = idx;
/*
 *       Look thru all avail kerns for one that matches MU/NU & can handle KR
 */
         else
         {
            int nidr=(-1);
            for (i=0; i < ATL_rkAMM_NCASES; i++)
            {
               if (ATL_AMM_KRUNTIME(i) && ATL_AMM_KBMINs[i] <= KR)
               {
                  nidr = i;
                  if (!ATL_AMM_KMAJOR(i)) /* K-vect kerns slow for small KR */
                     break;               /* so only quit if not K-vect */
               }
            }
/*
 *          May later want to search thru sq/ge KClean kerns for matching kerns.
 *          This will complicate things slighly, since the idx will be for
 *          the wrong header files.  For now, call present search OK
 */
            #if 0
            if (nidr == -1)
            {
               nidr = sqFindrkKClean(outR, mu, nu, KR);
               if (nidr == -1)
                  nidr = geFindrkKClean(outR, mu, nu, KR);
            }
            #endif
            if (nidr != -1)
               idr = nidr;
         }
      }
      if (idr >= 0)
      {
/*
 *       If we want to use this, will need to change amminstall to ensure
 *       this.  For now, simply assert it so we can assume compatible C
 */
         if (idx > 0)
         {
            FillInRankKInf(outR, idr, TA, TB, M, N, KR, lda, ldb, ldc, 
                           alpha, beta, out->mb, out->nb);
            ATL_assert(outR->mu == mu && outR->nu == nu);
         }
         else
            FillInRankKInf(outR, idr, TA, TB, M, N, KR, lda, ldb, ldc, 
                           alpha, beta, 0, 0);
      }
   }
   if (idx >= 0)
      printf("IDX=%d, B=(%d,%d,%d), U=(%d,%d,%d)\n",
             idx, out->mb, out->nb, out->kb, out->mu, out->nu, out->ku);
   else
      printf("IDX=%d\n", idx);
   if (idr >= 0)
      printf("IDR=%d, B=(%d,%d,%d), U=(%d,%d,%d)\n",
             idr, outR->mb, outR->nb, outR->kb, outR->mu, outR->nu, outR->ku);
   else
      printf("IDR=%d\n", idr);
}
@endskip

@ROUT ATL_GetRankKInfo0000 
/*
 * This function provides an estimate on max number of threads to use to
 * perform a rank-K update.
 */
size_t GetRankKNthr(ATL_CSZT M, ATL_CSZT N, ATL_CSZT K)
{
   size_t nnblks=N/ATL_rkAMM_LASTNB, nmblks=M/ATL_rkAMM_LASTMB;
/*
 * For degenerate cases, require 32 blocks to pay for parallel overhead
 */
   if (N <= ATL_rkAMM_LASTNB)
      return(nmblks>>5);
   if (M <= ATL_rkAMM_LASTMB)
      return(nnblks>>5);
/*
 * In general case, rank-K is bus noisy, so ask that all threads have at least
 * 4 big blocks of C.  On some systems where memory scales poorly this will
 * vastly overestimate, and will underestimate on very good scaling, but
 * very good memory scaling should only occur for low number of cores, where
 * this won't hurt.
 */
   return((nnblks*nmblks)>>2);
}
@ROUT ATL_GetAmmmInfo00
/*
 * This function provides an estimate on max number of threads to use to
 * perform a access-major GEMM.
 */
size_t GetAmmmNthr(ATL_CSZT M, ATL_CSZT N, ATL_CSZT K)
{
   int GetRankNthr(ATL_CSZT M, ATL_CSZT N, ATL_CSZT K);
   size_t nnblks, nmblks, nkblks, p;

   nmblks = (M >= ATL_AMM_66MB) ? M/ATL_AMM_66MB : 1;
   nnblks = (N >= ATL_AMM_66NB) ? N/ATL_AMM_66NB : 1;
   nkblks = (K >= ATL_AMM_66KB) ? K/ATL_AMM_66KB : 1;
/*
 * Any shape with two degenerate dimensions causes a lot of bus traffic,
 * with very little computation to overcome threading overheads,
 * so demand at least 32 blocks before parallelizing
 */
   if ((nmblks==1 && nnblks==1) || (nmblks==1 && nkblks==1) || 
       (nnblks==1 && nkblks==1))
      return((nnblks*nmblks*nkblks)>>5)
/*
 * If it is a rank-K update, ask to have 4 big blocks of C
 */
   if (K <= ATL_rkAMM_LASTMB)
   {
      nnblks=N/ATL_rkAMM_LASTNB, nmblks=M/ATL_rkAMM_LASTMB;
      return((nnblks*nmblks)>>2);
   }
   
/*
 * By default, give everyone 32 blocks to compute; for square problems,
 * the number of blocks is cubic, so this should not meaningfully restrict
 * parallelism.
 */
   return((nmblks*nnblks*nkblks)>>5);
}
@ROUT cnbtune
#include "atlas_misc.h"
#include Mstr(Mjoin(ATLAS_PRE,geamm_blk.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_ablk2cmat.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_aX.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,geamm_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_kern.h))

static int IK=ATL_AMM_NCASES-1, MB=0, NB=0, KB=0;
#ifdef DCPLX
   static char MY_PRE='z', MY_PRE2='Z';
#elif defined(SCPLX)
   static char MY_PRE='c', MY_PRE2='C';
#elif defined(SREAL)
   static char MY_PRE='s', MY_PRE2='S';
#else
   static char MY_PRE='d', MY_PRE2='D';
#endif
/*
 * This routine overrides normal GetAmmmInfo, so we can tune kernel params
 */
int Mjoin(PATL,GetAmmmInfo)
(
   amminfo_t *out,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   int ik=IK, appAl;  /* 0:A, 1:B, 2:C */

   ATL_assert(ik >= 0 && ik < ATL_AMM_NCASES);
   while (K < ATL_AMM_KBs[ik] && ik)
      ik--;
   out->IDX = ik;
   out->mb = (MB) ? MB : ATL_AMM_MBs[ik];
   out->nb = (NB) ? NB : ATL_AMM_NBs[ik];
   out->kb = (KB) ? KB : ATL_AMM_KBs[ik];
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
/*
 * Apply alpha to smallest matrix, and use alpha/beta to pick copy routines
 */
   if (SCALAR_IS_ONE(alpha))
   {
      appAl = 0;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = ATL_AMM_AT2BLK_a1[ik];
         else if (TA == AtlasTrans)
            out->a2blk = ATL_AMM_AN2BLK_a1[ik];
         else if (TA == AtlasConjTrans)
            out->a2blk = ATL_AMM_AC2BLK_a1[ik];
         else
            out->a2blk = ATL_AMM_AH2BLK_a1[ik];
         if (TB == AtlasNoTrans)
             out->b2blk = ATL_AMM_BN2BLK_a1[ik];
         else if (TB == AtlasTrans)
             out->b2blk = ATL_AMM_BT2BLK_a1[ik];
         else if (TB == AtlasConjTrans)
             out->b2blk = ATL_AMM_BH2BLK_a1[ik];
         else
             out->b2blk = ATL_AMM_BC2BLK_a1[ik];
      #else
         out->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_a1[ik]:ATL_AMM_AN2BLK_a1[ik];
         out->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_a1[ik]:ATL_AMM_BT2BLK_a1[ik];
      #endif
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
   }
   else  /* alpha is not one */
   {
      if (M >= N)                  /* A is larger than B, put alpha on C or B */
         appAl = (M >= K) ? 1 : 2;
      else                         /* B is larger than A, put alpha on C or A */
         appAl = (N >= K) ? 0 : 2;
      if (appAl == 2)  /* apply alpha to C */
      {
         #ifdef TCPLX
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_a1[ik];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_a1[ik];
            else if (TA == AtlasConjTrans)
               out->a2blk = ATL_AMM_AC2BLK_a1[ik];
            else
               out->a2blk = ATL_AMM_AH2BLK_a1[ik];
            if (TB == AtlasNoTrans)
                out->b2blk = ATL_AMM_BN2BLK_a1[ik];
            else if (TB == AtlasTrans)
                out->b2blk = ATL_AMM_BT2BLK_a1[ik];
            else if (TB == AtlasConjTrans)
                out->b2blk = ATL_AMM_BH2BLK_a1[ik];
            else
                out->b2blk = ATL_AMM_BC2BLK_a1[ik];
         #else
            out->a2blk = (TA == AtlasNoTrans) ?
                         ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
            out->b2blk = (TB == AtlasNoTrans) ?
                         ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
         #endif
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b1[ik] : ATL_AMM_BLK2C_aX_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b0[ik] : ATL_AMM_BLK2C_aX_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bn[ik] : ATL_AMM_BLK2C_aX_bn[ik];
         else
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bX[ik] : ATL_AMM_BLK2C_aX_bX[ik];
      }
      else  /* not applying alpha to C */
      {
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
         else
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
         if (!appAl)  /* apply to alpha to A */
         {
            #ifdef TCPLX
               if (TB == AtlasNoTrans)
                   out->b2blk = ATL_AMM_BN2BLK_a1[ik];
               else if (TB == AtlasTrans)
                   out->b2blk = ATL_AMM_BT2BLK_a1[ik];
               else if (TB == AtlasConjTrans)
                   out->b2blk = ATL_AMM_BH2BLK_a1[ik];
               else
                   out->b2blk = ATL_AMM_BC2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_an[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_an[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_an[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_an[ik];
               }
               else
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_aX[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_aX[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_aX[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_aX[ik];
               }
            #else
               if (SCALAR_IS_NONE(alpha))
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_an[ik] : ATL_AMM_AN2BLK_an[ik];
               else
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_aX[ik] : ATL_AMM_AN2BLK_aX[ik];
               out->b2blk = (TB == AtlasNoTrans) ?
                            ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
            #endif
         }
         else /* apply alpha to B */
         {
            #ifdef TCPLX
               if (TA == AtlasNoTrans)
                  out->a2blk = ATL_AMM_AT2BLK_a1[ik];
               else if (TA == AtlasTrans)
                  out->a2blk = ATL_AMM_AN2BLK_a1[ik];
               else if (TA == AtlasConjTrans)
                  out->a2blk = ATL_AMM_AC2BLK_a1[ik];
               else
                  out->a2blk = ATL_AMM_AH2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_an[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_an[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_an[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_an[ik];
               }
               else
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_aX[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_aX[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_aX[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_aX[ik];
               }
            #else
               out->a2blk = (TA == AtlasNoTrans) ?
                            ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_an[ik] : ATL_AMM_BT2BLK_an[ik];
               else
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_aX[ik] : ATL_AMM_BT2BLK_aX[ik];
            #endif
         }
      }
   }
   return(appAl);
}

double time00();
double Time2Mflops(int M, int N, int K, double t0)
{
   return((((2.0*M)*N)*K) / (1000000.0*t0));
}

int FindLowerBlock(int *M, int *N, int *K)
{
   int iret=1;
   if (ATL_AMM_KRUNTIME(ATL_AMM_KFLAG[IK]) && *K > *M && *K > *N &&
       *K-ATL_AMM_KUs[IK] >=  ATL_AMM_KBMINs[IK])
      *K -= ATL_AMM_KUs[IK];
   else if (*M >= *N && *M > ATL_AMM_MUs[IK])
      *M -= ATL_AMM_MUs[IK];
   else if (*N > ATL_AMM_NUs[IK])
      *N -= ATL_AMM_NUs[IK];
   else 
      iret = 0;
   return(iret);
}

double GetMflops(ATL_CINT M, ATL_CINT N, ATL_CINT K, TYPE *A, TYPE *B, TYPE *C)
{
   double t0;
   const TYPE ONE[2] = {ATL_rone, ATL_rzero};

   t0 = time00();
   Mjoin(PATL,ammm)(AtlasNoTrans, AtlasNoTrans, M, N, K, ONE, A, M, B, K,
                    ONE, C, M);
   t0 = time00() - t0;
   return(Time2Mflops(M, N, K, t0));
}

double TuneBlocking(int M, int N, int K, TYPE *A, TYPE *B, TYPE *C, 
                    int *MB_, int *NB_, int *KB_)
{
   int mbB=ATL_AMM_MBs[IK], nbB=ATL_AMM_NBs[IK], kbB=ATL_AMM_KBs[IK];
   int mb=mbB, nb=nbB, kb=kbB, m, n, k;
   double t0, t1, mf0, mf, mfB;

   printf("\nTRYING REDUCED BLOCKING WITH INDEX=%d\n", IK);
   printf("        M       N       K  IDX   MB   NB   KB         MFLOPS\n");
   printf("   ======  ======  ======  ===  ===  ===  ===  =============\n");
   m = (M/mbB)*mbB;
   n = (N/nbB)*nbB;
   k = (K/kbB)*kbB;
   mf0 = mf = mfB = GetMflops(m, n, k, A, B, C);
   printf("  %7d %7d %7d %4d %4d %4d %4d %14.2f\n", 
          m, n, k, IK, mb, nb, kb, 4.0*mf);
   while(FindLowerBlock(&mb, &nb, &kb))
   {
      MB = mb;
      NB = nb;
      KB = kb;
      m = (M/mb)*mb;
      n = (N/nb)*nb;
      k = (K/kb)*kb;
      mf = GetMflops(m, n, k, A, B, C);
      printf("  %7d %7d %7d %4d %4d %4d %4d %14.2f\n", 
             m, n, k, IK, mb, nb, kb, 4.0*mf);
      if (mf > mfB)
      {
         mbB = mb;
         nbB = nb;
         kbB = kb;
         mfB = mf;
      }
      else if (mf*1.02 <= mfB)
         break;
   }
   printf("BEST BLOCKING: MB=%d, NB=%d, KB=%d speedup=%.3f\n", 
          mbB, nbB, kbB, (mfB/mf0));
   *MB_ = mbB;
   *NB_ = nbB;
   *KB_ = kbB;
   return(mfB);
}

int TuneIndx(int M, int N, int K, TYPE *A, TYPE *B, TYPE *C)
{
   double mfB=0.0, mf;
   int ik, iB=ATL_AMM_NCASES-1;

   printf("\n\nFINDING BEST INDEX:\n");
   printf("        M       N       K  IDX   MB   NB   KB         MFLOPS\n");
   printf("   ======  ======  ======  ===  ===  ===  ===  =============\n");
   for (ik=iB; ik >= 0; ik--)
   {
      const int mb=ATL_AMM_MBs[ik],nb=ATL_AMM_NBs[ik],kb=ATL_AMM_KBs[ik];
      const int m=(M/mb)*mb, n=(N/nb)*nb, k=(K/kb)*kb;
      IK = ik;
      mf = GetMflops(m, n, k, A, B, C);
      printf("  %7d %7d %7d %4d %4d %4d %4d %14.2f\n", 
             m, n, k, ik, mb, nb, kb, 4.0*mf);
      if (mf > mfB)
      {
         iB = ik;
         mfB = mf;
      }
      else if (ATL_AMM_KBs[ik] < 16)
         break;
   }
   printf("\nBEST INDEX=%d (%.2f)\n", iB, mfB);
   return(iB);
}

void TuneCplxNB(FILE *fpout, int M, int N, int K, TYPE *A, TYPE *B, TYPE *C)
{
   int ik, mb, nb, kb;
   double mfB;
   ik = TuneIndx(M, N, K, A, B, C);
   IK = ik;
   mfB = TuneBlocking(M, N, K, A, B, C, &mb, &nb, &kb);
   fprintf(fpout, "#ifndef ATL_%cAMM_SUM_H\n   #define ATLAS_%cAMM_SUM_H\n\n",
           MY_PRE2, MY_PRE2);
   fprintf(fpout, "   #define ATL_CAMM_MAXINDX %d\n", IK);
   fprintf(fpout, "   #define ATL_CAMM_MAXMB %d\n", mb);
   fprintf(fpout, "   #define ATL_CAMM_MAXNB %d\n", nb);
   fprintf(fpout, "   #define ATL_CAMM_MAXKB %d\n", kb);
   fprintf(fpout, "   #define ATL_CAMM_APERF %e\n", 4.0*mfB);
   fprintf(fpout, "\n#endif\n");
   fclose(fpout);
}

FILE *GetFlags(int nargs, char **args, int *M, int *N, int *K)
{
   FILE *fp=NULL;
   *K = 1200;
   *M = *N = 2000;
   if (!fp)
   {
      char nam[32];
      sprintf(nam, "res/atlas_%samm_sum.h", Mstr(PRE));
      fp = fopen(nam, "w");
      ATL_assert(fp);
   }
   return(fp);
}


int main(int nargs, char **args)
{
   void *vp;
   TYPE *A, *B, *C;
   int M, N, K;
   size_t szA, szB, szC;
   FILE *fpout;

   fpout = GetFlags(nargs, args, &M, &N, &K);
   M = ((M+ATL_geAMM_LASTMB-1)/ATL_geAMM_LASTMB)*ATL_geAMM_LASTMB;
   N = ((N+ATL_geAMM_LASTNB-1)/ATL_geAMM_LASTNB)*ATL_geAMM_LASTNB;
   K = ((K+ATL_geAMM_LASTKB-1)/ATL_geAMM_LASTKB)*ATL_geAMM_LASTKB;
   szA = M*K;
   szB = K*N;
   szC = M*N;
   vp = malloc(ATL_MulBySize(szA + szB + szC) + 3*ATL_Cachelen);
   ATL_assert(vp);
   A = ATL_AlignPtr(vp);
   B = A + szA+szA;
   B = ATL_AlignPtr(B);
   C = B + szB+szB;
   C = ATL_AlignPtr(C);
   Mjoin(PATL,zero)(szA, A, 1);
   Mjoin(PATL,zero)(szB, B, 1);
   Mjoin(PATL,zero)(szC, C, 1);
   TuneCplxNB(fpout, M, N, K, A, B, C);
   free(vp);
   return(0);
}
@ROUT ATL_GetSqMNAmmmInfo
#include "atlas_misc.h"
#include Mstr(Mjoin(ATLAS_PRE,geamm_blk.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_ablk2cmat.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_aX.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,geamm_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_kern.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_perf.h))
#include Mstr(Mjoin(ATLAS_PRE,amm_sum.h))

/*
 * Chooses good square M & N blocking; starts from size that gets 98% of
 * performance, since smaller produces less wasted flops for triangular and
 * symmetric operations, which are what usually demand square M/N blocking
 */
int Mjoin(PATL,GetSqMNAmmmInfo)
(
   amminfo_t *out,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   int ik=ATL_sqAMM_98IDX;
   int appAl;  /* 0:A, 1:B, 2:C */
/*
 * For rank-K update, choose smallest KB that contains required K
 */
   if (K < ATL_rkAMM_LASTKB)
   {
      for (ik=0; ik < ATL_AMM_NCASES && ATL_AMM_KBs[ik] < K; ik++);
   }
   out->IDX = ik;
   u = ATL_98LCMMN;
   mb = ATL_AMM_MBs[ik];
   nb = ATL_AMM_NBs[ik];
   out->kb = ATL_AMM_KBs[ik];
   if(mb != nb)
      nb = (mb > u) ? (mb/u)*u : u;
   out->mb = mb = out->nb = nb;
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
/*
 * Apply alpha to smallest matrix, and use alpha/beta to pick copy routines
 */
   if (SCALAR_IS_ONE(alpha))
   {
      appAl = 0;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = ATL_AMM_AT2BLK_a1[ik];
         else if (TA == AtlasTrans)
            out->a2blk = ATL_AMM_AN2BLK_a1[ik];
         else if (TA == AtlasConjTrans)
            out->a2blk = ATL_AMM_AC2BLK_a1[ik];
         else
            out->a2blk = ATL_AMM_AH2BLK_a1[ik];
         if (TB == AtlasNoTrans)
             out->b2blk = ATL_AMM_BN2BLK_a1[ik];
         else if (TB == AtlasTrans)
             out->b2blk = ATL_AMM_BT2BLK_a1[ik];
         else if (TB == AtlasConjTrans)
             out->b2blk = ATL_AMM_BH2BLK_a1[ik];
         else
             out->b2blk = ATL_AMM_BC2BLK_a1[ik];
      #else
         out->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_a1[ik]:ATL_AMM_AN2BLK_a1[ik];
         out->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_a1[ik]:ATL_AMM_BT2BLK_a1[ik];
      #endif
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
   }
   else  /* alpha is not one */
   {
      if (M >= N)                  /* A is larger than B, put alpha on C or B */
         appAl = (M >= K) ? 1 : 2;
      else                         /* B is larger than A, put alpha on C or A */
         appAl = (N >= K) ? 0 : 2;
      if (appAl == 2)  /* apply alpha to C */
      {
         #ifdef TCPLX
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_a1[ik];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_a1[ik];
            else if (TA == AtlasConjTrans)
               out->a2blk = ATL_AMM_AC2BLK_a1[ik];
            else
               out->a2blk = ATL_AMM_AH2BLK_a1[ik];
            if (TB == AtlasNoTrans)
                out->b2blk = ATL_AMM_BN2BLK_a1[ik];
            else if (TB == AtlasTrans)
                out->b2blk = ATL_AMM_BT2BLK_a1[ik];
            else if (TB == AtlasConjTrans)
                out->b2blk = ATL_AMM_BH2BLK_a1[ik];
            else
                out->b2blk = ATL_AMM_BC2BLK_a1[ik];
         #else
            out->a2blk = (TA == AtlasNoTrans) ?
                         ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
            out->b2blk = (TB == AtlasNoTrans) ?
                         ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
         #endif
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b1[ik] : ATL_AMM_BLK2C_aX_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b0[ik] : ATL_AMM_BLK2C_aX_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bn[ik] : ATL_AMM_BLK2C_aX_bn[ik];
         else
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bX[ik] : ATL_AMM_BLK2C_aX_bX[ik];
      }
      else  /* not applying alpha to C */
      {
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
         else
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
         if (!appAl)  /* apply to alpha to A */
         {
            #ifdef TCPLX
               if (TB == AtlasNoTrans)
                   out->b2blk = ATL_AMM_BN2BLK_a1[ik];
               else if (TB == AtlasTrans)
                   out->b2blk = ATL_AMM_BT2BLK_a1[ik];
               else if (TB == AtlasConjTrans)
                   out->b2blk = ATL_AMM_BH2BLK_a1[ik];
               else
                   out->b2blk = ATL_AMM_BC2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_an[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_an[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_an[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_an[ik];
               }
               else
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_aX[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_aX[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_aX[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_aX[ik];
               }
            #else
               if (SCALAR_IS_NONE(alpha))
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_an[ik] : ATL_AMM_AN2BLK_an[ik];
               else
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_aX[ik] : ATL_AMM_AN2BLK_aX[ik];
               out->b2blk = (TB == AtlasNoTrans) ?
                            ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
            #endif
         }
         else /* apply alpha to B */
         {
            #ifdef TCPLX
               if (TA == AtlasNoTrans)
                  out->a2blk = ATL_AMM_AT2BLK_a1[ik];
               else if (TA == AtlasTrans)
                  out->a2blk = ATL_AMM_AN2BLK_a1[ik];
               else if (TA == AtlasConjTrans)
                  out->a2blk = ATL_AMM_AC2BLK_a1[ik];
               else
                  out->a2blk = ATL_AMM_AH2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_an[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_an[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_an[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_an[ik];
               }
               else
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_aX[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_aX[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_aX[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_aX[ik];
               }
            #else
               out->a2blk = (TA == AtlasNoTrans) ?
                            ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_an[ik] : ATL_AMM_BT2BLK_an[ik];
               else
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_aX[ik] : ATL_AMM_BT2BLK_aX[ik];
            #endif
         }
      }
   }
   return(appAl);
}
@ROUT ATL_ammmN ATL_cammmN
#include "atlas_amm.h"
/*
 * This function loops only over N.  Therefore, it updates 1 row-panel
 * of C using a rank-kb update.
 * If B2blk non-NULL, copy B, else assume already available in b.
 */
void Mjoin(PATL,ammmN) /* C <= beta*C + A*B, B/C nb-wide colpan */
(
   opinfo_t *rkinf,
   int M,              /* # of cols to do */
   int mb,             /* CEIL(N/nu)*nu */
   int nmu,            /* nb/nu */
   const TYPE *a,      /* access-major kb*nb copy of B */
   TYPE *b,            /* workspace for A */
   int INCB,           /* 0: don't increment b, else do */
   TYPE *c,            /* access-major mb*nb workspace for C */
   const TYPE *B,      /* col/row-major (original) A */
   TYPE *C,            /* col-major (original) C */
   const SCALAR beta   /* scale factor for C */
)
@ROUT ATL_ammmN
{
   ammkern_t amm=rkinf->amm_b0;
   ablk2cmat_t blk2C=rkinf->blk2C;/* frm C's access-maj storage to col-maj */
   cm2am_t b2blk=rkinf->b2blk;    /* copy from row/col major A to access-maj */
   const size_t nsnblks=rkinf->nsnblks, nnblks=rkinf->nnblks;
   const size_t incBnS=rkinf->incBnS, incBn=rkinf->incBn; 
   const size_t ldb=rkinf->ldb, ldc=rkinf->ldc;
   size_t n, incC;
   ATL_CINT nu=rkinf->nu, kb=rkinf->kb, K=rkinf->K;
   ATL_INT j, nb, nnu, incb;
/*
 * Loop over small N-blks of size NNU-1
 */
   nb = rkinf->nb - nu;
   nnu = rkinf->nnu - 1;
   incC = nb * ldc;
   incb = (INCB) ? rkinf->incaS : 0;
   for (n=rkinf->N, j=0; j < nsnblks; n -= nb, j++)
   {
      TYPE *bn = b + incb;
      const int nn = Mmin(n, nb);

      if (b2blk)
      {
         b2blk(K, nn, ATL_rone, B, ldb, b);
         B += incBnS;
      }
      amm(nmu, nnu, kb, a, b, c, a, bn, c);
      if (blk2C)
      {
         blk2C(M, nn, ATL_rone, c, beta, C, ldc);
         C += incC;
      }
      b = bn;
   }
/*
 * Now, finish col-panel out by looping over full blocks
 */
   nnu++;
   nb += nu;
   incC = nb * ldc;
   incb = (INCB) ? rkinf->inca : 0;
   for (; j < nnblks; j++, n -= nb)
   {
      TYPE *bn = b + incb;
      const int nn = Mmin(n, nb);

      if (b2blk)
      {
         b2blk(K, nn, ATL_rone, B, ldb, b);
         B += incBn;
      }
      amm(nmu, nnu, kb, a, b, c, a, bn, c);
      if (blk2C)
      {
         blk2C(M, nn, ATL_rone, c, beta, C, ldc);
         C += incC;
      }
      b = bn;
   }
}
@ROUT ATL_cammmN
{
   ammkern_t amm_b0=rkinf->amm_b0, amm_b1=rkinf->amm_b1,amm_bn=rkinf->amm_bn;
   ablk2cmat_t blk2C=rkinf->blk2C;/* frm C's access-maj storage to col-maj */
   cm2am_t b2blk=rkinf->b2blk;    /* copy from row/col major A to access-maj */
   TYPE *iB=b, *iC=c, *rC;
   const TYPE *rA, *iA=a;
   const size_t nsnblks=rkinf->nsnblks, nnblks=rkinf->nnblks;
   const size_t incBnS=rkinf->incBnS, incBn=rkinf->incBn; 
   const size_t ldb=rkinf->ldb, ldc=rkinf->ldc;
   size_t n, incC;
   ATL_CINT nu=rkinf->nu, kb=rkinf->kb, K=rkinf->K;
   ATL_INT j, nb, nnu, incb;
   TYPE ONE[2] = {ATL_rone, ATL_rzero};

   rA = iA + rkinf->mb*kb;
/*
 * Loop over small N blks of size NNU-1
 */
   nb = rkinf->nb - nu;
   incC = nb * (ldc+ldc);
   rC = iC + rkinf->szC;
   nnu = rkinf->nnu - 1;
   incb = rkinf->incaS;
   for (n=rkinf->N, j=0; j < nsnblks; n -= nb, j++)
   {
      TYPE *rB = iB + incb, *bn = (INCB) ? rB + incb : iB;
      const int nn = Mmin(n, nb);

      if (b2blk)
      {
         b2blk(K, nn, ONE, B, ldb, rB, iB);
         B += incBnS;
      }
      amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, rA, bn, iC);
      if (blk2C)
      {
         blk2C(M, nn, ONE, rC, iC, beta, C, ldc);
         C += incC;
      }
      iB = bn;
   }
/*
 * Now, finish col-panel out by looping over full blocks
 */
   nb += nu;
   incC = nb * (ldc+ldc);
   nnu++;
@skip   rC = iC + mb*nb;
   incb = rkinf->inca;
   for (; j < nnblks; j++, n -= nb)
   {
      TYPE *rB = iB + incb, *bn = (INCB) ? rB + incb : iB;
      const int nn = Mmin(n, nb);

      if (b2blk)
      {
         b2blk(K, nn, ONE, B, ldb, rB, iB);
         B += incBn;
      }
      amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, rA, bn, iC);
      if (blk2C)
      {
         blk2C(M, nn, ONE, rC, iC, beta, C, ldc);
         C += incC;
      }
      iB = bn;
   }
}
@ROUT ATL_ammmM ATL_cammmM
#include "atlas_amm.h"
/*
 * This function loops only over M.  Therefore, it updates 1 column-panel
 * of C using a rank-kb update of a column-panel of A * colpan of B
 * If A2blk non-NULL, copy A, else assume already available in a.
 */
void Mjoin(PATL,ammmM) /* C <= beta*C + A*B, B/C nb-wide colpan */
(
   opinfo_t *rkinf,
   int N,              /* # of cols to do */
   int nb,             /* CEIL(N/nu)*nu */
   int nnu,            /* nb/nu */
   TYPE *a,            /* workspace for A */
   int INCA,           /* 0: don't increment a, else do */
   const TYPE *b,      /* access-major kbXnb workspace for B */
   TYPE *c,            /* access-major mbXnb workspace for C */
   const TYPE *A,      /* col/row-major (original) A */
   TYPE *C,            /* col-major (original) C */
   const SCALAR beta   /* scale factor for C */
)
@ROUT ATL_ammmM
{
   ammkern_t amm=rkinf->amm_b0;
   ablk2cmat_t blk2C=rkinf->blk2C;/* frm C's access-maj storage to col-maj */
   cm2am_t a2blk=rkinf->a2blk;    /* copy from row/col major A to access-maj */
   const size_t nsmblks=rkinf->nsmblks, nmblks=rkinf->nmblks;
   const size_t incAmS=rkinf->incAmS, incAm=rkinf->incAm; 
   const size_t lda=rkinf->lda, ldc=rkinf->ldc;
   size_t m;
   ATL_CINT mu=rkinf->mu, kb=rkinf->kb, K=rkinf->K;
   ATL_INT i, mb, nmu, inca;
/*
 * Loop over small M-blks of size NMU-1
 */
   mb = rkinf->mb - mu;
   nmu = rkinf->nmu - 1;
   inca = (INCA) ? rkinf->incaS : 0;
   for (m=rkinf->M, i=0; i < nsmblks; m -= mb, i++)
   {
      TYPE *an = a + inca;
      const int mm = Mmin(m, mb);

      if (a2blk)
      {
         a2blk(K, mm, ATL_rone, A, lda, a);
         A += incAmS;
      }
      amm(nmu, nnu, kb, a, b, c, an, b, c);
      if (blk2C)
      {
         blk2C(mm, N, ATL_rone, c, beta, C, ldc);
         C += mb;
      }
      a = an;
   }
/*
 * Now, finish col-panel out by looping over full blocks
 */
   nmu++;
   mb += mu;
   inca = (INCA) ? rkinf->inca : 0;
   for (; i < nmblks; i++, m -= mb)
   {
      TYPE *an = a + inca;
      const int mm = Mmin(m, mb);
/* fprintf(stderr, "i=%d, mm=%d\n", (int)i, (int)mm); */

      if (a2blk)
      {
         a2blk(K, mm, ATL_rone, A, lda, a);
         A += incAm;
      }
      amm(nmu, nnu, kb, a, b, c, an, b, c);
      if (blk2C)
      {
         blk2C(mm, N, ATL_rone, c, beta, C, ldc);
         C += mb;
      }
      a = an;
   }
}
@ROUT ATL_cammmM
{
   ammkern_t amm_b0=rkinf->amm_b0, amm_b1=rkinf->amm_b1,amm_bn=rkinf->amm_bn;
   ablk2cmat_t blk2C=rkinf->blk2C;/* frm C's access-maj storage to col-maj */
   cm2am_t a2blk=rkinf->a2blk;    /* copy from row/col major A to access-maj */
   TYPE *iA=a, *iC=c, *rC;
   const TYPE *rB, *iB=b;
   const size_t nsmblks=rkinf->nsmblks, nmblks=rkinf->nmblks;
   const size_t incAmS=rkinf->incAmS, incAm=rkinf->incAm; 
   const size_t lda=rkinf->lda, ldc=rkinf->ldc;
   size_t m;
   ATL_CINT mu=rkinf->mu, kb=rkinf->kb, K=rkinf->K;
   ATL_INT i, mb, mb2, nmu, inca;
   TYPE ONE[2] = {ATL_rone, ATL_rzero};

   rB = iB + rkinf->nb*kb;
/*
 * Loop over small M-blks of size NMU-1
 */
   mb = rkinf->mb - mu;
   rC = iC + mb*nb;
   mb2 = mb + mb;
   nmu = rkinf->nmu - 1;
   inca = rkinf->incaS;
   for (m=rkinf->M, i=0; i < nsmblks; m -= mb, i++)
   {
      TYPE *rA = iA + inca, *an = (INCA) ? rA + inca : iA;
      const int mm = Mmin(m, mb);

      if (a2blk)
      {
         a2blk(K, mm, ONE, A, lda, rA, iA);
         A += incAmS;
      }
      amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, an, iB, iC);
      if (blk2C)
      {
         blk2C(mm, N, ONE, rC, iC, beta, C, ldc);
         C += mb2;
      }
      iA = an;
   }
/*
 * Now, finish col-panel out by looping over full blocks
 */
   nmu++;
   mb += mu;
   rC = iC + mb*nb;
   mb2 = mb + mb;
   inca = rkinf->inca;
   for (; i < nmblks; i++, m -= mb)
   {
      TYPE *rA = iA + inca, *an = (INCA) ? rA + inca : iA;
      const int mm = Mmin(m, mb);

      if (a2blk)
      {
         a2blk(K, mm, ONE, A, lda, rA, iA);
         A += incAm;
      }
      amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, an, iB, iC);
      if (blk2C)
      {
         blk2C(mm, N, ONE, rC, iC, beta, C, ldc);
         C += mb2;
      }
      iA = an;
   }
}
@ROUT ATL_ammm_rkK
#include "atlas_amm.h"
/*
 * This routine called when 2 < K <= MAXK
 */
int Mjoin(PATL,ammm_rkK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   void *vp;
   TYPE *a, *b, *iC, *rC;
   opinfo_t op;
   size_t nnblks;
   #ifdef TCPLX
      const size_t ldc2=ldc+ldc;
   #else
      #define ldc2 ldc
   #endif
void Mjoin(PATL,opinfo)(opinfo_t *out, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta);
      

   if (K < 3)
   {
      Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
      return(0);
   }
@skip   Mjoin(PATL,GetRKInfo)(&op, 0, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta);
   Mjoin(PATL,opinfo)(&op, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta);
   nnblks = op.nfnblks + op.npnblks;
   #if 0
   printf("MB=(%d,%d), mb=(%d,%d); NB=(%d,%d), nb=(%d,%d)\n",
          op.mb, (int)op.nfmblks, op.pmb, (int)op.npmblks,
          op.nb, (int)op.nfnblks, op.pnb, (int)op.npnblks);
   #endif
/*
 *  Usual case, compute column-panel of C at a time, need workspace of
 *  1 block of B and C, and 1 col-panel of A.
 */
   if (op.nfmblks+op.npmblks != 1)
   {
      size_t sz, szA, j;
      if (nnblks > 1)
         szA = op.szA*op.nfmblks + op.pszA*op.npmblks;
      else 
         szA = op.szA;
      sz = szA + op.szC + op.szB + (op.mu<<1)*op.nu;
      vp = malloc(ATL_MulBySize(sz) + 3*ATL_Cachelen);
      if (!vp)
         return(1);
      a = ATL_AlignPtr(vp);
      b = a + (szA SHIFT);
      b = ATL_AlignPtr(b);
      iC = b + (op.szB SHIFT);
      iC = ATL_AlignPtr(iC);
      #ifdef TCPLX
         rC = iC + op.szC;
      #else
         rC = iC;
      #endif

      if (nnblks == 1)
         Mjoin(PATL,oploopsM)(&op, 0, 0, A, B, C, 0, a, b, rC, iC);
      else
      {
         for (j=0; j < nnblks; j++)
         {
            Mjoin(PATL,oploopsM)(&op, 0, j, A, B, C, 1, a, b, rC, iC);
            A = NULL;
         }
      }
   }
   else  /* only 1 block of A, traverse C row-wise */
   {
      size_t sz;
      sz = op.szA + op.szB + op.szC + op.exsz;
      vp = malloc(ATL_MulBySize(sz) + 3*ATL_Cachelen);
      if (!vp)
         return(1);
      a = ATL_AlignPtr(vp);
      b = a + (op.szA SHIFT);
      b = ATL_AlignPtr(b);
      iC = b + (op.szB SHIFT);
      iC = ATL_AlignPtr(iC);
      #ifdef TCPLX
         rC = iC + op.szC;
      #else
         rC = iC;
      #endif
      if (nnblks > 1)
         Mjoin(PATL,oploopsN)(&op, 0, 0, A, B, C, 0, a, b, rC, iC);
      else
         Mjoin(PATL,opblk)(&op, 0, 0, A, B, C, a, a, b, b, rC, iC);
   }
   free(vp);
   return(0);
}
@beginskip
{
   void *vp;
   TYPE *a, *b, *c;
   size_t szA, szB, szC, incC, incBn, nnblks, nsnblks, nmblks, nsmblks;
   opinfo_t rkinf;
   ATL_UINT kb, NOREP, mb, MB, NB, NNU, mu, nu;
   #ifdef TCPLX
      TYPE *rB;
      const size_t ldc2=ldc+ldc;
   #else
      #define ldc2 ldc
   #endif
      

   if (K < 3)
   {
      Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
      return(0);
   }
   Mjoin(PATL,GetRKInfo)(&rkinf, 0,TA, TB, M, N, K, lda, ldb, ldc, alpha, beta);

   kb = rkinf.kb;
   nnblks = rkinf.nnblks;
   nsnblks = rkinf.nsnblks;
   nmblks = rkinf.nmblks;
   nsmblks = rkinf.nsmblks;
   MB = rkinf.mb;
   NB = rkinf.nb;
   NNU = rkinf.nnu;
   mu = rkinf.mu;
   nu = rkinf.nu;
   mb = MB - mu;
   NOREP = (nnblks < 2 || nmblks < 2);
   if (NOREP)
      szA = MB*kb;
   else
      szA = (mb*kb)*nsmblks + (MB*kb)*(nmblks-nsmblks);
   szB = NB*kb;
@skip   szC = MB*NB;
   szC = rkinf.szC;
   vp = malloc(3*ATL_Cachelen + ATL_MulBySize(szA+szB+szC+2*mu*nu*rkinf.ku));
   ATL_assert(vp);
   if (!vp)
      return(1);
   a = ATL_AlignPtr(vp);
   b = a + (szA SHIFT);
   b = ATL_AlignPtr(b);
   c = b + (szB SHIFT);
   c = ATL_AlignPtr(c);

/*
 * If we have a degenerate case of 1 row-panel of C, handle that seperately
 */
   if (nmblks < 2 && nnblks > 1)
   {
      cm2am_t a2blk = rkinf.a2blk;
      size_t M=rkinf.M;
      int nmu = rkinf.nmu;

      #ifdef TCPLX
         a2blk(K, M, alpha, A, lda, a+szA, a);
      #else
         a2blk(K, M, alpha, A, lda, a);
      #endif
      if (nsmblks)
         nmu--;
      else
         mb = MB;
      Mjoin(PATL,ammmN)(&rkinf, M, mb, nmu, a, b, 0, c, B, C, beta);
   }
   else  /* usual case, work on column-panel of C at a time */
   {
      cm2am_t b2blk = rkinf.b2blk;
      size_t n, j;
      #ifdef TCPLX
         TYPE *rB = b + szB;
      #endif

      for (n=N,j=0; j < nnblks; j++)
      {
         size_t incB;
         int nmu, mb, nnu, nb, nn;
   
         if (j < nsnblks)
         {
            nb = NB-nu;
            nnu = NNU-1;
            incB = rkinf.incBnS;
         }
         else
         {
            nb = NB;
            nnu = NNU;
            incB = rkinf.incBn;
         }
         nn = Mmin(n, nb);
         #ifdef TCPLX
            b2blk(K, nn, alpha, B, ldb, rB, b);
         #else
            b2blk(K, nn, alpha, B, ldb, b);
         #endif
         B += incB;
         Mjoin(PATL,ammmM)(&rkinf, nn, nb, nnu, a, !NOREP, b, c, A, C, beta);
         rkinf.a2blk = NULL;  /* A copied fully in this 1 call */
         C += nb*ldc2;
         n -= nb;
      }
   }
   free(vp);
   return(0);
}
@endskip
#ifdef ldc2
   #undef ldc2
#endif
@ROUT ATL_ammmNKM
#include "atlas_amm.h"

static void Mjoin(PATL,ammmKM)/* computes full answer for one col-panel of C */
(                      /* by looping over both M&K */
   opinfo_t *rkinf,    /* amm info for kb-width cols */
   opinfo_t *krinf,    /* amm info for K remainder cols */
   int nb,             /* # of cols to do */
   int nnu,            /* NB/nu */
   TYPE *a,            /* workspace for A */
   ATL_CINT incam,     /* gap between blocks (>= mb*kb) */
   ATL_CINT incak,     /* 0: reuse same col of a, else a M*K in size */
   TYPE *b,            /* access-major kbXnb workspace for B */
   TYPE *c,            /* access-major mbXnb workspace for C */
   ATL_CINT inccm,     /* 0: write to C, else: write only to c */
   const TYPE *A,      /* col/row-major (original) A */
   const TYPE *B,      /* col/row-major (original) B */
   TYPE *C,            /* col-major (original) C */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   const SCALAR alpha, /* scale factor for B */
   const SCALAR beta   /* scale factor for C */
)
{
   const size_t incAk=rkinf->incAk, incBk=rkinf->incBk;
   const size_t ldb=rkinf->ldb;
   cm2am_t b2blk=rkinf->b2blk;
   ablk2cmat_t blk2c=rkinf->blk2c;
   ammkern_t amm=rkinf->amm_b0, amm_b1=rkinf->amm_b1;
   ATL_CINT idr=krinf->idx;
   ATL_CINT kb=rkinf->kb, kbL=rkinf->kbL, nfkblks=rkinf->nfkb;
   ATL_INT k, nk=rkinf->nfkb, DOPEEL=1;
   
   ATL_assert(rkinf->idx != -1);  /* don't call w/o more than 1 K block */
/*
 * The last block must be peeled to write C unless the last block is actually
 * a partial K-block, which isn't handled here anyway.  We also must peel and
 * write C if the K-block doesn't use the same C storage, which requires
 * an additional write to the original C to handle.  So, the only time we
 * don't peel an iteration is when the K-cleaner exists, and uses the 
 * the same format as the mainline K
 */
   if (kbL == 0 || idr == -1) /* no K-clean or GER/GER2 clean forces peel */
      nk--;
   else if (krinf->mu != rkinf->mu || krinf->nu != rkinf->nu)
      nk--;
   else
      DOPEEL=0;

   rkinf->blk2c = NULL;           /* don't write C out until K loop done */
   for (k=0; k < nk; k++, A += incAk, B += incBk)
   {
      b2blk(kb, nb, alpha, B, ldb, b);
      Mjoin(PATL,ammmM)(rkinf, nb, nnu, amm, a, incam, b, c, inccm, A, C, beta);
      amm = amm_b1;
      a += incak;
   }
   rkinf->blk2c = blk2c;  /* next ammmM call should write to C */
/*
 * If we peeled to write C, do that along with last full M block
 */
   if (DOPEEL)
   {
      b2blk(kb, nb, alpha, B, ldb, b);
      Mjoin(PATL,ammmM)(rkinf, nb, nnu, amm, a, incam, b, c, inccm, A, C, beta);
      a += incak;
      A += incAk;
      B += incBk;
   }
/*
 * Do we have K-cleanup to do?
 */
   if (kbL)
   {
      if (idr >= 0)  /* K cleanup uses gemm kernel */
      {
         krinf->kb = kbL;
         krinf->b2blk(kbL, nb, alpha, B, ldb, b);
         Mjoin(PATL,ammmM)(krinf, nb, nnu, krinf->amm_b1, a, incam, b, 
                           c, inccm, A, C, (DOPEEL)?ATL_rone:beta);
      }
/*
 *    If we use GER1/GER2 for cleanup, beta has already been applied above
 */
      else if (kbL == 2)  /* use GER2 to clean up */
         Mjoin(PATL,ammm_rk2)(TA, TB, M, nb, alpha, A, rkinf->lda, B, ldb, 
                              ATL_rone, C, rkinf->ldc);
      else /* kbL == 1, use GER1 */
      {
         #ifdef TCPLX
            ATL_CINT incA = (TA==AtlasNoTrans || TA==AtlasConj) ? 1:rkinf->lda;
            ATL_CINT incB = (TB==AtlasNoTrans || TB==AtlasConj) ? ldb:1;
         #else
            ATL_CINT incA = (TA==AtlasNoTrans) ? 1:rkinf->lda;
            ATL_CINT incB = (TB==AtlasNoTrans) ? ldb:1;
         #endif
         Mjoin(PATL,ger)(M, nb, alpha, A, incA, B, incB, C, rkinf->ldc);
      }
   }
}


static int ATL_ammm_rkK
(
   opinfo_t *krinf,
   ATL_CSZT N,
   const SCALAR alpha,
   const TYPE *A,
   const TYPE *B,
   TYPE *C,
   const SCALAR beta
)
{
   const size_t ldb=krinf->ldb, ldc=krinf->ldc;
   ATL_CINT NB=krinf->nb, mu=krinf->mu, MB=krinf->mb, kb=krinf->kb;
   ATL_CINT mbL=krinf->mbL, nfnb=krinf->nfnb, nnu=krinf->nnu;
   ATL_INT inca, j;
   const size_t incC=NB*ldc, incBn=krinf->incBn;
   size_t szA, szB, szC;
   cm2am_t b2blk = krinf->b2blk;
   TYPE *a, *b, *c;
   void *vp;

   if (N > NB)
   {
      szA = (MB*krinf->nfmb + krinf->MBL)*kb;
      inca = MB*kb;
   }
   else
   {
      szA = MB*kb;
      inca = 0;
   }
   szB = NB*kb;
@skip   szC = MB*NB;
   szC = krinf->szC;
   vp = malloc(3*ATL_Cachelen + ATL_MulBySize(szA+szB+szC));
   ATL_assert(vp);
   if (!vp)
      return(1);
   a = ATL_AlignPtr(vp);
   b = a + szA;
   b = ATL_AlignPtr(b);
   c = b + szB;
   c = ATL_AlignPtr(c);

   if (nfnb)
   {
      b2blk(kb, NB, alpha, B, ldb, b);
      Mjoin(PATL,ammmM)(krinf, NB, nnu, krinf->amm_b0, a, inca, b, c, 0, A, 
                        C, beta);
      krinf->a2blk = NULL;
      C += incC;
      B += incBn;
      for (j=1; j < nfnb; j++, C += incC, B += incBn)
      {
         b2blk(kb, NB, alpha, B, ldb, b);
         Mjoin(PATL,ammmM)(krinf, NB, nnu, krinf->amm_b0, a, inca, b, c, 0, A, 
                           C, beta);
      }
   }
   if (krinf->nbL)
   {
      b2blk(kb, krinf->nbL, alpha, B, ldb, b);
      Mjoin(PATL,ammmM)(krinf, krinf->nbL, krinf->nnuL, krinf->amm_b0, a, inca,
                        b, c, 0, A, C, beta);
   }
   free(vp);
}

int Mjoin(PATL,ammmNKM)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   opinfo_t kbinf, krinf;
   size_t szA, szB, szC, incak, inccm, incBn, incC;
   ATL_INT j, mb, nfmb, nb, mbL, kb, kbL, incam, nfnb, nfkb, RCPYA=0;
   ATL_INT nnu, nmblks, nkblks;
   TYPE *a, *b, *c;
   void *vp;
   void Mjoin(PATL,GetBestKBInfo)
      (opinfo_t*, opinfo_t*, enum ATLAS_TRANS, enum ATLAS_TRANS,
       ATL_CSZT, ATL_CSZT, ATL_CSZT, size_t, size_t, size_t,
       const SCALAR, const SCALAR);

   if (K < 3)
   {
      Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
      return(0);
   }
   Mjoin(PATL,GetBestKBInfo)(&kbinf, &krinf, TA, TB, M, N, K, lda, ldb, ldc,
                             alpha, beta);
   if (kbinf.idx == -1)
      return(ATL_ammm_rkK(&krinf, N, alpha, A, B, C, beta));

   mb = kbinf.mb;
   nb = kbinf.nb;
   kb = kbinf.kb;
   mbL = kbinf.mbL;
   kbL = kbinf.kbL;
   nfmb = kbinf.nfmb;
   nfnb = kbinf.nfnb;
   nfkb = kbinf.nfkb;
   nmblks = (mbL) ? nfmb+1 : nfmb;
   nkblks = (kbL) ? nfkb+1 : nfkb;
   nnu = kbinf.nnu;
   incBn = kbinf.incBn;
   incC = nb*ldc;
   if (K > kb)
   {
      inccm = mb*nb;
      szC = (nfmb*mb+kbinf.MBL)*nb;
   }
   else
   {
      szC = mb*nb;
      inccm = 0;
   }
   if (N > nb)
   {
      incam = mb*kb;        
      incak = incam*nmblks;
      szA = incak * nkblks;
   }
   else
   {
      incam = incak = 0;
      szA = mb * kb;
   }

   if (krinf.idx >= 0)
      RCPYA = krinf.a2blk != kbinf.a2blk;
   szB = kb*nb;
   vp = malloc(3*ATL_Cachelen + ATL_MulBySize(szA+szB+szC));
   ATL_assert(vp);
   a = ATL_AlignPtr(vp);
   b = a + szA;
   b = ATL_AlignPtr(b);
   c = b + szB;
   c = ATL_AlignPtr(c);
   for (j=0; j < nfnb; j++, C += incC, B += incBn)
      Mjoin(PATL,ammmKM)(&kbinf, &krinf, nb, nnu, a, incam, incak, b,
                         c, inccm, A, B, C, TA, TB, M, N, alpha, beta);
   if (kbinf.nbL)
   {
      Mjoin(PATL,ammmKM)(&kbinf, &krinf, kbinf.nbL, kbinf.nnuL, a, incam, incak,
                         b, c, inccm, A, B, C, TA, TB, M, N, alpha, beta);
   }
   free(vp);
   return(0);
}
@ROUT ATL_oploops
/*
 * These loops are used for outer product GEMM formulations, 
 * where K <= ATL_rkAMM_LASTKB.
 * 
 */
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

void Mjoin(PATL,ammPadZero)(ATL_CUINT npan, ATL_CUINT npad, ATL_CUINT szPan, 
#ifdef TCPLX
                            TYPE *rB, TYPE *iB)
#else
                            TYPE *B)
#endif
/*
 * For M- or N-vectorized kerns, zeros last npad entries in each K-panel
 */
{
   ATL_UINT k, i;
   #ifdef TCPLX
      rB += szPan - npad;
      iB += szPan - npad;
      for (k=0; k < npan; k++, rB += szPan, iB += szPan)
         for (i=0; i < npad; i++)
            rB[i] = iB[i] = ATL_rzero;
   #else
      B += szPan - npad;
      for (k=0; k < npan; k++, B += szPan)
         for (i=0; i < npad; i++)
            B[i] = ATL_rzero;
   #endif
}
/*
 * This function used primarily by threaded rank-K update cases.  It has
 * following options:
 *   If A/B i/j block can be copied by passing base A/B ptr 
 *   If rC is NULL, then do only the indicated A/B copy, w/o ammm
 *   if C is NULL, then don't copy out, else do
 */
void Mjoin(PATL,opblk)
(
   opinfo_t *op,
   size_t i,      /* which global row blk of C is being computed */
   size_t j,      /* which global column blk of C is being computed */
   const TYPE *A, /* if non-NULL, base A ptr to copy */
   const TYPE *B, /* if non-NULL, base B ptr to copy */
   TYPE *C,       /* C <- alpha * A * B + beta * C */
   TYPE *pA,      /* wrkspace for block-copied A */
   TYPE *pAn,     /* next A wrkspc to be prefetched */
   TYPE *pB,      /* wrkspace for block-copied B */
   TYPE *pBn,     /* next B wrkspc to be prefetched */
   TYPE *rC,      /* if non-NULL: ptr to real part of access-major C wrkspc */
   TYPE *iC       /* ptr to cplx portion of access-major C workspace */
)
{
   const size_t nfnblks=op->nfnblks, nnblks=nfnblks+op->npnblks;
   const size_t nfmblks=op->nfmblks, nmblks=nfmblks+op->npmblks;
   size_t m, n;
   const unsigned int szA = ((i < op->nfmblks) ? op->szA:op->pszA);
   const unsigned int szB = ((j < op->nfnblks) ? op->szB:op->pszB);
   #ifdef TCPLX
      TYPE *iA=pA, *iB=pB;
      TYPE *rA = pA + szA;
      TYPE *rB = pB + szB;
   #endif
   ATL_CUINT kb = op->KB, K=op->kb;
   ATL_UINT nb, nnu, mb, nmu;

   if (j < nfnblks)
   {
      nb = op->nb;
      nnu = op->nnu;
      n = j;
   }
   else if (j != nnblks-1)
   {
      nb = op->pnb;
      nnu = op->pnnu;
      n = nfnblks;
   }
   else
   {
      nb = op->nF;
      nnu = op->nnuF;
      n = nfnblks;
   }
   j -= n;
   if (i < nfmblks)
   {
      mb = op->mb;
      nmu = op->nmu;
      m = i;
   }
   else if (i != nmblks-1)
   {
      mb = op->pmb;
      nmu = op->pnmu;
      m = nfmblks;
   }
   else
   {
      mb = op->mF;
      nmu = op->nmuF;
      m = nfmblks;
   }
   i -= m;
   if (B)
   {
      B += op->incBn * n + op->pincBn * j;
      #ifdef TCPLX
         op->b2blk(K, nb, op->alpB, B, op->ldb, rB, iB);
      #else
         op->b2blk(K, nb, op->alpB, B, op->ldb, pB);
      #endif
   }
   if (A)
   {
      A += op->incAm * m + op->pincAm * i;
      #ifdef TCPLX
         op->a2blk(K, mb, op->alpA, A, op->lda, rA, iA);
      #else
         op->a2blk(K, mb, op->alpA, A, op->lda, pA);
      #endif
   }

   if (rC)   /* want to do matrix multiplication */
   {
      #ifdef TCPLX
         ammkern_t amm_b0=op->amm_b0, amm_b1=op->amm_b1, amm_bn=op->amm_bn;
         amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
         amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
         amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
         amm_b1(nmu, nnu, kb, iA, rB, iC, pAn, pBn, rC);
         if (C)
         {
            C += (op->nb * n + op->pnb * j)*((op->ldc)SHIFT) +
                 ((op->mb * m + op->pmb * i)SHIFT);
            op->blk2C(mb, nb, op->ONE, rC, iC, op->beta, C, op->ldc);
         }
      #else
         op->amm_b0(nmu, nnu, kb, pA, pB, rC, pAn, pBn, rC);
         if (C)
         {
            C += (op->nb * n + op->pnb * j)*(op->ldc) +
                 (op->mb * m + op->pmb * i);
            op->blk2C(mb, nb, ATL_rone, rC, op->beta, C, op->ldc);
         }
      #endif
   }
}

void Mjoin(PATL,oploopsM)
(
   opinfo_t *op,
   size_t i,      /* which global row blk of C is being computed */
   size_t j,      /* which global column blk of C is being computed */
   const TYPE *A, /* if non-NULL, portion of A to copy */
   const TYPE *B, /* if non-NULL, portion of B to copy */
   TYPE *C,       /* C <- alpha * A * B + beta * C */
   int MV,        /* 1: move a */
   TYPE *a,       /* wrkspace for block-copied A */
   TYPE *b,       /* wrkspace for block-copied B */
   TYPE *rC,      /* ptr to real portion of access-major C workspace */
   TYPE *iC       /* ptr to cplx portion of access-major C workspace */
)
{
   #ifdef TCPLX
      TYPE *iA=a, *rA, *iB=b, *rB=b+op->szB;
      const TYPE *alpA=op->alpA, *alpB=op->alpB, *beta=op->beta;
      const ammkern_t amm0=op->amm_b0, amm1=op->amm_b1, ammN=op->amm_bn;
   #else
      const ammkern_t amm=op->amm_b0;
   #endif
   const cm2am_t a2blk=op->a2blk, b2blk=op->b2blk;
   const ablk2cmat_t blk2C=op->blk2C;
   const size_t nfmblks=op->nfmblks, nmblks=op->npmblks+nfmblks, lda=op->lda;
   const size_t nfnblks=op->nfnblks, nnblks=op->npnblks+nfnblks;
   #ifndef TCPLX
      const TYPE alpA=op->alpA, alpB=op->alpB, beta=op->beta;
   #endif
   ATL_CUINT kb=op->kb, KB=op->KB;
   ATL_CUINT mu=op->mu, nu=op->nu;
   ATL_UINT nmu, mb, nnu=op->nnu, nb=op->nb;

/*
 * If needed, copy B block before starting operations
 */
   if (B)
   {
      ATL_UINT szB=op->szB;
      if (j)  /* need to increment B & C before copy */
      {
         const size_t incCn=(op->ldc)SHIFT;
         size_t nblks=Mmin(j, nfnblks);
         B += nblks * op->incBn;
         C += nblks*nb*incCn;
         if (j >= nfnblks)  /* need to switch to smaller nb */
         {
            szB = op->pszB;
            #ifdef TCPLX
               rB = iB + szB;
            #endif
            nb = op->pnb;
            nnu = op->pnnu;
            nblks = j - nfnblks;
            B += nblks*op->pincBn;
            C += nblks*nb*incCn;
         }
         else
            szB = op->szB;
      }
      if (j == nnblks-1 && j >= nfnblks)
      {
         szB = op->pszB;
         nb = op->nF;
         nnu = op->nnuF;
      }
      #ifdef TCPLX
         b2blk(kb, nb, alpB, B, op->ldb, rB, iB);
      #else
         b2blk(kb, nb, alpB, B, op->ldb, b);
      #endif
   }
   else   /* still need to inc C ptr & set nnu/nb */
   {
      size_t incBn=op->incBn, incCn=(op->ldc)SHIFT;
      size_t nblks=Mmin(j, nfnblks);
      C += nblks*nb*incCn;
      if (j >= nfnblks)  /* need to switch to smaller nb */
      {
         #ifdef TCPLX
            rB = iB + op->pszB;
         #endif
         nb = op->pnb;
         nnu = op->pnnu;
         nblks = j - nfnblks;
         C += nblks*nb*incCn;
         if (j == nnblks-1)
         {
            nb = op->nF;
            nnu = op->nnuF;
         }
      }
   }
/*
 * If present block is one of first large blocks, loop over large blks
 */
   if (i < nfmblks)
   {
      const size_t incAm = (A) ? op->incAm:0, incCm = (op->mb)SHIFT, m;
      ATL_UINT szA = op->szA;

      if (i)               /* if we need to skip some blocks */
      {                    /* Increment A/C ptrs as needed for i */
         if (A)
            A += i * incAm;   
         C += i * incCm;
      }
      #ifdef TCPLX
         rA = iA + szA;
      #endif
      nmu = op->nmu;
      mb = op->mb;
      for (; i < nfmblks; i++)
      {
         #ifdef TCPLX
            TYPE *an=iA;
         #else
            TYPE *an=a;
         #endif
@skip         mb = (i != nmblks-1) ? op->mb : op->mF;
         if (A)
         {
            #ifdef TCPLX
               a2blk(kb, mb, alpA, A, lda, rA, iA);
            #else
               a2blk(kb, mb, alpA, A, lda, a);
            #endif
            A = (nmblks != 1) ? (A+incAm) : NULL;
         }
         if (MV&1)
         #ifdef TCPLX
            an = rA + szA;
         #else
            an += szA;
         #endif
         #ifdef TCPLX
            amm0(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
            amm0(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
            ammN(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
            amm1(nmu, nnu, KB, iA, rB, iC, an, iB, iC);
            blk2C(mb, nb, op->ONE, rC, iC, beta, C, op->ldc);
            iA = an;
            rA = an + szA;
         #else
            amm(nmu, nnu, KB, a, b, rC, an, b, rC);
            blk2C(mb, nb, ATL_rone, rC, beta, C, op->ldc);
            a = an;
         #endif
         C += incCm;
      }
   }
/*
 * If present block past end of large blocks, increment A/C appropriately
 */
   else if (i && nfmblks)
   {
      if (A)
         A += nfmblks * op->incAm;
      C += nfmblks * ((op->mb)SHIFT);
   }
/*
 * If there are still small blocks to do after doing all large blocks
 */
   if (i < nmblks)
   {
      const size_t incAm = (A) ? op->pincAm:0, incCm = (op->pmb)SHIFT;
      ATL_UINT szA = op->pszA;

      if (i > nfmblks)  /* I need to move past some small blocks too */
      {
         size_t nblks = i - nfmblks;
         A += nblks * incAm;
         C += nblks * incCm;
      }
      mb = op->pmb;
      nmu = op->pnmu;
      for (; i < nmblks; i++)
      {
         #ifdef TCPLX
            TYPE *an=iA;
         #else
            TYPE *an=a;
         #endif
         if (i == nmblks-1)
         {
            mb = op->mF;
            nmu = op->nmuF;
         }
@skip         mb = (i != nmblks-1) ? mb : op->mF;
         #ifdef TCPLX
            rA = iA + szA;
         #endif
         if (A)
         {
            #ifdef TCPLX
               a2blk(kb, mb, alpA, A, lda, rA, iA);
            #else
               a2blk(kb, mb, alpA, A, lda, a);
            #endif
            A = (nmblks != 1) ? (A+incAm) : NULL;
         }
         #ifdef TCPLX
            if (MV&1)
               an = rA + szA;
            amm0(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
            amm0(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
            ammN(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
            amm1(nmu, nnu, KB, iA, rB, iC, an, iB, iC);
            blk2C(mb, nb, op->ONE, rC, iC, beta, C, op->ldc);
            iA = an;
            rA = an + szA;
         #else
            if (MV&1)
               an += szA;
            amm(nmu, nnu, KB, a, b, rC, an, b, rC);
            blk2C(mb, nb, ATL_rone, rC, beta, C, op->ldc);
            a = an;
         #endif
         C += incCm;
      }
   }
}
void Mjoin(PATL,oploopsN)
(
   opinfo_t *op,
   size_t i,      /* which global row blk of C is being computed */
   size_t j,      /* which global column blk of C is being computed */
   const TYPE *A, /* if non-NULL, portion of A to copy */
   const TYPE *B, /* if non-NULL, portion of B to copy */
   TYPE *C,       /* C <- alpha * A * B + beta * C */
   int MV,        /* 2: move b */
   TYPE *a,       /* wrkspace for block-copied A */
   TYPE *b,       /* wrkspace for block-copied B */
   TYPE *rC,      /* ptr to real portion of access-major C workspace */
   TYPE *iC       /* ptr to cplx portion of access-major C workspace */
)
{
   #ifdef TCPLX
      TYPE *iA=a, *rA=a+op->szA, *iB=b, *rB;
      const TYPE *alpA=op->alpA, *alpB=op->alpB, *beta=op->beta;
      const ammkern_t amm0=op->amm_b0, amm1=op->amm_b1, ammN=op->amm_bn;
   #else
      const ammkern_t amm=op->amm_b0;
   #endif
   const cm2am_t a2blk=op->a2blk, b2blk=op->b2blk;
   const ablk2cmat_t blk2C=op->blk2C;
   const size_t nfmblks=op->nfmblks, nmblks=op->npmblks+nfmblks, ldb=op->ldb;
   const size_t nfnblks=op->nfnblks, nnblks=op->npnblks+nfnblks, ldc=op->ldc;
   #ifndef TCPLX
      const TYPE alpA=op->alpA, alpB=op->alpB, beta=op->beta;
   #endif
   ATL_CUINT kb=op->kb, KB=op->KB;
   ATL_CUINT mu=op->mu, nu=op->nu;
   ATL_UINT nmu=op->nmu, mb=op->mb, nnu, nb, szA = op->szA;

/*
 * If needed, copy A block before starting operations
 */
   if (A)
   {
      if (i)  /* need to increment A & C before copy */
      {
         size_t nblks=Mmin(i, nfmblks);
         A += nblks * op->incAm;
         C += nblks*(mb SHIFT);
         if (i >= nfmblks)  /* need to switch to smaller mb */
         {
            szA = op->pszA;
            #ifdef TCPLX
               rA = iA + szA;
            #endif
            mb = op->pmb;
            nmu = op->pnmu;
            nblks = i - nfmblks;
            A += nblks*op->pincAm;
            C += nblks*(mb SHIFT);
         }
      }
      if (i == nmblks-1 && i >= nfmblks)
      {
         szA = op->pszA;
         mb = op->mF;
         nmu = op->nmuF;
      }
      #ifdef TCPLX
         a2blk(kb, mb, alpA, A, op->lda, rA, iA);
      #else
         a2blk(kb, mb, alpA, A, op->lda, a);
      #endif
   }
   else   /* still need to inc C ptr & set nnu/nb */
   {
      size_t nblks=Mmin(i, nfmblks);
      C += nblks*(mb SHIFT);
      if (i >= nfmblks)  /* need to switch to smaller mb */
      {
         szA = op->pszA;
         #ifdef TCPLX
            rA = iA + szA;
         #endif
         mb = op->pmb;
         nmu = op->pnmu;
         nblks = i - nfmblks;
         C += nblks*(mb SHIFT);
         if (i == nmblks-1)
         {
            mb = op->mF;
            nmu = op->nmuF;
         }
      }
   }
/*
 * If present block is one of first large blocks, loop over large blks
 */
   if (j < nfnblks)
   {
      const size_t incBn = (B) ? op->incBn:0, incCn = ldc*(op->nb)SHIFT;
      ATL_UINT szB = op->szB;
      ATL_CUINT incBw = (MV&2) ? ((szB)SHIFT):0;

      if (j)               /* if we need to skip some blocks */
      {                    /* Increment B/C ptrs as needed for j */
         if (B)
            B += j * incBn;
         C += j * incCn;
      }
      #ifdef TCPLX
         rB = iB + szB;
      #endif
      nnu = op->nnu;
      nb = op->nb;
      for (; j < nfnblks; j++)
      {
         #ifdef TCPLX
            TYPE *bn=iB+incBw;
         #else
            TYPE *bn=b+incBw;
         #endif
         if (B)
         {
            #ifdef TCPLX
               b2blk(kb, nb, alpB, B, ldb, rB, iB);
            #else
               b2blk(kb, nb, alpB, B, ldb, b);
            #endif
            B = (nnblks != 1) ? (B+incBn) : NULL;
         }
         #ifdef TCPLX
            amm0(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
            amm0(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
            ammN(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
            amm1(nmu, nnu, KB, iA, rB, iC, iA, bn, iC);
            blk2C(mb, nb, op->ONE, rC, iC, beta, C, ldc);
            iB = bn;
            rB = bn + szB;
         #else
            amm(nmu, nnu, KB, a, b, rC, a, bn, rC);
            blk2C(mb, nb, ATL_rone, rC, beta, C, ldc);
            b = bn;
         #endif
         C += incCn;
      }
   }
/*
 * If present block past end of large blocks, increment B/C appropriately
 */
   else if (j && nfnblks)
   {
      if (B)
         B += nfnblks * op->incBn;
      C += nfnblks * (op->nb * ldc)SHIFT;
   }
/*
 * If there are still small blocks to do after doing all large blocks
 */
   if (j < nnblks)
   {
      const size_t incBn = (B) ? op->pincBn:0, incCn = ldc*(op->pnb)SHIFT;
      ATL_UINT szB = op->pszB;
      ATL_CUINT incBw = (MV&2) ? ((szB)SHIFT):0;

      if (j > nfnblks)  /* I need to move past some small blocks too */
      {
         size_t nblks = j - nfnblks;
         B += nblks * incBn;
         C += nblks * incCn;
      }
      nb = op->pnb;
      nnu = op->pnnu;
      for (; j < nnblks; j++)
      {
         #ifdef TCPLX
            TYPE *bn = iB + incBw;
         #else
            TYPE *bn = b + incBw;
         #endif
         if (j == nnblks-1)
         {
            nb = op->nF;
            nnu = op->nnuF;
         }
         #ifdef TCPLX
            rB = iB + szB;
         #endif
         if (B)
         {
            #ifdef TCPLX
               b2blk(kb, nb, alpB, B, ldb, rB, iB);
            #else
               b2blk(kb, nb, alpB, B, ldb, b);
            #endif
            B = (nnblks != 1) ? (B+incBn) : NULL;
         }
         #ifdef TCPLX
            amm0(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
            amm0(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
            ammN(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
            amm1(nmu, nnu, KB, iA, rB, iC, iA, bn, iC);
            blk2C(mb, nb, op->ONE, rC, iC, beta, C, op->ldc);
            iB = bn;
            rB = bn + szB;
         #else
            amm(nmu, nnu, KB, a, b, rC, a, bn, rC);
            blk2C(mb, nb, ATL_rone, rC, beta, C, op->ldc);
            b = bn;
         #endif
         C += incCn;
      }
   }
}
@ROUT ATL_iploops ATL_ciploops
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
/*
 * A & B ptrs should point to start of K iteration in this rout
 */
void Mjoin(PATL,iploopsK)
(
   ipinfo_t *ip,
   size_t i,              /* which global row block of C is being computed */
   size_t j,              /* which global col block of C is being computed */
   const TYPE *A,         /* if non-NULL, Portion A to cpy */
   const TYPE *B,         /* if non-NULL, Portion B to cpy, else ignored */
   TYPE *C,               /* original C to write ans to at end of Kloop */
   int MV,                /* 1: move a, 2: move b, 3: move A & B */
   TYPE *a,               /* wrkspace for block-copied A */
   TYPE *b,               /* wrkspace for block-copied B */
   TYPE *rC,              /* ptr to real portion of C access-major workspace */
   TYPE *iC,              /* ptr to complex C workspace */
   const SCALAR beta,     /* scaling factor for C */
   const ablk2cmat_t blk2c   /* C = alpC*(rC,iC) + beta*C */
)
{
   cm2am_t a2blk=ip->a2blk, b2blk=ip->b2blk;
   ammkern_t amm=ip->ammK1_b0;
   ATL_CUINT kb=ip->kb, kb0=ip->kb0, KB0=ip->KB0;
   ATL_CUINT mu=ip->mu, nu=ip->nu;
   ATL_UINT nmu, nnu, mb, nb;
   const size_t nfmblks=ip->nfmblks, nfnblks=ip->nfnblks, nfkblks=ip->nfkblks;
   const size_t nmblks=ip->npmblks+nfmblks, nnblks=ip->npnblks+nfnblks;
   const size_t lda=ip->lda, ldb=ip->ldb;
   const size_t incAk=ip->incAk, incBk=ip->incBk;
   size_t inca, incb, k;
   TYPE *an, *bn;
   #ifdef TCPLX
      ammkern_t amm_bn=ip->amm_bn, amm_b1=ip->amm_b1;
      size_t cinca, cincb;
      const TYPE *alpA=ip->alpA, *alpB=ip->alpB;
   #else
      const TYPE alpA=ip->alpA, alpB=ip->alpB;
   #endif

   if (i == nmblks-1)
   {
      nmu = ip->nmuF;
      mb = ip->mF;
      inca = (i < nfmblks) ? ip->szA : ip->pszA;
   }
   else if (i < nfmblks)
   {
      nmu = ip->nmu;
      mb = ip->mb;
      inca = ip->szA;
   }
   else
   {
      nmu = ip->pnmu;
      inca = ip->pszA;
      mb = ip->pmb;
   }
   
   if (j == nnblks-1)
   {
      nnu = ip->nnuF;
      nb = ip->nF;
      incb = (j < nfnblks) ? ip->szB : ip->pszB;
   }
   else if (j < nfnblks)
   {
      nnu = ip->nnu;
      incb = ip->szB;
      nb = ip->nb;
   }
   else
   {
      nnu = ip->pnnu;
      incb = ip->pszB;
      nb = ip->pnb;
   }

#ifdef TCPLX
   cinca = inca;
   cincb = incb;
   inca = (MV&1) ? inca+inca : 0;
   incb = (MV&2) ? incb+incb : 0;
/*
 * =========================================================
 * Peel first iteration to handle K remainder and use beta=0
 * =========================================================
 */
/* 
 * If last K block of different size, take it from end of vector to avoid
 * screwing up alignment
 */
   if (kb0 != kb)
   {
      TYPE *iA, *rA, *iB, *rB;
      an = a; bn = b;
      iA = a + nfkblks*inca;
      rA = iA + cinca;
      if (A)
         a2blk(kb0, mb, alpA, A+incAk*nfkblks, lda, rA, iA);
      iB = b + nfkblks*incb;
      rB=iB+cincb;
      if (B)
         b2blk(kb0, nb, alpB, B+incBk*nfkblks, ldb, rB, iB);
      if (iC)
      {
         amm(nmu, nnu, KB0, iA, iB, rC, rA, iB, iC);
         amm(nmu, nnu, KB0, rA, iB, iC, rA, rB, rC);
         ip->ammK1_bn(nmu, nnu, KB0, rA, rB, rC, iA, rB, iC);
         ip->ammK1_b1(nmu, nnu, KB0, iA, rB, iC, an, bn, rC);
      }
   }
/*
 * Otherwise just take first block, so any hardware prefetch isn't confused
 */
   else
   {
      TYPE *iA=a, *rA=iA+cinca, *iB=b, *rB=iB+cincb;
      an=a+inca; bn=b+incb;
      if (A)
      {
         a2blk(kb0, mb, alpA, A, lda, rA, iA);
         A += incAk;
      }
      if (B)
      {
         b2blk(kb0, nb, alpB, B, ldb, rB, iB);
         B += incBk;
      }
      if (iC)
      {
         amm(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
         amm(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
         ip->ammK1_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
         ip->ammK1_b1(nmu, nnu, kb, iA, rB, iC, an, bn, rC);
      }
   }
   a = an;
   b = bn;

   for (k=0; k < nfkblks; k++)
   {
      TYPE *iA=a, *rA=iA+cinca, *iB=b, *rB=iB+cincb;
      an=a+inca; bn=b+incb;
      if (A)
      {
         a2blk(kb, mb, alpA, A, lda, rA, iA);
         A += incAk;
      }
      if (B)
      {
         b2blk(kb, nb, alpB, B, ldb, rB, iB);
         B += incBk;
      }
      an = a + inca;
      bn = b + incb;
      if (iC)
      {
         amm_bn(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
         amm_b1(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
         amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
         amm_b1(nmu, nnu, kb, iA, rB, iC, an, bn, rC);
      }

      a = an;
      b = bn;
   }
   if (blk2c)
      blk2c(mb, nb, ip->alpC, rC, iC, beta, C, ip->ldc);
#else
   if (!(MV&1))
      inca = 0;
   if (!(MV&2))
      incb = 0;
/*
 * =========================================================
 * Peel first iteration to handle K remainder and use beta=0
 * =========================================================
 */
/* 
 * If last K block of different size, take it from end of vector to avoid
 * screwing up alignment
 */
   if (kb0 != kb)
   {
      an=a; bn=b;
      a += nfkblks*inca;
      if (A)
         a2blk(kb0, mb, alpA, A+incAk*nfkblks, lda, a);
      b += nfkblks*incb;
      if (B)
         b2blk(kb0, nb, alpB, B+incBk*nfkblks, ldb, b);
      if (rC)
         amm(nmu, nnu, KB0, a, b, rC, an, bn, rC);
   }
/*
 * Otherwise just take first block, so any hardware prefetch isn't confused
 */
   else
   {
      an=a+inca; bn=b+incb;
      if (A)
      {
         a2blk(kb0, mb, alpA, A, lda, a);
         A += incAk;
      }
      if (B)
      {
         b2blk(kb0, nb, alpB, B, ldb, b);
         B += incBk;
      }
      if (rC)
         amm(nmu, nnu, KB0, a, b, rC, an, bn, rC);
   }
   amm = ip->amm_b1;
   a = an;
   b = bn;

   for (k=0; k < nfkblks; k++)
   {
      if (A)
      {
         a2blk(kb, mb, alpA, A, lda, a);
         A += incAk;
      }
      if (B)
      {
         b2blk(kb, nb, alpB, B, ldb, b);
         B += incBk;
      }
      an = a + inca;
      bn = b + incb;
      if (rC)
         amm(nmu, nnu, kb, a, b, rC, an, bn, rC);
      a = an;
      b = bn;
   }
   if (blk2c)
      blk2c(mb, nb, ip->alpC, rC, beta, C, ip->ldc);
#endif
}

/*
 * MVS: bit pattern with following meaning by bit position:
 *   0: set: move A workspace;  unset: A work only mb*nb
 *   1: set: move B workspace;  unset: B work only kb*nb
 *   2: set: A wrkspc hold full mat;  unset: A wrkspc holds panel only
 *      if bit 0 unset, this bit has no affect
 *   3: set: B wrkspc hold full mat;  unset: B wrkspc holds panel only
 *      if bit 1 unset, this bit has no affect
 *
 * NOTE: we assume global (i,j), but this function assumes any j indexing
 *       has been rolled into the B/C ptrs.  It does only i indexing for A&C.
 *       When i|j > 0, we do *NOT* move around in the workspace as we would 
 *       if we copied them ourselves.  This allows callers that don't need 
 *       full workspace (eg., triangular loops) to avoid allocating it.
 */
void Mjoin(PATL,iploopsMK)
(
   ipinfo_t *ip,
   size_t i,              /* which glbl rowblk to start at (ignore blks <i) */
   size_t j,              /* which global col block of C is being computed */
   const TYPE *A,         /* if non-NULL, A to cpy, else ignored */
   const TYPE *B,         /* if non-NULL, Portion B to cpy, else ignored */
   TYPE *C,               /* original C to write ans to at end of Kloop */
   const int MVS,         /* 1:move A workspace, 2:move B wrkspc, 3: mv both */
   TYPE *a,               /* wrkspace for block-copied A */
   TYPE *b,               /* wrkspace for block-copied B */
   TYPE *rC,              /* ptr to real portion of C access-major workspace */
   TYPE *iC,              /* ptr to complex C workspace */
   const SCALAR beta,     /* scaling factor for C */
   const ablk2cmat_t blk2c   /* C = alpC*(rC,iC) + beta*C */
)
{
   const size_t nfmblks=ip->nfmblks, nmblks=ip->npmblks+nfmblks;
   const size_t BA=((MVS&1)&&(MVS&4)) ? (~0):0;
   const TYPE *pB=B;
   if (i < nfmblks)
   {
      const size_t incAm = (A) ? ip->incAm:0, incCm = (ip->mb)SHIFT;
      const size_t pansz = BA & ((ip->nfkblks + 1)*((ip->szA)SHIFT));
      if (i)
      {
         A += i * incAm;
         C += i * incCm;
      }
      for (; i < nfmblks; i++)
      {
         Mjoin(PATL,iploopsK)(ip, i, j, A, pB, C, MVS, a, b, 
                              rC, iC, beta, blk2c);
         A += incAm;
         C += incCm;
         a += pansz;
         pB = NULL;  /* copy B col-panel only on first iteration */
      }
   }
   else if (i && nfmblks)
   {
      if (A)
         A += nfmblks * ip->incAm;
      C += nfmblks * ((ip->mb)SHIFT);
   }
   if (i < nmblks)
   {
      const size_t incAm = (A) ? ip->pincAm:0, incCm = (ip->pmb)SHIFT;
      const size_t pansz = BA & ((ip->nfkblks + 1)*((ip->pszA)SHIFT));
      if (i > nfmblks)
      {
         size_t k = i - nfmblks;
         A += k * incAm;
         C += k * incCm;
      }
      for (; i < nmblks; i++)
      {
         Mjoin(PATL,iploopsK)(ip, i, j, A, pB, C, MVS, a, b,
                              rC, iC, beta, blk2c);
         A += incAm;
         C += incCm;
         a += pansz;
         pB = NULL;  /* copy B col-panel only on first iteration */
      }
   }
}
/*
 * MVS: bit pattern with following meaning by bit position:
 *   0: set: move A workspace;  unset: A work only mb*nb
 *   1: set: move B workspace;  unset: B work only kb*nb
 *   2: set: A wrkspc hold full mat;  unset: A wrkspc holds panel only
 *      if bit 0 unset, this bit has no affect
 *   3: set: B wrkspc hold full mat;  unset: B wrkspc holds panel only
 *      if bit 1 unset, this bit has no affect
 *
 * NOTE: we assume global (i,j), but this function assumes any i indexing
 *       has been rolled into the A/C ptrs.  It does only j indexing for B&C.
 *       When i|j > 0, we do *NOT* move around in the workspace as we would 
 *       if we copied them ourselves.  This allows callers that don't need 
 *       full workspace (eg., triangular loops) to avoid allocating it.
 */
void Mjoin(PATL,iploopsNK)
(
   ipinfo_t *ip,
   size_t i,              /* which global row block of C is being computed */
   size_t j,              /* which glbl colblk to start at (ignore blks <j) */
   const TYPE *A,         /* if non-NULL, A to cpy, else ignored */
   const TYPE *B,         /* if non-NULL, Portion B to cpy, else ignored */
   TYPE *C,               /* original C to write ans to at end of Kloop */
   const int MVS,         /* 1:move A workspace, 2:move B wrkspc, 3: mv both */
   TYPE *a,               /* wrkspace for block-copied A */
   TYPE *b,               /* wrkspace for block-copied B */
   TYPE *rC,              /* ptr to real portion of C access-major workspace */
   TYPE *iC,              /* ptr to complex C workspace */
   const SCALAR beta,     /* scaling factor for C */
   const ablk2cmat_t blk2c   /* C = alpC*(rC,iC) + beta*C */
)
{
   const size_t nfnblks=ip->nfnblks, nnblks=ip->npnblks+nfnblks;
   const size_t BB=((MVS&2)&&(MVS&8)) ? (~0):0;
   const TYPE *pA=A;
   if (j < nfnblks)
   {
      const size_t incBn = (B) ? ip->incBn:0, incCn = ip->ldc*((ip->nb)SHIFT);
      const size_t pansz = BB & ((ip->nfkblks + 1)*((ip->szB)SHIFT));
      if (j)
      {
         B += j * incBn;
         C += j * incCn;
      }
      for (; j < nfnblks; j++)
      {
         Mjoin(PATL,iploopsK)(ip, i, j, pA, B, C, MVS, a, b, 
                              rC, iC, beta, blk2c);
         B += incBn;
         C += incCn;
         b += pansz;
         pA = NULL;  /* copy A row-panel only on first iteration */
      }
   }
   else if (j && nfnblks)
   {
      if (B)
         B += nfnblks * ip->incBn;
      C += nfnblks * ip->ldc * ((ip->mb)SHIFT);
   }
   if (j < nnblks)
   {
      const size_t incBn = (B) ? ip->pincBn:0, incCn = ip->ldc*((ip->pnb)SHIFT);
      const size_t pansz = BB & ((ip->nfkblks + 1)*((ip->pszB)SHIFT));
      if (j > nfnblks)
      {
         size_t k = j - nfnblks;
         B += k * incBn;
         C += k * incCn;
      }
      for (; j < nnblks; j++)
      {
         Mjoin(PATL,iploopsK)(ip, i, j, pA, B, C, MVS, a, b,
                              rC, iC, beta, blk2c);
         B += incBn;
         C += incCn;
         b += pansz;
         pA = NULL;  /* copy A row-panel only on first iteration */
      }
   }
}

/*
 * A & B ptrs should always be base ptrs to this func.
 * MVS: bit pattern with following meaning by bit position:
 *   0: set: move A workspace;  unset: A work only mb*nb
 *   1: set: move B workspace;  unset: B work only kb*nb
 *   2: set: A wrkspc hold full mat;  unset: A wrkspc holds panel only
 *      if bit 0 unset, this bit has no affect
 *   3: set: B wrkspc hold full mat;  unset: B wrkspc holds panel only
 *      if bit 1 unset, this bit has no affect
 *
 */
void Mjoin(PATL,iploopsNMK)
(
   ipinfo_t *ip,
   size_t i,              /* which glbl rowblk to start at (ignore blks <i) */
   size_t j,              /* which global col block of C is being computed */
   const TYPE *A,         /* if non-NULL, A to cpy, else ignored */
   const TYPE *B,         /* if non-NULL, Portion B to cpy, else ignored */
   TYPE *C,               /* original C to write ans to at end of Kloop */
   const int MVS,         /* 1:move A workspace, 2:move B wrkspc, 3: mv both */
   TYPE *a,               /* wrkspace for block-copied A */
   TYPE *b,               /* wrkspace for block-copied B */
   TYPE *rC,              /* ptr to real portion of C access-major workspace */
   TYPE *iC,              /* ptr to complex C workspace */
   const SCALAR beta,     /* scaling factor for C */
   const ablk2cmat_t blk2c   /* C = alpC*(rC,iC) + beta*C */
)
{
   const size_t nfnblks=ip->nfnblks, nnblks=ip->npnblks+nfnblks, ldc=ip->ldc;
   const size_t BMSKA=((MVS&1)&&(MVS&4)) ? 0:(~0);
   const size_t BMSKB=((MVS&2)&&(MVS&8)) ? (~0):0;
   if (j < nfnblks)
   {
      const size_t pansz = BMSKB & ((ip->nfkblks+1)*((ip->szB)SHIFT));
      const size_t incBn = ip->incBn, incCn = ldc*((ip->nb)SHIFT);
      if (j)
      {
         B += j*incBn;
         C += j*incCn;
      }
      for (; j < nfnblks; j++)
      {
         Mjoin(PATL,iploopsMK)(ip, i, j, A, B, C, MVS, a, b,
                               rC, iC, beta, blk2c);
         A = (TYPE*)(((size_t)A) & BMSKA);
         b += pansz;
         B += incBn;
         C += incCn;
      }
   }
   else if (j && nfnblks)
   {
      B += j * ip->incBn;
      C += j * ldc * ((ip->nb)SHIFT);
   }
   if (j < nnblks)
   {
      const size_t incBn = ip->pincBn, incCn = ldc*((ip->pnb)SHIFT);
      const size_t pansz = BMSKB & ((ip->nfkblks+1)*((ip->pszB)SHIFT));
      if (j > nfnblks)
      {
         size_t k = j - nfnblks;
         B += k * incBn;
         C += k * incCn;
      }
      for(; j < nnblks; j++)
      {
         Mjoin(PATL,iploopsMK)(ip, i, j, A, B, C, MVS, a, b,
                               rC, iC, beta, blk2c);
         A = (TYPE*)(((size_t)A) & BMSKA);
         b += pansz;
         B += incBn;
         C += incCn;
      }
   }
}
/*
 * A & B ptrs should always be base ptrs to this func.
 * MVS: bit pattern with following meaning by bit position:
 *   0: set: move A workspace;  unset: A work only mb*nb
 *   1: set: move B workspace;  unset: B work only kb*nb
 *   2: set: A wrkspc hold full mat;  unset: A wrkspc holds panel only
 *      if bit 0 unset, this bit has no affect
 *   3: set: B wrkspc hold full mat;  unset: B wrkspc holds panel only
 *      if bit 1 unset, this bit has no affect
 *
 */
void Mjoin(PATL,iploopsMNK)
(
   ipinfo_t *ip,
   size_t i,              /* which glbl rowblk to start at (ignore blks <i) */
   size_t j,              /* which global col block of C is being computed */
   const TYPE *A,         /* if non-NULL, A to cpy, else ignored */
   const TYPE *B,         /* if non-NULL, Portion B to cpy, else ignored */
   TYPE *C,               /* original C to write ans to at end of Kloop */
   const int MVS,         /* 1:move A workspace, 2:move B wrkspc, 3: mv both */
   TYPE *a,               /* wrkspace for block-copied A */
   TYPE *b,               /* wrkspace for block-copied B */
   TYPE *rC,              /* ptr to real portion of C access-major workspace */
   TYPE *iC,              /* ptr to complex C workspace */
   const SCALAR beta,     /* scaling factor for C */
   const ablk2cmat_t blk2c   /* C = alpC*(rC,iC) + beta*C */
)
{
   const size_t nfmblks=ip->nfmblks, nmblks=ip->npmblks+nfmblks, ldc=ip->ldc;
   const size_t BMSKA=((MVS&1)&&(MVS&4)) ? (~0):0;
   const size_t BMSKB=((MVS&2)&&(MVS&8)) ? 0:(~0);
   if (i < nfmblks)
   {
      const size_t pansz = BMSKA & ((ip->nfkblks+1)*((ip->szA)SHIFT));
      const size_t incAm = ip->incAm, incCm = (ip->mb)SHIFT;
      if (i)
      {
         A += i*incAm;
         C += i*incCm;
      }
      for (; i < nfmblks; i++)
      {
         Mjoin(PATL,iploopsNK)(ip, i, j, A, B, C, MVS, a, b,
                               rC, iC, beta, blk2c);
         B = (TYPE*)(((size_t)B) & BMSKB);
         a += pansz;
         A += incAm;
         C += incCm;
      }
   }
   else if (i && nfmblks)
   {
      A += i * ip->incAm;
      C += i * ((ip->mb)SHIFT);
   }
   if (i < nmblks)
   {
      const size_t incAm = ip->pincAm, incCm = (ip->pmb)SHIFT;
      const size_t pansz = BMSKA & ((ip->nfkblks+1)*((ip->pszA)SHIFT));
      if (i > nfmblks)
      {
         size_t k = i - nfmblks;
         A += k * incAm;
         C += k * incCm;
      }
      for(; i < nmblks; i++)
      {
         Mjoin(PATL,iploopsNK)(ip, i, j, A, B, C, MVS, a, b,
                               rC, iC, beta, blk2c);
         B = (TYPE*)(((size_t)B) & BMSKB);
         a += pansz;
         A += incAm;
         C += incCm;
      }
   }
}
@ROUT ATL_ammmK ATL_cammmK
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

void Mjoin(PATL,ammmK)
(
   amminfo_t *mminf,
   const int mb,           /* # of rows of C to compute */
   const int nmu,          /* CEIL(mb/mu) */
   const int nb,  
   const int nnu,
   ATL_CINT nfkblks, /* FLOOR(K/kb) */
   const int kb,
   const int kb0,
   const int KB0,
   const TYPE *A,
   const size_t lda,   
   const size_t incAk, /* 0: no need to copy A, else incK for cpying A */
   const TYPE *B,
   const size_t ldb,   
   const size_t incBk, /* 0: no need to copy B, else incK for cpying A */
   const ablk2cmat_t blk2c,
   TYPE *C,
   const size_t ldc,   
   TYPE *a,
   ATL_CINT inca,      /* size of blocks of A, or 0 to reuse space */
   TYPE *b,
   ATL_CINT incb,      /* size of blocks of B, or 0 to reuse space */
   TYPE *rC, 
   TYPE *iC, 
   const SCALAR alpA,
   const SCALAR alpB,
   const SCALAR alpC,
   const SCALAR beta
)
@ROUT ATL_ammmK
{
   cm2am_t a2blk=mminf->a2blk, b2blk=mminf->b2blk;
   ammkern_t amm=mminf->amm_b0;
   TYPE *an=a+inca, *bn=b+incb;
   ATL_INT k;
/*
 * Peel first iteration to handle KR and use beta=0
 */
   if (kb0 != kb)
   {
      ATL_CINT ku=mminf->ku;
      amm = mminf->amm_k1_b0;
      if ( ATL_AMMFLG_KRUNTIME(mminf->flag) && (mminf->kbmin <= KB0) && 
           (ATL_AMMFLG_KMAJOR(mminf->flag) || (KB0 == kb0)) &&
           (kb0/ku)*ku == kb0)
         amm = mminf->amm_b0;
      if (incAk)
         a2blk(kb0, mb, alpA, A+incAk*nfkblks, lda, a);
      if (incBk)
         b2blk(kb0, nb, alpB, B+incBk*nfkblks, ldb, b);
      amm(nmu, nnu, KB0, a, b, rC, an, bn, rC);
   }
   else
   {
      if (incAk)
      {
         a2blk(kb0, mb, alpA, A, lda, a);
         A += incAk;
      }
      if (incBk)
      {
         b2blk(kb0, nb, alpB, B, ldb, b);
         B += incBk;
      }
      amm(nmu, nnu, KB0, a, b, rC, an, bn, rC);
   }
   amm = mminf->amm_b1;
   a = an;
   b = bn;

   for (k=0; k < nfkblks; k++)
   {
      if (incAk)
      {
         a2blk(kb, mb, alpA, A, lda, a);
         A += incAk;
      }
      if (incBk)
      {
         b2blk(kb, nb, alpB, B, ldb, b);
         B += incBk;
      }
      an = a + inca;
      bn = b + incb;
      amm(nmu, nnu, kb, a, b, rC, an, bn, rC);
      a = an;
      b = bn;
   }
   if (blk2c)
      blk2c(mb, nb, alpC, rC, beta, C, ldc);
}
@ROUT ATL_ammmKn
@ROUT ATL_cammmK
{
   cm2am_t a2blk=mminf->a2blk, b2blk=mminf->b2blk;
   ammkern_t amm_b0=mminf->amm_b0, amm_b1=mminf->amm_b1, amm_bn=mminf->amm_bn;
   ATL_CINT inca2=inca+inca, incb2=incb+incb;
   ATL_INT szA = inca, szB = incb;
   TYPE *iA=a, *iB=b, *rA, *rB;
   TYPE *an=iA+inca2, *bn=iB+incb2;
   ATL_INT k;
   if (!szA)
      szA = nmu*mminf->mu*Mmax(kb,KB0);
   if (!szB)
      szB = nnu*mminf->nu*Mmax(kb,KB0);
   rA = iA + szA;
   rB = iB + szB;
/*
 * Peel first iteration to handle KR and use beta=0
 */
   if (kb0 != kb)
   {
      amm_b0 = mminf->amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminf->flag) && (mminf->kbmin <= KB0))
      {
         int ku = mminf->ku;
         #if ATL_geAMM_MAXKVEC > 1
         if (ATL_AMMFLG_KMAJOR(mminf->flag))
            amm_b0 = mminf->amm_b0;
         else
         #endif
         if ((kb0/ku)*ku == kb0)
            amm_b0 = mminf->amm_b0;
      }
      if (amm_b0 != mminf->amm_b0)
      {
         amm_b1 = mminf->amm_k1_b1;
         amm_bn = mminf->amm_k1_bn;
      }
      if (incAk)
         a2blk(kb0, mb, alpA, A+incAk*nfkblks, lda, rA, iA);
      if (incBk)
         b2blk(kb0, nb, alpB, B+incBk*nfkblks, ldb, rB, iB);

      amm_b0(nmu, nnu, KB0, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, KB0, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, KB0, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, KB0, iA, rB, iC, an, bn, rC);

      amm_b1 = mminf->amm_b1;
      amm_bn = mminf->amm_bn;
   }
   else
   {
      if (incAk)
      {
         a2blk(kb, mb, alpA, A, lda, rA, iA);
         A += incAk;
      }
      if (incBk)
      {
         b2blk(kb, nb, alpB, B, ldb, rB, iB);
         B += incBk;
      }
      amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, an, bn, rC);
   }

   for (k=0; k < nfkblks; k++)
   {
      iA = an;
      iB = bn;
      rA = iA + szA;
      rB = iB + szB;
      an = iA + inca2;
      bn = iB + incb2;
      if (incAk)
      {
         a2blk(kb, mb, alpA, A, lda, rA, iA);
         A += incAk;
      }
      if (incBk)
      {
         b2blk(kb, nb, alpB, B, ldb, rB, iB);
         B += incBk;
      }
      amm_bn(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b1(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, an, bn, rC);
   }
   if (blk2c)
      blk2c(mb, nb, alpC, rC, iC, beta, C, ldc);
}
@ROUT ATL_ammmKNMK
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

@beginskip
static void ATL_ammmMK
(
   amminfo_t *mminf,
   ATL_CSZT nfmblks,         /* FLOOR(M/mb) */
   const int mbL,            /* mbL=M%mb */
   const int nmuL,
   const int nb,
   const int nnu,
   ATL_CSZT nfkblks,         /* FLOOR(K/kb) */
   const int kb0,
   const int KB0,
   const TYPE *A,
   const size_t lda,
   const size_t incAk,       /* 0: no need to copy A, else incK for cpying A */
   const size_t incAm,
   const TYPE *B,
   const size_t ldb,
   const size_t incBk0,      /* 0: no need to copy B, else incK for cpying A */
   TYPE *C,
   const size_t ldc,
   const size_t incCm,
   TYPE *a,
   ATL_CINT inca,      /* size of blocks of A, or 0 to reuse space */
   ATL_CSZT incam,
   TYPE *b,
   ATL_CINT incb,      /* size of blocks of B, or 0 to reuse space */
   TYPE *rC,
   TYPE *iC,
   const SCALAR alpA,
   const SCALAR alpB,
   const SCALAR alpC,
   const SCALAR beta
)
{
   ATL_SZT i, incBk=incBk0;
   const int mu=mminf->mu, mb=mminf->mb, nmu=(mb+mu-1)/mu; 
   const int kb=mminf->kb;
   ablk2cmat_t blk2c=mminf->Cblk2cm;

   for (i=0; i < nfmblks; i++, A += incAm, C += incCm, a += incam)
   {
      Mjoin(PATL,ammmK)(mminf, mb, nmu, nb, nnu, nfkblks, kb, kb0, KB0, 
                        A, lda, incAk, B, ldb, incBk, blk2c, C, ldc, 
                        a, inca, b, incb, rC, iC, alpA, alpB, alpC, beta);
      incBk = 0; /* reuse B for rest of C colum panel */
   }
   if (mbL)
      Mjoin(PATL,ammmK)(mminf, mbL, nmuL, nb, nnu, nfkblks, kb, kb0, KB0, 
                        A, lda, incAk, B, ldb, incBk, blk2c, C, ldc, 
                        a, inca, b, incb, rC, iC, alpA, alpB, alpC, beta);
}

static void ATL_ammmNMK
(
   amminfo_t *mminf,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   TYPE *C,
   ATL_CSZT ldc,
   ATL_SZT nmblks,            /* CEIL(M/mb) */
   ATL_SZT nkblks,            /* CEIL(K/kb) */
   TYPE *a,
   TYPE *b, 
   TYPE *c,
   const SCALAR alpA,
   const SCALAR alpB,
   const SCALAR alpC,
   const SCALAR beta
)
{
   const int mb=mminf->mb, nb=mminf->nb, kb=mminf->kb;
   const int mu=mminf->mu, nu=mminf->nu, ku=mminf->ku;
   const int nmu=(mb+mu-1)/mu, nnu=(nb+nu-1)/nu;
   const int inca=mb*kb, incb=kb*nb;
   int mbL=0, nmuL=0, nbF=nb, nnuF=nnu, KB0, kb0;
   ATL_CSZT incam = nkblks*(inca SHIFT), incCn = nb*(ldc SHIFT);
   ATL_SZT j, incAm, incAk, incBk, incBn, incBnF;
   ATL_SZT nnblks = (N-1)/nb;
   #ifdef TCPLX
      TYPE *iC=c, *rC=c+mb*nb;
      const int mb2=mb+mb;
   #else
      #define rC c
      #define iC c
      #define mb2 mb
   #endif

   j = nmblks*mb;
   if (j != M)
   {
      nmblks--;
      mbL = M - j + mb;
      nmuL = (mbL+mu-1)/mu;
   }
   j = nnblks*nb;
   nbF = N - j;
   if (nbF != nb)
      nnuF = (nbF+nu-1)/nu;
   nkblks--;
   j = nkblks*kb;
   KB0 = kb0 = K - j;
   #if ATL_geAMM_MAXKVEC > 1
      if (kb0 != kb && ATL_AMMFLG_KMAJOR(mminf->flag))
         KB0 = ((kb0+ku-1)/ku)*ku;
   #endif
   if (IS_COLMAJ(TA))
   {
      incAk = kb*lda;
      incAm = mb;
   }
   else
   {
      incAk = kb;
      incAm = mb*lda;
   }
   if (IS_COLMAJ(TB))
   {
      incBk = kb;
      incBn = nb*ldb;
      incBnF = nbF*ldb;
   }
   else
   {
      incBk = kb*ldb;
      incBn = nb;
      incBnF = nbF;
   }
   #ifdef TCPLX
      incAk += incAk;
      incAm += incAm;
      incBk += incBk;
      incBn += incBn;
      incBnF += incBnF;
   #endif
/*
 * In first nbF-wide panel, we copy all of A into workspace
 */
   ATL_ammmMK(mminf, nmblks, mbL, nmuL, nbF, nnuF, nkblks, kb0, KB0,
              A, lda, incAk, incAm, B, ldb, incBk, C, ldc, mb2,
              a, inca, incam, b, incb, rC, iC, alpA, alpB, alpC, beta);
   C += ldc*(nbF SHIFT);
   B += incBnF;
/*
 * In all other N-panel computation, reuse previously copied A!
 */
   if (nnblks)
   {
      incAk = 0;
      for (j=0; j < nnblks; j++, C += incCn, B += incBn)
         ATL_ammmMK(mminf, nmblks, mbL, nmuL, nb, nnu, nkblks, kb0, KB0,
                    A, lda, incAk, incAm, B, ldb, incBk, C, ldc, mb2,
                    a, inca, incam, b, incb, rC, iC, alpA, alpB, alpC, beta);
   }
}
#ifndef TCPLX
   #undef rC
   #undef iC
   #undef mb2
#endif

int Mjoin(PATL,ammmKNMK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef TCPLX
      const TYPE ONE[2]={ATL_rone,ATL_rzero}, ZERO[2]={ATL_rzero,ATL_rzero};
      const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
   #else
      #define ONE ATL_rone
      TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   #endif
   void *vp=NULL;
   TYPE *a, *b, *c;
   ATL_SZT szA, szB, szC, sz, nmblks, nkblks, nkblksP, k;
   ATL_INT nkP=0;
   int mu, nu, mb, nb, kb, incak, incbk;
   amminfo_t mminf;


   mu = Mjoin(PATL,GetAmmmInfo)(&mminf, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminf.mu;
   nu = mminf.nu;
   mb = mminf.mb;
   nb = mminf.nb;
   kb = mminf.kb;
   nmblks = (M+mb-1)/mb;
   nkblksP = nkblks = (K+kb-1)/kb;
   nkblksP <<= 1;
   incak = mb*kb;
   incbk = kb*nb;
   szC = mb*nb;
   #if 0
   if (nkblks > 1)
   {
      nkP++;
      nkblksP >>= 1;
   }
   #endif
   do
   {
      nkP++;
      nkblksP >>= 1;
      szA = nkblksP*nmblks*incak;
      szB = nkblksP*incbk;
      sz = ATL_MulBySize(szA+szB+szC+(mu+mu)*nu) + 2*ATL_Cachelen;
      if (sz <= ATL_MaxMalloc)
         vp = malloc(sz);
   }
   while (!vp && nkblksP >= 3);
   if (!vp)
      return(1);

   a = ATL_AlignPtr(vp);
   b = a + (szA SHIFT);
   c = b + (szB SHIFT);
   
   if (nkblksP == nkblks)
      ATL_ammmNMK(&mminf, TA, TB, M, N, K, A, lda, B, ldb, C, ldc, nmblks, 
                  nkblks, a, b, c, alpA, alpB, alpC, beta);
   else
   {
      ATL_CSZT KK = nkblksP*kb;
      ATL_SZT incAkp, incBkp;
      incBkp = incAkp = KK SHIFT;
      if (IS_COLMAJ(TA))
         incAkp *= lda;
      if (!IS_COLMAJ(TB))
         incBkp *= ldb;
      for (k=0; k < nkblks; k += nkblksP, A += incAkp, B += incBkp)
      {
         ATL_SZT nk=nkblks-k, kk;
         if (nk > nkblksP)
         {
            kk = KK;
            nk = nkblksP;
         }
         else
            kk = K - k*kb;
         ATL_ammmNMK(&mminf, TA, TB, M, N, kk, A, lda, B, ldb, C, ldc, nmblks, 
                     nk, a, b, c, alpA, alpB, alpC, beta);
      }
   }
   free(vp);
   return(0);
}
@endskip
int Mjoin(PATL,ammmKNMK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   TYPE *a, *b, *c;
   void *vp=NULL;
   size_t szA, szB, nfkblks, nkblksP;
   #ifdef TCPLX
      TYPE *rC;
      const TYPE *bet=beta;
   #else
      TYPE bet=beta;
      #define rC c
   #endif
   int i, kb, extra;
   ipinfo_t ip;

   Mjoin(PATL,ipgenInfo)(&ip, 0, TA, TB, M, N, K, lda, ldb, ldc, alpha, bet);
/*
 * Figure out a partition of K that should allow malloc to succeed. 
 * In this routine, we need to allocate space for a block of C,
 * a column-panel of B, and the full matrix A.  If we can't get that
 * much space, we partition K into Kp, and reduce Kp until the malloc
 * succeeds.  If Kp drops below 3*LASTKB, we give up and return non-zero,
 * to indicate that recursion should be used to cut all dims until a malloc
 * can succeed.
 */
   kb = ip.kb;
   nkblksP = nfkblks = ip.nfkblks;
/*
 * Set up extra to have all sizes that are independent of K.
 * sz[A,B] will be multiplied by number of K blks to get final answer.
 */
   extra = ATL_MulBySize(ip.szC+ip.exsz) + 3 * ATL_Cachelen; 
   szA = ip.szA*ip.nfmblks + ip.pszA*ip.npmblks;
   szB = ip.szB;
   while(1)
   {
      size_t sz;
      sz = ATL_MulBySize((szA+szB)*(nkblksP+1)) + extra;
      if (sz <= ATL_MaxMalloc)
         vp = malloc(sz);
      if (vp)
         break;
      nkblksP = (nkblksP>>1);
      if (nkblksP < 3)
         return(1);
   }
@skip   ATL_assert(nkblksP);
@skip printf("nkblksP=%d of %d, K=%d\n", (int)nkblksP, (int)nfkblks, (int)K);
   szA *= (nkblksP+1);
   szB *= (nkblksP+1);
   a = ATL_AlignPtr(vp);
   b = a + (szA SHIFT);
   b = ATL_AlignPtr(b);
   c = b + (szB SHIFT);
   c = ATL_AlignPtr(c);
   #ifdef TCPLX
      rC=c+ip.szC;
   #endif

   if (nkblksP == nfkblks)
      Mjoin(PATL,iploopsNMK)(&ip, 0, 0, A, B, C, 1|2|4, a, b, 
                             rC, c, beta, ip.blk2c);
   else   /* have partitioned K into areas of at most (nkblksP+1)*kb */
   {
      const size_t incAk=ip.incAk*(nkblksP+1);
      const size_t incBk=ip.incBk*(nkblksP+1), Kp=(nkblksP+1)*kb;
      size_t k;
      ablk2cmat_t blk2c = ip.blk2c;

      for (k=Kp; k < K; k += Kp)
      {
         Mjoin(PATL,ipgenInfo)(&ip,0,TA,TB, M, N, K, lda, ldb, ldc, alpha, bet);
         Mjoin(PATL,iploopsNMK)(&ip, 0, 0, A, B, C, 1|2|4, a, b, 
                                rC, c, bet, ip.blk2c);
         #ifdef TCPLX
            bet = ip.ONE;
         #else
            bet = ATL_rone;
         #endif
         A += incAk;
         B += incBk;
      }
      k = K - k + Kp;
      Mjoin(PATL,ipgenInfo)(&ip, 0, TA, TB, M, N, K, lda, ldb, ldc, alpha, bet);
      Mjoin(PATL,iploopsNMK)(&ip, 0, 0, A, B, C, 1|2|4, a, b, 
                             rC, c, bet, ip.blk2c);
   }

   free(vp);
   return(0);
}
#ifndef TCPLX
   #undef rC
#endif
@ROUT ATL_ammmKMNK
#include "atlas_misc.h"
#include "atlas_amm.h"

int Mjoin(PATL,ammmKMNK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   TYPE *a, *b, *c;
   void *vp=NULL;
   size_t szA, szB, nfkblks, nkblksP;
   #ifdef TCPLX
      TYPE *rC;
      const TYPE *bet=beta;
   #else
      TYPE bet=beta;
      #define rC c
   #endif
   int i, kb, extra;
   ipinfo_t ip;

   Mjoin(PATL,ipgenInfo)(&ip, 0, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta);
/*
 * Figure out a partition of K that should allow malloc to succeed.
 * In this routine, we need to allocate space for a block of C,
 * a row-panel of A, and the full matrix B.  If we can't get that
 * much space, we partition K into Kp, and reduce Kp until the malloc
 * succeeds.  If Kp drops below 3*LASTKB, we give up and return non-zero,
 * to indicate that recursion should be used to cut all dims until a malloc
 * can succeed.
 */
   kb = ip.kb;
   nkblksP = nfkblks = ip.nfkblks;
/*
 * Set up extra to have all sizes that are independent of K.
 * sz[A,B] will be multiplied by number of K blks to get final answer.
 */
   extra = ATL_MulBySize(ip.szC+ip.exsz) + 3 * ATL_Cachelen;
   szB = ip.szB*ip.nfnblks + ip.pszB*ip.npnblks;
   szA = ip.szA;
   while(1)
   {
      size_t sz;
      sz = ATL_MulBySize((szA+szB)*(nkblksP+1)) + extra;
      if (sz <= ATL_MaxMalloc)
         vp = malloc(sz);
      if (vp)
         break;
      nkblksP = (nkblksP>>1);
      if (nkblksP < 3)
         return(1);
   }
   szA *= (nkblksP+1);
   szB *= (nkblksP+1);
   a = ATL_AlignPtr(vp);
   b = a + (szA SHIFT);
   b = ATL_AlignPtr(b);
   c = b + (szB SHIFT);
   c = ATL_AlignPtr(c);
   #ifdef TCPLX
      rC=c+ip.szC;
   #endif

   if (nkblksP == nfkblks)
      Mjoin(PATL,iploopsMNK)(&ip, 0, 0, A, B, C, 1|2|8, a, b,
                             rC, c, beta, ip.blk2c);
   else   /* have partitioned K into areas of at most (nkblksP+1)*kb */
   {
      const size_t incAk=ip.incAk*(nkblksP+1);
      const size_t incBk=ip.incBk*(nkblksP+1), Kp=(nkblksP+1)*kb;
      size_t k;
      ablk2cmat_t blk2c = ip.blk2c;

      for (k=Kp; k < K; k += Kp)
      {
         Mjoin(PATL,ipgenInfo)(&ip,0,TA,TB, M, N, K, lda, ldb, ldc, alpha, bet);
         Mjoin(PATL,iploopsMNK)(&ip, 0, 0, A, B, C, 1|2|8, a, b,
                                rC, c, bet, ip.blk2c);
         #ifdef TCPLX
            bet = ip.ONE;
         #else
            bet = ATL_rone;
         #endif
         A += incAk;
         B += incBk;
      }
      k = K - k + Kp;
      Mjoin(PATL,ipgenInfo)(&ip, 0, TA, TB, M, N, K, lda, ldb, ldc, alpha, bet);
      Mjoin(PATL,iploopsMNK)(&ip, 0, 0, A, B, C, 1|2|8, a, b,
                             rC, c, bet, ip.blk2c);
   }

   free(vp);
   return(0);
}
#ifndef TCPLX
   #undef rC
#endif
@beginskip
static void ATL_ammmNK
(
   amminfo_t *mminf,
   const int mb,
   const int nmu,
   ATL_CSZT nfnblks,         /* FLOOR(N/nb) */
   const int nbL,            /* nbL=N%nb */
   const int nnuL,
   ATL_CSZT nfkblks,         /* FLOOR(K/kb) */
   const int kb0,
   const int KB0,
   const TYPE *A,
   const size_t lda,
   const size_t incAk0,      /* 0: no need to copy A, else incK for cpying A */
   const TYPE *B,
   const size_t ldb,
   const size_t incBk,       /* 0: no need to copy B, else incK for cpying A */
   const size_t incBn,
   TYPE *C,
   const size_t ldc,
   const size_t incCn,
   TYPE *a,
   ATL_CINT inca,      /* size of blocks of A, or 0 to reuse space */
   TYPE *b,
   ATL_CINT incb,      /* size of blocks of B, or 0 to reuse space */
   ATL_CSZT incbn,
   TYPE *rC,
   TYPE *iC,
   const SCALAR alpA,
   const SCALAR alpB,
   const SCALAR alpC,
   const SCALAR beta
)
{
   ATL_SZT j, incAk=incAk0;
   const int nu=mminf->nu, nb=mminf->nb, nnu=(nb+nu-1)/nu;
   const int kb=mminf->kb;
   ablk2cmat_t blk2c=mminf->Cblk2cm;

   for (j=0; j < nfnblks; j++, B += incBn, C += incCn, b += incbn)
   {
      Mjoin(PATL,ammmK)(mminf, mb, nmu, nb, nnu, nfkblks, kb, kb0, KB0,
                        A, lda, incAk, B, ldb, incBk, blk2c, C, ldc,
                        a, inca, b, incb, rC, iC, alpA, alpB, alpC, beta);
      incAk = 0; /* reuse A for rest of C row panel */
   }
   if (nbL)
      Mjoin(PATL,ammmK)(mminf, mb, nmu, nbL, nnuL, nfkblks, kb, kb0, KB0,
                        A, lda, incAk, B, ldb, incBk, blk2c, C, ldc,
                        a, inca, b, incb, rC, iC, alpA, alpB, alpC, beta);
}
static void ATL_ammmMNK
(
   amminfo_t *mminf,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   TYPE *C,
   ATL_CSZT ldc,
   ATL_SZT nnblks,            /* CEIL(N/nb) */
   ATL_SZT nkblks,            /* CEIL(K/kb) */
   TYPE *a,
   TYPE *b, 
   TYPE *c,
   const SCALAR alpA,
   const SCALAR alpB,
   const SCALAR alpC,
   const SCALAR beta
)
{
   const int mb=mminf->mb, nb=mminf->nb, kb=mminf->kb;
   const int mu=mminf->mu, nu=mminf->nu, ku=mminf->ku;
   const int nmu=(mb+mu-1)/mu, nnu=(nb+nu-1)/nu;
   const int inca=mb*kb, incb=kb*nb;
   int nbL=0, nnuL=0, mbF=mb, nmuF=nmu, KB0, kb0;
   ATL_CSZT incbn = nkblks*(incb SHIFT), incCn = nb*(ldc SHIFT);
   ATL_SZT j, incAm, incAk, incBk, incBn, incAmF;
   ATL_SZT nmblks = (M-1)/mb;
   #ifdef TCPLX
      TYPE *iC=c, *rC=c+mb*nb;
      const int mb2=mb+mb;
   #else
      #define rC c
      #define iC c
      #define mb2 mb
   #endif

   j = nnblks*nb;
   if (j != N)
   {
      nnblks--;
      nbL = N - j + nb;
      nnuL = (nbL+nu-1)/nu;
   }
   j = nmblks*mb;
   mbF = M - j;
   if (mbF != mb)
      nmuF = (mbF+mu-1)/mu;
   nkblks--;
   j = nkblks*kb;
   KB0 = kb0 = K - j;
   #if ATL_geAMM_MAXKVEC > 1
      if (kb0 != kb && ATL_AMMFLG_KMAJOR(mminf->flag))
         KB0 = ((kb0+ku-1)/ku)*ku;
   #endif
   if (IS_COLMAJ(TA))
   {
      incAk = kb*lda;
      incAm = mb;
      incAmF = mbF;
   }
   else
   {
      incAk = kb;
      incAm = mb*lda;
      incAmF = mbF*lda;
   }
   if (IS_COLMAJ(TB))
   {
      incBk = kb;
      incBn = nb*ldb;
   }
   else
   {
      incBk = kb*ldb;
      incBn = nb;
   }
   #ifdef TCPLX
      incAk += incAk;
      incAm += incAm;
      incBk += incBk;
      incBn += incBn;
      incAmF += incAmF;
   #endif
/*
 * In first mbF-wide panel, we copy all of B into workspace
 */
   ATL_ammmNK(mminf, mbF, nmuF, nnblks, nbL, nnuL, nkblks, kb0, KB0,
              A, lda, incAk, B, ldb, incBk, incBn, C, ldc, incCn,
              a, inca, b, incb, incbn, rC, iC, alpA, alpB, alpC, beta);
   C += (mbF SHIFT);
   A += incAmF;
/*
 * In all other M-panel computation, reuse previously copied B!
 */
   if (nmblks)
   {
      for (j=0; j < nmblks; j++, C += mb2, A += incAm)
         ATL_ammmNK(mminf, mb, nmu, nnblks, nbL, nnuL, nkblks, kb0, KB0,
                    A, lda, incAk, B, ldb, 0, incBn, C, ldc, incCn,
                    a, inca, b, incb, incbn, rC, iC, alpA, alpB, alpC, beta);
   }
}
#ifndef TCPLX
   #undef rC
   #undef iC
   #undef mb2
#endif

int Mjoin(PATL,ammmKMNK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef TCPLX
      const TYPE ONE[2]={ATL_rone,ATL_rzero}, ZERO[2]={ATL_rzero,ATL_rzero};
      const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
   #else
      #define ONE ATL_rone
      TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   #endif
   void *vp=NULL;
   TYPE *a, *b, *c;
   ATL_SZT szA, szB, szC, sz, nnblks, nkblks, nkblksP, k;
   ATL_INT nkP=0;
   int mu, nu, mb, nb, kb, incak, incbk;
   amminfo_t mminf;


   mu = Mjoin(PATL,GetAmmmInfo)(&mminf, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminf.mu;
   nu = mminf.nu;
   mb = mminf.mb;
   nb = mminf.nb;
   kb = mminf.kb;
   nnblks = (N+nb-1)/nb;
   nkblksP = nkblks = (K+kb-1)/kb;
   nkblksP <<= 1;
   incak = mb*kb;
   incbk = kb*nb;
   szC = mb*nb;
   do
   {
      nkP++;
      nkblksP >>= 1;
      szA = nkblksP*incak;
      szB = nkblksP*nnblks*incbk;
      sz = ATL_MulBySize(szA+szB+szC+(mu+mu)*nu) + 2*ATL_Cachelen;
      if (sz <= ATL_MaxMalloc)
         vp = malloc(sz);
   }
   while (!vp && nkblksP >= 3);
   if (!vp)
      return(1);

   b = ATL_AlignPtr(vp);
   a = b + (szB SHIFT);
   c = a + (szA SHIFT);

   if (nkblksP == nkblks)
      ATL_ammmMNK(&mminf, TA, TB, M, N, K, A, lda, B, ldb, C, ldc, nnblks,
                  nkblks, a, b, c, alpA, alpB, alpC, beta);
   else
   {
      ATL_CSZT KK = nkblksP*kb;
      ATL_SZT incAkp, incBkp;
      incBkp = incAkp = KK SHIFT;
      if (IS_COLMAJ(TA))
         incAkp *= lda;
      if (!IS_COLMAJ(TB))
         incBkp *= ldb;
      for (k=0; k < nkblks; k += nkblksP, A += incAkp, B += incBkp)
      {
         ATL_SZT nk=nkblks-k, kk;
         if (nk > nkblksP)
         {
            kk = KK;
            nk = nkblksP;
         }
         else
            kk = K - k*kb;
         ATL_ammmMNK(&mminf, TA, TB, M, N, kk, A, lda, B, ldb, C, ldc, nnblks,
                     nk, a, b, c, alpA, alpB, alpC, beta);
      }
   }
   free(vp);
   return(0);
}
@endskip
@ROUT ATL_ammm_syrk
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

@beginskip
int Mjoin(PATL,ammm_syrk2)
(
   const enum ATLAS_UPLO  Uplo,
   const enum ATLAS_TRANS TA,
   ATL_CSZT  N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   int i;
   ipinfo_t ip;
   i = Mjoin(PATL,sqGetAmmmIndx)(0, N, K);
   Mjoin(PATL,sqComputeIPInfo)(&ip, TA, 0, 0, N, K, lda, 0, ldc, alpha, beta);
   return(0);
}
@endskip

int Mjoin(PATL,ammm_syrk)
(
   const enum ATLAS_UPLO  Uplo,
   const enum ATLAS_TRANS TA,
   ATL_CSZT  N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   ablk2cmat_t blk2c, blk2c_b0;
   ATL_CSZT ldcp1=(ldc+1)SHIFT;
   ATL_SZT i, j, szA, pansz, sz, nnblks, nkblks, incCn, incAk, incAn, incAnF;
   const TYPE *B = A;
   const TYPE *a;
   TYPE *wa, *ar, *wb, *wc, *wC, *c;
   void *vp=NULL;
   const int ISHERK=(TA == AtlasConj || TA == AtlasConjTrans);
   int ibet=1, ialp=1;
   int mu, nu, ku, incw, nb, nnu, nmu, nbF, nnuF, nmuF, kb0, KB0;
   #ifdef TCPLX
      const TYPE ONE[2] = {ATL_rone, ATL_rzero};
      const TYPE ZERO[2] = {ATL_rzero, ATL_rzero};
      TYPE *rC, *CC=C;
      int incw2, nb2;
   #else
      #define ONE ATL_rone
      #define ZERO ATL_rzero
      #define rC wc
      #define incw2 incw
      #define nb2 nb
   #endif
   amminfo_t mminf;


/*   printf("UP=%c, N=%d, K=%d\n", Uplo==AtlasLower?'L':'U', (int)N, (int)K); */
   if (SCALAR_IS_NONE(alpha))
      ialp = -1;
   else if (!SCALAR_IS_ONE(alpha))
      ialp = 2;
   if (SCALAR_IS_ZERO(beta))
      ibet = 0;
   else if (SCALAR_IS_NONE(beta))
      ibet = -1;
   else if (!SCALAR_IS_ONE(beta))
      ibet = 2;

   nb = Mjoin(PATL,GetSyrkInfo)(&mminf, ialp, TA, N, K, ibet);
   blk2c = mminf.Cblk2cm;
   blk2c_b0 = mminf.Cblk2cm_b1;
   mu = mminf.mu;
   nu = mminf.nu;
   ku = mminf.ku;
   nmu = (nb+mu-1)/mu;
   nnu = (nb+nu-1)/nu;
   nnblks = (N+nb-1)/nb;
   nkblks = (K+nb-1)/nb;
   incw = nb*nb;
   #ifdef TCPLX
      nb2 = nb + nb;
      incw2 = incw + incw;
   #endif
   pansz = nkblks*incw;
   szA = Mmax(nnblks-1,1);
   szA *= pansz;
   sz = szA + pansz + incw + incw + (mu+mu)*nu;
   sz = ATL_MulBySize(sz) + ATL_Cachelen;
   if (sz <= ATL_MaxMalloc)
      vp = malloc(sz);
   if (!vp)
      return(1);
   #ifdef TCPLX
      pansz += pansz;
   #endif
   wa = ATL_AlignPtr(vp);
   wb = wa + (szA SHIFT);
   wc = wb + pansz;
   wC = wc + incw2;

   nbF = N - (--nnblks)*nb;
   if (nbF == nb)
   {
      nmuF = nmu;
      nnuF = nnu;
   }
   else
   {
      nmuF = (nbF+mu-1)/mu;
      nnuF = (nbF+nu-1)/nu;
   }
   KB0 = kb0 = K - (--nkblks)*nb;
   #if ATL_geAMM_MAXKVEC > 1
      if (kb0 != nb && ATL_AMMFLG_KMAJOR(mminf.flag))
         KB0 = ((kb0+ku-1)/ku)*ku;
   #endif
   #ifdef TCPLX
      rC = wc + incw;
   #endif
   if (IS_COLMAJ(TA))
   {
      incAk = nb*(lda SHIFT);
      incAn = nb2;
      incAnF = nbF SHIFT;
   }
   else
   {
      incAk = nb2;
      incAn = lda SHIFT;
      incAnF = incAn * nbF;
      incAn *= nb;
   }
   incCn = nb*ldcp1;
   if (Uplo == AtlasLower)
   {
/*
 *    Peel first column of C computation, which will handle all partial blocks
 *    First rowpan of A not reused, so set inca=0
 */
      Mjoin(PATL,ammmK)(&mminf, nbF, nmuF, nbF, nnuF, nkblks, nb, kb0, KB0,
                        A, lda, incAk, B, lda, incAk, blk2c_b0, wC, nb,
                        wa, 0, wb, incw, rC, wc, ONE, alpha, ONE, ZERO);
      Mjoin(PATL,tradd)(Uplo, nbF, wC, nb, beta, C, ldc);
      if (ISHERK)
         Mjoin(PATLU,zero)(nbF, C+1, ldcp1);
      c = C + (nbF SHIFT);
      A += incAnF;
      B += incAnF;
      C += nbF*ldcp1;
      ar = wa;
      for (i=0; i < nnblks; i++, c += nb2, A += incAn, ar += pansz)
         Mjoin(PATL,ammmK)(&mminf, nb, nmu, nbF, nnuF, nkblks, nb, kb0, KB0,
                           A, lda, incAk, B, lda, 0, blk2c, c, ldc,
                           ar, incw, wb, incw, rC, wc, ONE, alpha, ONE, beta);
      for (j=0; j < nnblks; j++, B += incAn, C += incCn, wa += pansz)
      {
         Mjoin(PATL,ammmK)(&mminf, nb, nmu, nb, nnu, nkblks, nb, kb0, KB0,
                           A, lda, 0, B, lda, incAk, blk2c_b0, wC, nb,
                           wa, incw, wb, incw, rC, wc, ONE, alpha, ONE, ZERO);
         Mjoin(PATL,tradd)(Uplo, nb, wC, nb, beta, C, ldc);
         if (ISHERK)
            Mjoin(PATLU,zero)(nb, C+1, ldcp1);
         c = C + nb2;
         ar = wa + pansz;
         for (i=j+1; i < nnblks; i++, c += nb2, ar += pansz)
            Mjoin(PATL,ammmK)(&mminf, nb, nmu, nb, nnu, nkblks, nb, kb0, KB0,
                              A, lda, 0, B, lda, 0, blk2c, c, ldc, ar, incw,
                              wb, incw, rC, wc, ONE, alpha, ONE, beta);
      }
   }
/*
 * Upper runs backwards: start from last (partial) colpan, go left.  This
 * allows col-major access on Upper, avoiding TLB problems on C access.
 * Within the panel, start at diag on bottom and go up.  This allows us to
 * use less A storage, as with lower.  
 */
   else /* if (TA == AtlasUpper) */
   {
      C += nnblks*incCn;
      A += nnblks*incAn;
      B = A;
      Mjoin(PATL,ammmK)(&mminf, nbF, nmuF, nbF, nnuF, nkblks, nb, kb0, KB0,
                        A, lda, incAk, B, lda, incAk, blk2c_b0, wC, nb,
                        wa, 0, wb, incw, rC, wc, ONE, alpha, ONE, ZERO);
      Mjoin(PATL,tradd)(Uplo, nbF, wC, nb, beta, C, ldc);
      if (ISHERK)
         Mjoin(PATLU,zero)(nbF, C+1, ldcp1);
      c = C - nb2;
      C -= incCn;
      A -= incAn;
      B -= incAn;
      ar = wa;
      for (i=0; i < nnblks; i++, c -= nb2, A -= incAn, ar += pansz)
         Mjoin(PATL,ammmK)(&mminf, nb, nmu, nbF, nnuF, nkblks, nb, kb0, KB0,
                           A, lda, incAk, B, lda, 0, blk2c, c, ldc,
                           ar, incw, wb, incw, rC, wc, ONE, alpha, ONE, beta);
      for (j=0; j < nnblks; j++, B -= incAn, C -= incCn, wa += pansz)
      {
         Mjoin(PATL,ammmK)(&mminf, nb, nmu, nb, nnu, nkblks, nb, kb0, KB0,
                           A, lda, 0, B, lda, incAk, blk2c_b0, wC, nb,
                           wa, incw, wb, incw, rC, wc, ONE, alpha, ONE, ZERO);
         Mjoin(PATL,tradd)(Uplo, nb, wC, nb, beta, C, ldc);
         if (ISHERK)
            Mjoin(PATLU,zero)(nb, C+1, ldcp1);
         c = C - nb2;
         ar = wa + pansz;
         for (i=j+1; i < nnblks; i++, c -= nb2, ar += pansz)
            Mjoin(PATL,ammmK)(&mminf, nb, nmu, nb, nnu, nkblks, nb, kb0, KB0,
                              A, lda, 0, B, lda, 0, blk2c, c, ldc, ar, incw,
                              wb, incw, rC, wc, ONE, alpha, ONE, beta);
      }
   }
   return(0);
}
#ifndef TCPLX
   #undef ONE
   #undef ZERO
   #undef rC
   #undef incw2
#endif
@ROUT prefparse
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -b <ipf> : translate pref bitvec to string\n");
   fprintf(stderr, "   -p <Ab> <Bb> <C> <Ak> <Bk>\n");
   fprintf(stderr, "      Each arg to -p is the cache level to prefetch to.\n");
   fprintf(stderr, "      0 means do not prefetch, 3 means pfX\n");
   exit(ierr ? ierr : -1);
}

int GetFlags(int nargs, char **args, int ipfs[5])
{
   int i, k, ipf;
   if (nargs < 2)
   {
      fprintf(stderr, "\nMUST SPECIFY EITHER -p OR -b!\n");
      PrintUsage(args[0], 1, NULL);
   }
   ipf = 0;
   ipfs[0] = -1;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'b':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         ipf = atoi(args[i]);
         break;
      case 'p':
         for (k=0; k < 5; k++)
         {
            int j;
            if (++i >= nargs)
                PrintUsage(args[0], i-1, NULL);
            j = ipfs[k] = atoi(args[i]);
            if (j > 3 || j < 0)
               PrintUsage(args[0], i, "Cache level out of range");
         }
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (ipf && ipfs[0] != -1)
   {
      printf("\nCANNOT SPECIFY BOTH -p AND -b!\n");
      PrintUsage(args[0], 1, NULL);
   }
   return(ipf);
}

int main(int nargs, char **args)
{
   int ipf, ipfs[5];

   ipf = GetFlags(nargs, args, ipfs);
   if (ipfs[0] == -1)  /* translating bitvec to string */
   {
      printf("IPF=%d:", ipf);
      PrintPref(stdout, ipf);
      printf("\n");
   }
   else  /* translate pref setting to bitvec */
   {     /* ipfs = 0:Ab 1:Bb 2:C 3:Ak 4:Bk */
      ipf = 0;
      if (ipfs[0])
      {
         ipf |= 2;
         if (ipfs[0] == 1)
            ipf |= 64;
         else if (ipfs[0] == 3)
            ipf |= 512;
      }
      if (ipfs[1])
      {
         ipf |= 4;
         if (ipfs[1] == 1)
            ipf |= 128;
         else if (ipfs[1] == 3)
            ipf |= 1024;
      }
      if (ipfs[2])
      {
         ipf |= 1;
         if (ipfs[2] == 1)
            ipf |= 32;
         else if (ipfs[2] == 3)
            ipf |= 256;
      }
      if (ipfs[3])
      {
         ipf |= 8;
         if (ipfs[3] == 1)
            ipf |= 2048;
         else if (ipfs[3] == 3)
            ipf |= 8192;
      }
      if (ipfs[4])
      {
         ipf |= 16;
         if (ipfs[4] == 1)
            ipf |= 4096;
         else if (ipfs[4] == 3)
            ipf |= 16384;
      }
      printf("Ab=%d, Bb=%d, C=%d, Ak=%d, Bk=%d: bitvec=%d\n", 
             ipfs[0],ipfs[1],ipfs[2],ipfs[3],ipfs[4], ipf);
   }/* ipfs = 0:Ab 1:Bb 2:C 3:Ak 4:Bk */
   return(0);
}
@ROUT szblk
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
int main(int nargs, char **args)
{
   int i, iarr[5];
   if (nargs != 6)
   {
      /* entry in iarr:            0    1    2    3      4 */
      fprintf(stderr, "USAGE: %s <mb> <nb> <mu> <nu> <vlen>\n", args[0]);
      exit(1);
   }
   for (i=0; i < 5; i++)
   {
      int k;
      k = atoi(args[i+1]);
      assert (k > 0);
      if (i == 2 || i == 3)
         assert(k < iarr[i-2]);
      iarr[i] = k;
   }
   i = getsz(iarr[0],iarr[1],iarr[2],iarr[3],iarr[4]);
   printf("BLOCKSIZE=%d\n", i);
   return(0);
}
@ROUT uammgen
@extract -b @(topd)/cw.inc lang=C -def cwdate 2015 
#include "atlas_misc.h"
#include "atlas_mmgen.h"
#include "atlas_sys.h"

#define NMMLISTS 2
#define IUSR   0
#define IUSRK1 1

   static int UID=0, UIL=1;
   static char unam[16];

@extract -b @(basd)/atlas.base rout=Mylcm
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -p [s,d]: set type/precision prefix (d) \n");
   fprintf(stderr, "      s/d will generate for complex (c/z) as well\n");
   fprintf(stderr, "   -d <outdir>: directory to dump files to\n");
   fprintf(stderr, 
      "   -I <ID>: unique non-negative ID for header/kern files\n");
   fprintf(stderr, "   -ub [r,c] <user-case kernel file> \n");
   fprintf(stderr, "   -uk [r,c] <user-case KClean file (if needed)>\n");
   exit(ierr ? ierr : -1);
}


/*
 * RETURNS: precision prefix [s,d,c,z]
 */
char *GetFlags(int nargs, char **args, char *PRE, ATL_mmnode_t **lists)
{
   int i, j=0, n, k;
   int GotAnySumFile = 0;
   char pre='d', cpre, ch;
   char *outd=NULL;
   char *fn[2]={"uAMMRES.sum","uAMMKCLEAN.sum"};

   for (i=0; i < 2*NMMLISTS; i++)
      lists[i] = NULL;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         pre = tolower(args[i][0]);
         if (pre == 'z')
            pre = 'd';
         else if (pre == 'c')
            pre = 's';
         assert(pre == 's' || pre == 'd');
         cpre = (pre == 'd') ? 'z' : 'c';
         break;
      case 'I':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         UID = atoi(args[i]);
         for (k=10; k<=UID; k*=10)
            UIL++;
         break;
      case 'u':
         GotAnySumFile = 1;
         switch(args[i][2])
         {
      @multidef i   0 1
      @whiledef flg b k
         case '@(flg)': /* [r,c] <file> */
            if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            ch = args[i][0];
            if (ch == 'c')
               k = NMMLISTS + @(i);
            else if (ch == 'r')
               k = @(i);
            else
               PrintUsage(args[0],i, "1st arg to -u@(flg) must be 'r' or 'c'!");
            if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            lists[k] = ReadMMFile(args[i]);
            assert(lists[k]);
            break;
      @undef i
      @endwhile
         default:
            PrintUsage(args[0], i, args[i]);
         }
         break;
      case 'd':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        outd = DupString(args[i]);
        break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   *PRE = pre;
   sprintf(unam, "u%d", UID);
/*
 * Fill in any required list entry
 */
   for (i=0; i < 2*NMMLISTS; i++)
   {
      const char pr=(i<NMMLISTS) ? pre : cpre;
      const int k = (i<NMMLISTS) ? i : i-NMMLISTS;
      if (!lists[i] && (!GotAnySumFile || (i&1==0)))
         lists[i] = ReadMMFileWithPath(pr, "res", fn[k]);
      if (!lists[i])
         fprintf(stderr, "CANNOT FIND FILE 'res/%c%s'!\n", pr, fn[k]);
      if (i&1 == 0) assert(lists[i]);
   }
   return(outd);
}


double GenPerfH(char pre, char *outd, char *cn, double mfMax,
                ATL_mmnode_t *mb, ATL_mmnode_t *k1)
{
   FILE *fp;
   ATL_mmnode_t *mp;
   #define NTHRSH 11
   int THRSH[NTHRSH] = {25, 33, 50, 66, 75, 80, 85, 90, 95, 98, 99};
   int idxT[NTHRSH];
   ATL_mmnode_t *mpT[NTHRSH];
   const int FNDMAX = (mfMax == 0.0);
   int i, n, idxMax=0;
   double fcnt;

   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "perf", mb);
/*
 * If not already set, compute the max perf & its index.  We'll use this
 * max as the denominator in our PERF array.
 */
   if (FNDMAX)
   {
      for (i=0; i < NTHRSH; i++)
         mpT[i] = NULL;
      for (n=0,mp=mb; mp; n++, mp = mp->next)
      {
         if (mp->mflop[0] > mfMax)
         {
            mfMax = mp->mflop[0];
            idxMax = n;
         }
      }
   }
/*
 * If our denom comes from other file, just count the number of entries
 */
   else
   {
      for (n=0,mp=mb; mp; n++, mp = mp->next);
      idxMax = -1;
   }
   fprintf(fp, "#define ATL_%sAMM_NCASES %d\n", cn, n);
   fprintf(fp, "#define ATL_%sAMM_DENOM %le /* (%.2f)*/ \n", cn,
           mfMax, mfMax);
   fprintf(fp, "#define ATL_%sAMM_MAXMFLOPIDX %d\n\n", cn, idxMax);
   if (FNDMAX)
   {
      for (n=0,mp=mb; mp; mp = mp->next, n++)
      {
         double mf = mp->mflop[0] / mfMax;
         for (i=0; i < NTHRSH; i++)
         {
            if (!mpT[i] && THRSH[i]*0.01*mfMax < mp->mflop[0])
            {
               mpT[i] = mp;
               idxT[i] = n;
            }
         }
      }
      for (i=0; i < NTHRSH; i++)
      {
         mp = mpT[i];
         fprintf(fp, "#define ATL_%sAMM_%dLCMU %d\n", cn, THRSH[i],
                 Mylcm(Mylcm(mp->mu,mp->nu),mp->ku));
         fprintf(fp, "#define ATL_%sAMM_%dLCMMN %d\n", cn, THRSH[i],
                 Mylcm(mp->mu,mp->nu));
         fprintf(fp, "#define ATL_%sAMM_%dMB %d\n", cn, THRSH[i], mp->mbB);
         fprintf(fp, "#define ATL_%sAMM_%dNB %d\n", cn, THRSH[i], mp->nbB);
         fprintf(fp, "#define ATL_%sAMM_%dKB %d\n", cn, THRSH[i], mp->kbB);
         fprintf(fp, "#define ATL_%sAMM_%dIDX %d\n", cn, THRSH[i], idxT[i]);
      }
      mp = ATL_FindLastNode(mb, GetOffset(&mb->next, mb));
      fprintf(fp, "#define ATL_%sAMM_LCMU %d\n", cn, 
              Mylcm(Mylcm(mp->mu,mp->nu),mp->ku));
      fprintf(fp, "#define ATL_%sAMM_LCMMN %d\n", cn, Mylcm(mp->mu,mp->nu));
      fprintf(fp, "\n");
   }

   fprintf(fp, "#if !defined(NOPERF) && !defined(NOARRS)\n");
   fprintf(fp, "static const float ATL_%sAMM_PERF[%d] =\n", cn, n);
   fprintf(fp, "{  /* %% of performance of best kernel */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d, mf=%.0f */\n", mp->mflop[0]/mfMax,
              (mp->next)?',':' ', i, mp->kbB, mp->mflop[0]);
   fprintf(fp, "};\n#endif\n\n");

   if (k1)
   {
      ATL_mmnode_t *kp;
      fprintf(fp, "#if !defined(NOK1RATIO) && !defined(NOARRS)\n");
      fprintf(fp, "static const float ATL_%sAMM_K1RATIO[%d] =\n", cn, n);
      fprintf(fp, "{  /* ratio of %sAMM perf wt that of its K=1 K-cleaner */\n",
              cn);
      for (i=0,mp=mb,kp=k1; mp; i++,mp = mp->next,kp = kp->next)
         fprintf(fp, "   %f%c  /* IDX=%d, KB=%d IDs=[%d,%d]*/\n", 
                 kp->mflop[0]/mp->mflop[0], (mp->next)?',':' ', i, mp->kbB,
                 mp->ID, kp->ID);
      fprintf(fp, "};\n#endif\n\n");
   }

   fprintf(fp, "#if !defined(NOTIME) && !defined(NOARRS)\n");
   fprintf(fp, "static const float ATL_%sAMM_TIME[%d] =\n", cn, n);
   fprintf(fp, "{  /* actual seconds to compute one block */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      if (mp->blask == 0)
         fcnt = (2.0*mp->mbB)*mp->nbB*mp->kbB;  /* gemm flop count */
      else
         fcnt = (1.0*mp->mbB)*mp->nbB*mp->kbB;  /* roughly right */
      fprintf(fp, "   %e%c  /* IDX=%d, B=(%d,%d,%d) */\n",
              fcnt / (mp->mflop[0]*1.0e6),
              (mp->next)?',':' ', i, mp->mbB, mp->nbB, mp->kbB);
   }
   fprintf(fp, "};\n#endif\n");
   CloseGenHeader(fp);
   return(mfMax);
}

void GenKernH
   (char pre, char *outd, char *cn, ATL_mmnode_t *mb, ATL_mmnode_t *mkb,
    ATL_mmnode_t *ub)
{
   FILE *fp;
   int ib, inxt, iaut;
   char bes[3] = {'0', '1', 'n'};

   inxt = GetOffset(&mb->next, mb);
   iaut = GetOffset(&ub->auth, ub);
   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "kern", mb);
   for (ib=0; ib < 3; ib++)
      PrintMMProtos(fp, pre, "KERN", ub, iaut, bes[ib]);
   for (ib=0; ib < 3; ib++)
   {
      PrintStrArrAtOff(fp, pre, "KERN", mb, inxt, iaut, "ammkern_t", 
                       0, 0, bes[ib]);
      if (mkb)
         PrintStrArrAtOff(fp, pre, "KERN_K1", mkb, inxt, iaut, "ammkern_t", 
                          0, 0, bes[ib]);
   }
   CloseGenHeader(fp);
}

void PrintFlagArr(FILE *fp, ATL_mmnode_t *mb)
{
   ATL_mmnode_t *mp;
   int n;

   n = CountListEntries(mb, GetOffset(&mb->next, mb));
   fprintf(fp, "#ifndef NOKFLAG\n");
   fprintf(fp, "static const unsigned char ATL_AMM_KFLAG[%d] =\n{\n", n);
   for (n=0,mp=mb; mp; n++, mp = mp->next)
   {
      unsigned char flag=FLAG_IS_SET(mp->flag, MMF_KRUNTIME) ? 1 : 0;
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         flag |= 2;
      fprintf(fp, "%6d%c   /* IDX=%d */\n", flag, mp->next ? ',':' ', n);
   }
   fprintf(fp, "};\n");
   fprintf(fp, "   #define ATL_AMM_KRUNTIME(idx_) (ATL_AMM_KFLAG[idx_] & 1)\n");
   fprintf(fp, "   #define ATL_AMM_KMAJOR(idx_) (ATL_AMM_KFLAG[idx_] & 2)\n");
   fprintf(fp, "#endif\n");
}
void GenBlkH(char pre, char *outd, char *cn, ATL_mmnode_t *mb)
{
   FILE *fp;
   ATL_mmnode_t *mp;
   int *KUs;
   int i, n, inxt;

   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "blk", mb);
   inxt = GetOffset(&mb->next, mb);
   mp = ATL_FindLastNode(mb, inxt);
   fprintf(fp, "#define ATL_%sAMM_LASTMB %d\n", cn, mp->mbB);
   fprintf(fp, "#define ATL_%sAMM_LASTNB %d\n", cn, mp->nbB);
   fprintf(fp, "#define ATL_%sAMM_LASTKB %d\n", cn, mp->kbB);
   fprintf(fp, "\n");
/*
 * Save original KUs, and overwrite compile-time-K KUs with kbB for printing
 */
   n = CountListEntries(mb, inxt);
   KUs = malloc(sizeof(int)*n*3);
   assert(KUs);
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      KUs[i] = mp->ku;
      KUs[i+n] = mp->kbmin;
      KUs[i+n+n] = mp->kbmax;
      #if 0
      if (FLAG_IS_SET(mp->flag,MMF_KUISKB))
         mp->kbmin = mp->kbmax = mp->ku = mp->kbB;
      else if (!FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
         mp->kbmin = mp->kbmax = mp->kbB;
      #endif
   }
   @multidef st VLENs KBMAXs KBMINs KUs NUs MUs KBs NBs MBs
   @whiledef iv vlen  kbmax  kbmin  ku  nu  mu  kbB nbB mbB
@skip   PrintMMIntOffArr(fp, pre, "@(st)", mb, GetOffset(&mb->@(iv), mb));
   PrintIntArrAtOff(fp, pre, "@(st)", mb, inxt, GetOffset(&mb->@(iv), mb),0,0);
      @undef st
   @endwhile
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      mp->ku = KUs[i];
      mp->kbmin = KUs[i+n];
      mp->kbmax = KUs[i+n+n];
   }
   PrintFlagArr(fp, mb);
   free(KUs);
   CloseGenHeader(fp);
}

int StrFindReplace(char **org, char *find, char *replace)
{
   char *pre, *post, *final;
   char *orig = *(org);
   int idx = (strstr(orig, find) - orig) / sizeof(char);
   int len = strlen(orig);
   int flen = strlen(find);
   int rlen = strlen(replace);
   if (idx < 0) return(len); /* not found */
   pre = malloc(sizeof(char)*idx + 1);
   post = malloc(sizeof(char)*(len - idx - flen) + 1);
   strncpy(pre, orig, idx);
   pre[idx] = '\0';
   strcpy(post, orig+idx+flen);
   len = len - flen + rlen;
   free(orig);
   orig = malloc(sizeof(char)*(len) + 1);
   strcpy(orig, pre);
   strcat(orig, replace);
   strcat(orig, post);
   *org = orig;
   return(len);
}

void AdjustCPNamesWithID(char pre, ATL_cpnode_t *cb)
{
   char find[24] = "";
   char replace[24] = "";
   ATL_cpnode_t *cp;
   sprintf(find, "ATL_%c", pre);
   sprintf(replace, "ATL_%cu%d", pre, UID);
   for (cp=cb; cp; cp=cp->next)
      cp->rtlen = StrFindReplace(&cp->rout, find, replace);
}

void GenCpyA(char pre, char *outd, char *cn, char dir, char alp, 
             ATL_mmnode_t *mb)
/* presently leaving alp='[1,n,X]', cn=[ge,sq,rk], dir='[F,T]' to caller */
{
   FILE *fp;
   const int nt = (pre == 'd' || pre == 's') ? 2 : 4;
   int flag=0, i, j, it, im;
   char tas[4] = {'N', 'T', 'C', 'H'};
   char mats[2] = {'A', 'B'};
   char arrnm[12]={'x', 'x', '2', 'B', 'L', 'K', '_', 'a', alp, '\0'};
   char fn[12];
   int mati, transi;

   if (dir == 'T')
   {
      sprintf(fn, "cm2am_a%c", alp);
      mati = 0; transi = 1;
   }
   else
   {
      sprintf(fn, "am2cm_a%c", alp);
      sprintf(arrnm, "BLK2xx_a%c", alp);
      mati = 4; transi = 5;
   }
   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, fn, mb);
   fn[6] = 't'; fn[7] = '\0';  /* switch fn to type name */

   for (im=0; im < 2; im++)
   {
      arrnm[mati] = mats[im];
      for (it=0; it < nt; it++)
      {
         ATL_cpnode_t *cb, *ucb;
         int i;
         const char ta = tas[it]; 

         arrnm[transi] = ta;
         cb = GetMMCopyFromMMNodes(CopyEncode(pre, dir, mats[im], ta), mb);
         assert(cb);
         AdjustCPNamesWithID(pre, cb);
         ucb = AddUniqueCopyNode(NULL, cb);
         arrnm[6] = '\0';
         PrintMMCpProtosA(fp, arrnm, ucb, dir, alp);
         KillAllCopyNodes(ucb);
         PrintStrArrAtOff(fp, pre, arrnm, cb, GetOffset(&cb->next, cb),
                          GetOffset(&cb->rout, cb), fn, ta, alp, 0);
         KillAllCopyNodes(cb);
      }
   }
   CloseGenHeader(fp);
}

void GenCpyC(FILE *fp, char pre, char *outd, char *cn, char dir, char *type, 
             char alp, char bet, ATL_mmnode_t *mb)
{
   char *arrnm = (dir == 'T') ? "C2BLK" : "BLK2C";
   ATL_cpnode_t *cb, *ucb;
   int flag=0, i, j;

   cb = GetMMCopyFromMMNodes(CopyEncode(pre, dir, 'c', 'n'), mb);
   assert(cb);
   AdjustCPNamesWithID(pre, cb);
   #ifdef Debug
      i = CountListEntries(cb, GetOffset(&cb->next, cb));
      j = CountListEntries(mb, GetOffset(&mb->next, mb));
      fprintf(stderr, "ncpy=%d, nmm=%d!\n", i, j);
   #endif
   ucb = AddUniqueCopyNode(NULL, cb);
   PrintMMCpProtosC(fp, arrnm, ucb, dir, alp, bet);
   KillAllCopyNodes(ucb);
   PrintStrArrAtOff(fp, pre, arrnm, cb, GetOffset(&cb->next, cb),
                    GetOffset(&cb->rout, cb), type, 0, alp, bet);
   KillAllCopyNodes(cb);
}

void PrintDiv(FILE *fp, char *exp, int v)
/* 
 * Prints either exp/v or exp>>lg2(v), dep on v being power of 2 or not 
 * caller must put parens where appropriate (if exp is not a simple variable
 * name, it must have parens to produce the right answer!).
 */
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "%s>>%d", exp, p);
   else
      fprintf(fp, "%s/%d", exp, v);
}
void PrintCeil(FILE *fp, char *exp, int v)
/* 
 * Prints either ((exp+v-1)/v)*v or same things wt shifts if power of 2.
 */
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "((%s+%d)>>%d)", exp, v-1, p);
   else
      fprintf(fp, "((%s+%d)/%d)", exp, v-1, v);
}
void PrintCeilMul(FILE *fp, char *exp, int v)
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "(((%s+%d)>>%d)<<%d)", exp, v-1, p, p);
   else
      fprintf(fp, "(((%s+%d)/%d)*%d)", exp, v-1, v, v);
}

void GenFullCpyC(char pre, char *outd, char dir, char *cn, ATL_mmnode_t *mb)
{
   ATL_mmnode_t *mp;
   FILE *fp;
   int ib, NEEDSZF=0;
   char rt[16];
   char bets[4] = {'0', '1', 'n', 'X'};

/*
 * Create atlas_<pre><cn>szC.h if necessary
 */
   for (mp=mb; mp; mp = mp->next)
      if (FLAG_IS_SET(mp->flag, MMF_KVEC) && ib == -1 &&
          (mp->mu*mp->nu) % mp->vlen != 0)
         break;
   if (mp)
   {
      ATL_cpnode_t *cb, *ucb, *cp;
      int n;
      NEEDSZF=1;
      fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "szC", mb);
      cb = GetMMCopyFromMMNodes(CopyEncode(pre, dir, 'c', 'n'), mb);
      assert(cb);
      AdjustCPNamesWithID(pre, cb);
      ucb = AddUniqueCopyNode(NULL, cb);
      KillAllCopyNodes(cb);
/*
 *    Generate needed funcs for size query
 */
      for (cp=ucb; cp; cp = cp->next)
      {
         const unsigned kvec=cp->kvec;
         const unsigned int mu=cp->mu, nu=cp->nu, b = mu*nu;
         const unsigned int B = (kvec > 1) ? ((b+kvec-1)/kvec)*kvec : 0;
         fprintf(fp, "#define uint unsigned int\n");
         if (b != B)
         {
            assert(!cp->ID);
            fprintf(fp, "static uint ATL_szC_%dx%d(uint M, uint N, "
                        "uint mu, uint nu, uint vlen)", mu, nu);
            fprintf(fp, "\n{\n");
            fprintf(fp, "   return(");
            PrintCeilMul(fp, "M", mu);
            fprintf(fp, "*");
            PrintCeilMul(fp, "N", nu);
            fprintf(fp, "*");
            fprintf(fp, "%d);\n", B);
            fprintf(fp, "}\n");
         }
         fprintf(fp, "typedef uint (*szC_t)(uint,uint,uint,uint,uint);\n");
         fprintf(fp, "#undef uint\n");
         for (n=0,cp=cb; cp; n++, cp = cp->next);
         fprintf(fp, "static szC_t ATL_AMM_SZCW[%d] =\n{\n", n);
         for (cp=cb,n=0; cp; cp = cp->next,n++)
         {
            const unsigned kvec=cp->kvec;
            const unsigned int mu=cp->mu, nu=cp->nu, b = mu*nu;
            const unsigned int B = (kvec > 1) ? ((b+kvec-1)/kvec)*kvec : 0;
            fprintf(fp, "/* IDX=%d */ ", n);
            if (b != B)
               fprintf(fp, "ATL_szC_%dx%d", mu, nu);
            else
               fprintf(fp, "NULL"); 
            if (cp->next)
               fprintf(fp, ",\n");
            else
               fprintf(fp, "\n");
         }
      }
      KillAllCopyNodes(cb);
      CloseGenHeader(fp);
   }
#if 0
#endif

   if (dir == 'T')
      strcpy(rt, "cmat2ablk");
   else
      strcpy (rt, "ablk2cmat");

   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, rt, mb);
   if(NEEDSZF)
   {
      fprintf(fp, "#ifndef NOSZC\n");
      fprintf(fp, "   #include \"atlas_%c%sszC.h\"\n", pre, cn);
      fprintf(fp, "#endif\n");
   }
   rt[9] = '_'; rt[10] = 't'; rt[11] = '\0';
@skip   strcpy(rt, dir == 'T' ? "cmat2ablk_t" : "ablk2cmat_t");
   for (ib=0; ib < 4; ib++)
   {
      int ia;
      char alps[3] = {'1', 'n', 'X'};
      const char bet = bets[ib];

      for (ia=0; ia < 3; ia++)
         GenCpyC(fp, pre, outd, cn, dir, rt, alps[ia], bet, mb);
   }
   CloseGenHeader(fp);
}

void GenAllCpyC(char pre, char *outd, char dir, ATL_mmnode_t *ub)
{
   if (ub)
      GenFullCpyC(pre, outd, dir, unam, ub);
}
void GenAllCpyA(char pre, char *outd, char dir, ATL_mmnode_t *ub)
/* presently leaving dir='[F,T]' to caller */
{
   int ia;
   char alps[3] = {'1', 'n', 'X'};

   for (ia=0; ia < 3; ia++)
   {
      if (ub)
         GenCpyA(pre, outd, unam, dir, alps[ia], ub);
   }
}

double PrintSum(FILE *fp, char *cn, ATL_mmnode_t *b, double mfGE)
{
   int inxt, max, i, kvec;
   double mf;
   ATL_mmnode_t *mp;

   inxt = GetOffset(&b->next, b);
   fprintf(fp, "#define ATL_%sAMM_NCASES %d\n", cn, CountListEntries(b, inxt));
   mp = ATL_FindLastNode(b, inxt);
   fprintf(fp, "#define ATL_%sAMM_LASTMB %d\n", cn, mp->mbB);
   fprintf(fp, "#define ATL_%sAMM_LASTNB %d\n", cn, mp->nbB);
   fprintf(fp, "#define ATL_%sAMM_LASTKB %d\n", cn, mp->kbB);
   mf = mp->mflop[0];
   fprintf(fp, "#define ATL_%sAMM_LASTMU %d\n", cn, mp->mu);
   fprintf(fp, "#define ATL_%sAMM_LASTNU %d\n", cn, mp->nu);
   fprintf(fp, "#define ATL_%sAMM_LASTKU %d\n", cn, mp->nu);
   fprintf(fp, "#define ATL_%sAMM_LASTLCMMN %d\n\n", cn, Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_%sAMM_LASTLCMU %d\n\n", cn,
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   #if 0
   fprintf(fp, "#define ATL_%sAMM_LASTMFLOP %e\n", cn, mf);
   if (mfGE > 0.0)
      fprintf(fp, "#define ATL_%sAMM_MFLOP_RATIO %e\n", cn, mf/mfGE);
   #endif
   for (kvec=0,mp=b; mp; mp = mp->next)
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         kvec = Mmax(kvec, mp->vlen);
   fprintf(fp, "#ifndef  ATL_%sAMM_MAXKVEC\n", cn);
   fprintf(fp, "   #define ATL_%sAMM_MAXKVEC %d\n", cn, kvec);
   fprintf(fp, "#endif\n");
   fprintf(fp, "\n");
   return(mf);
}

void GenSumH(char pre, char *outd, ATL_mmnode_t *ub)
/*
 * cn:[u%d]
 * For [u%d] report: ncases, max[nb,mb,kb]
 * -> for maxB, report: perf,time,ratio wt best user-case
 */
{
   FILE *fp;
   double mf;
   int i;

   fp = OpenMMGenHeader(outd, 0, pre, unam, 0, 0, "sum", ub);
   mf = PrintSum(fp, unam, ub, 0.0);
   CloseGenHeader(fp);
}

void GenAllHeaders(char pre, char *outd, ATL_mmnode_t **lists)
{
   ATL_cpnode_t *cb;
   ATL_mmnode_t *mb;
   char *nm="perf";
   double mfMax;
   int i, k, SKSAME;
   char pr;

/*
 * Handle [perf,blk,flag,sum] which require only ordered lists
 */
   for (pr=pre,k=0; k < 2*NMMLISTS; k += NMMLISTS)
   {
      mfMax = GenPerfH(pr, outd, unam, 0.0, lists[k+IUSR], lists[k+IUSRK1]);

      GenBlkH(pr, outd, unam, lists[k+IUSR]); 
      pr = (pre == 'd') ? 'z' : 'c';
   }
   GenSumH(pre, outd, lists[IUSR]);
   GenSumH(pr, outd, lists[IUSR+NMMLISTS]);
/*
 * Create lists of only the unique kernels for [ub] in real & cplx
 * for use in prototyping.  We combine kern & K1 lists for each.
 * We can now gen [kern].
 */
   for (pr=pre,k=0; k < 2; k++)
   {
      for (i=0; i < 1; i++)
      {
         ATL_mmnode_t *ulst;  /* unordered list of only unique kernels */
         const int h = i+i+k*NMMLISTS, u=k+i;
         ulst = AddUniqueMMKernCompList(NULL, lists[h]);
         ulst = AddUniqueMMKernCompList(ulst, lists[h+1]);
         GenKernH(pr, outd, unam, lists[h], lists[h+1], ulst);
         KillAllMMNodes(ulst);  /* done with these! */
      }
      pr = (pre == 's') ? 'c' : 'z';
   }
/*
 * [cmat2ablk_a[1,n,X]_b[0,1,n,X],ablk2cmat_a?_b?,am2cm_a[1,n,X]]
 * -> have never genned, can we?: am2rm_a[1,n,X],
 */
   GenAllCpyA(pre, outd, 'T', lists[IUSR]);
   GenAllCpyA(pre, outd, 'F', lists[IUSR]);
   GenAllCpyA(pr, outd, 'T', lists[IUSR+NMMLISTS]);
   GenAllCpyA(pr, outd, 'F', lists[IUSR+NMMLISTS]); /* for now */

   GenAllCpyC(pre, outd, 'F', lists[IUSR]);
   GenAllCpyC(pre, outd, 'T', lists[IUSR]);
   GenAllCpyC(pr, outd, 'F', lists[IUSR+NMMLISTS]);
   GenAllCpyC(pr, outd, 'T', lists[IUSR+NMMLISTS]); /* for now */
}

static void AddAlpBetSuf(char *rt, int rl, int ial, int ibe)
/*
 * Add _aXbX suffix to rt, which is presently of length rl
 */
{
   rt[rl] = '_';
   rt[rl+1] = 'a';
   if (ial == -1)
      rt[rl+2] = 'n';
   else if (ial == 2)
      rt[rl+2] = 'X';
   else
      rt[rl+2] = ial+48;
   rt[rl+3] = 'b';
   if (ibe == -1)
      rt[rl+4] = 'n';
   else if (ibe > 1)
      rt[rl+4] = 'X';
   else
      rt[rl+4] = ibe+48;
}

void GenAllKerns(char pre, char *outd, ATL_mmnode_t *rb, 
                 ATL_cpnode_t *cpA, ATL_cpnode_t *cpC)
{
   ATL_cpnode_t *last, *cp;
   ATL_mmnode_t *mp;
   char *sgen;
   int i, len, dlen, mID, mU;
   char pr=pre;
/*
 * join all copy routs into one list temporarily
 */
   last = FindLastCopyNode(cpA);
   last->next = cpC;
/*
 * Get a string of max length for all system calls
 */
   mID=mU=len=i=0;
   for (cp=(!i)?cpA:cpC; cp; cp = cp->next)
   {
      len = Mmax(len, cp->rtlen);
      mID = Mmax(mID, cp->ID);
      mU = Mmax(mU, cp->mu);
      mU = Mmax(mU, cp->nu);
      mU = Mmax(mU, cp->kvec);
   }
   dlen = strlen(outd);
   len += dlen + 1;  /* outd */
   len += 17;  /* " > /dev/null 2>&1" */
   assert(mID == 0);  /* just until we support user copies */
   len += 64 - 2*4;  /* C format string */
   len += 4*NumDecDigits(mU); /* mu,nu,kvec */
   len += 2;                  /* extra for syrk */
   sgen = malloc(len+1);
   assert(sgen);
/*
 * Generate all needed copy routines
 */
   printf("\nGENERATING MMCOPY FILES\n");
   for (cp=cpA; cp; cp = cp->next)
   {
      int flag = cp->flag;
      int k;
      char pr;
      pr = CopyGetPre(cp->flag);
      printf("   -> %s\n", cp->rout);
      if (flag & (1<<CPF_CBLK))
      {
         unsigned int kvec = cp->kvec;
         if (flag & (1<<CPF_SYRK))
         {
            k = sprintf(sgen, 
"make genall_syblk2C pre=%c vec=NA vlen=%d mu=%d nu=%d cpvlen=1 rt=%s/%s.c",
                        pr, kvec, cp->mu, cp->nu, outd, cp->rout);
         }
         else if (flag & (1<<CPF_CBLK))
         {
            k = sprintf(sgen, 
      "make genall_%s pre=%c vec=NA vlen=%d mu=%d nu=%d cpvlen=1 rt=%s/%s.c",
                        (flag&(1<<CPF_TOBLK)) ? "C2blk":"blk2C", pr, 
                        kvec, cp->mu, cp->nu, outd, cp->rout);
         }
      }
      else /* generate A/B copy */
      {
         unsigned int kvec = cp->kvec;
         char *targ;
         if (flag & (1<<CPF_REAL))
            targ = (flag & (1<<CPF_TOBLK)) ? "A2blk":"blk2A";
         else
            targ = (flag & (1<<CPF_TOBLK)) ? "cA2blk":"cblk2A";
         k = sprintf(sgen, 
             "make genall_%s pre=%c kmaj=%d vlen=%d UR=%d cpvlen=1 rt=%s/%s.c",
                     targ, pr, kvec, kvec ? kvec:1, 
                     cp->nu, outd, cp->rout);
      }
      assert(k < len);
      k += sprintf(sgen+k, " > /dev/null 2>&1");
      assert(k <= len);
      if ((k=system(sgen)))
      {
         fprintf(stderr, "\n\ncpgenstr='%s' returns %d!\n\n", sgen, k);
         exit(k);
      }
   }
   printf("DONE GENERATING MMCOPY FILES\n");
   last->next = NULL;  /* disconnect A/C lists */
/*
 * Generate/copy all required kernels.  This list has files with compile-time
 * K repeated, but we'll check ID to avoid repeated copies of user-supplied, 
 * and generated kernels need a new generation for each required KB.
 */
   printf("\nGENERATING AMM KERNS:\n");
   for (mp=rb; mp; mp = mp->next)
   {
      const int id=mp->ID;
      if (!id)
      {
         printf("   -> %s\n", mp->rout);
         assert(mp->genstr);
         if ( (i=system(mp->genstr)) )
         {
            fprintf(stderr, "GENSTR RETURNS %d:\n'%s'\n", i, mp->genstr);
            exit(i);
         }
      }
      else /* user-supplied kernel */
      {
         ATL_mmnode_t *p;
         for (p=rb; p != mp && p->ID != id; p = p->next);
         if (p == mp)  /* this is first mention of this ID */
         {
            printf("   %s -> %s\n", mp->genstr, mp->rout);
            i = strlen(mp->genstr) + strlen(mp->rout) + dlen + 16;
            if (i > len)
            {
               free(sgen);
               sgen = malloc(i*sizeof(char));
               assert(sgen);
               len = i;
            }
            sprintf(sgen, "cp AMMCASES/%s %s/%s", mp->genstr, outd, mp->rout);
            
            if ( (i=system(sgen)) )
            {
               fprintf(stderr, "FAILED CP='%s'\n", sgen);
               exit(i);
            }
         }
         else /* they better have same filename! */
         {
            if (strcmp(mp->rout, p->rout))
            {
               printf("rout=(%s,%s)!\n", mp->rout, p->rout);
               exit(1);
            }
         }
      }
   }
   printf("DONE GENERATING AMM KERNS.\n");
   free(sgen);
}

void GenMake(char pre, char *outd, ATL_mmnode_t *mb,
             ATL_cpnode_t *cpA, ATL_cpnode_t *cpC)
/*
 * mb files have already been made at least compile-time unique (same source
 * file might occur multiple times due to need to compile with -DKB)
 */
{
   FILE *fp;
   char *fn;
   ATL_cpnode_t *cp;
   ATL_mmnode_t *mp;
   char *sals[3] = {"1", "N1", "X"};
   char als[3] = {'1', 'n', 'X'};
   char *sbes[4] = {"0", "1", "N1", "X"};
   char bes[4] = {'0', '1', 'n', 'X'};  /* use 1st 3 for mmkerns */
   char ctas[4] = {'N', 'T', 'C', 'H'};
   char dcomp[8] = {'$', '(', 'D', 'M', 'C', ')', '\0'};
   char dflags[12] = {'$','(','D','M','C','F','L','A','G','S',')','\0'};


   fn = malloc(strlen(outd)+11);
   assert(fn);
   sprintf(fn, "%s/%cMake_amm", outd, pre);
   fp = fopen(fn, "w");
   assert(fp);
   free(fn);
   fprintf(fp, "include ../Make.inc\n");
   fprintf(fp, "CDEFS2=$(CDEFS)\n\n");
/*
 * Spew out kernels to be compiled
 */
   fprintf(fp, "objs =");
   for (mp=mb; mp; mp = mp->next)
   {
      int ib;
      for (ib=0; ib < 3; ib++)
         fprintf(fp, " \\\n       %s_b%c.o", mp->auth, bes[ib]);
   }
   for (cp=cpC; cp; cp = cp->next)  /* C copy routs */
   {
      int ib;
      for (ib=0; ib < 4; ib++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
            fprintf(fp, " \\\n       %s_a%cb%c.o", cp->rout, als[ia], bes[ib]);
      }
   }

   for (cp=cpA; cp; cp = cp->next)  /* A/B copy routs */
   {
      const int NTA = (cp->flag & (1<<CPF_REAL)) ? 2:4;
      int it;
      for (it=0; it < NTA; it++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
            fprintf(fp, " \\\n       %s_%ca%c.o", cp->rout, ctas[it], als[ia]);
      }
   }
   fprintf(fp, "\n");
/*
 * library make targets
 */
   fprintf(fp, "\n\nlib : %clib.grd\nall : %clib.grd\n%clib : %clib.grd\n",
           pre, pre, pre, pre);
   fprintf(fp, "%clib.grd : $(objs)\n", pre);
   fprintf(fp, "\t$(ARCHIVER) $(ARFLAGS) $(UAMMlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(UAMMlib)\n");
   fprintf(fp, "\t touch %clib.grd\n", pre);
   fprintf(fp, "clean : %cclean\n", pre);
   fprintf(fp, "%cclean:\n\t- rm -f $(objs)\n", pre);
   fprintf(fp, "killall : %ckillall\n", pre);
   fprintf(fp, "%ckillall : %cclean\n", pre, pre);
   fprintf(fp, "\t- $(ARCHIVER) d $(UAMMlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(UAMMlib)\n");
   fprintf(fp, "\t- rm -f ATL_%c*.[S,c]\n\n", pre);
/*
 * Make targets for amm kerns
 */
   fprintf(fp, "#\n#  AMM kernel rules\n#\n");
   fn = (pre == 'd' || pre == 'z') ?  "-DDREAL=1" : "-DSREAL";
   for (mp=mb; mp; mp = mp->next)
   {
      int ib;
      char *comp, *flgs;

      comp = GetMMKernComp(mp, dcomp, dflags, &flgs);
      for (ib=0; ib < 3; ib++)
      {
         char *sp=" ";
         fprintf(fp, "%s_b%c.o : %s\n", mp->auth, bes[ib], mp->rout);
         fprintf(fp, "\t%s $(CDEFS2) %s -DBETA%s=1 \\\n", comp, fn, sbes[ib]);
         if (!FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
            fprintf(fp, "        -DMB=%d -DNB=%d -DKB=%d", 
                    mp->mbB, mp->nbB, mp->kbB);
         else
            sp = "        ";
   @whiledef mtx C B A
         if (FLAG_IS_SET(mp->flag, MMF_MV@(mtx)))
         {
            fprintf(fp, "%s-DATL_MOVE@(mtx)", sp);
            sp = " ";
         }
   @endwhile
         fprintf(fp, " \\\n        %s \\\n", flgs);
         fprintf(fp, 
                 "        -DATL_USERMM=%s_b%c \\\n        -c -o %s_b%c.o \\\n",
                 mp->auth, bes[ib], mp->auth, bes[ib]);
         fprintf(fp, "        %s\n", mp->rout);
      }
   }
/*
 * Make targets for C copy routines
 */
   fprintf(fp, "#\n#  C copy rules\n#\n");
   dflags[3] = dcomp[3] = 'K';
   for (cp=cpC; cp; cp = cp->next)  /* C copy routs */
   {
      char *styp;
      int ib;
      char pr;

      styp = CopyGetCompType(cp->flag);
      for (ib=0; ib < 4; ib++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
         {
            fprintf(fp, "%s_a%cb%c.o : %s.c\n", cp->rout, als[ia], bes[ib], 
                    cp->rout);
            fprintf(fp, "\t%s %s -c $(CDEFS) -D%s=1 -DBETA%s=1 -DALPHA%s=1",
                    dcomp, dflags, styp, sbes[ib], sals[ia]);
            fprintf(fp, 
            " \\\n           -DATL_USERCPMM=%s_a%c_b%c -DATL_MU=%d -DATL_NU=%d",
                    cp->rout, als[ia], bes[ib], cp->mu, cp->nu);
            fprintf(fp, " \\\n           -o %s_a%cb%c.o %s.c\n", 
                    cp->rout, als[ia], bes[ib], cp->rout);
         }
      }
   }
/*
 * Make targets for A/B copy routines
 */
   fprintf(fp, "#\n#  A/B copy rules\n#\n");
   for (cp=cpA; cp; cp = cp->next) 
   {
      char *styp, *cnj[2] = {"", "-DConj_=1"};
      const int flag = cp->flag;
      const int NC = (flag&(1<<CPF_REAL)) ? 1 : 2;
      int ic;
      char pr;
      styp = CopyGetCompType(cp->flag);
      for (ic=0; ic < NC; ic++)
      {
         int it;
         for (it=0; it < 2; it++)
         {
            int ia;
            const int itc = ic*NC+it;
            for (ia=0; ia < 3; ia++)
            {
               fprintf(fp, "%s_%ca%c.o : %s.c\n", cp->rout, ctas[itc], 
                       als[ia], cp->rout);
               fprintf(fp, "\t%s %s -c $(CDEFS) -D%s=1 -DALPHA%s=1",
                       dcomp, dflags, styp, sals[ia]);
               fprintf(fp, " \\\n           -DATL_NU=%d -DTRANS%c_=1 %s", 
                       cp->nu, ctas[it],  cnj[ic]);
               fprintf(fp, " \\\n           -DATL_USERCPMM=%s_%ca%c", cp->rout, 
                       ctas[itc], als[ia]);
               fprintf(fp, " \\\n           -o %s_%ca%c.o %s.c\n", 
                       cp->rout, ctas[itc], als[ia], cp->rout);
            }
         }
      }
   }
   fclose(fp);
}

void GenAllFiles(char pre, char *outd, ATL_mmnode_t **lists)
{
   FILE *fp;
   int i, RCSAME;
   ATL_mmnode_t *rb=NULL, *ib=NULL, *mp;
   ATL_cpnode_t *cpA=NULL, *cpC=NULL, *ncp;
   const char cpr = (pre == 'd') ? 'z' : 'c';
/*
 * First, generate performance files, which require routs separated by
 * various lists
 */
   printf("\nGENERATING HEADER FILES\n");
   GenAllHeaders(pre, outd, lists);
   printf("DONE HEADER GENERATION\n");

/*
 * Generating kernels & Makefile do not care which list kernels came from,
 * or their order, so combine them all into one list for each data type 
 * (2 lists total: real,complex), and remove any redundancies.
 * NOTE2: I think we should generate copy routs at this time and then
 *        can pass info to GenAllKerns & GenMake.
 */
   for (i=0; i < NMMLISTS; i++)
   {
      rb = AddUniqueMMKernCompList(rb, lists[i]);
      KillAllMMNodes(lists[i]);
      ib = AddUniqueMMKernCompList(ib, lists[NMMLISTS+i]);
      KillAllMMNodes(lists[NMMLISTS+i]);
   }
/*
 * Now create lists of copy routines for both real & complex
 */
   GetMMAllUniqueCopyFromMMNodes(pre, 'F', 'T', rb, &cpA, &cpC);
   GetMMAllUniqueCopyFromMMNodes(pre, 'T', 'F', rb, &cpA, &cpC);
   GetMMAllUniqueCopyFromMMNodes(cpr, 'F', 'T', ib, &cpA, &cpC);
   GetMMAllUniqueCopyFromMMNodes(cpr, 'T', 'F', ib, &cpA, &cpC); /* for now */
/*
 * Now, kerns are compiled the same for real and complex, so reduce real
 * and complex to one unique list
 */
   rb = AddUniqueMMKernCompList(rb, ib);
   KillAllMMNodes(ib);
   AdjustCPNamesWithID(pre, cpA);
   AdjustCPNamesWithID(cpr, cpA);
   AdjustCPNamesWithID(pre, cpC);
   AdjustCPNamesWithID(cpr, cpC);
   GenAllKerns(pre, outd, rb, cpA, cpC);
   GenMake(pre, outd, rb, cpA, cpC);
   KillAllMMNodes(rb);
   KillAllCopyNodes(cpA);
   KillAllCopyNodes(cpC);
}

void AdjustMMNamesWithID(char pre, ATL_mmnode_t *mb)
{
   char find[24] = "";
   char replace[24] = "";
   ATL_mmnode_t *mp;
   sprintf(find, "ATL_%c", pre);
   sprintf(replace, "ATL_%cu%d", pre, UID);
   for (mp=mb; mp; mp=mp->next)
      StrFindReplace(&mp->auth, find, replace);
}

int main(int nargs, char **args)
{
   char *outd;
   ATL_mmnode_t *lists[2*NMMLISTS];
   int i;
   char pre, cpr;

   outd = GetFlags(nargs, args, &pre, lists);
   cpr = (pre == 'd') ? 'z' : 'c';
/*
 * Prep file for generation.  Free present values, and replace with:
 * ->auth  : kernel name without _b[1,n,0] suffix
 * ->genstr: for ID=0: genstr, else user kernel name (came in ->rout)
 * ->rout  : correct present filename
 */
   for (i=0; i < 2*NMMLISTS; i++)
   {
      PrepMMForGen(pre, outd, "amm", lists[i]);
   }
   for (i=0; i < 2*NMMLISTS; i++)
      AdjustMMNamesWithID(pre, lists[i]);

   GenAllFiles(pre, outd, lists);

   free(outd);
   return(0);
}
@ROUT ammgen
@extract -b @(topd)/cw.inc lang=C -def cwdate 2015 
#include "atlas_misc.h"
#include "atlas_mmgen.h"
#include "atlas_sys.h"

#define NMMLISTS 8
#define IGE   0
#define IGEK1 1
#define ISQ   2
#define ISQK1 3
#define IRKK  4
#define ITRSM 5
#define ISYRK 6
#define ISYRKT 7

@extract -b @(basd)/atlas.base rout=Mylcm
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -p [s,d]: set type/precision prefix (d) \n");
   fprintf(stderr, "      s/d will generate for complex (c/z) as well\n");
   fprintf(stderr, "   -d <outdir>: directory to dump files to\n");
   fprintf(stderr, "   -g [r,c] <rect kern file> <geKCleanFile>\n");
   fprintf(stderr, "   -r [r,c] <rank-K kernel file> \n");
   fprintf(stderr, "   -s [r,c] <square-case kernel file> <sqKCleanFile>\n");
   fprintf(stderr, "   -t [r,c] <trsm file> : should match -s\n");
   fprintf(stderr, "   -k syrk <syrk file> \n");
   exit(ierr ? ierr : -1);
}


/*
 * RETURNS: precision prefix [s,d,c,z]
 */
char *GetFlags(int nargs, char **args, char *PRE, ATL_mmnode_t **lists)
{
   int i, j=0, n, k;
   char pre='d', cpre, ch;
   char *outd=NULL;
   char *fn[8]={"geAMMRES.sum","geAMMKCLEAN.sum",
      "sqAMMRES.sum","sqAMMKCLEAN.sum", "rkAMMRES.sum", 
      "tsAMMRES.sum","gAMSYRK.sum", "syrkK.sum"};

   for (i=0; i < 2*NMMLISTS; i++)
      lists[i] = NULL;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        if (pre == 'z')
           pre = 'd';
        else if (pre == 'c')
           pre = 's';
        assert(pre == 's' || pre == 'd');
        cpre = (pre == 'd') ? 'z' : 'c';
        break;
   @multidef i   0 2
   @whiledef flg g s
      case '@(flg)': /* [r,c] <amm file> <K1file> */
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        ch = args[i][0];
        if (ch == 'c')
           k = NMMLISTS + @(i);
        else if (ch == 'r')
           k = @(i);
        else
            PrintUsage(args[0], i, "1st arg to -@(flg) must be 'r' or 'c'!");
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        lists[k] = ReadMMFile(args[i]);
        assert(lists[k]);
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        lists[++k] = ReadMMFile(args[i]);
        assert(lists[k]);
        break;
      @undef i
   @endwhile
   @multidef i   4 5
   @whiledef flg r t
      case '@(flg)': /* [r,c] <amm file> */
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        ch = args[i][0];
        if (ch == 'c')
           k = NMMLISTS + @(i);
        else if (ch == 'r')
           k = @(i);
        else
            PrintUsage(args[0], i, "1st arg to -@(flg) must be 'r' or 'c'!");
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        lists[k] = ReadMMFile(args[i]);
        assert(lists[k]);
      @undef i
   @endwhile
      case 'k':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        assert(!strcmp(args[i], "syrk"));
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        k = ISYRK;
        lists[k] = ReadMMFile(args[i]);
        break;
      case 'd':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        outd = DupString(args[i]);
        break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   *PRE = pre;
/*
 * Fill in any required list entry
 */
   for (i=0; i < 2*NMMLISTS; i++)
   {
      const char pr=(i<NMMLISTS) ? pre : cpre;
      const int k = (i<NMMLISTS) ? i : i-NMMLISTS;
      if (i == NMMLISTS+ITRSM) /* complex trsm not */
         continue;             /* presently used */
      if (!lists[i])
         lists[i] = ReadMMFileWithPath(pr, "res", fn[k]);
      if (!lists[i])
         fprintf(stderr, "CANNOT FIND FILE 'res/%c%s'!\n", pr, fn[k]);
      assert(lists[i]);
   }
   return(outd);
}

void GenSyrkH(char pre, char *outd, ATL_mmnode_t *mb, int RCSAME)
{
   ATL_cpnode_t *cb;
   FILE *fp;
   const int ntr = (pre == 'd' || pre == 's') ? 2 : 4;
   int ial, ibe, itr;
   const char be[3] = {'0', '1', 'n'};
   char bes[4] = {'1', 'n', 'X', '0'};
   char trs[4] = {'N', 'T', 'C', 'H'};
   char rcs[4] = {'c', 'r', 'c', 'r'};
   char cjs[4] = {' ', ' ', 'C', 'C'};


   if (!mb)
      return;
   assert(!mb->next);
   fp = OpenMMGenHeader(outd, 0, pre, NULL, "amm", "syrk", NULL);
   fprintf(fp, "#define SYRK_NB %d\n", mb->kbB);
   fprintf(fp, "#define ATL_SYRKK_VLEN %d\n", mb->vlen);
   fprintf(fp, "#define ATL_SYRKK_KVEC %d\n", 
           FLAG_IS_SET(mb->flag, MMF_KVEC) ? mb->vlen:0);
   fprintf(fp, "#define ATL_SYRKK_NU %d\n", mb->nu);
   fprintf(fp, "#define ATL_SYRKK_KU %d\n", mb->ku);
/*
 * Prototype ATL_<pre>_[sq,um]syrkK kernel
 */
   if (RCSAME && (pre == 'c' || pre == 'z'))
   {
      const char upr = (pre == 'z') ? 'd' : 's';
      for (ibe=0; ibe < 3; ibe++)
         fprintf(fp, "#define ATL_%c%ssyrkK_b%c ATL_%c%ssyrkK_b%c\n", 
                 pre, sh, be[ibe], upr, sh, be[ibe]);
   }
   for (ibe=0; ibe < 3; ibe++)
   {
      fprintf(fp, 
"void ATL_%camsyrkK_b%c(ATL_CSZT,ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,\n",
              pre, be[ibe]);
      fprintf(fp, 
      "                     TYPE*, const TYPE*, const TYPE*, const TYPE*);\n");
   }
/*
 * Prototype/rename all A cpy routs: ATL_<pre>cm2am_syrk<TA>
 */
#if 1
   cb = AddMMUniqueACopyFromMMNodes(pre, 'T', mb, NULL);
   fprintf(fp, "#define ATL_%ca2blk_syrkN %s_Na1\n", 
           pre, cb->rout);
   fprintf(fp, "#define ATL_%ca2blk_syrkT %s_Ta1\n", 
           pre, cb->rout);
   for (itr=0; itr < 2; itr++)
   {
      char tr = itr ? 'T' : 'N';
      fprintf(fp, "void ATL_%ca2blk_syrk%c", pre, tr);
      if (pre == 'd' || pre == 's')
         fprintf(fp, 
         "(ATL_CSZT,ATL_CSZT,const TYPE,const TYPE*,ATL_CSZT,TYPE*);\n");
      else
         fprintf(fp, 
         "(ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
   }
   KillAllCopyNodes(cb);
#else
   for (itr=0; itr < ntr; itr++)
   {
      fprintf(fp, "#define ATL_%ccm2am_syrk%c ATL_%c%cm2am_a1_%dx%d%c\n", 
              pre, trs[itr], pre, rcs[itr], mb->nu, 
              FLAG_IS_SET(mb->flag, MMF_KVEC)?mb->vlen:0, cjs[itr]);
      fprintf(fp, "void ATL_%ccm2am_syrk%c", pre, trs[itr]);
      if (pre == 'd' || pre == 's')
         fprintf(fp, 
         "(ATL_CSZT,ATL_CSZT,const TYPE,const TYPE*,ATL_CSZT,TYPE*);\n");
      else
         fprintf(fp, 
         "(ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
   }
#endif
/*
 * Prototype all C cpy routs: ATL_<pre>SyrkIntoC_a<alp>_b<bet>
 */
   for (ial=0; ial < 3; ial++)
   {
      for (ibe=0; ibe < 4; ibe++)
      {
         fprintf(fp, "void ATL_%cSyrkIntoC_a%c_b%c\n", pre,bes[ial],bes[ibe]);
         if (pre == 's' || pre == 'd')
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const SCALAR, TYPE *,ATL_CSZT);\n");
         else
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const TYPE*,const SCALAR, TYPE *,ATL_CSZT);\n");
      }
   }
   CloseGenHeader(fp);
}

double GenPerfH(char pre, char *outd, char *ip, char *cn, double mfMax,
                ATL_mmnode_t *mb, ATL_mmnode_t *k1)
{
   FILE *fp;
   ATL_mmnode_t *mp;
   #define NTHRSH 11
   int THRSH[NTHRSH] = {25, 33, 50, 66, 75, 80, 85, 90, 95, 98, 99};
   int idxT[NTHRSH];
   ATL_mmnode_t *mpT[NTHRSH];
   const int FNDMAX = (mfMax == 0.0);
   int i, n, idxMax=0;
   double fcnt;

   fp = OpenMMGenHeader(outd, 0, pre, ip, cn, "perf", mb);
/*
 * If not already set, compute the max perf & its index.  We'll use this
 * max as the denominator in our PERF array.
 */
   if (FNDMAX)
   {
      for (i=0; i < NTHRSH; i++)
         mpT[i] = NULL;
      for (n=0,mp=mb; mp; n++, mp = mp->next)
      {
         if (mp->mflop[0] > mfMax)
         {
            mfMax = mp->mflop[0];
            idxMax = n;
         }
      }
   }
/*
 * If our denom comes from other file, just count the number of entries
 */
   else
   {
      for (n=0,mp=mb; mp; n++, mp = mp->next);
      idxMax = -1;
   }
   fprintf(fp, "#define ATL_%sAMM_NCASES %d\n", cn, n);
   fprintf(fp, "#define ATL_%sAMM_DENOM %le /* (%.2f)*/ \n", cn,
           mfMax, mfMax);
   fprintf(fp, "#define ATL_%sAMM_MAXMFLOPIDX %d\n\n", cn, idxMax);
   if (FNDMAX)
   {
      for (n=0,mp=mb; mp; mp = mp->next, n++)
      {
         double mf = mp->mflop[0] / mfMax;
         for (i=0; i < NTHRSH; i++)
         {
            if (!mpT[i] && THRSH[i]*0.01*mfMax < mp->mflop[0])
            {
               mpT[i] = mp;
               idxT[i] = n;
            }
         }
      }
      for (i=0; i < NTHRSH; i++)
      {
         mp = mpT[i];
         fprintf(fp, "#define ATL_%sAMM_%dLCMU %d\n", cn, THRSH[i],
                 Mylcm(Mylcm(mp->mu,mp->nu),mp->ku));
         fprintf(fp, "#define ATL_%sAMM_%dLCMMN %d\n", cn, THRSH[i],
                 Mylcm(mp->mu,mp->nu));
         fprintf(fp, "#define ATL_%sAMM_%dMB %d\n", cn, THRSH[i], mp->mbB);
         fprintf(fp, "#define ATL_%sAMM_%dNB %d\n", cn, THRSH[i], mp->nbB);
         fprintf(fp, "#define ATL_%sAMM_%dKB %d\n", cn, THRSH[i], mp->kbB);
         fprintf(fp, "#define ATL_%sAMM_%dIDX %d\n", cn, THRSH[i], idxT[i]);
      }
      mp = ATL_FindLastNode(mb, GetOffset(&mb->next, mb));
      fprintf(fp, "#define ATL_%sAMM_LCMU %d\n", cn, 
              Mylcm(Mylcm(mp->mu,mp->nu),mp->ku));
      fprintf(fp, "#define ATL_%sAMM_LCMMN %d\n", cn, Mylcm(mp->mu,mp->nu));
      fprintf(fp, "\n");
   }

   fprintf(fp, "#if !defined(NOPERF) && !defined(NOARRS)\n");
   fprintf(fp, "static const float ATL_%sAMM_PERF[%d] =\n", cn, n);
   fprintf(fp, "{  /* %% of performance of best kernel */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d, mf=%.0f */\n", mp->mflop[0]/mfMax,
              (mp->next)?',':' ', i, mp->kbB, mp->mflop[0]);
   fprintf(fp, "};\n#endif\n\n");

   if (k1)
   {
      ATL_mmnode_t *kp;
      fprintf(fp, "#if !defined(NOK1RATIO) && !defined(NOARRS)\n");
      fprintf(fp, "static const float ATL_%sAMM_K1RATIO[%d] =\n", cn, n);
      fprintf(fp, "{  /* ratio of %sAMM perf wt that of its K=1 K-cleaner */\n",
              cn);
      for (i=0,mp=mb,kp=k1; mp; i++,mp = mp->next,kp = kp->next)
         fprintf(fp, "   %f%c  /* IDX=%d, KB=%d IDs=[%d,%d]*/\n", 
                 kp->mflop[0]/mp->mflop[0], (mp->next)?',':' ', i, mp->kbB,
                 mp->ID, kp->ID);
      fprintf(fp, "};\n#endif\n\n");
   }

   fprintf(fp, "#if !defined(NOTIME) && !defined(NOARRS)\n");
   fprintf(fp, "static const float ATL_%sAMM_TIME[%d] =\n", cn, n);
   fprintf(fp, "{  /* actual seconds to compute one block */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      if (mp->blask == 0)
         fcnt = (2.0*mp->mbB)*mp->nbB*mp->kbB;  /* gemm flop count */
      else
         fcnt = (1.0*mp->mbB)*mp->nbB*mp->kbB;  /* roughly right */
      fprintf(fp, "   %e%c  /* IDX=%d, B=(%d,%d,%d) */\n",
              fcnt / (mp->mflop[0]*1.0e6),
              (mp->next)?',':' ', i, mp->mbB, mp->nbB, mp->kbB);
   }
   fprintf(fp, "};\n#endif\n");
   CloseGenHeader(fp);
   return(mfMax);
}

void GenKernH
   (char pre, char *outd, char *ip, char *cn, ATL_mmnode_t *mb, 
    ATL_mmnode_t *mkb, ATL_mmnode_t *ub)
{
   FILE *fp;
   int ib, inxt, iaut;
   char bes[3] = {'0', '1', 'n'};

   inxt = GetOffset(&mb->next, mb);
   iaut = GetOffset(&ub->auth, ub);
   fp = OpenMMGenHeader(outd, 0, pre, ip, cn, "kern", mb);
   for (ib=0; ib < 3; ib++)
      PrintMMProtos(fp, pre, "KERN", ub, iaut, bes[ib]);
   for (ib=0; ib < 3; ib++)
   {
      PrintStrArrAtOff(fp, pre, "KERN", mb, inxt, iaut, "ammkern_t", 
                       0, 0, bes[ib]);
      if (mkb)
         PrintStrArrAtOff(fp, pre, "KERN_K1", mkb, inxt, iaut, "ammkern_t", 
                          0, 0, bes[ib]);
   }
   CloseGenHeader(fp);
}

void PrintFlagArr(FILE *fp, ATL_mmnode_t *mb)
{
   ATL_mmnode_t *mp;
   int n;

   n = CountListEntries(mb, GetOffset(&mb->next, mb));
   fprintf(fp, "#ifndef NOKFLAG\n");
   fprintf(fp, "static const unsigned char ATL_AMM_KFLAG[%d] =\n{\n", n);
   for (n=0,mp=mb; mp; n++, mp = mp->next)
   {
      unsigned char flag=FLAG_IS_SET(mp->flag, MMF_KRUNTIME) ? 1 : 0;
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         flag |= 2;
      fprintf(fp, "%6d%c   /* IDX=%d */\n", flag, mp->next ? ',':' ', n);
   }
   fprintf(fp, "};\n");
   fprintf(fp, "   #define ATL_AMM_KRUNTIME(idx_) (ATL_AMM_KFLAG[idx_] & 1)\n");
   fprintf(fp, "   #define ATL_AMM_KMAJOR(idx_) (ATL_AMM_KFLAG[idx_] & 2)\n");
   fprintf(fp, "#endif\n");
}
void GenBlkH(char pre, char *outd, char *ip, char *cn, ATL_mmnode_t *mb)
{
   FILE *fp;
   ATL_mmnode_t *mp;
   int *KUs;
   int i, n, inxt;

   fp = OpenMMGenHeader(outd, 0, pre, ip, cn, "blk", mb);
   inxt = GetOffset(&mb->next, mb);
   mp = ATL_FindLastNode(mb, inxt);
   fprintf(fp, "#define ATL_%sAMM_LASTMB %d\n", cn, mp->mbB);
   fprintf(fp, "#define ATL_%sAMM_LASTNB %d\n", cn, mp->nbB);
   fprintf(fp, "#define ATL_%sAMM_LASTKB %d\n", cn, mp->kbB);
   fprintf(fp, "\n");
/*
 * Save original KUs, and overwrite compile-time-K KUs with kbB for printing
 */
   n = CountListEntries(mb, inxt);
   KUs = malloc(sizeof(int)*n*3);
   assert(KUs);
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      KUs[i] = mp->ku;
      KUs[i+n] = mp->kbmin;
      KUs[i+n+n] = mp->kbmax;
      #if 0
      if (FLAG_IS_SET(mp->flag,MMF_KUISKB))
         mp->kbmin = mp->kbmax = mp->ku = mp->kbB;
      else if (!FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
         mp->kbmin = mp->kbmax = mp->kbB;
      #endif
   }
   @multidef st VLENs KBMAXs KBMINs KUs NUs MUs KBs NBs MBs
   @whiledef iv vlen  kbmax  kbmin  ku  nu  mu  kbB nbB mbB
@skip   PrintMMIntOffArr(fp, pre, "@(st)", mb, GetOffset(&mb->@(iv), mb));
   PrintIntArrAtOff(fp, pre, "@(st)", mb, inxt, GetOffset(&mb->@(iv), mb),0,0);
      @undef st
   @endwhile
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      mp->ku = KUs[i];
      mp->kbmin = KUs[i+n];
      mp->kbmax = KUs[i+n+n];
   }
   PrintFlagArr(fp, mb);
   free(KUs);
   CloseGenHeader(fp);
}

@BEGINSKIP
void GenCpyA(char pre, char *outd, char *cn, char dir, char alp, 
             ATL_mmnode_t *mb)
/* presently leaving alp='[1,n,X]', cn=[ge,sq,rk], dir='[F,T]' to caller */
{
   FILE *fp;
   const int nt = (pre == 'd' || pre == 's') ? 2 : 4;
   int flag=0, i, j, it, im;
   char tas[4] = {'N', 'T', 'C', 'H'};
   char mats[2] = {'A', 'B'};
   char arrnm[12]={'x', 'x', '2', 'B', 'L', 'K', '_', 'a', alp, '\0'};
   char fn[12];

   if (dir == 'T')
      sprintf(fn, "cm2am_a%c", alp);
   else
      sprintf(fn, "am2cm_a%c", alp);
   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, fn, mb);
   fn[6] = 't'; fn[7] = '\0';  /* switch fn to type name */

   for (im=0; im < 2; im++)
   {
      arrnm[0] = mats[im];
      for (it=0; it < nt; it++)
      {
         ATL_cpnode_t *cb, *ucb;
         int i;
         const char ta = tas[it]; 

         arrnm[1] = ta;
         cb = GetMMCopyFromMMNodes(CopyEncode(pre, dir, mats[im], ta), mb);
         assert(cb);
         ucb = AddUniqueCopyNode(NULL, cb);
         arrnm[6] = '\0';
         PrintMMCpProtosA(fp, arrnm, ucb, dir, alp);
         KillAllCopyNodes(ucb);
         PrintStrArrAtOff(fp, pre, arrnm, cb, GetOffset(&cb->next, cb),
                          GetOffset(&cb->rout, cb), fn, ta, alp, 0);
         KillAllCopyNodes(cb);
      }
   }
   CloseGenHeader(fp);
}

void GenCpyC(FILE *fp, char pre, char *outd, char *cn, char dir, char *type, 
             char alp, char bet, ATL_mmnode_t *mb)
{
   char *arrnm = (dir == 'T') ? "C2BLK" : "BLK2C";
   ATL_cpnode_t *cb, *ucb;
   int flag=0, i, j;

   cb = GetMMCopyFromMMNodes(CopyEncode(pre, dir, 'c', 'n'), mb);
   assert(cb);
   #ifdef Debug
      i = CountListEntries(cb, GetOffset(&cb->next, cb));
      j = CountListEntries(mb, GetOffset(&mb->next, mb));
      fprintf(stderr, "ncpy=%d, nmm=%d!\n", i, j);
   #endif
   ucb = AddUniqueCopyNode(NULL, cb);
   PrintMMCpProtosC(fp, arrnm, ucb, dir, alp, bet);
   KillAllCopyNodes(ucb);
   PrintStrArrAtOff(fp, pre, arrnm, cb, GetOffset(&cb->next, cb),
                    GetOffset(&cb->rout, cb), type, 0, alp, bet);
   KillAllCopyNodes(cb);
}
@ENDSKIP

void PrintDiv(FILE *fp, char *exp, int v)
/* 
 * Prints either exp/v or exp>>lg2(v), dep on v being power of 2 or not 
 * caller must put parens where appropriate (if exp is not a simple variable
 * name, it must have parens to produce the right answer!).
 */
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "%s>>%d", exp, p);
   else
      fprintf(fp, "%s/%d", exp, v);
}
void PrintCeil(FILE *fp, char *exp, int v)
/* 
 * Prints either ((exp+v-1)/v)*v or same things wt shifts if power of 2.
 */
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "((%s+%d)>>%d)", exp, v-1, p);
   else
      fprintf(fp, "((%s+%d)/%d)", exp, v-1, v);
}
void PrintCeilMul(FILE *fp, char *exp, int v)
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "(((%s+%d)>>%d)<<%d)", exp, v-1, p, p);
   else
      fprintf(fp, "(((%s+%d)/%d)*%d)", exp, v-1, v, v);
}

@BEGINSKIP
void GenFullCpyC(char pre, char *outd, char dir, char *cn, ATL_mmnode_t *mb)
{
   ATL_mmnode_t *mp;
   FILE *fp;
   int ib, NEEDSZF=0;
   char rt[16];
   char bets[4] = {'0', '1', 'n', 'X'};

/*
 * Create atlas_<pre><cn>szC.h if necessary
 */
   for (mp=mb; mp; mp = mp->next)
      if (FLAG_IS_SET(mp->flag, MMF_KVEC) && ib == -1 &&
          (mp->mu*mp->nu) % mp->vlen != 0)
         break;
   if (mp)
   {
      ATL_cpnode_t *cb, *ucb, *cp;
      int n;
      NEEDSZF=1;
      fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "szC", mb);
      cb = GetMMCopyFromMMNodes(CopyEncode(pre, dir, 'c', 'n'), mb);
      assert(cb);
      ucb = AddUniqueCopyNode(NULL, cb);
      KillAllCopyNodes(cb);
/*
 *    Generate needed funcs for size query
 */
      for (cp=ucb; cp; cp = cp->next)
      {
         const unsigned int kvec=cp->kvec;
         const unsigned int mu=cp->mu, nu=cp->nu, b = mu*nu;
         const unsigned int B = (kvec > 1) ? ((b+kvec-1)/kvec)*kvec : 0;
         fprintf(fp, "#define uint unsigned int\n");
         if (b != B)
         {
            assert(!cp->ID);
            fprintf(fp, "static uint ATL_szC_%dx%d(uint M, uint N, "
                        "uint mu, uint nu, uint vlen)", mu, nu);
            fprintf(fp, "\n{\n");
            fprintf(fp, "   return(");
            PrintCeilMul(fp, "M", mu);
            fprintf(fp, "*");
            PrintCeilMul(fp, "N", nu);
            fprintf(fp, "*");
            fprintf(fp, "%d);\n", B);
            fprintf(fp, "}\n");
         }
         fprintf(fp, "typedef uint (*szC_t)(uint,uint,uint,uint,uint);\n");
         fprintf(fp, "#undef uint\n");
         for (n=0,cp=cb; cp; n++, cp = cp->next);
         fprintf(fp, "static szC_t ATL_AMM_SZCW[%d] =\n{\n", n);
         for (cp=cb,n=0; cp; cp = cp->next,n++)
         {
            const unsigned int kvec=cp->kvec;
            const unsigned int mu=cp->mu, nu=cp->nu, b = mu*nu;
            const unsigned int B = (kvec > 1) ? ((b+kvec-1)/kvec)*kvec : 0;
            fprintf(fp, "/* IDX=%d */ ", n);
            if (b != B)
               fprintf(fp, "ATL_szC_%dx%d", mu, nu);
            else
               fprintf(fp, "NULL"); 
            if (cp->next)
               fprintf(fp, ",\n");
            else
               fprintf(fp, "\n");
         }
      }
      KillAllCopyNodes(cb);
      CloseGenHeader(fp);
   }
#if 0
#endif

   if (dir == 'T')
      strcpy(rt, "cmat2ablk");
   else
      strcpy (rt, "ablk2cmat");

   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, rt, mb);
   if(NEEDSZF)
   {
      fprintf(fp, "#ifndef NOSZC\n");
      fprintf(fp, "   #include \"atlas_%c%sszC.h\"\n", pre, cn);
      fprintf(fp, "#endif\n");
   }
   rt[9] = '_'; rt[10] = 't'; rt[11] = '\0';
@skip   strcpy(rt, dir == 'T' ? "cmat2ablk_t" : "ablk2cmat_t");
   for (ib=0; ib < 4; ib++)
   {
      int ia;
      char alps[3] = {'1', 'n', 'X'};
      const char bet = bets[ib];

      for (ia=0; ia < 3; ia++)
         GenCpyC(fp, pre, outd, cn, dir, rt, alps[ia], bet, mb);
   }
   CloseGenHeader(fp);
}

void GenAllCpyC(char pre, char *outd, char dir, ATL_mmnode_t *gb, 
                ATL_mmnode_t *sb, ATL_mmnode_t *rb)
{
   if (gb)
      GenFullCpyC(pre, outd, dir, "ge", gb);
   if (sb)
      GenFullCpyC(pre, outd, dir, "sq", sb);
   if (rb)
      GenFullCpyC(pre, outd, dir, "rk", rb);
}
void GenAllCpyA(char pre, char *outd, char dir, ATL_mmnode_t *gb,
                ATL_mmnode_t *sb, ATL_mmnode_t *rb)
/* presently leaving dir='[F,T]' to caller */
{
   int ia;
   char alps[3] = {'1', 'n', 'X'};

   for (ia=0; ia < 3; ia++)
   {
      if (gb)
         GenCpyA(pre, outd, "ge", dir, alps[ia], gb);
      if (sb)
         GenCpyA(pre, outd, "sq", dir, alps[ia], sb);
      if (rb)
         GenCpyA(pre, outd, "rk", dir, alps[ia], rb);
   }
}
@ENDSKIP

double PrintSum(FILE *fp, char *cn, ATL_mmnode_t *b, double mfGE)
{
   int inxt, max, i, kvec;
   double mf;
   ATL_mmnode_t *mp;

   inxt = GetOffset(&b->next, b);
   fprintf(fp, "#define ATL_%sAMM_NCASES %d\n", cn, CountListEntries(b, inxt));
   mp = ATL_FindLastNode(b, inxt);
   fprintf(fp, "#define ATL_%sAMM_LASTMB %d\n", cn, mp->mbB);
   fprintf(fp, "#define ATL_%sAMM_LASTNB %d\n", cn, mp->nbB);
   fprintf(fp, "#define ATL_%sAMM_LASTKB %d\n", cn, mp->kbB);
   mf = mp->mflop[0];
   fprintf(fp, "#define ATL_%sAMM_LASTMU %d\n", cn, mp->mu);
   fprintf(fp, "#define ATL_%sAMM_LASTNU %d\n", cn, mp->nu);
   fprintf(fp, "#define ATL_%sAMM_LASTKU %d\n", cn, mp->nu);
   fprintf(fp, "#define ATL_%sAMM_LASTLCMMN %d\n\n", cn, Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_%sAMM_LASTLCMU %d\n\n", cn,
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   #if 0
   fprintf(fp, "#define ATL_%sAMM_LASTMFLOP %e\n", cn, mf);
   if (mfGE > 0.0)
      fprintf(fp, "#define ATL_%sAMM_MFLOP_RATIO %e\n", cn, mf/mfGE);
   #endif
   for (kvec=0,mp=b; mp; mp = mp->next)
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         kvec = Mmax(kvec, mp->vlen);
   fprintf(fp, "#ifndef  ATL_%sAMM_MAXKVEC\n", cn);
   fprintf(fp, "   #define ATL_%sAMM_MAXKVEC %d\n", cn, kvec);
   fprintf(fp, "#endif\n");
   fprintf(fp, "\n");
   return(mf);
}

void GenSumH(char pre, char *outd, ATL_mmnode_t *gb, ATL_mmnode_t *sb, 
             ATL_mmnode_t *rb)
/*
 * cn:[ge,sq,rk]
 * For [ge,sq,rk] report: ncases, max[nb,mb,kb]
 * -> for maxB, report: perf,time,ratio wt best ge
 */
{
   FILE *fp;
   double mf;
   int i;

   fp = OpenMMGenHeader(outd, 0, pre, NULL, "amm", "sum", gb);
   mf = PrintSum(fp, "ge", gb, 0.0);
   if (sb)
      PrintSum(fp, "sq", sb, mf);
   if (rb)
      PrintSum(fp, "rk", rb, mf);
   CloseGenHeader(fp);
}

void GenDegenH_IP(char pre, char *outd, char *cn, ATL_mmnode_t *mb)
/*
 * Used to generate timing/index file for when one or more dims are degenerate
 * for inner product.  mb should be ordered by the degen dim(s), ivar should
 * have the index of kern.h that corresponds to this kern.
 */
{
   FILE *fp;
   ATL_mmnode_t *mp;
   int i, n, idxMax=0, maxM=0, maxN=0, maxK=0;
   double fcnt, mfMax=0.0;

   fp = OpenMMGenHeader(outd, 0, pre, "ip", cn, "geIdx", mb);
/*
 * Compute max perf & M,N,K
 */
   for (n=0,mp=mb; mp; n++, mp = mp->next)
   {
      maxM = Mmax(maxM, mp->mbB);
      maxN = Mmax(maxN, mp->nbB);
      maxK = Mmax(maxK, mp->kbB);
      if (mp->mflop[0] > mfMax)
      {
         if (mp->ivar > 0)
            (mp->ivar)--;
         mfMax = mp->mflop[0];
         idxMax = n;
      }
   }
   fprintf(fp, "#ifdef NOARRS\n");
   fprintf(fp, "   #define NOPERF 1\n");
   fprintf(fp, "   #define NOTIME 1\n");
   fprintf(fp, "   #define NOKIDX 1\n");
   fprintf(fp, "   #define NONBs  1\n");
   fprintf(fp, "#endif\n");
   fprintf(fp, "#define ATL_%sAMM_NCASES %d\n", cn, n);
   fprintf(fp, "#define ATL_%sAMM_DENOM %le /* (%.2f)*/ \n", cn,
           mfMax, mfMax);
   fprintf(fp, "#define ATL_%sAMM_MAXMFLOPIDX %d\n", cn, idxMax);
   fprintf(fp, "#define ATL_%sAMM_MAXMB %d\n", cn, maxM);
   fprintf(fp, "#define ATL_%sAMM_MAXNB %d\n", cn, maxN);
   fprintf(fp, "#define ATL_%sAMM_MAXKB %d\n\n", cn, maxK);

   fprintf(fp, "#ifndef NOPERF\n");
   fprintf(fp, "static const float ATL_%sAMM_PERF[%d] =\n", cn, n);
   fprintf(fp, "{  /* %% of performance of best kernel */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
      fprintf(fp, "   %f%c  /* CNT=%d, KB=%d, mf=%.0f */\n", mp->mflop[0]/mfMax,
              (mp->next)?',':' ', i, mp->kbB, mp->mflop[0]);
   fprintf(fp, "};\n#endif\n\n");

   fprintf(fp, "#if !defined(NOTIME) && !defined(NOARRS)\n");
   fprintf(fp, "static const float ATL_%sAMM_TIME[%d] =\n", cn, n);
   fprintf(fp, "{  /* actual seconds to compute one block */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      if (mp->blask == 0)
         fcnt = (2.0*mp->mbB)*mp->nbB*mp->kbB;  /* gemm flop count */
      else
         fcnt = (1.0*mp->mbB)*mp->nbB*mp->kbB;  /* roughly right */
      fprintf(fp, "   %e%c  /* CNT=%d, B=(%d,%d,%d) */\n",
              fcnt / (mp->mflop[0]*1.0e6),
              (mp->next)?',':' ', i, mp->mbB, mp->nbB, mp->kbB);
   }
   fprintf(fp, "};\n#endif\n");

   fprintf(fp, "#define ATL_AMM_NBs ATL_pmnAMM_NBs\n");
   PrintIntArrAtOff(fp, pre, "NBs", mb, GetOffset(&mb->next, mb), 
                    GetOffset(&mb->nbB, mb), 0, 0);
   fprintf(fp, "#undef ATL_AMM_NBs\n");
   fprintf(fp, "#define ATL_AMM_KBs ATL_pmnAMM_KBs\n");
   PrintIntArrAtOff(fp, pre, "KBs", mb, GetOffset(&mb->next, mb), 
                    GetOffset(&mb->kbB, mb), 0, 0);
   fprintf(fp, "#undef ATL_AMM_KBs\n");
   PrintIntArrAtOff(fp, pre, "KIDX", mb, GetOffset(&mb->next, mb), 
                    GetOffset(&mb->ivar, mb), 0, 0);
   fprintf(fp, "#ifdef NOARRS\n");
   fprintf(fp, "   #undef NOPERF\n");
   fprintf(fp, "   #undef NOTIME\n");
   fprintf(fp, "   #undef NOKIDX\n");
   fprintf(fp, "   #undef NONBs\n");
   fprintf(fp, "#endif\n");
   CloseGenHeader(fp);
}

void GenAllHeaders(char pre, char *outd, ATL_mmnode_t **lists)
{
   ATL_cpnode_t *cb;
   ATL_mmnode_t *mmb;
   char *nm="perf";
   char *cn[4]={"ge", "sq", "rk", "ts"};
   double mfMax;
   int i, k, SKSAME;
   char pr;
/*
 * Write degenerate case header files.  Kind of ugly hardwiring names here,
 * but I don't see point in taking these from command line.
 */
   pr=pre;
   DO_TYPE:
   @BEGINSKIP
   @multidef pf dn dm mn
   @whiledef nm n   m mn
   mmb = ReadMMFileWithPath(pr, "res", "ip@(nm)PERF.sum");
   if (mmb)
   {
      GenDegenH_IP(pr, outd, "@(pf)", mmb);
      KillAllMMNodes(mmb);  /* done with these! */
   }
   @endwhile
   @ENDSKIP
   if (pr == pre)
   {
      pr = (pre == 'd') ? 'z' : 'c';
      goto DO_TYPE;
   }
   SKSAME = MMKernsPerfSame(lists[ISYRK], lists[ISYRK+NMMLISTS]);
/*
 * Handle [perf,blk,flag,sum] which require only ordered lists
 */
   for (pr=pre,k=0; k < 2*NMMLISTS; k += NMMLISTS)
   {
      mfMax = GenPerfH(pr, outd, "ip", "ge", 0.0, lists[k+IGE], lists[k+IGEK1]);
      if (k < NMMLISTS)  /* ts only in real for now */
         GenPerfH(pr, outd, "tr","sm", mfMax, lists[k+ITRSM], NULL);
      KillAllMMNodes(lists[k+ITRSM]);  /* done with these! */
      lists[k+ITRSM] = NULL;
@skip      if (lists[k+ISYRKT])
@skip      {
      GenPerfH(pr, outd, "sy","sk", mfMax, lists[k+ISYRKT], NULL);
      KillAllMMNodes(lists[k+ISYRKT]);  /* done with these! */
      lists[k+ISYRKT] = NULL;
@skip      }
      GenSyrkH(pr, outd, lists[k+ISYRK], SKSAME);

      GenPerfH(pr, outd, "op","sq", 0.0, lists[k+ISQ], lists[k+ISQK1]);
      GenPerfH(pr, outd, "op","rk", 0.0, lists[k+IRKK], NULL);

      GenBlkH(pr, outd, "ip", "ge", lists[k+IGE]); 
      GenBlkH(pr, outd, "op", "sq", lists[k+ISQ]); 
      GenBlkH(pr, outd, "op", "rk", lists[k+IRKK]);
      pr = (pre == 'd') ? 'z' : 'c';
   }
   GenSumH(pre, outd, lists[IGE], lists[ISQ], lists[IRKK]);
   GenSumH(pr, outd, lists[IGE+NMMLISTS], lists[ISQ+NMMLISTS], 
           lists[IRKK+NMMLISTS]);
/*
 * Create lists of only the unique kernels for [ge,sq,rk] in real & cplx
 * for use in prototyping.  We combine kern & K1 lists for each.
 * We can now gen [kern].
 */
   for (pr=pre,k=0; k < 2; k++)
   {
      for (i=0; i < 3; i++)
      {
         ATL_mmnode_t *ulst;  /* unordered list of only unique kernels */
         const int h = i+i+k*NMMLISTS, u=k*3+i;

         ulst = AddUniqueMMKernCompList(NULL, lists[h]);
         if (i < 2)
         {
            char *ip = (i) ? "op":"ip";
            ulst = AddUniqueMMKernCompList(ulst, lists[h+1]);
            GenKernH(pr, outd, ip, cn[i], lists[h], lists[h+1], ulst);
         }
         else
            GenKernH(pr, outd, i==2?"op":"tr", cn[i], lists[h], NULL, ulst);
         KillAllMMNodes(ulst);  /* done with these! */
      }
      pr = (pre == 's') ? 'c' : 'z';
   }
@beginskip
/*
 * [cmat2ablk_a[1,n,X]_b[0,1,n,X],ablk2cmat_a?_b?,am2cm_a[1,n,X]]
 * -> have never genned, can we?: am2rm_a[1,n,X],
 */
   GenAllCpyA(pre, outd, 'T', lists[IGE], lists[ISQ], lists[IRKK]);
   GenAllCpyA(pr, outd, 'T', lists[IGE+NMMLISTS], lists[ISQ+NMMLISTS], 
              lists[IRKK+NMMLISTS]);
   GenAllCpyC(pre, outd, 'F', lists[IGE], lists[ISQ], lists[IRKK]);
   GenAllCpyC(pr, outd, 'F', lists[IGE+NMMLISTS], lists[ISQ+NMMLISTS], 
              lists[IRKK+NMMLISTS]);
@endskip
}

static void AddAlpBetSuf(char *rt, int rl, int ial, int ibe)
/*
 * Add _aXbX suffix to rt, which is presently of length rl
 */
{
   rt[rl] = '_';
   rt[rl+1] = 'a';
   if (ial == -1)
      rt[rl+2] = 'n';
   else if (ial == 2)
      rt[rl+2] = 'X';
   else
      rt[rl+2] = ial+48;
   rt[rl+3] = 'b';
   if (ibe == -1)
      rt[rl+4] = 'n';
   else if (ibe > 1)
      rt[rl+4] = 'X';
   else
      rt[rl+4] = ibe+48;
}

void GenAllKerns(char pre, char *outd, ATL_mmnode_t *rb)
@skip                 ATL_cpnode_t *cpA, ATL_cpnode_t *cpC)
{
@skip   ATL_cpnode_t *last, *cp;
   ATL_mmnode_t *mp;
   char *sgen=NULL;
   int i, len, dlen, mID, mU;
   char pr=pre;
@BEGINSKIP
/*
 * join all copy routs into one list temporarily
 */
   last = FindLastCopyNode(cpA);
   last->next = cpC;
/*
 * Get a string of max length for all system calls
 */
   mID=mU=len=i=0;
   for (cp=(!i)?cpA:cpC; cp; cp = cp->next)
   {
      len = Mmax(len, cp->rtlen);
      mID = Mmax(mID, cp->ID);
      mU = Mmax(mU, cp->mu);
      mU = Mmax(mU, cp->nu);
      mU = Mmax(mU, cp->kvec);
   }
   dlen = strlen(outd);
   len += dlen + 1;  /* outd */
   len += 17;  /* " > /dev/null 2>&1" */
   assert(mID == 0);  /* just until we support user copies */
   len += 64 - 2*4;  /* C format string */
   len += 4*NumDecDigits(mU); /* mu,nu,kvec */
   len += 2;                  /* extra for syrk */
   sgen = malloc(len+1);
   assert(sgen);
/*
 * Generate all needed copy routines
 */
   printf("\nGENERATING MMCOPY FILES\n");
   for (cp=cpA; cp; cp = cp->next)
   {
      int flag = cp->flag;
      int k;
      char pr;
      pr = CopyGetPre(cp->flag);
      printf("   -> %s\n", cp->rout);
      if (flag & (1<<CPF_CBLK))
      {
         const unsigned int kvec=cp->kvec ? cp->kvec:1;
         if (flag & (1<<CPF_SYRK))
         {
            k = sprintf(sgen, 
"make genall_syblk2C pre=%c vec=NA vlen=%d mu=%d nu=%d cpvlen=1 rt=%s/%s.c",
                        pr, kvec, cp->mu, cp->nu, outd, cp->rout);
         }
         else if (flag & (1<<CPF_CBLK))
         {
            k = sprintf(sgen, 
      "make genall_%s pre=%c vec=NA vlen=%d mu=%d nu=%d cpvlen=1 rt=%s/%s.c",
                        (flag&(1<<CPF_TOBLK)) ? "C2blk":"blk2C", pr, 
                        kvec, cp->mu, cp->nu, outd, cp->rout);
         }
      }
      else /* generate A/B copy */
      {
         char *targ;
         const unsigned int kvec=cp->kvec;
         if (flag & (1<<CPF_REAL))
            targ = (flag & (1<<CPF_TOBLK)) ? "A2blk":"blk2A";
         else
            targ = (flag & (1<<CPF_TOBLK)) ? "cA2blk":"cblk2A";
         k = sprintf(sgen, 
             "make genall_%s pre=%c kmaj=%d vlen=%d UR=%d cpvlen=1 rt=%s/%s.c",
                     targ, pr, kvec, kvec ? kvec:1, cp->nu, outd, cp->rout);
      }
      assert(k < len);
      k += sprintf(sgen+k, " > /dev/null 2>&1");
      assert(k <= len);
      if ((k=system(sgen)))
      {
         fprintf(stderr, "\n\ncpgenstr='%s' returns %d!\n\n", sgen, k);
         exit(k);
      }
   }
   printf("DONE GENERATING MMCOPY FILES\n");
   last->next = NULL;  /* disconnect A/C lists */
@ENDSKIP
   dlen = strlen(outd);
   len = 0;
/*
 * Generate/copy all required kernels.  This list has files with compile-time
 * K repeated, but we'll check ID to avoid repeated copies of user-supplied, 
 * and generated kernels need a new generation for each required KB.
 */
   printf("\nGENERATING AMM KERNS:\n");
   for (mp=rb; mp; mp = mp->next)
   {
      const int id=mp->ID;
      if (!id)
      {
         printf("   -> %s\n", mp->rout);
         assert(mp->genstr);
         if ( (i=system(mp->genstr)) )
         {
            fprintf(stderr, "GENSTR RETURNS %d:\n'%s'\n", i, mp->genstr);
            exit(i);
         }
      }
      else /* user-supplied kernel */
      {
         ATL_mmnode_t *p;
         for (p=rb; p != mp && p->ID != id; p = p->next);
         if (p == mp)  /* this is first mention of this ID */
         {
            printf("   %s -> %s\n", mp->genstr, mp->rout);
            i = strlen(mp->genstr) + strlen(mp->rout) + dlen + 16;
            if (i > len)
            {
               if (sgen)
                  free(sgen);
               sgen = malloc(i*sizeof(char));
               assert(sgen);
               len = i;
            }
            sprintf(sgen, "cp AMMCASES/%s %s/%s", mp->genstr, outd, mp->rout);
            
            if ( (i=system(sgen)) )
            {
               fprintf(stderr, "FAILED CP='%s'\n", sgen);
               exit(i);
            }
         }
         else /* they better have same filename! */
         {
            if (strcmp(mp->rout, p->rout))
            {
               printf("rout=(%s,%s)!\n", mp->rout, p->rout);
               exit(1);
            }
         }
      }
   }
   printf("DONE GENERATING AMM KERNS.\n");
   free(sgen);
}

void GenMake(char pre, char *outd, ATL_mmnode_t *mb)
@skip             ATL_cpnode_t *cpA, ATL_cpnode_t *cpC)
/*
 * mb files have already been made at least compile-time unique (same source
 * file might occur multiple times due to need to compile with -DKB)
 */
{
   FILE *fp;
   char *fn;
@skip   ATL_cpnode_t *cp;
   ATL_mmnode_t *mp;
   char *sals[3] = {"1", "N1", "X"};
   char als[3] = {'1', 'n', 'X'};
   char *sbes[4] = {"0", "1", "N1", "X"};
   char bes[4] = {'0', '1', 'n', 'X'};  /* use 1st 3 for mmkerns */
   char ctas[4] = {'N', 'T', 'C', 'H'};
   char dcomp[8] = {'$', '(', 'D', 'M', 'C', ')', '\0'};
   char dflags[12] = {'$','(','D','M','C','F','L','A','G','S',')','\0'};


   fn = malloc(strlen(outd)+11);
   assert(fn);
   sprintf(fn, "%s/%cMake_amm", outd, pre);
   fp = fopen(fn, "w");
   assert(fp);
   free(fn);
   fprintf(fp, "include ../Make.inc\n");
   fprintf(fp, "CDEFS2=$(CDEFS)\n\n");
/*
 * Spew out kernels to be compiled
 */
   fprintf(fp, "objs =");
   for (mp=mb; mp; mp = mp->next)
   {
      int ib;
      for (ib=0; ib < 3; ib++)
         fprintf(fp, " \\\n       %s_b%c.o", mp->auth, bes[ib]);
   }
   @BEGINSKIP
   for (cp=cpC; cp; cp = cp->next)  /* C copy routs */
   {
      int ib;
      for (ib=0; ib < 4; ib++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
            fprintf(fp, " \\\n       %s_a%cb%c.o", cp->rout, als[ia], bes[ib]);
      }
   }

   for (cp=cpA; cp; cp = cp->next)  /* A/B copy routs */
   {
      const int NTA = (cp->flag & (1<<CPF_REAL)) ? 2:4;
      int it;
      for (it=0; it < NTA; it++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
            fprintf(fp, " \\\n       %s_%ca%c.o", cp->rout, ctas[it], als[ia]);
      }
   }
   @ENDSKIP
   fprintf(fp, "\n");
/*
 * library make targets
 */
   fprintf(fp, "\n\nlib : %clib.grd\nall : %clib.grd\n%clib : %clib.grd\n",
           pre, pre, pre, pre);
   fprintf(fp, "%clib.grd : $(objs)\n", pre);
   fprintf(fp, "\t$(ARCHIVER) $(ARFLAGS) $(ATLASlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(ATLASlib)\n");
   fprintf(fp, "\t touch %clib.grd\n", pre);
   fprintf(fp, "clean : %cclean\n", pre);
   fprintf(fp, "%cclean:\n\t- rm -f $(objs)\n", pre);
   fprintf(fp, "killall : %ckillall\n", pre);
   fprintf(fp, "%ckillall : %cclean\n", pre, pre);
   fprintf(fp, "\t- $(ARCHIVER) d $(ATLASlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(ATLASlib)\n");
   fprintf(fp, "\t- rm -f ATL_%c*.[S,c]\n\n", pre);
/*
 * Make targets for amm kerns
 */
   fprintf(fp, "#\n#  AMM kernel rules\n#\n");
   fn = (pre == 'd' || pre == 'z') ?  "-DDREAL=1" : "-DSREAL";
   for (mp=mb; mp; mp = mp->next)
   {
      int ib;
      char *comp, *flgs;

      comp = GetMMKernComp(mp, dcomp, dflags, &flgs);
      for (ib=0; ib < 3; ib++)
      {
         char *sp=" ";
         fprintf(fp, "%s_b%c.o : %s\n", mp->auth, bes[ib], mp->rout);
         fprintf(fp, "\t%s $(CDEFS2) %s -DBETA%s=1 \\\n", comp, fn, sbes[ib]);
         if (!FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
            fprintf(fp, "        -DMB=%d -DNB=%d -DKB=%d", 
                    mp->mbB, mp->nbB, mp->kbB);
         else
            sp = "        ";
   @whiledef mtx C B A
         if (FLAG_IS_SET(mp->flag, MMF_MV@(mtx)))
         {
            fprintf(fp, "%s-DATL_MOVE@(mtx)", sp);
            sp = " ";
         }
   @endwhile
         fprintf(fp, " \\\n        %s \\\n", flgs);
         fprintf(fp, 
                 "        -DATL_USERMM=%s_b%c \\\n        -c -o %s_b%c.o \\\n",
                 mp->auth, bes[ib], mp->auth, bes[ib]);
         fprintf(fp, "        %s\n", mp->rout);
      }
   }
   @BEGINSKIP
/*
 * Make targets for C copy routines
 */
   fprintf(fp, "#\n#  C copy rules\n#\n");
   dflags[3] = dcomp[3] = 'K';
   for (cp=cpC; cp; cp = cp->next)  /* C copy routs */
   {
      char *styp;
      int ib;
      char pr;

      styp = CopyGetCompType(cp->flag);
      for (ib=0; ib < 4; ib++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
         {
            fprintf(fp, "%s_a%cb%c.o : %s.c\n", cp->rout, als[ia], bes[ib], 
                    cp->rout);
            fprintf(fp, "\t%s %s -c $(CDEFS) -D%s=1 -DBETA%s=1 -DALPHA%s=1",
                    dcomp, dflags, styp, sbes[ib], sals[ia]);
            fprintf(fp, 
            " \\\n           -DATL_USERCPMM=%s_a%c_b%c -DATL_MU=%d -DATL_NU=%d",
                    cp->rout, als[ia], bes[ib], cp->mu, cp->nu);
            fprintf(fp, " \\\n           -o %s_a%cb%c.o %s.c\n", 
                    cp->rout, als[ia], bes[ib], cp->rout);
         }
      }
   }
/*
 * Make targets for A/B copy routines
 */
   fprintf(fp, "#\n#  A/B copy rules\n#\n");
   for (cp=cpA; cp; cp = cp->next) 
   {
      char *styp, *cnj[2] = {"", "-DConj_=1"};
      const int flag = cp->flag;
      const int NC = (flag&(1<<CPF_REAL)) ? 1 : 2;
      int ic;
      char pr;
      styp = CopyGetCompType(cp->flag);
      for (ic=0; ic < NC; ic++)
      {
         int it;
         for (it=0; it < 2; it++)
         {
            int ia;
            const int itc = ic*NC+it;
            for (ia=0; ia < 3; ia++)
            {
               fprintf(fp, "%s_%ca%c.o : %s.c\n", cp->rout, ctas[itc], 
                       als[ia], cp->rout);
               fprintf(fp, "\t%s %s -c $(CDEFS) -D%s=1 -DALPHA%s=1",
                       dcomp, dflags, styp, sals[ia]);
               fprintf(fp, " \\\n           -DATL_NU=%d -DTRANS%c_=1 %s", 
                       cp->nu, ctas[it],  cnj[ic]);
               fprintf(fp, " \\\n           -DATL_USERCPMM=%s_%ca%c", cp->rout, 
                       ctas[itc], als[ia]);
               fprintf(fp, " \\\n           -o %s_%ca%c.o %s.c\n", 
                       cp->rout, ctas[itc], als[ia], cp->rout);
            }
         }
      }
   }
   @ENDSKIP
   fclose(fp);
}

void GenAllFiles(char pre, char *outd, ATL_mmnode_t **lists)
{
   FILE *fp;
   int i, RCSAME;
   ATL_mmnode_t *rb=NULL, *ib=NULL, *mp;
   ATL_cpnode_t *cpA=NULL, *cpC=NULL, *ncp;
   const char cpr = (pre == 'd') ? 'z' : 'c';
/*
 * First, generate performance files, which require routs separated by
 * various lists
 */
   printf("\nGENERATING HEADER FILES\n");
   GenAllHeaders(pre, outd, lists);
   printf("DONE HEADER GENERATION\n");

/*
 * Generating kernels & Makefile do not care which list kernels came from,
 * or their order, so combine them all into one list for each data type 
 * (2 lists total: real,complex), and remove any redundancies.
 * NOTE: rank-K should be distinguished by flag setting (MMF_MV[A,B,C]),
 * and so doesn't need protection in new naming system.
 * NOTE2: I think we should generate copy routs at this time and then
 *        can pass info to GenAllKerns & GenMake.
 */
   for (i=0; i < ITRSM; i++)
   {
      rb = AddUniqueMMKernCompList(rb, lists[i]);
      KillAllMMNodes(lists[i]);
      ib = AddUniqueMMKernCompList(ib, lists[NMMLISTS+i]);
      KillAllMMNodes(lists[NMMLISTS+i]);
   }
@beginskip
/*
 * Now create lists of copy routines for both real & complex
 */
   GetMMAllUniqueCopyFromMMNodes(pre, 'F', 'T', rb, &cpA, &cpC);
   GetMMAllUniqueCopyFromMMNodes(cpr, 'F', 'T', ib, &cpA, &cpC);
/*
 * SYRK A2blk copy rout same as GEMM, so add it to list; 
 * syblk2C not same, so add w/o checking uniqueness
 */
   cpA = AddMMUniqueACopyFromMMNodes(pre, 'T', lists[ISYRK], cpA);
   cpA = AddMMUniqueACopyFromMMNodes(cpr, 'T', lists[NMMLISTS+ISYRK], cpA);
   cpC = AddMMCKernCopyFromMMNodes(pre, 'F', CPF_SYRK, lists[ISYRK], cpC);
   cpC = AddMMCKernCopyFromMMNodes(cpr, 'F', CPF_SYRK, 
                                  lists[NMMLISTS+ISYRK], cpC);
@endskip
/*
 * Now, kerns are compiled the same for real and complex, so reduce real
 * and complex to one unique list
 */
   rb = AddUniqueMMKernCompList(rb, ib);
   KillAllMMNodes(ib);
/*
 * SYRK never same as GEMM, so just add syrk kerns to list, but don't dup if
 * real/cplx are same kernel other than blocking
 */
   ib = lists[ISYRK];
   if (ib)
   {
      ATL_mmnode_t *p = lists[NMMLISTS+ISYRK];
      assert(p);
      if (!MMKernsPerfSame(lists[ISYRK], p))
      {
         ib->next = lists[NMMLISTS+ISYRK];
         ib->next->next = rb;
      }
      else
      {
         ib->next = rb;
         KillAllMMNodes(p);
      }
      rb = ib;
   }
   GenAllKerns(pre, outd, rb);
   GenMake(pre, outd, rb);  
   KillAllMMNodes(rb);
   KillAllCopyNodes(cpA);
   KillAllCopyNodes(cpC);
}

int main(int nargs, char **args)
{
   char *outd;
   ATL_mmnode_t *lists[2*NMMLISTS];
   int i;
   char pre, cpr;

   outd = GetFlags(nargs, args, &pre, lists);
   cpr = (pre == 'd') ? 'z' : 'c';
/*
 * Prep file for generation.  Free present values, and replace with:
 * ->auth  : kernel name without _b[1,n,0] suffix
 * ->genstr: for ID=0: genstr, else user kernel name (came in ->rout)
 * ->rout  : correct present filename
 * TRSM/SYRKT entries we just set all these to NULL, since not needed.
 * TRSM/SYRKT used to [ts,sk]amm_perf.h, needs perf,NB,IDX
 */
   for (i=0; i < 2*NMMLISTS; i++)
   {
      if (i == ITRSM || i == ITRSM+NMMLISTS ||
          i == ISYRKT || i == ISYRKT+NMMLISTS)
         KillAllMMStrings(lists[i]);
      else if (i == ISYRK || i == ISYRK+NMMLISTS)
         PrepMMForGen((i==ISYRK)?pre:cpr, outd, "syrk", lists[i]);
      else
         PrepMMForGen(pre, outd, "amm", lists[i]);
   }

   GenAllFiles(pre, outd, lists);

   free(outd);
   return(0);
}
@ROUT N2Idx
static INLINE int N2Idx(const unsigned int N)
/*
 * Uses Recursive halving to find smallest NB >= N in VWsyrk.
 */
{
   unsigned int idxB=ATL_VWsyrk_NCASES-1, idxS=0, idxM;
   unsigned int nbB, nbS=ATL_VWsyrk_MIN_NB, nbM;
   if (N <= ATL_VWsyrk_MIN_NB)
      return(0);
   nbB = ATL_GetVWsyrkMB(idxB);
   if (N >= nbB)
      return(ATL_VWsyrk_NCASES-1);
   KEEP_ON:
      idxM = ((idxB-idxS)>>1)+idxS;
      if (idxM == idxS)
         return((nbS >= N) ? idxS:idxB);
      nbM = ATL_GetVWsyrkMB(idxM);
      if (nbM > N)
      {
         idxB = idxM;
         nbB = nbM;
      }
      else if (nbM < N)
      {
         idxS = idxM;
         nbS = nbM;
      }
      else /* if (nbM == N) */
         return(idxM);
   goto KEEP_ON;
}
@ROUT uammsrch
#include "atlas_misc.h"
#include "atlas_mmtesttime.h"
#define CON_NOKVEC 0
#define CON_NOMVEC 1
#define CON_NOCOMPK 2


void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -T #  : set pruning tolerance for slower kernels:\n");
   fprintf(stderr,
   "      # <= 0.0 : keep all legal kernel sizes regardless of performance\n");
   fprintf(stderr,
   "      # >=0.0 : delete all kerns wt perf*# < maxSmallerPerf\n");
   fprintf(stderr,
   "                maxSmallerPerf= max perf found in smaller-sized kern\n");
   fprintf(stderr, "   -p [s,d]: set precision prefix (d) \n");
   fprintf(stderr, "   -b # nb1 ... nb# : square NBs to force\n");
   fprintf(stderr, "   -B # mb1 nb1 kb1 ... mb# nb# kb#: dims to force\n");
   fprintf(stderr, "   -S B0 Bn Binc : do series [B0,Bn] wt Binc stride\n");
   fprintf(stderr, "   -N maxB : try all blks up to & including maxB\n");
   fprintf(stderr, 
      "   -F # a/b/c1 ... a/b/c#: which matblks should be cache flushed\n");
   fprintf(stderr, "   -v <verb> : set verbosity (1)\n");
   fprintf(stderr, "   -C [kmc] : Constrain kernel choice:\n");
   fprintf(stderr, "      k : don't allow K-vectorized storage\n");
   fprintf(stderr, "      m : don't allow M-vectorized storage\n");
   fprintf(stderr, "      c : don't allow compile-time K kernels\n");
   fprintf(stderr, "   -K <1/0> : do/don't generate K cleanup\n");
   fprintf(stderr, "   -o <outfile> : [res/<pre>UAMMRES.sum]\n");

   exit(ierr ? ierr : -1);
}

char *GetFlags(int nargs, char **args, char *PRE, int *C, int *MVS,
               int *NN, int **MBS, int **NBS, int **KBS, float *TOL,
               int *KCLEAN)
{
   ATL_mmnode_t *mmb=NULL;
   int B0=0, BN, KI;
   int *mbs=NULL, *nbs=NULL, *kbs=NULL;
   int i, k, j, N=0, ALL=0, MV=3, b0, bn, incB;
   char *cs, *fout=NULL;
   static char fnam[32];

   *TOL = 0.0;
   *PRE = 'd';
   *C = 0;
   *KCLEAN = 1;
   for (i=1; i < nargs; i++)
   {
      int n;
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'o':
         if (++i >= nargs)
             PrintUsage(args[0], i-1, NULL);
         fout = args[i];
         break;
      case 'p':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *PRE = tolower(args[i][0]);
         assert(*PRE == 's' || *PRE == 'd' || *PRE == 'z' || *PRE == 'c');
         break;
      case 'T':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *TOL = atof(args[i]);
         if (*TOL < 0.0)
            *TOL = 0.0;
         break;
      case 'F':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         n = atoi(args[i]);
         for (MV=k=0; k < n; k++)
         {
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            if (args[i][0] == 'a' || args[i][0] == 'A')
               MV |= 1;
            else if (args[i][0] == 'b' || args[i][0] == 'B')
               MV |= 2;
            else if (args[i][0] == 'c' || args[i][0] == 'C')
               MV |= 4;
            else
               PrintUsage(args[0], -i, "UNKNOWN MATRIX FOR -M");
         }
         break;
      case 'K':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *KCLEAN = atoi(args[i]);
         break;
@beginskip
      case 'v':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *VERB = atoi(args[i]);
         break;
@endskip
      case 'C':  /* -C <constraint string */
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         cs = args[i];
         n = strlen(cs);
         for (k=0; k < n; k++)
         {
            switch(cs[k])
            {
            case 'm':
               *C |= 1<<CON_NOMVEC;
               break;
            case 'k':
               *C |= 1<<CON_NOKVEC;
               break;
            case 'c':
               *C |= 1<<CON_NOCOMPK;
               break;
            default:
               PrintUsage(args[0], -i, "UNKNOWN CONSTRAINT");
            }
         }
         break;
      case 'N': /* <maxNB> */
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         else
         {
            int b0, bn, incB, n, k;
            bn = atoi(args[i]);
            b0 = 4;
            incB = 1;
            n = 1 + (bn-b0)/incB;
            mbs = malloc(n*sizeof(int));
            nbs = malloc(n*sizeof(int));
            kbs = malloc(n*sizeof(int));
            assert(mbs && nbs && kbs);
            for (k=0,n=b0; n <= bn; k++, n += incB)
               mbs[k] = nbs[k] = kbs[k] = n;
            assert(k <= n);
            *NN = k;
         }
         break;
      case 'S':  /* <b0> <bN> <incB> */
         if (i+3 >= nargs)
            PrintUsage(args[0], i-1, NULL);
         else
         {
            int b0, bn, incB, n, k;

            b0 = atoi(args[i+1]);
            bn = atoi(args[i+2]);
            incB = atoi(args[i+3]);
            n = 1 + (bn-b0)/incB;
            mbs = malloc(n*sizeof(int));
            nbs = malloc(n*sizeof(int));
            kbs = malloc(n*sizeof(int));
            assert(mbs && nbs && kbs);
            for (k=0,n=b0; n <= bn; k++, n += incB)
               mbs[k] = nbs[k] = kbs[k] = n;
            assert(k <= n);
            i += 3;
            *NN = k;
         }
         break;
      case 'B':
         if (nbs)
         {
            free(mbs);
            free(nbs);
            free(kbs);
         }
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *NN = N = atoi(args[i]);
         assert(N > 0);
         nbs = malloc(N*sizeof(int));
         assert(nbs);
         mbs = malloc(N*sizeof(int));
         assert(mbs);
         kbs = malloc(N*sizeof(int));
         assert(kbs);
         for (k=0; k < N; k++)
         {
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           mbs[k] = atoi(args[i]);
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           nbs[k] = atoi(args[i]);
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           kbs[k] = atoi(args[i]);
         }
         break;
      case 'b':
         if (nbs)
         {
            free(mbs);
            free(nbs);
            free(kbs);
         }
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         N = atoi(args[i]);
         if (N < 0)
         {
            ALL = (N == -2) ? 32 : -1;  /* -2: don't force MB */
            N = 36;
         }
         *NN = N;
         assert(N > 0);
         nbs = malloc(N*sizeof(int));
         assert(nbs);
         mbs = malloc(N*sizeof(int));
         assert(nbs);
         kbs = malloc(N*sizeof(int));
         assert(nbs);
         if (ALL)  /* special case to just try most possible NBs */
         {
            mbs[ 0]=nbs[ 0]=kbs[ 0]=4;
            mbs[ 1]=nbs[ 1]=kbs[ 1]=6;
            mbs[ 2]=nbs[ 2]=kbs[ 2]=8;
            mbs[ 3]=nbs[ 3]=kbs[ 3]=12;
            mbs[ 4]=nbs[ 4]=kbs[ 4]=14;
            mbs[ 5]=nbs[ 5]=kbs[ 5]=16;
            mbs[ 6]=nbs[ 6]=kbs[ 6]=20;
            mbs[ 7]=nbs[ 7]=kbs[ 7]=22;
            mbs[ 8]=nbs[ 8]=kbs[ 8]=24;
            mbs[ 9]=nbs[ 9]=kbs[ 9]=26;
            mbs[10]=nbs[10]=kbs[10]=28;
            mbs[11]=nbs[11]=kbs[11]=32;
            mbs[12]=nbs[12]=kbs[12]=36;
            mbs[13]=nbs[13]=kbs[13]=40;
            mbs[14]=nbs[14]=kbs[14]=44;
            mbs[15]=nbs[15]=kbs[15]=48;
            mbs[16]=nbs[16]=kbs[16]=52;
            mbs[17]=nbs[17]=kbs[17]=56;
            mbs[18]=nbs[18]=kbs[18]=60;
            mbs[19]=nbs[19]=kbs[19]=64;
            mbs[20]=nbs[20]=kbs[20]=72;
            mbs[21]=nbs[21]=kbs[21]=80;
            mbs[22]=nbs[22]=kbs[22]=84;
            mbs[23]=nbs[23]=kbs[23]=88;
            mbs[24]=nbs[24]=kbs[24]=96;
            mbs[25]=nbs[25]=kbs[25]=104;
            mbs[26]=nbs[26]=kbs[26]=112;
            mbs[27]=nbs[27]=kbs[27]=120;
            mbs[28]=nbs[28]=kbs[28]=128;
            mbs[29]=nbs[29]=kbs[29]=132;
            mbs[30]=nbs[30]=kbs[30]=144;
            mbs[31]=nbs[31]=kbs[31]=156;
            mbs[32]=nbs[32]=kbs[32]=168;
            mbs[33]=nbs[33]=kbs[33]=192;
            mbs[34]=nbs[34]=kbs[34]=216;
            mbs[35]=nbs[35]=kbs[35]=240;
            for (k=0; k < ALL; k++)     /* don't force any particular */
               mbs[k] = 0;              /* MB during search */
         }
         else
         {
            for (k=0; k < N; k++)
            {
              if (++i >= nargs)
                  PrintUsage(args[0], i-1, NULL);
               mbs[k] = kbs[k] = nbs[k] = atoi(args[i]);
            }
         }
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (!nbs)
      PrintUsage(args[0], -1, "Dimensional flag (-b, -B -N, or -S) required!");
   *MBS = mbs;
   *NBS = nbs;
   *KBS = kbs;
   *MVS = MV;
   if (!fout)
   {
      sprintf(fnam, "res/%cuAMMRES.sum", *PRE);
      fout = fnam;
   }
   return(fout);
}

ATL_mmnode_t *DoSrch(ATL_mmnode_t *mmb, char pre, int flag, int beta, 
                     int cflush, int nB, int *mbs, int *nbs, int *kbs)
/* need args for: moves */
{
   ATL_mmnode_t *mmB=NULL;
   int ib;
   printf("\nFINDING BEST AMONGST %d KERNELS and %d BLOCK FACTORS:\n", 
          ATL_CountNumberOfMMNodes(mmb), nB);
   for (ib=0; ib < nB; ib++)
   {
      ATL_mmnode_t *mmp;
      const int mb = mbs[ib], nb=nbs[ib], kb=kbs[ib];
      mmp = MMBestWithGenKB(1, 0, flag, mmb, pre, mb, nb, kb, beta, -1, cflush);
      if (mmp)
      {
         mmp->next = mmB;
         mmB = mmp;
         printf("   BEST FOR B=(%d,%d,%d): %d,%s, mf=%.2f\n", 
                mb, nb, kb, mmp->ID, mmp->rout, mmp->mflop[0]);
      }
      else
         printf("   NO VALID KERNEL FOR B=(%d,%d,%d)!\n", mb, nb, kb);
   }
   return(ReverseMMQ(mmB));
}

int main(int nargs, char **args)
{
   ATL_mmnode_t *mmb, *mmB;
   int *mbs, *nbs, *kbs;
   char *fnout;
   int C, MVS, N, KCLEAN;
   float tol;
   char pre, upr;

   fnout = GetFlags(nargs, args, &pre, &C, &MVS, &N, &mbs, &nbs, &kbs, &tol,
                    &KCLEAN);
   if (pre == 'd' || pre == 's')
      upr = pre;
   else
      upr = (pre == 'z') ? 'd' : 's';
/*
 * Get all working user-supplied kerns & best found generated kerns
 * assumes default search already run to produce [WORKING,gAMMRES].sum
 */
   mmb = ReadMMFileWithPath(upr, "res", "WORKING.sum");
   ATL_LastMMNode(mmb)->next = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   assert(mmb);
/*
 * Remove kernels that don't meet required constraints
 */
   if (C)
   {
      ATL_mmnode_t *mp=mmb;
      do
      {
         ATL_mmnode_t *nxt = mp->next;
         int kill;
         kill  = (C & (1<<CON_NOKVEC)) && FLAG_IS_SET(mp->flag, MMF_KVEC);
         kill |= (C & (1<<CON_NOMVEC)) && !FLAG_IS_SET(mp->flag, MMF_KVEC);
         kill |= (C & (1<<CON_NOCOMPK)) && !FLAG_IS_SET(mp->flag, MMF_KRUNTIME);
         if (kill)
         {
            mmb = RemoveMMNodeFromQ(mmb, mp);
            KillMMNode(mp);
         }
         mp = nxt;
      }
      while (mp);
      assert(mmb);
   }
   MMApplyMoves2Flags(mmb, MVS);  /* use requested flushing */
   mmB = DoSrch(mmb, pre, 0, 1, -1, N, mbs, nbs, kbs);
   KillAllMMNodes(mmb);
   free(mbs);
   free(nbs);
   free(kbs);
   assert(mmB);
   if (tol > 0.0)
      MMPruneMflopTol(mmB, 0, tol);
   WriteMMFile(fnout, mmB);
   KillAllMMNodes(mmB);
   return(0);
}
@ROUT ATL_CopyInfo_rkK
#include "atlas_amm.h"
@whiledef vw oprk opsq
#ifdef ATL_@(vw)_
   #define CCPRE Mjoin(ATLAS_PRE,@(vw)_)
   #define ATL_FillInCopy Mjoin(PATL,FillInCopy_@(vw))
   #include Mstr(Mjoin(CCPRE,FromANdecl_a1.h))
   #ifdef SREAL
      #ifdef ATLAS_S@(vw)_FROMANDECL_A1_H
         #define ATL_READY 1
      #endif
    #elif defined(DCPLX)
      #ifndef ATLAS_Z@(vw)_FROMANDECL_A1_H
         #define ATL_READY 1
      #endif
    #elif defined(SCPLX)
      #ifndef ATLAS_C@(vw)_FROMANDECL_A1_H
         #define ATL_READY 1
      #endif
    #else
      #ifndef ATLAS_D@(vw)_FROMANDECL_A1_H
         #define ATL_READY 1
      #endif
    #endif
#endif
#ifndef ATL_READY
   #define ATL_READY 0
#endif
@endwhile
#if ATL_READY /* Don't try to compile until header files are genned */
@whiledef al 1 N X
   @whiledef ta N T
   #include Mstr(Mjoin(CCPRE,FromA@(ta)decl_a@(al).h))
   #include Mstr(Mjoin(CCPRE,FromB@(ta)decl_a@(al).h))
   @endwhile
   @whiledef be 0 1 N X
   #include Mstr(Mjoin(CCPRE,IntoCdecl_a@(al)b@(be).h))
   @endwhile
@endwhile
   #ifdef TCPLX
@whiledef al 1 N X
   @whiledef ta H C
      #include Mstr(Mjoin(CCPRE,FromA@(ta)decl_a@(al).h))
      #include Mstr(Mjoin(CCPRE,FromB@(ta)decl_a@(al).h))
   @endwhile
@endwhile
   #endif

void ATL_FillInCopy
   (opinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, 
    int ALPA, const SCALAR alpha, const SCALAR beta)
{
   const int AlpOne = SCALAR_IS_ONE(alpha);

   if (ALPA || AlpOne) /* alpha 1,N or X, apply it to A */
   {
      ip->alpA = alpha;
      #ifdef TCPLX
         ip->alpB = ip->ONE;
      #else
         ip->alpB = ATL_rone;
      #endif
      if (AlpOne)
      {
         #ifdef TCPLX
         if (TA == AtlasConj)
            ip->a2blk = ATL_AMM_AC2BLK_a1[idx];
         else if (TA == AtlasConjTrans)
            ip->a2blk = ATL_AMM_AH2BLK_a1[idx];
         else
         #endif
         ip->a2blk = (TA == AtlasNoTrans) ? 
                     ATL_AMM_AN2BLK_a1[idx]:ATL_AMM_AT2BLK_a1[idx];
      }
      else  /* know alpha=N or X if we reach here */
      {
         if (TA == AtlasNoTrans)
            ip->a2blk = SCALAR_IS_NONE(alpha) ? 
                        ATL_AMM_AN2BLK_aN[idx]:ATL_AMM_AN2BLK_aX[idx];
         #ifdef TCPLX
         else if (TA == AtlasConj)
            ip->a2blk = SCALAR_IS_NONE(alpha) ? 
                        ATL_AMM_AC2BLK_aN[idx]:ATL_AMM_AC2BLK_aX[idx];
         else if (TA == AtlasConjTrans)
            ip->a2blk = SCALAR_IS_NONE(alpha) ? 
                        ATL_AMM_AH2BLK_aN[idx]:ATL_AMM_AH2BLK_aX[idx];
         #endif
         else
            ip->a2blk = SCALAR_IS_NONE(alpha) ? 
                        ATL_AMM_AT2BLK_aN[idx]:ATL_AMM_AT2BLK_aX[idx];
      }
      #ifdef TCPLX
         if (TB == AtlasConj)
            ip->b2blk = ATL_AMM_BC2BLK_a1[idx];
         else if (TB == AtlasConjTrans)
            ip->b2blk = ATL_AMM_BH2BLK_a1[idx];
         else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ? 
                     ATL_AMM_BN2BLK_a1[idx]:ATL_AMM_BT2BLK_a1[idx];
   }
   else /* alpha=N or X, apply alpha to B */
   {
      ip->alpB = alpha;
      #ifdef TCPLX
         ip->alpA = ip->ONE;
      #else
         ip->alpA = ATL_rone;
      #endif
      if (TB == AtlasNoTrans)
         ip->b2blk = SCALAR_IS_NONE(alpha) ? 
                     ATL_AMM_BN2BLK_aN[idx]:ATL_AMM_BN2BLK_aX[idx];
      #ifdef TCPLX
      else if (TB == AtlasConj)
         ip->b2blk = SCALAR_IS_NONE(alpha) ? 
                     ATL_AMM_BC2BLK_aN[idx]:ATL_AMM_BC2BLK_aX[idx];
      else if (TB == AtlasConjTrans)
         ip->b2blk = SCALAR_IS_NONE(alpha) ? 
                     ATL_AMM_BH2BLK_aN[idx]:ATL_AMM_BH2BLK_aX[idx];
      #endif
      else
         ip->b2blk = SCALAR_IS_NONE(alpha) ? 
                     ATL_AMM_BT2BLK_aN[idx]:ATL_AMM_BT2BLK_aX[idx];
      #ifdef TCPLX
         if (TA == AtlasConj)
            ip->a2blk = ATL_AMM_AC2BLK_a1[idx];
         else if (TA == AtlasConjTrans)
            ip->a2blk = ATL_AMM_AH2BLK_a1[idx];
         else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ? 
                     ATL_AMM_AN2BLK_a1[idx]:ATL_AMM_AT2BLK_a1[idx];
   }
   if (SCALAR_IS_NONE(beta))
      ip->blk2C = ATL_AMM_C2BLK_a1_bN[idx];
   else if (SCALAR_IS_ONE(beta))
      ip->blk2C = ATL_AMM_C2BLK_a1_b1[idx];
   else
      ip->blk2C = SCALAR_IS_ZERO(beta) ? 
                  ATL_AMM_C2BLK_a1_b0[idx]:ATL_AMM_C2BLK_a1_bX[idx];
}
#endif  /* end test if generated file exist */
@ROUT ATL_GetInfo_rkK
#include "atlas_amm.h"
#include Mstr(Mjoin(ATLAS_PRE,amm_sum.h))
@multidef pf rk    sq
@whiledef vw oprk  opsq
#ifdef ATL_@(vw)_
   #define AMPRE Mjoin(ATLAS_PRE,@(vw)_)
   #define ATL_FillInInfo Mjoin(PATL,FillInInfo_@(vw))
   #define ATL_FillInCopy Mjoin(PATL,FillInCopy_@(vw))
   #define ATL_GetInfo Mjoin(PATL,GetInfo_@(vw))
   #define ATL_GetInfo_1b Mjoin(PATL,GetInfo_1b_@(vw))
   #ifdef ATL_AMM_NCASES
      #undef ATL_AMM_NCASES
   #endif
   @whiledef mn LASTKB NCASES LASTMB LASTNB MAXKVEC
   #define ATL_AMM_@(mn) ATL_@(pf)AMM_@(mn)
   @endwhile
   @undef pf
#endif
@endwhile
#ifdef SREAL
   #ifdef ATLAS_SAMM_SUM_H
      #define ATL_READY 1
   #endif
#elif defined(SCPLX)
   #ifdef ATLAS_CAMM_SUM_H
      #define ATL_READY 1
   #endif
#elif defined(DCPLX)
   #ifdef ATLAS_ZAMM_SUM_H
      #define ATL_READY 1
   #endif
#else
   #ifdef ATLAS_DAMM_SUM_H
      #define ATL_READY 1
   #endif
#endif
#ifndef ATL_READY
   #define ATL_READY 0
#endif
#if ATL_READY /* Don't try to compile until header files are genned */
   #include Mstr(Mjoin(AMPRE,kern.h))
   #include Mstr(Mjoin(AMPRE,blk.h))
   #include Mstr(Mjoin(AMPRE,perf.h))
void ATL_FillInCopy
   (opinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, 
    int ALPA, const SCALAR alpha, const SCALAR beta);

void ATL_FillInInfo
   (opinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, ATL_CSZT lda, ATL_CSZT ldb, 
    ATL_CSZT ldc, const SCALAR alpha, const SCALAR beta,
    size_t nfmblks, size_t npmblks, int mb, int pmb,
    size_t nfnblks, size_t npnblks, int nb, int pnb)
{
   #if ATL_AMM_MAXKVEC == 0
      const unsigned int kb = K;
   #else
      int unsigned kb = K;
   #endif
   const unsigned int mu=ATL_AMM_MUs[idx], nu=ATL_AMM_NUs[idx];
   const unsigned int ku=ATL_AMM_KUs[idx], vlen=ATL_AMM_VLENs[idx];
   unsigned int sz, nmu, nnu;
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      #define CONE ATL_rone
   #endif

   #if ATL_AMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   ip->kb = K;
   ip->KB = kb;
   #ifdef TCPLX
      ip->ONE = CONE;
   #endif
   ip->beta = beta;
   @multidef v mu nu ku vlen idx
   @whiledef v nfmblks npmblks mb pmb nfnblks npnblks nb pnb lda ldb ldc
   ip->@(v) = @(v);
   @endwhile
   @multidef mt B A
   @whiledef d  n m
   ip->n@(d)u = @(d)b / @(d)u;
   ip->pn@(d)u = p@(d)b / @(d)u;
   if (np@(d)blks)
   {
      ip->@(d)F = @up@(d) - nf@(d)blks*@(d)b - (np@(d)blks-1)*p@(d)b;
      ip->n@(d)uF = (ip->@(d)F+@(d)u-1) / @(d)u;
   }
   else
      ip->n@(d)uF = ip->@(d)F = 0;
   ip->psz@(mt) = p@(d)b*kb;
   ip->sz@(mt) = kb * (@(d)b ? @(d)b:p@(d)b);
      @undef mt
   @endwhile
   sz = ((mu*nu+vlen-1)/vlen)*vlen;
   sz *= (ip->nmu) ? ip->nmu : ip->pnmu;
   sz *= (ip->nnu) ? ip->nnu : ip->pnnu;
   ip->szC = sz;
   ip->amm_b0 = ATL_AMM_KERN_b0[idx];
   #ifdef TCPLX
      ip->amm_b1 = ATL_AMM_KERN_b1[idx];
      ip->amm_bn = ATL_AMM_KERN_bn[idx];
   #endif
   #ifdef TCPLX
   if (TA == AtlasNoTrans || TA == AtlasConj)
   #else
   if (TA == AtlasNoTrans)
   #endif
   {
      ip->incAm = mb SHIFT;
      ip->pincAm = pmb SHIFT;
   }
   else
   {
      ip->incAm = lda*(mb SHIFT);
      ip->pincAm = lda*(pmb SHIFT);
   }
   #ifdef TCPLX
   if (TB == AtlasNoTrans || TB == AtlasConj)
   #else
   if (TB == AtlasNoTrans)
   #endif
   {
      ip->incBn = ldb*(nb SHIFT);
      ip->pincBn = ldb*(pnb SHIFT);
   }
   else
   {
      ip->incBn  = nb SHIFT;
      ip->pincBn = pnb SHIFT;
   }
   ATL_FillInCopy(ip, idx, TA, TB, (M<=N), alpha, beta);
}

#ifdef ATL_opsq_
static int FindKB(unsigned int K)
/*
 * Returns -1 if you should use rkmm instead of this case.  
 * The smallest KB is special, because it is known to be 4 for opsq, 
 * while it is 3 for rkmm.  We'd rather pad K to at most 1 step than
 * possibly pad M & N to mu-1 and nu-1 respectively.  So, if our smallest
 * kernel can do the problem, we return 0 even when K < 4.
 * For any other case, we return only on precise match.  sqmm should always
 * beat rkmm for MB=NB=KB, since it is tuned for this precise case, while
 * kbmm assumes MB & NB are free variables (can be as large as we want).
 */
{
   register unsigned int IH=ATL_sqAMM_NCASES-1, IL, I, kb, gap;
   if (K >= ATL_sqAMM_LASTKB)  /* check if last KB is runtime, so can handle */
   {
      if (K == ATL_sqAMM_LASTKB)
         return(IH);
      return(-1);  /* cannot handle this K */
   }
   kb = *ATL_AMM_KBs;
   if (kb >= K)
   {
      register unsigned int ku;
      const int KMAJ=ATL_AMM_KMAJOR(0);
      if (kb == K)
         return(0);
      ku = *ATL_AMM_KUs;
      if (KMAJ && ((K+ku-1)/ku)*ku >= K)
         return(0);
      if (ATL_AMM_KRUNTIME(0)) /* possibly can decrease K to handle */
      {
         if (KMAJ)      /* handles K%ku by padding */
            return(0);  /* so works wt any K */
         else if ((K/ku)*ku == K)
            return(0);
      }
      return(-1); /* smallest kernel can't handle K */
   }
/*
 * Otherwise, do binary search for exact KB match, and return -1 if not found
 */
   IL=0;
   gap = IH - IL - 1;
   while (gap > 2)
   {
      I = IL + (gap>>1);
      kb = ATL_AMM_KBs[I];
      if (kb > K)
         IH = I;
      else if (kb < K)
         IL = I;
      else
         return(I);
      gap = IH - IL - 1;
   }
   if (gap)
   {
      if (ATL_AMM_KBs[IL+1] == K)
         return(IL+1);
      if (IL+1 < IH-1)
         if (ATL_AMM_KBs[IH-1] == K)
             return(IH-1);
   }
   return(-1);
}
#endif
#ifdef ATL_oprk_
static INLINE int HandleBigK(const unsigned int K)
/*
 * Called when K > MAXKB, will return last case if it can do that K, -1 else
 */
{
   if (ATL_AMM_KRUNTIME(ATL_rkAMM_NCASES-1))
   {
      if (ATL_AMM_KMAJOR(ATL_rkAMM_NCASES-1))
         return(ATL_rkAMM_NCASES-1);
      else
      {
         int ku=ATL_AMM_KBs[ATL_rkAMM_NCASES-1];
         if ((K/ku)*ku == K)
            return(ATL_rkAMM_NCASES-1);
      }
   }
   return(-1);
}
#endif
@BEGINPROC findIDX dl
   #ifdef ATL_opsq_
      idx = FindKB(K);
      if (idx == -1)
         return(-1);
   #endif
   #ifdef ATL_oprk_
      if (N == M && N == K)  /* try square case instead */
      {
         idx = Mjoin(PATL,GetInfo@(dl)opsq)
                  (ip, TA,TB, M,N,K, lda,ldb,ldc, alpha,beta);
         if (idx != -1)
            return(idx);
      }
      #if 0   /* these views not yet supported */
      if (N == K)
      {
         idx = Mjoin(PATL,GetInfo@(dl)opnk)
                  (ip, TA,TB, M,N,K, lda,ldb,ldc, alpha,beta);
         if (idx != -1)
            return(idx);
      }
      else if (M == K)
      {
         idx = Mjoin(PATL,GetInfo@(dl)opmk)
                  (ip, TA,TB, M,N,K, lda,ldb,ldc, alpha,beta);
         if (idx != -1)
            return(idx);
      }
      #endif
      if (K > ATL_AMM_LASTKB)
      {
         idx = HandleBigK(K);
         if (idx == -1)
            return(-1);
      }
      else
         idx = K-3;
   #endif
@ENDPROC
int ATL_GetInfo_1b
   (opinfo_t *ip, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, ATL_CSZT lda, ATL_CSZT ldb,
    ATL_CSZT ldc, const SCALAR alpha, const SCALAR beta)
{
   int idx;
   unsigned int mu, nu, nfmblks, npmblks, nfnblks, npnblks, mb, nb, pmb, pnb;
   @callproc findIDX _1b_
   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
   mb = ((M+mu-1)/mu)*mu;
   nb = ((N+nu-1)/nu)*nu;
   if (mb == M)
   {
      nfmblks = 1;
      pmb = npmblks = 0;
   }
   else
   {
      pmb = mb;
      mb = nfmblks = 0;
      npmblks = 1;
   }
   if (nb == N)
   {
      nfnblks = 1;
      pnb = npnblks = 0;
   }
   else
   {
      pnb = nb;
      nb = nfnblks = 0;
      npnblks = 1;
   }
   ATL_FillInInfo(ip, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta,
                  nfmblks, npmblks, mb, pmb, nfnblks, npnblks, nb, pnb);
   return(idx);
}

int ATL_GetInfo
   (opinfo_t *ip, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, ATL_CSZT lda, ATL_CSZT ldb,
    ATL_CSZT ldc, const SCALAR alpha, const SCALAR beta)
{
   int idx, mu, nu, mb, nb, pmb, pnb, nmu, nnu;
   ATL_SZT nfmblks, npmblks, nfnblks, npnblks;

   @callproc findIDX _

   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];

   @whiledef d n m
   @(d)b = ATL_AMM_@up@(d)Bs[idx];
   if (@(d)b > @up@(d))
   {
      p@(d)b = ((@up@(d)+@(d)u-1)/@(d)u)*@(d)u;
      np@(d)blks = 1;
      @(d)b = 0;
      nf@(d)blks = 0;
   }
   else
   {
      nf@(d)blks = @up@(d) / @(d)b;
      p@(d)b = @up@(d) - nf@(d)blks*@(d)b;
      np@(d)blks = (p@(d)b) ? 1 : 0;
      p@(d)b = ((p@(d)b+@(d)u-1)/@(d)u)*@(d)u;
   }
   @endwhile
   ATL_FillInInfo(ip, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta,
                  nfmblks, npmblks, mb, pmb, nfnblks, npnblks, nb, pnb);
   return(idx);
}
#endif  /* end guard for generated header files */
@ROUT ATL_GetInfo_ip
#include "atlas_amm.h"
#include Mstr(Mjoin(ATLAS_PRE,amm_sum.h))
@multidef pf ge  
@whiledef vw ipge
#ifdef ATL_@(vw)_
   #define AMPRE Mjoin(ATLAS_PRE,@(vw)_)
   #define ATL_FillInInfo Mjoin(PATL,FillInInfo_@(vw))
   #define ATL_FillInCopy Mjoin(PATL,FillInCopy_@(vw))
   #define ATL_GetInfo Mjoin(PATL,GetInfo_@(vw))
   #define ATL_GetInfo_1b Mjoin(PATL,GetInfo_1b_@(vw))
   #ifdef ATL_AMM_NCASES
      #undef ATL_AMM_NCASES
   #endif
   @whiledef mn LASTKB NCASES LASTMB LASTNB MAXKVEC
   #define ATL_AMM_@(mn) ATL_@(pf)AMM_@(mn)
   @endwhile
   @undef pf
#endif
@endwhile
#include Mstr(Mjoin(AMPRE,kern.h))
#include Mstr(Mjoin(AMPRE,blk.h))
#include Mstr(Mjoin(AMPRE,perf.h))
void ATL_FillInCopy
   (opinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, 
    int ALPA, const SCALAR alpha, const SCALAR beta);

void ATL_FillInInfo
   (opinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, ATL_CSZT lda, ATL_CSZT ldb, 
    ATL_CSZT ldc, const SCALAR alpha, const SCALAR beta,
    size_t nfmblks, size_t npmblks, int mb, int pmb,
    size_t nfnblks, size_t npnblks, int nb, int pnb)
{
   #if ATL_AMM_MAXKVEC == 0
      const unsigned int kb = K;
   #else
      int unsigned kb = K;
   #endif
   const unsigned int mu=ATL_AMM_MUs[idx], nu=ATL_AMM_NUs[idx];
   const unsigned int ku=ATL_AMM_KUs[idx], vlen=ATL_AMM_VLENs[idx];
   unsigned int sz, nmu, nnu;
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      #define CONE ATL_rone
   #endif

   #if ATL_AMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   ip->kb = K;
   ip->KB = kb;
   #ifdef TCPLX
      ip->ONE = CONE;
   #endif
   ip->beta = beta;
   @multidef v mu nu ku vlen idx
   @whiledef v nfmblks npmblks mb pmb nfnblks npnblks nb pnb lda ldb ldc
   ip->@(v) = @(v);
   @endwhile
   @multidef mt B A
   @whiledef d  n m
   ip->n@(d)u = @(d)b / @(d)u;
   ip->pn@(d)u = p@(d)b / @(d)u;
   if (np@(d)blks)
   {
      ip->@(d)F = @up@(d) - nf@(d)blks*@(d)b - (np@(d)blks-1)*p@(d)b;
      ip->n@(d)uF = (ip->@(d)F+@(d)u-1) / @(d)u;
   }
   else
      ip->n@(d)uF = ip->@(d)F = 0;
   ip->psz@(mt) = p@(d)b*kb;
   ip->sz@(mt) = kb * (@(d)b ? @(d)b:p@(d)b);
      @undef mt
   @endwhile
   sz = ((mu*nu+vlen-1)/vlen)*vlen;
   sz *= (ip->nmu) ? ip->nmu : ip->pnmu;
   sz *= (ip->nnu) ? ip->nnu : ip->pnnu;
   ip->szC = sz;
   ip->amm_b0 = ATL_AMM_KERN_b0[idx];
   #ifdef TCPLX
      ip->amm_b1 = ATL_AMM_KERN_b1[idx];
      ip->amm_bn = ATL_AMM_KERN_bn[idx];
   #endif
   #ifdef TCPLX
   if (TA == AtlasNoTrans || TA == AtlasConj)
   #else
   if (TA == AtlasNoTrans)
   #endif
   {
      ip->incAm = mb SHIFT;
      ip->pincAm = pmb SHIFT;
   }
   else
   {
      ip->incAm = lda*(mb SHIFT);
      ip->pincAm = lda*(pmb SHIFT);
   }
   #ifdef TCPLX
   if (TB == AtlasNoTrans || TB == AtlasConj)
   #else
   if (TB == AtlasNoTrans)
   #endif
   {
      ip->incBn = ldb*(nb SHIFT);
      ip->pincBn = ldb*(pnb SHIFT);
   }
   else
   {
      ip->incBn  = nb SHIFT;
      ip->pincBn = pnb SHIFT;
   }
   ATL_FillInCopy(ip, idx, TA, TB, (M<=N), alpha, beta);
}

#ifdef ATL_opsq_
static int FindKB(unsigned int K)
/*
 * Returns -1 if you should use rkmm instead of this case.  
 * The smallest KB is special, because it is known to be 4 for opsq, 
 * while it is 3 for rkmm.  We'd rather pad K to at most 1 step than
 * possibly pad M & N to mu-1 and nu-1 respectively.  So, if our smallest
 * kernel can do the problem, we return 0 even when K < 4.
 * For any other case, we return only on precise match.  sqmm should always
 * beat rkmm for MB=NB=KB, since it is tuned for this precise case, while
 * kbmm assumes MB & NB are free variables (can be as large as we want).
 */
{
   register unsigned int IH=ATL_sqAMM_NCASES-1, IL, I, kb, gap;
   if (K >= ATL_sqAMM_LASTKB)  /* check if last KB is runtime, so can handle */
   {
      if (K == ATL_sqAMM_LASTKB)
         return(IH);
      return(-1);  /* cannot handle this K */
   }
   kb = *ATL_AMM_KBs;
   if (kb >= K)
   {
      register unsigned int ku;
      const int KMAJ=ATL_AMM_KMAJOR(0);
      if (kb == K)
         return(0);
      ku = *ATL_AMM_KUs;
      if (KMAJ && ((K+ku-1)/ku)*ku >= K)
         return(0);
      if (ATL_AMM_KRUNTIME(0)) /* possibly can decrease K to handle */
      {
         if (KMAJ)      /* handles K%ku by padding */
            return(0);  /* so works wt any K */
         else if ((K/ku)*ku == K)
            return(0);
      }
      return(-1); /* smallest kernel can't handle K */
   }
/*
 * Otherwise, do binary search for exact KB match, and return -1 if not found
 */
   IL=0;
   gap = IH - IL - 1;
   while (gap > 2)
   {
      I = IL + (gap>>1);
      kb = ATL_AMM_KBs[I];
      if (kb > K)
         IH = I;
      else if (kb < K)
         IL = I;
      else
         return(I);
      gap = IH - IL - 1;
   }
   if (gap)
   {
      if (ATL_AMM_KBs[IL+1] == K)
         return(IL+1);
      if (IL+1 < IH-1)
         if (ATL_AMM_KBs[IH-1] == K)
             return(IH-1);
   }
   return(-1);
}
#endif
#ifdef ATL_oprk_
static INLINE int HandleBigK(const unsigned int K)
/*
 * Called when K > MAXKB, will return last case if it can do that K, -1 else
 */
{
   if (ATL_AMM_KRUNTIME(ATL_rkAMM_NCASES-1))
   {
      if (ATL_AMM_KMAJOR(ATL_rkAMM_NCASES-1))
         return(ATL_rkAMM_NCASES-1);
      else
      {
         int ku=ATL_AMM_KBs[ATL_rkAMM_NCASES-1];
         if ((K/ku)*ku == K)
            return(ATL_rkAMM_NCASES-1);
      }
   }
   return(-1);
}
#endif
@BEGINPROC findIDX dl
   #ifdef ATL_opsq_
      idx = FindKB(K);
      if (idx == -1)
         return(-1);
   #endif
   #ifdef ATL_oprk_
      if (N == M && N == K)  /* try square case instead */
      {
         idx = Mjoin(PATL,GetInfo@(dl)opsq)
                  (ip, TA,TB, M,N,K, lda,ldb,ldc, alpha,beta);
         if (idx != -1)
            return(idx);
      }
      #if 0   /* these views not yet supported */
      if (N == K)
      {
         idx = Mjoin(PATL,GetInfo@(dl)opnk)
                  (ip, TA,TB, M,N,K, lda,ldb,ldc, alpha,beta);
         if (idx != -1)
            return(idx);
      }
      else if (M == K)
      {
         idx = Mjoin(PATL,GetInfo@(dl)opmk)
                  (ip, TA,TB, M,N,K, lda,ldb,ldc, alpha,beta);
         if (idx != -1)
            return(idx);
      }
      #endif
      if (K > ATL_AMM_LASTKB)
      {
         idx = HandleBigK(K);
         if (idx == -1)
            return(-1);
      }
      else
         idx = K-3;
   #endif
@ENDPROC
int ATL_GetInfo_1b
   (opinfo_t *ip, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, ATL_CSZT lda, ATL_CSZT ldb,
    ATL_CSZT ldc, const SCALAR alpha, const SCALAR beta)
{
   int idx;
   unsigned int mu, nu, nfmblks, npmblks, nfnblks, npnblks, mb, nb, pmb, pnb;
   @callproc findIDX _1b_
   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
   mb = ((M+mu-1)/mu)*mu;
   nb = ((N+nu-1)/nu)*nu;
   if (mb == M)
   {
      nfmblks = 1;
      pmb = npmblks = 0;
   }
   else
   {
      pmb = mb;
      mb = nfmblks = 0;
      npmblks = 1;
   }
   if (nb == N)
   {
      nfnblks = 1;
      pnb = npnblks = 0;
   }
   else
   {
      pnb = nb;
      nb = nfnblks = 0;
      npnblks = 1;
   }
   ATL_FillInInfo(ip, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta,
                  nfmblks, npmblks, mb, pmb, nfnblks, npnblks, nb, pnb);
   return(idx);
}

int ATL_GetInfo
   (opinfo_t *ip, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, ATL_CSZT lda, ATL_CSZT ldb,
    ATL_CSZT ldc, const SCALAR alpha, const SCALAR beta)
{
   int idx, mu, nu, mb, nb, pmb, pnb, nmu, nnu;
   ATL_SZT nfmblks, npmblks, nfnblks, npnblks;

   @callproc findIDX _

   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];

   @whiledef d n m
   @(d)b = ATL_AMM_@up@(d)Bs[idx];
   if (@(d)b > @up@(d))
   {
      p@(d)b = ((@up@(d)+@(d)u-1)/@(d)u)*@(d)u;
      np@(d)blks = 1;
      @(d)b = 0;
      nf@(d)blks = 0;
   }
   else
   {
      nf@(d)blks = @up@(d) / @(d)b;
      p@(d)b = @up@(d) - nf@(d)blks*@(d)b;
      np@(d)blks = (p@(d)b) ? 1 : 0;
      p@(d)b = ((p@(d)b+@(d)u-1)/@(d)u)*@(d)u;
   }
   @endwhile
   ATL_FillInInfo(ip, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta,
                  nfmblks, npmblks, mb, pmb, nfnblks, npnblks, nb, pnb);
   return(idx);
}
@ROUT htsearch
#include "atlas_misc.h"
#include "atlas_mmtesttime.h"
/*
 * This search produces htammgood.sum, which is a list of all kernels
 * that are within 5% of the peak performer for that region.
 */
int main(int nargs, char **args)
{
}
@ROUT ATL_ammKernInfo
#include "atlas_amm.h"
#include "atlas_ammkern_decl.h"

int Mjoin(PATL_,ammKernInfo)(int idx, int KINF, int *ia, void **va)
/*
 * ATL_AMM_IHOT are blocks of [flg,mu,nu,ku]
 * ATL_AMM_ICLD are blocks of [K1idx, vlen, kbmin, kbmax]
 * ia: 0:mu, 1:nu, 2:ku, 3:vlen, 5:kbmin, 6:kbmax (3-6 only set if KINF true)
 * va[0:2]: funcptrs to b0,b1,bn amm kern
 * va[3:5]: funcptrs for K1 kerns if KINF non-zero
 * RETURNS: flag
 */
{
   const unsigned int i4=idx<<2, i3=(idx<<1)+idx;

   flg = ATL_AMM_IHOT[i4];       /* flag */
   ia[0] = ATL_AMM_IHOT[i4+1];   /* mu */
   ia[1] = ATL_AMM_IHOT[i4+2];   /* nu */
   ia[2] = ATL_AMM_IHOT[i4+3];   /* ku */
   va[0] = ATL_AMM_KERN[i3];     /* amm_b0 */
   va[1] = ATL_AMM_KERN[i3+1];   /* amm_b1 */
   va[2] = ATL_AMM_KERN[i3+2];   /* amm_bn */
   if (KINF)
   {
      unsigned int k1;

      k1    = ATL_AMM_ICLD[i4];
      ia[3] = ATL_AMM_ICLD[i4+1];
      ia[4] = ATL_AMM_ICLD[i4+2];
      ia[5] = ATL_AMM_ICLD[idx+3];
      k1 = (k1<<1) + k1;
      va[4] = ATL_AMM_KERN[k1];
      va[5] = ATL_AMM_KERN[k1+1];
      va[6] = ATL_AMM_KERN[k1+2];
   }
   return(flg);
}
@ROUT ammvgen
#include "atlas_mmgen.h"

void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);

   fprintf(stderr,"USAGE: %s [flags:\n", name);
   fprintf(stderr,"   -p [d,s,c,z]\n");
   fprintf(stderr,"   -o /path : specify directory to generate into\n");
   fprintf(stderr,"   -V [0:noKClean, 1:KClean] <name> mmview.sum:\n");
   exit(ierr ? ierr : -1);
}

ATL_view_t *GetFlags(int nargs, char **args, char *PRE, char **PTH)
{
   ATL_view_t *vb=NULL, *vp;
   char *pth=NULL;
   int i;
   char pre='d';

   for (i=1; i < nargs; i++)
   {
      char *nam;
      int k, flag;
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         pre = tolower(args[i][0]);
         assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
         break;
      case 'o':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         pth = DupString(args[i]);
         break;
      case 'V': /* -V <flag> <name> mmview.sum */
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         flag = atoi(args[i]);
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         nam = DupString(args[i]);
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         vp = ATL_NewView(flag, nam, DupString(args[i]));
         vp->next = vb;
         vb = vp;
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   assert(vb);
   if (!pth)
      pth = DupString("tmp");
   *PTH = pth;
   *PRE = pre;
   return(vb);
}

void GenKernList(char pre, char *path, ATL_view_t *vb)
{
   ATL_mmnode_t *mb=NULL, *mp;
   ATL_view_t *vp;
   int nxtoff, imax=0, i, j, N;
   char *ityp, *sp;

   printf("SEARCHING VIEWS FOR UNIQUE KERNELS\n");
   for (vp=vb; vp; vp = vp->next)
   {
      mp = ReadMMFile(vp->fnam);
      assert(mp);
      AddUniqueMMKernCompList(mb, mp);
      KillAllMMNodes(mp);
   }
   PrepMMForGen(pre, outd, "amm", mb);
/*
 * Find integral type to use
 */
   nxtoff = GetOffset(&mb->next, mb);
   N = GetIntMaxMinAtOff(mb, nxtoff, GetOffset(&mb->mu, mb), &i, &j);
   printf("FOUND %d UNIQUE KERNELS.\n");
   assert(j >= 0);  /* can't store negative numbers! */
   max = Mmax(i,max);
   @whiledef vv mu nu ku vlen
   GetIntMaxMinAtOff(mb, nxtoff, GetOffset(&mb->@(vv), mb), &i, &j);
   assert(j >= 0);  /* can't store negative numbers! */
   max = Mmax(i,max);
   @endwhile
   if (max < (1<<8))
      ityp = "unsigned char";
   else
      ityp = (max < (1<<16)) ? "unsigned short" : "unsigned int";
   fp = OpenFileWithPath(path, "
}
int main(int nargs, char **args)
{
   ATL_view_t *vb;
   char *path;
   char pre;
   bv = GetFlags(nargs, args, &pre, &path);
   GenKernList(pre, path, vb);
   return(0);
}
@ROUT ammk1srch
#include "atlas_mmtesttime.h"
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -i ammsearch.sum: repeat for multiple\n");
   fprintf(stderr, "   -o <output file>\n");
   exit(ierr ? ierr : -1);
}

ATL_mmnode_t *GetFlags(int nargs, char **args, char *PRE, char **FOUT)
{
   ATL_mmnode_t *cb=NULL, *cp;
   char *fout=NULL;
   int i;
   char pre='d';

   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        break;
      case 'i':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        if (!cb)
           cb = ReadMMFile(args[i]);
        else
        {
           cp = ATL_LastMMNode(cb);
           cp->next = ReadMMFile(args[i]);
        }
        break;
      case 'o':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        fout = DupString(args[i]);
        break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   assert(cb);
   for (cp=cb; cp; cp = cp->next)
   {
/*
 *    TRSM kernels are just TRMM kernels w/o K cleanup.
 *    TRMM kernels aren't, but we put a matching gemm kernel in anyway, so
 *    call them GEMM to avoid problems with copies.
 */
      if (cp->blask == ATL_KTRSM || cp->blask == ATL_KTRMM)
      {                            
         cp->blask = ATL_KGEMM;
         cp->ivar = 0;
      }
      else
         cp->ivar = FLAG_IS_SET(cp->flag, MMF_KCLN) ? -1 : 0;
   }
   if (!fout)
   {
      fout = malloc(18);
      assert(fout);
      strcpy(fout, "res/");
      fout[4] = pre;
      strcpy(fout+5, "AMMLIST.sum");
   }
   *FOUT = fout;
   *PRE = pre;
   return(cb);
}

void FindValidCleanKUs(ATL_mmnode_t *p, ATL_mmnode_t *mb)
/*
 * Searches master list given by mb, finding all kernel compiles that match p
 * to find all kbB that this kern comp is used with.  This allows us to compute
 * whether a given KU is legal.  Recall that we can pad kbB up to 4.  1 is
 * always a multiple of all kbB, and so can be used for cleanup always.  
 * However, imagine we want to have pad to 3 for cleanup.  If any target
 * kernel is used with a kernel where kbB % 3 != 0, we would either have
 * memory overwrite on non-cleanup code, or have to have non-cleanup nodes
 * allocate the extra space.  Therefore, for the possibly incompatible KUs of
 * 4, 3, 2, we rule them out if some target kbB doesn't evenly divide them.
 * mp->flag sets: 31:4, 30:3, 29:2 -- set to 1 if OK clean mul, else 0.
 */
{
   unsigned int flg = (0x7<<29);
   ATL_mmnode_t *mp;

   if (!FLAG_IS_SET(p->flag, MMF_KCLN))
      return;
   for (mp=mb; mp; mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KCLN) && MMKernCompsSame(p, mp))
      {
         const unsigned kb = mp->kbB;
         if (kb & 0x3)            /* if (mp->kbB % 4 != 0) */
            flg &= ~(1<<31);
         if (kb % 3)
            flg &= ~(1<<30);
         if (kb & 1)              /* if (mp->kbB % 2 != 0) */
            flg &= ~(1<<29);
      }
   }
   p->flag = flg | (p->flag & (~(0x7<<29)));
}

ATL_mmnode_t *GetDesiredK1(ATL_mmnode_t *mb)
/*
 * Finds all unique kernels in mb, and then takes the largest blocking factor
 * that matches that signature.
 */
{
   ATL_mmnode_t *ub=NULL, *bp, *mp;
   int mbC, nbC;
   double avgK=0.0;
   if (!mb)
      return(NULL);
/*
 * We know ku=1 legal cleanup, use 3 most sig buts for U=4,3,2 resp, 
 * 1 means an unroll of this size can be used for cleanup, 0 means not.
 * For an U to be legal for cleanup, it must be a multiple of all KB.
 */
   assert(32-MMF_MAXBIT >= 3); /* need 3 bits, ku=2,3,4 */
/*
 * K cleanup can be done by any kernel with the same storage for A/B/C, so it
 * doesn't have to be the exact same kernel implementation, assuming it can
 * handle all the required K values.  Therefore, start by finding all storage
 * types that require K-cleanup.
 */
   for (mp=mb; mp; mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KCLN))
      {
         FindValidCleanKUs(mp, mb);
         if (MMKernCleansK(mp, mp))
            mp->ivar = 0;
         else if (!MMCompatKernPresent(ub, mp))/* no storg compat kern in ub */
         {
            ATL_mmnode_t *p;
            p = CloneMMNode(mp);
            p->next = ub;
            ub = p;
         }
      }
      else
         mp->ivar = 0;
   }
/*
 * We're going to use the same K-cleanup for all storage-compatible kernels,
 * which means it can be used for wildly varying dimensions.  We will use
 * the largest observed MB/NB, while using a small KB.  We'll set KB to roughly
 * half the size of the average KB it'll be cleaning.
 * For each K-clean target, examine all kernels it will clean for to find
 * dims to use.
 */
   for (bp=ub; bp; bp = bp->next)
   {
      int nk=0;
      mbC = nbC = 0;
      mp = mb;
      bp->flag |= 7<<29;
      while (mp = MMCompatKernPresent(mp, bp))
      {
         if (FLAG_IS_SET(mp->flag, MMF_KCLN))
         {
            const unsigned kb = mp->kbB;
            mbC = Mmax(mbC, mp->mbB);
            nbC = Mmax(mbC, mp->nbB);
            if (kb & 0x3)            /* if (mp->kbB % 4 != 0) */
               bp->flag &= ~(1<<31);
            if (kb % 3)
               bp->flag &= ~(1<<30);
            if (kb & 1)              /* if (mp->kbB % 2 != 0) */
               bp->flag &= ~(1<<29);
            avgK += mp->kbB;
            nk++;
         }
         mp = mp->next;
      }
      avgK /= (nk<<1);
      bp->mbB = mbC;
      bp->nbB = nbC;
      bp->kbB = avgK;
      assert(mbC && nbC && bp->kbB);
   }
   return(ub);
}

ATL_mmnode_t *BestCompatKern
(
   char pre, 
   ATL_mmnode_t *dp, /* amm kerntype & dims desiring K cleanup */
   ATL_mmnode_t *mb  /* list of kernels to try */
)
/* 
 * RETURNS: dp if it can do K cleanup on its own, else NULL if no kernel in mb
 *          can do cleanup, otherwise a clone of the best-performing node in mb
 *          with mflop set to cleanup performance.
 */
{
   ATL_mmnode_t *mp, *mpB=NULL;
   double mfB=0.0;
   int mbB, nbB, kbB, cnt, cntB=0;

   if (!dp) 
      return(dp);
   if (MMKernCleansK(dp, dp))
   {
      printf("   ID=%d '%s' U=(%u,%u,%u) B=(%u,%u,%u), cleans itself!\n",
             dp->ID, dp->rout?dp->rout:"NULL", dp->mu, dp->nu, dp->ku,
             dp->mbB, dp->nbB, dp->kbB);
      return(dp);
   }
   if (!mb)
      return(NULL);
   mbB = dp->mbB;
   nbB = dp->nbB;
   kbB = dp->kbB;

   printf(
"   SEARCHING FOR BEST K-CLEANER FOR ID=%d, U=(%u,%u,%u) B=(%u,%u,%u) %c%d\n", 
          dp->ID, dp->mu, dp->nu, dp->ku, dp->mbB, dp->nbB, dp->kbB,
          FLAG_IS_SET(dp->flag, MMF_KVEC)?'K':'M', dp->vlen);
   for (cnt=0,mp=mb; mp; mp = mp->next, cnt++)
   {
      if (MMKernCleansK(dp, mp))
      {
         double mf;
         mf = TimeMMKernel(0, 0, mp, pre, mbB, nbB, kbB, 0, 0, -1);
         printf("      ID=%d, IDX=%d, mf=%.0f\n", mp->ID, cnt, mf);
         if (mf > mfB)
         {
            mfB = mf;
            mpB = mp;
            cntB = cnt;
         }
      }
   }
   if (mpB)
   {
      printf("   DONE, BEST: ID=%d, IDX=%d, mf=%.0f.\n\n", mpB->ID, cntB, mfB);
      mpB = CloneMMNode(mpB);
      mpB->mbB = mbB;
      mpB->nbB = nbB;
      mpB->kbB = kbB;
      mpB->mflop[0] = mfB;
   }
   else
      printf("   DONE: NO KCLEAN FOR THIS KERNEL!\n\n");
   return(mpB);
}

ATL_mmnode_t *FindAllBestCompatKern
(
   char pre, 
   ATL_mmnode_t *db, /* amm kerntype & dims desiring K cleanup */
   ATL_mmnode_t *mb  /* list of kernels to try */
)
{
   ATL_mmnode_t *kb=NULL, *dp;

   for (dp=db; dp; dp = dp->next)
   {
      ATL_mmnode_t *mpB;
      mpB = BestCompatKern(pre, dp, mb);
      if (mpB == dp)
         dp->ivar = -1;
      else
      {
         if (!mpB) /* no cleaner so far found */
         {
            mpB = CloneMMNode(dp);  /* keep placeholder */
            mpB->mflop[0] = -2.0;   /* and indicate no cleaner available yet */
         }
         mpB->next = kb;
         kb = mpB;
      }
   }
   return(ReverseMMQ(kb));  /* now in same order as db */
}

ATL_mmnode_t *FindK1Clean
(
   char pre, 
   char *fout,       /* output filename */
   ATL_mmnode_t *db, /* storage formats & NBs desiring K cleanup */
   ATL_mmnode_t *mb  /* already-existing kernels to be scope for cleanup */
)
{
   ATL_mmnode_t *dp, *kb=NULL, *gb=NULL, *nb, *mp;
   unsigned int L1ELTS;
   char upr;
   
   if (pre == 'z')
      upr = 'd';
   else 
      upr = (pre == 'c') ? 's' : pre;
   printf("FINDING K-CLEANERS AMONGST EXISTING KERNELS\n");
   kb = FindAllBestCompatKern(pre, db, mb);
/*
 * Now we consider adding kernels to do K-cleanup.  kb is best found so far
 * (-2 mflop indicates no cleanup so far, so forced new kern).
 * We have two options for K-clean: any working user-contributed kernel, or
 * a generated kernel. 
 */
/*
 * Create generated cleaners for each kernel, using best-found flags from
 * prior searches.  Recall that gAMMRES first three cases are best cases
 * for (# is order in file): 0: A,B,C fit in L1, 1: B fits in L1, 2: mu*K panel
 * fits in L1 (L2 blocked).  Since M,N,K will vary by kernel, we can't be sure
 * of which of these to use, but since we can control only prefetch and nobcast,
 * its no big deal if we use the wrong one.
 */
   nb = ReadMMFileWithPath(pre, "res", "gAMMRES.sum"); /* tuned params */
   assert(nb); /* all 3 fit L1, ->B fits; ->->pan fits */
   L1ELTS = GetL1CacheElts(upr);
   for (dp=db; dp; dp = dp->next)
   {
      ATL_mmnode_t *gp, *op;
      const int M=dp->mbB, N=dp->nbB, K=dp->kbB;
      int flag;

      if (N*M + K*(N+M) <= L1ELTS)
         op = nb;
      else
         op = (K*N <= L1ELTS) ? nb->next : nb->next->next;
      flag = op->flag & MMF_ALLPF;
      if (!FLAG_IS_SET(dp->flag, MMF_KVEC))
         flag |= op->flag & (1<<MMF_NOBCAST);
      gp = MMGetGenCaseKClean(dp);
      gp->flag |= flag;
      gp->rout = DupString("ATL_tmp.c");
      gp->genstr = MMGetGenString(pre, gp);
      gp->next = gb;
      gb = gp;
   }
   KillAllMMNodes(nb);
/*
 * Get all working user-contributed kernels, and grab the ones that could
 * clean for selected kerns
 */
   nb = ReadMMFileWithPath(pre, "res", "WORKING.sum");
   if (nb)
   {
      mp = MMGetKCleanQ(db, nb);
      KillAllMMNodes(nb);
      if (mp)
      {
         nb = ATL_LastMMNode(mp);
         nb->next = gb;
         gb = mp;
      }
   }
/*
 * Now search for best new kernel to use amongst hand-tuned & generated
 */
   printf("FINDING K-CLEANERS AMONGST NEW KERNELS\n");
   nb = FindAllBestCompatKern(pre, db, gb);
   KillAllMMNodes(gb);
/*
 * nb (best new) & kb (best existing) are in same order, so we can compare
 * them directly.  Require a new kernel to be 4% faster than an existing
 * kernel before adding it, since expanding the list of supported kernels
 * is last thing we need to do.
 */
   gb = NULL;
   for (dp=kb, mp=nb; dp; dp=dp->next, mp=mp->next)
   {
      ATL_mmnode_t *newp;

      if (dp->mflop[0]*1.04 < mp->mflop[0])
      {
         newp = CloneMMNode(mp);
         newp->next = gb;
         newp->flag &= ~(1<<MMF_KCLN);
         newp->ivar = 0;
         gb = newp;
      }
   }

   KillAllMMNodes(kb);
   KillAllMMNodes(nb);
   if (gb)
   {
      printf("\nKERNELS ADDED TO MASTER LIST FOR KCLEAN:\n");
      PrintMMNodes(stdout, gb);
   }
   else
      printf("\nNO KERNELS ADDED TO MASTER LIST FOR KCLEAN.\n");
   return(gb);
}

int GetIdxOfKClean
(
   ATL_mmnode_t *dp, /* kern desiring K1 cleaner */
   ATL_mmnode_t *kb, /* queue containing K1 cleaner kerns */
   ATL_mmnode_t *ml  /* master list showing all kbs used by dp */
)
/*
 * dp is kern desiring K1 cleaner, kb is queue containing such cleaners
 */
{
   ATL_mmnode_t *kp;
   int cnt;
/*
 * Prioritize self-cleaning over other-cleaning so that we don't do unnec
 * instruction load for kb0 case
 */
   FindValidCleanKUs(dp, ml);
   if (MMKernCleansK(dp, dp))
   {
      for (cnt=0,kp=kb; kp; kp = kp->next, cnt++)
         if (kp == dp)
            return(cnt);
      assert(0);  /* should not be reached! */
   }
   for (cnt=0,kp=kb; kp; kp = kp->next, cnt++)
   {
      if (MMKernCleansK(dp, kp))
         return(cnt);
   }
   return(-1);
}

void NumberKClean
(
   ATL_mmnode_t *ml, /* non-unique list of all kernel usages */
   ATL_mmnode_t *mb  /* unique list of things requiring cleaning */
)
{
   ATL_mmnode_t *mp;
   int cnt;

   for (cnt=0,mp=mb; mp; mp = mp->next, cnt++)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KCLN))
      {
          int idx;
          idx = GetIdxOfKClean(mp, mb, ml);
          if (idx < 0)
          {
             fprintf(stderr, "WTF: cnt=%d\n", cnt);
             PrintMMLine(stderr, mp);
          }
          assert(idx >= 0);
          mp->ivar = idx + 1;
      }
   }
}

/*
 * This routine takes as input all amm kerns to be used in building ATLAS.
 * Any kernels with MMF_KCLN needs a K-cleaner.  We will search for cleaners
 * for any such kernel.  A K-cleaning kernel must have MMF_KRUNTIME &
 * ku <= X, where X is max of (mu-1,nu-1,4,KVEC?VLEN:1).
 * The best existing kernel will be compared to a generated kernel on perf.
 * If the genned kernel provides higher performance, then it will be added
 * to the list of output kernels (with KCLN=0, obviously). 
 * For a given kernel match, only one K-cleaner is generated, which means that
 * multiple kernels may share.
 * In the output file, those kernels not requiring K-cleanup, or who can serve
 * as their own K-cleanup, have ivar=0, KCLN=0.  For those needing Kclean,
 * KCLN=1, and ivar=#, where # is the position in the file of the cleaning kern.
 *
 * This should be run as last step before generation, and the output file
 * will be all the output kernels to generate (more may have been added by
 * search in order to do cleanup).  It will use ivar to express how cleanup
 * is being done.  ivar=0 indicates that no cleanup is required (KCLN not
 * set or the function can handle all K-cleanup itself).
 * ivar > 0 means that kern@ ivar-1 in the given kernel order provided kcleanup.
 */
int main(int nargs, char **args)
{
   ATL_mmnode_t *mb, *db, *kb, *ml;
   unsigned int msk;
   char pre;
   char *fout;

   ml = GetFlags(nargs, args, &pre, &fout);

   db = GetDesiredK1(ml);  /* get list of K cleaners to make */
   mb = AddUniqueMMKernCompList(NULL, ml); /* remove repeated comps frm lst */
   printf("KERNELS REQUIRING NON-SELF KCLEANERS:\n");
   PrintMMNodes(stdout, db);
   printf("\n\n");
/*
 * Find K1 cleaners and add them to the list of final kernels to build
 */
   kb = FindK1Clean(pre, fout, db, mb);
   KillAllMMNodes(db);
   if (kb)
   {
      mb = AddUniqueMMKernCompList(mb, kb);
      KillAllMMNodes(kb);
   }
/*
 * Number ivar with location of Kcleaners, and use this to set str to
 * the actual node address, which reverts ivar to -1 for KCLN nodes; we
 * will renumber after reordering nodes to try to place Kcleaners right
 * next to node they clean up for.
 */
   NumberKClean(ml, mb);
   KillAllMMNodes(ml);
   WriteMMFile("tmp.sum", mb);
   MMIvar2str(mb);
/*
 * Start new queue in kb with all nodes needing non-self K cleaning, and have
 * their K-cleaners placed right after them when possible (an earlier kernel
 * using same K-cleaner will force us to use non-contiguous locations).
 */
   kb = NULL;
   KEEP_LOOKING:
   {
      ATL_mmnode_t *mp;
      mp = MMFindKCleanStr(mb); /* 1st node wth non-NULL,mp address */
      if (mp)
      {
         ATL_mmnode_t *p;
         mb = RemoveMMNodeFromQ(mb, mp);
         p = (void*)mp->str;
         mb = RemoveMMNodeFromQ(mb, p);
         mp->next = p;
         p->next = kb;
         kb = mp;
/*
 *       Now, remove all nodes requiring cleaner mp->str, and put them close
 */
         while ((p=MMFindStrMatch(mb, mp->str)))
         {
            mb = RemoveMMNodeFromQ(mb, p);
            p->next = kb;
            kb = p;
         }
         goto KEEP_LOOKING;
      }
   }
/*
 * Join K-clean and their cleaners together with non-cleaning nodes, and then
 * translate str back to ivar (str does not show up in file, ivar does).
 * Write out final output file that will be blindly used to generate master
 * kernel list for ATLAS.
 */
   if (mb)
      mb = ATL_JoinMMQs(kb, mb);
   MMstr2Ivar(mb);
/*
 * Get rid of temporary flag bits
 */
   msk = (1<<MMF_MAXBIT)-1;
   for (kb=mb; kb; kb=kb->next)
      kb->flag &= msk;
   printf("DONE K CLEANUP SEARCH, OUTPUT IN '%s'\n", fout);
   WriteMMFile(fout, mb);
   free(fout);
   KillAllMMNodes(mb);
   return(0);
}
@ROUT ATL_ammPad0
#include "atlas_misc.h"

void Mjoin(ATL,PadA0)(ATL_UINT K0, ATL_UINT K, ATL_UINT N, ATL_UINT U, 
                      ATL_UINT KVEC, TYPE *b)
/*
 * b is a block of access-major storage for the A or B matrix for an AMM kern.
 * This function pads the existing NxK block with zeros.  If KVEC > 1, then
 * this is a k-vectorized kernel, and both K0 & K must be multiples of KVEC.
 * N must be a multiple of U (i.e. it will be NB/MB, not N/M).
 */
{
   
   if (K0 > K)
   {
      int D = N*(K-K0);
      int i;
      b += N*K;
      for (i=0; i < D; i++)
         b[i] = ATL_rzero;
   }
}
@ROUT ATL_trsm_ammLL
#include "atlas_misc.h"
#include "atlas_amm.h"
#include "atlas_reflevel3.h"
void Mjoin(PATL,reftrsmLLNN)
   (const int M, const int N, const SCALAR alp, const TYPE*A, const int lda, 
    TYPE *B, const int ldb);
typedef void (*trsmK_t)
   (const int M, const int N, const SCALAR alp, const TYPE*A, const int lda, 
    TYPE *B, const int ldb);

#define ATL_MU 12
#define ATL_NU  4
#define ATL_MUNU (ATL_MU*ATL_NU)

void Mjoin(PATL,trsm_ammLL)
   (ATL_CINT N, ATL_CSZT R, const SCALAR alpha, const TYPE *A, ATL_CSZT lda, 
    TYPE *X, ATL_CSZT ldx)
{
   trsmK_t trsm=Mjoin(PATL,reftrsmLLNN);
   #ifdef TCPLX
      TYPE ONE[2] = {ATL_rone, ATL_rzero, ATL_rzero}, *ZERO=ONE+1;
      TYPE NONE[2] = {ATL_rnone, ATL_rzero};
   #else
      #define ONE ATL_rone
      #define ZERO ATL_rzero
      #define NONE ATL_rnone
   #endif
   SCALAR alpT = alpha;
   TYPE w[ATL_MUNU];
   const TYPE *Ad = A;
   ATL_SZT r;
   for (r=0; r < R; r += ATL_NU, X += (ATL_NU SHIFT)*lda)
   {
      SCALAR alpT = alpha;
      int i, nu = R-r;
      nu = Mmin(nu,ATL_NU);
      for (i=0; i < N; i += ATL_MU)
      {
         int mu=N-i;
         mu = Mmin(ATL_MU, mu);
         if (i)
         {
            Mjoin(PATL,refgemm)(AtlasNoTrans, AtlasNoTrans, mu, nu, i, ONE,
                             A+(i SHIFT), lda, X, ldx, ZERO, w, mu);
            Mjoin(PATL,geadd)(mu, nu, NONE, w, mu, alpha, X+(i SHIFT), ldx);
         }
         trsm(mu, nu, alpT, A+(i SHIFT)*(lda+1), lda, X+(i SHIFT), ldx);
         alpT = ONE;
      }
   }
}
@ROUT addKClean
@extract -b @(topd)/cw.inc lang=C -def cwdate 2016 
#include "atlas_mmparse.h"
void PrintUsage(char *name, int ierr, char *flag)
{
   fprintf(stderr, 
"This routine adds a demand for every kernel in input to get a\n"
"K-dimension cleanup routine.\n"
"NOTE: it is legal for both input and output file to have same name.\n");
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);

   fprintf(stderr,"USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -i : input sumfile (stdin); can be repeated\n");
   fprintf(stderr, "   -o : output sumfile (stdout)\n");
   exit(ierr ? ierr : -1);
}

ATL_mmnode_t *GetFlags(int nargs, char **args, char **FOUT)
{
   FILE *fpin=stdin;
   char *fout=NULL;
   ATL_mmnode_t *mb=NULL, *mp;
   int i;

   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'i':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        mp = ReadMMFile(args[i]);
        assert(mp);
        if (!mb)
           mb = mp;
        else
        {
           ATL_mmnode_t *p;
           p = ATL_LastMMNode(mb);
           p->next = mp;
        }
        break;
      case 'o':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        fout = args[i];
        break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (!mb)
   {
      mb = ReadMMFile(NULL);
      assert(mb);
   }
   *FOUT = fout;
   return(mb);
}

int main(int nargs, char **args)
{
   ATL_mmnode_t *mb, *mp;
   char *fout;
   mb = GetFlags(nargs, args, &fout);

   for (mp=mb; mp; mp = mp->next)
      mp->flag |= (1<<MMF_KCLN);

   WriteMMFile(fout, mb);
   KillAllMMNodes(mb);
   return(0);
}
@ROUT ammsrch
void PrintUsage(char *name, int ierr, char *flag)
{
   fprintf(stderr, 
"This search times the kernels specified -i or stdin.  It produces output\n"
"files that can be passed merged with other search results via mrgmmsrch\n\n");
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);

   fprintf(stderr,"USAGE: %s [flags:\n", name);
   fprintf(stderr,"   -p [d,s,c,z]\n");
   fprintf(stderr,
   "   -i 0/file: (WORKING.sum) exact amm kerns to search\n");
   fprintf(stderr,"   -o outfile : (stdout) specify output file\n");
   fprintf(stderr,"   -Kc 0/1: don't/do label as needing K-cleanup\n");

   fprintf(stderr,"   -c <be> <en> <inc>: search near-square blkgs in [be,en]"
           "by steps of inc\n");
   fprintf(stderr, 
      "   -m[A,B,C] 0/1: don't/do move indicated matrix in timings\n");
   fprintf(stderr, "      inner product: -mA 1 -mB 1 -C 0\n");
   fprintf(stderr, "      outer product: -mA 1 -mB 0 -C 1\n");
   exit(ierr ? ierr : -1);
}
/*
 * For both op&ip, first search all problems in range 3-sqrt(L1) to get a list
 * of well-performing small-case kernels.
 */
@ROUT opsrch ipsrch
#include "atlas_cache.h"
#include "atlas_genparse.h"
#include "atlas_mmtesttime.h"
#include <math.h>

static unsigned int FULLSRCH=0;
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
   fprintf(stderr, "   -F 0/1: don't/do do full search (default 0) \n");
}

char GetFlags(int nargs, char **args)
{
   char pre = 'd';
   int i;

   for (i=1; i < nargs; i++)
   {
      int wch, *ip, **ipp, TST=0;
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'F':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         FULLSRCH = atoi(args[i]);
         break;
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   return(pre);
}

void do_bfi(char pre, int K0, int KN, int iK, char *fin, char *fout, 
            double runBon)
{
   int L, i;
   char *ln;
   L = strlen(fout) + 45;
   L += strlen(fin);
   L += NumDecDigits(K0);
   L += NumDecDigits(KN);
   L += NumDecDigits(iK);
   if (runBon > 0.0)
      L += 16;
   ln = malloc(L*sizeof(char));
   assert(ln);
@ROUT opsrch
   i = sprintf(ln, "./xbfisrch -p %c -s p O R -i %s -o res/%c%s", 
               pre, fin, pre, fout);
@ROUT ipsrch
   i = sprintf(ln, "./xbfisrch -p %c -s p i R -i %s -o res/%c%s", 
               pre, fin, pre, fout);
@ROUT opsrch ipsrch
   assert(i < L);
   if (K0 && KN && iK)
      i += sprintf(ln+i, " -Bk %u %u %u", K0, KN, iK);
   if (runBon > 0.0)
      i += sprintf(ln+i, " -r %e", runBon);
   assert(i < L);
   i = system(ln);
   if (i)
   {
      fprintf(stderr, "'%s' RET: %d!\n", ln, i);
      assert(0);
   }
   free(ln);
}
@ROUT ipsrch
/*
 * This routine suggests the largest square block that will fit the working
 * set of the computation in the cache of CS (bytes).  It first translates
 * CS to NELT (bytes -> elements).  The working set of one iteration is
 * mu*nu + kb*(mu+nu).  Our typical kernel used loop order MNK, which means
 * both C and B will move in inner loop, so for safety double these sizes:
 *   2*mu*nu + kb*(mu+2*nu) <= NELT ==> KB = (NELT - 2*mu*nu)/(mu+2*nu)
 * We will solve this equation for all kernels, and return the smallest kb.
 */
int maxSquareNB(char pre, size_t CS, ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mp;
   unsigned int eltsh = (pre == 'd') ? 3 : 2, kbB=8000;
   const size_t NELT = CS >> eltsh;
   assert(pre == 'd' || pre == 's');
   assert(mmb);
   for (mp=mmb; mp; mp = mp->next)
   {
      const unsigned int mu=mp->mu, nu=mp->nu;
      const unsigned kb = (NELT-((mu+mu)*nu))/(mu+nu+nu);
      if (kb < kbB)
         kbB = kb;
   }
   return(kbB);
}

int minSquareNB(char pre, size_t CS, ATL_mmnode_t *mmb)
/* 
 * This routine returns largest NB that will be able to fully reuse all 
 * operands between calls assuming LRU cache. We will therefore want to
 * contain all three blocks in the cache, plus the working set of next
 * call for safety.  This is: M*N + K*(M+N+MU+NU) <= NELT, now if D=M=N=K:
 *    D^2 + D^2 + D^2 + D(MU+NU) = NELT --->  3D^2 + D(MU+NU) - NELT = 0
 * so quadratic equation gives: D = -(MU+NU) + sqrt((MU+NU)^2 + 12*NELT)/6
 */
{
   ATL_mmnode_t *mp;
   unsigned int eltsh = (pre == 'd') ? 3 : 2, mupnu, D;
   const size_t NELT = CS >> eltsh;
   assert(pre == 'd' || pre == 's');
   assert(mmb);
   mupnu = mmb->mu + mmb->nu;
   for (mp=mmb; mp; mp = mp->next)
   {
      unsigned int mn=mp->mu + mp->nu;
      mupnu = (mn > mupnu) ? mn : mupnu;
   }
   D = sqrt(mupnu*mupnu + 3.0*(NELT<<2)) / 6.0;
   D -= mupnu;
   return(D);
}

void do_ipdek(int verb, char pre, int NEK)
{
   ATL_mmnode_t *mp, *mb=NULL;
   int tflag = 0;
   unsigned int i, U, N;
   const char ch=NEK?'N':'M';
   char *fn=NEK?"ipnek.sum":"ipmek.sum";

   mb = TimeMMFileWithPath(pre, "res", fn, 0, verb|1, 0, 0, 0, -1);
   if (mb)
   {
      KillAllMMNodes(mb);
      return;
   }
   mp = ReadMMFileWithPath(pre, "res", "ipgen.sum");
   assert(mp);
   while (mp->next)
      mp = KillMMNode(mp);
   mp->flag = (mp->flag&(~MMF_MVSET)) | ((1<<MMF_MVA)|(1<<MMF_MVB));
   if (NEK)
      tflag |= 1<<31;
   mp->mflop[0] = 0;
   assert(mp);
   printf("FINDING BEST CASE FOR %c=K INNER PRODUCT:\n", ch);
   MMExpandNK(verb, pre, tflag, 1, mp);
   printf("BEST %c=K: ID=%u, B=(%u,%u,%u), mf=.2f\n\n", ch, mp->ID, 
          mp->mbB, mp->nbB, mp->kbB);
   U = mp->ku;
   if (NEK)
   {
      U = ATL_iLCM(U, mp->nu);
      N = mp->nbB;
   }
   else
   {
      U = ATL_iLCM(U, mp->mu);
      N = mp->mbB;
   }
   U = (U == 1 || U == 2) ? 4 : U;
   for (i=U; i < N; i += U)
   {
      ATL_mmnode_t *p;
      unsigned int b;
      printf("   FINDING BEST CASE FOR %c=K=%u:\n", ch, i);
      p = CloneMMNode(mp);
      if (NEK)
         p->nbB = p->kbB = i;
      else
         p->mbB = p->kbB = i;
      MMExpandMorN(verb, pre, tflag, 1, p, !NEK, 512);
      printf("   BEST CASE FOR %c=K=%u: B=(%u,%u,%u), mf=%.2f\n", ch, i, 
             p->mbB, p->nbB, p->kbB, p->mflop[0]);
      p->next = mb;
      mb = p;
   }
   mp->next = mb;
   mb = mp;
   mb = ReverseMMQ(mb);
   MMPruneMflopTol(mb, 0, 1.0);
   WriteMMFileWithPath(pre, "res", fn, mb);
   KillAllMMNodes(mb);
}

void findBestIP(char pre, int verb, ATL_mmnode_t *mmb, char *fnout)
/*
 * This search simply finds best performing kernel, produces ip.sum
 * with best found kernel and blocking parameter
 */
{
   ATL_mmnode_t *tb, *mp, *mpB, *mpU, *mpD;
   double mfB, mf, t0;
   unsigned int mbB, nbB, kbB, maxD=240, D, iD, iD0;
   char upr = pre;
   if (pre == 'z')
      upr = 'd';
   else if (pre == 'c')
      upr = 's';

   mp = TimeMMFileWithPath(pre, "res", "ipgen.sum", 0, 1, 0, 1, 0, -1);
   if (mp)
   {
      KillAllMMNodes(mmb);
      KillAllMMNodes(mp);
      return;
   }
   nbB = minSquareNB(upr, LLC_SZ, mmb);
   printf("bLLC = %u\n", nbB);
   if (nbB >= 132)
      nbB -= 12;
/*
 * Get rid of all kernels that aren't within 60% of max performance
 */
   D = ATL_CountNumberOfMMNodes(mmb);
   printf("ELIMINATING UNCOMPETITIVE KERNELS out of %u:\n", D);
   mmb = ElimSlowKern(pre, verb, mmb, nbB, nbB, nbB, 0, 0, 0.60);
   iD = ATL_CountNumberOfMMNodes(mmb);
   printf("DONE: ELIMINATED %u UNCOMPETITIVE KERNELS, %u LEFT.\n", 
          D-iD, iD);
   PrintMMNodes(stdout, mmb);
   printf("LOOKING FOR BEST ASYMPTOTIC INNER-PRODUCT KERNEL:\n");
   mpB = mp = FindMaxMflopMMQ(mmb, 0);
   mfB = mp->mflop[0];
   mbB = mp->mbB;
   nbB = mp->nbB;
   kbB = mp->kbB;
   printf("\nBEST KERNEL AT START:\n");
   PrintMMLine(stdout, mpB);
   for (mp=mmb; mp; mp = mp->next)
   {
      mf = mp->mflop[0];
      if (mf*1.2 >= mfB)  /* try all competitive kerns */
      {
         double mfN;
         tb = mp->next;
         printf("   TUNE BLK for %s, current=(%u,%u,%u), mf=%.2f\n",
                GetMMLabelName(pre, mp), mp->mbB, mp->nbB, mp->kbB, 
                mp->mflop[0]);
         mfN = MMExpandMNK(verb, pre, 0, 0, 0, NULL, maxD, mp);
         if (mfN > mfB)
         {
            printf(
               "   BEST SO FAR: (%u,%u,%u), mf=%.2f, spup=%.2f, spupB=%.2f\n",
                   mp->mbB, mp->nbB, mp->kbB, mfN, mfN/mf, mfN/mfB);
            PrintMMLine(stdout, mp);
            mpB = mp;
            mfB = mp->mflop[0];
            mbB = mp->mbB;
            nbB = mp->nbB;
            kbB = mp->kbB;
         }
         else
            printf("   NOT BEST: (%u,%u,%u), mf=%.2f, spdup=%.2f\n",
                   mp->mbB, mp->nbB, mp->kbB, mfN, mfN/mfB);
      }
      else
         printf("Not timing ID=%d %s (%u,%u,%u): mf=%.2f, mfB=%.2f\n",
                mp->ID, GetMMLabelName(pre, mp), mp->mbB, mp->nbB, mp->kbB,
                mf, mfB);
   }
   printf("CHOSEN: ID=%d %s (%u,%u,%u), mf=%.2f\n\n", mpB->ID, 
           GetMMLabelName(pre, mpB), mbB, nbB, kbB, mfB);
   PrintMMLine(stdout, mpB);
   mpD = CloneMMNode(mpB);
   KillAllMMNodes(mmb);
   mpD->mflop[0] = mfB;
   mpD->mbB = mbB;
   mpD->nbB = nbB;
   mpD->kbB = kbB;
   printf("CHOSEN2: ID=%d %s (%u,%u,%u), mf=%.2f\n\n", mpD->ID, 
          GetMMLabelName(pre, mpD), mpD->mbB,mpD->nbB,mpD->kbB, mpD->mflop[0]);
   mpU = CloneMMNode(mpD);
   printf("FINDING LARGE BLOCK FACTORS FOR CHOSEN KERNEL:\n");
   mf = MMExpandMNK(verb, pre, 0, 0, 0, NULL, 480, mpU);
   if (mf < mfB)
   {
      KillMMNode(mpU);
      mpU = CloneMMNode(mpD);
   }
   printf("LRGBLK CHOSEN: ID=%d %s (%u,%u,%u), mf=%.2f\n\n", mpU->ID, 
           GetMMLabelName(pre, mpU), mpU->mbB, mpU->nbB, mpU->kbB, mf);

   PrintMMLine(stdout, mpU);
   iD0 = ATL_iLCM(mpU->mu, mpU->nu);
   maxD = Mmax(mpU->mbB, mpU->nbB);
   iD = maxD / iD0;
   if (iD*iD0 == maxD)
      maxD -= iD0;
   else
      maxD = iD*iD0;
   for (iD=iD0; iD < 24; iD += iD);
   printf("LOOKING FOR BEST KERNS WITH RESTRICTED M&N <= %u, STEPS=%u:\n", 
          maxD, iD);
   mmb = mpU;
   mmb->flag |= (1<<MMF_KCLN);
   for (D=maxD; D >= iD; D -= iD)
   {
      printf("   LOOKING FOR BEST KERNS WITH M&N < %d:\n", D);
      mp = CloneMMNode(mpD);
      mf = MMExpandMN_K(verb, pre, 0, 0, 0, NULL, D, mp);
      mp->flag |= (1<<MMF_KCLN);
      mp->next = mmb;
      mmb = mp;
      printf("   FOUND ID=%d : B=(%d,%d,%d) mf=%.2f\n",  mp->ID, mp->mbB, 
             mp->nbB, mp->kbB, mp->mflop[0]);
      PrintMMLine(stdout, mp);
   }
   if (iD != iD0)
   {
      for (D=D+iD-iD0; D >= iD0; D -= iD0)
      {
         printf("   LOOKING FOR BEST KERNS WITH M&N < %d:\n", D);
         mp = CloneMMNode(mpD);
         mf = MMExpandMN_K(verb, pre, 0, 0, 0, NULL, D, mp);
         mp->flag |= (1<<MMF_KCLN);
         mp->next = mmb;
         mmb = mp;
         printf("   FOUND ID=%d : B=(%d,%d,%d) mf=%.2f\n",  mp->ID, mp->mbB, 
                mp->nbB, mp->kbB, mp->mflop[0]);
         PrintMMLine(stdout, mp);
      }
      if (iD0 > 16) /* didn't get small enough with LCM! */
      {
         iD = Mmax(mpU->mu, mpU->nu);
         for (D=iD0-iD; D >= iD; D -= iD)
         {
            printf("   LOOKING FOR BEST KERNS WITH M&N < %d:\n", D);
            mp = CloneMMNode(mpD);
            mf = MMExpandMN_K(verb, pre, 0, 0, 0, NULL, D, mp);
            mp->flag |= (1<<MMF_KCLN);
            mp->next = mmb;
            mmb = mp;
            printf("   FOUND ID=%d : B=(%d,%d,%d) mf=%.2f\n",  mp->ID, mp->mbB, 
                   mp->nbB, mp->kbB, mp->mflop[0]);
            PrintMMLine(stdout, mp);
         }
      }
   }
   printf("DONE LOOKING FOR RESTRICTED D KERNELS.\n");
   MMWinnowByOrder(mmb, 0, 1.0);
   WriteMMFileWithPath(pre, "res", "ipgen.sum", mmb);

@skip   tb = NULL;
@skip   MMSplitByFlagAny((1<<MMF_KUISKB), &mmb, &tb); /* tb gets fully unrolled K */
   KillAllMMNodes(mmb);
}

ATL_mmnode_t *bestUM(char pre, int verb, ATL_mmnode_t *IP) 
   /* IP: fastest inner product kernel with mu not mult of nu */
{
   ATL_mmnode_t *bp, *prv, *mp, *bestp=NULL;
   const unsigned int MB=IP->mbB, NB=IP->nbB, KB=IP->kbB;
   double mfB=0.0;
   mp = TimeMMFileWithPath(pre, "res", "ipbestUM.sum", 0, 1, 0, 1, 0, -1);
   if (mp)
      return(mp);
/*
 * Get all working user cases, and remove any where M/N unroll not multiple or
 * K isn't runtime <= 4;
 */
   bp = ReadMMFileWithPath(pre, "res", "gSYRKUM.sum");
   assert(bp);
   bp->next = GetWorkingUserCases(verb, pre);
   prv = bp;
   mp = bp->next;
   while(mp)
   {
      ATL_mmnode_t *nxt=mp->next;
      const unsigned int mu=mp->mu, nu=mp->nu,
         maxKU=(FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen : 4);
      if (mu%nu && nu%mu || mp->ku > maxKU || 
          !FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
      {
         prv->next = nxt;
         KillMMNode(mp);
      }
      else
         prv = mp;
      mp = nxt;
   }
/*
 * Now, find fastest asymptotic sized kernel
 */
   printf("FINDING FASTEST AMM WITH MU/NU THAT DIVIDE EVENLY:\n");
   for (mp=bp; mp; mp = mp->next)
   {
      double mf;
      const unsigned int mu=mp->mu, nu=mp->nu, ku=mp->ku;
      unsigned int mb=(MB/mu)*mu, nb=(NB/nu)*nu, kb=(KB/ku)/ku;
      mb = (mb) ? mb : mu;
      nb = (nb) ? nb : nu;
      kb = (kb) ? kb : ku;
      mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, kb, 1, -1, -1);
      printf("   ID=%u: B=(%u,%u,%u), U=(%u,%u,%u), mf=%.2f\n", mp->ID, 
             mb, nb, kb, mu, nu, ku, mf);
      if (mf > mfB)
      {
         mp->mbB = mb;
         mp->nbB = nb;
         mp->nbB = kb;
         bestp = mp;
         mfB = mf;
      }
   }
   assert(bestp);
   bestp->mflop[0] = mfB;
   mp = bestp;
   printf("CHOSE: ID=%u: B=(%u,%u,%u), mf=%.2f\n", mp->ID, mp->mbB, mp->nbB, 
          mp->kbB, mfB);
   bp = RemoveMMNodeFromQ(bp, bestp);
   KillAllMMRouts(bp);
   WriteMMFileWithPath(pre, "res", "ipbestUM.sum", bestp);
   return(bestp);
}

void srch_menUM(char pre, int verb)
/*
 * Finds kernels for cases with M=N at fixed values, while K is tuned.
 * Used in SYRK.
 */
{
   ATL_mmnode_t *bp, *mmb=NULL;
   unsigned int U, D, d, maxK, maxKU;
   
   bp = TimeMMFileWithPath(pre, "res", "ipmenUM.sum", 0, 1, 0, 1, 0, -1);
   if (bp)
   {
      mmb = bp;
      bp = TimeMMFileWithPath(pre, "res", "ipsyrkUM.sum", 0, 1, 0, 1, 0, -1);
      if (!bp)
         goto TIME_SYRKUM;
      KillAllMMNodes(bp);
      KillAllMMNodes(mmb);
      return;
   }
   bp = ReadMMFileWithPath(pre, "res", "ipmen.sum");
   assert(bp);
   while (bp->next)
      bp = KillMMNode(bp);
   if (bp->mu % bp->nu && bp->nu % bp->mu)
   {
      ATL_mmnode_t *tp=bp;
      bp = bestUM(pre, verb, bp);
      KillMMNode(tp);
   }
   U = ATL_iLCM(bp->mu, bp->nu);
   D = Mmax(bp->mbB, bp->nbB);
   maxK = Mmax(bp->kbB, D);
   for (d=U; d <= D; d += U)
   {
      ATL_mmnode_t *mp;
      mp = CloneMMNode(bp);
      mp->next = mmb;
      mmb = mp;
      mp->mbB = mp->nbB = d;
      MMExpandK(verb, pre, 0, 1, mp, maxK);
      printf("\n");
   }
   KillMMNode(bp);
/*   PrintMMNodes(stdout, mmb); */
   while (mmb->next && mmb->mflop[0] < mmb->next->mflop[0])
      mmb = KillMMNode(mmb);
   mmb = ReverseMMQ(mmb);
   MMPruneMflopTol(mmb, 0, 1.0);
   WriteMMFileWithPath(pre, "res", "ipmenUM.sum", mmb);
/*
 * Now, create a SYRK kernel with its own time in mflop[0], and gemm's in
 * mflop[1], and write it it to "ipsyrkUM.sum"
 */
TIME_SYRKUM:
   while (mmb->next)                      /* get rid of all but */
      mmb = KillMMNode(mmb);              /* asymptotic case */
   maxKU = FLAG_IS_SET(mmb->flag, MMF_KVEC) ? mmb->vlen : 4;
/*
 * Try generating with straight params from search
 */
   bp = MMGetNodeGEN(pre, 0, 0, mmb->mu, mmb->nu, mmb->ku, mmb->vlen, 
                     FLAG_IS_SET(mmb->flag, MMF_KVEC), mmb->pref, mmb->pfLS, 
                     NULL);
   bp->flag = ((mmb->flag | (1<<MMF_KRUNTIME)) & 
               (~((1<<MMF_X87)|(1<<MMF_KUISKB))));
   bp->mbB = mmb->mbB;
   bp->nbB = mmb->nbB;
   bp->kbB = mmb->kbB;
   if (bp->ku > maxKU)
   {
      if (FLAG_IS_SET(bp->flag, MMF_KVEC))
         bp->ku = maxKU;
      else
      {
         unsigned int ku=maxKU, kb=mmb->kbB;
         while((kb/ku)*ku != kb)
            ku--;
         bp->ku = ku;
      }
   }
   bp->mflop[1] = mmb->mflop[0];
   bp->blask = ATL_KSYRK;
   if (bp->genstr)
      free(bp->genstr);
   bp->genstr = NULL;
/*
 * Duplicate this node so we can try BREG1 & NOBCAST
 */
   KillMMNode(mmb);
   mmb = CloneMMNode(bp);
   mmb->flag |= (1<<MMF_BREG1);
   bp->mflop[0] = TimeMMKernel(verb, 0, bp, pre, bp->mbB, bp->nbB, bp->kbB,
                               1, 0, -1);
   printf("   SYRK/GEMM DEFAULT MFLOP=%.4f\n", bp->mflop[0]/bp->mflop[1]);
   mmb->mflop[0] = TimeMMKernel(verb, 0, mmb, pre, bp->mbB, bp->nbB, bp->kbB,
                                1, 0, -1);
   printf("   SYRK/GEMM BREG1   MFLOP=%.4f\n", mmb->mflop[0]/mmb->mflop[1]);
/*
 * bp is best found case so far
 */
   if (mmb->mflop[0] >= bp->mflop[0])
   {
      ATL_mmnode_t *tp=mmb;
      mmb = bp;
      bp = tp;
   }
/*
 * If nu mult of vlen, try NOBCAST
 */
   if (!bp->vlen || (bp->nu % bp->vlen) == 0)
   {
      mmb->flag = (mmb->flag | (1<<MMF_NOBCAST)) & (~(1<<MMF_BREG1));
      mmb->mflop[0] = TimeMMKernel(verb, 0, mmb, pre, bp->mbB, bp->nbB, bp->kbB,
                                   1, 0, -1);
      printf("   SYRK/GEMM NOBCAST MFLOP=%.4f\n", mmb->mflop[0]/mmb->mflop[1]);
      if (mmb->mflop[0] >= bp->mflop[0])
      {
         ATL_mmnode_t *tp=mmb;
         mmb = bp;
         bp = tp;
      }
   }
   KillMMNode(mmb);
   printf("SYRK/GEMM MFLOP=%.4f\n", bp->mflop[0]/bp->mflop[1]);
   if (pre == 'c' || pre == 'z')
      bp->flag |= 1<<MMF_COMPLEX;
   WriteMMFileWithPath(pre, "res", "ipsyrkUM.sum", bp);
   KillMMNode(bp);
}

void srch_men(char pre, int verb)
/*
 * Finds kernels for cases with M=N at fixed values, while K is tuned.
 * Used in SYRK.
 */
{
   ATL_mmnode_t *bp, *mmb=NULL;
   unsigned int U, D, d, maxK;
   
   bp = TimeMMFileWithPath(pre, "res", "ipmen.sum", 0, 1, 0, 1, 0, -1);
   if (bp)
   {
      KillAllMMNodes(bp);
      return;
   }
   bp = ReadMMFileWithPath(pre, "res", "ipgen.sum");
   assert(bp);
   while (bp->next)
      bp = KillMMNode(bp);
   U = ATL_iLCM(bp->mu, bp->nu);
   D = Mmax(bp->mbB, bp->nbB);
   maxK = Mmax(bp->kbB, D);
   for (d=U; d <= D; d += U)
   {
      ATL_mmnode_t *mp;
      mp = CloneMMNode(bp);
      mp->next = mmb;
      mmb = mp;
      mp->mbB = mp->nbB = d;
      MMExpandK(verb, pre, 0, 1, mp, maxK);
      printf("\n");
   }
   KillMMNode(bp);
/*   PrintMMNodes(stdout, mmb); */
   while (mmb->next && mmb->mflop[0] < mmb->next->mflop[0])
      mmb = KillMMNode(mmb);
   mmb = ReverseMMQ(mmb);
   MMPruneMflopTol(mmb, 0, 1.0);
   WriteMMFileWithPath(pre, "res", "ipmen.sum", mmb);
   KillAllMMNodes(mmb);
}

int main(int nargs, char **args)
{
   ATL_mmnode_t *mmb, *mp;
   int verb=0, nkern0, nkern, flag=0;
   unsigned int bLLC;
   char pre, upr;
   upr = pre = GetFlags(nargs, args);
   if (pre == 'z')
      upr = 'd';
   else if (pre == 'c')
      upr = 's';
      
/*
 * Get user & gen cases, and try compile- and run-time versions
 */
   mmb = GetWorkingUserCases(verb, pre);
   mmb = MMApplyRules(mmb, flag, 0, 0);
   mp = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   mp = MMApplyRules(mp, flag|(1<<MMR_MKCOMP), 0, 0);
   assert(mp);
   mmb = AddUniqueMMKernCompList(mmb, mp);
   KillAllMMNodes(mp);
   flag = (verb > 3) ? 3:(verb&3);
   flag |= 3 << 2;

   for (mp=mmb; mp; mp = mp->next)
      mp->flag = ((mp->flag) & (~MMF_MVSET)) | ((1<<MMF_MVA) | (1<<MMF_MVB));

   findBestIP(pre, verb, mmb, NULL);
   srch_men(pre, verb);
   srch_menUM(pre, verb);
   do_ipdek(verb, pre, 0);
   do_ipdek(verb, pre, 1);

   return(0);
}
@ROUT opsrch
int opWorkSetOK(unsigned long csz, ATL_mmnode_t *mp, int mb, int nb, int kb)
/*
 * RETURNS: 0 if working set for usual outer product > csz, else 1
 */
{
   unsigned long sz;
   sz = mb*nb + kb*(mp->mu+mb+nb);
   return(sz <= csz);
}

void do_opdek(int verb, char pre, int NEK)
{
   ATL_mmnode_t *mp, *mb=NULL;
   int tflag = 0;
   unsigned int i, U, N;
   const char ch=NEK?'N':'M';
   char *fn=NEK?"opnek.sum":"opmek.sum";

   mb = TimeMMFileWithPath(pre, "res", fn, 0, verb|1, 0, 0, 0, -1);
   if (mb)
   {
      KillAllMMNodes(mb);
      return;
   }
   mp = ReadMMFileWithPath(pre, "res", "opASYMP.sum");
   if (NEK)
   {
      mp->flag = (mp->flag&(~MMF_MVSET)) | 
                 ((1<<MMF_MVC)|(1<<MMF_CPC)|(1<<MMF_MVA));
      tflag |= 1<<31;
   }
   else
      mp->flag = (mp->flag&(~MMF_MVSET)) | 
                 ((1<<MMF_MVC)|(1<<MMF_CPC)|(1<<MMF_MVB));
   mp->mflop[0] = 0;
   assert(mp);
   printf("FINDING BEST CASE FOR %c=K OUTER PRODUCT:\n", ch);
   MMExpandNK(verb, pre, tflag, 1, mp);
   printf("BEST %c=K: ID=%u, B=(%u,%u,%u), mf=.2f\n\n", ch, mp->ID, 
          mp->mbB, mp->nbB, mp->kbB);
   U = mp->ku;
   if (NEK)
   {
      U = ATL_iLCM(U, mp->nu);
      N = mp->nbB;
   }
   else
   {
      U = ATL_iLCM(U, mp->mu);
      N = mp->mbB;
   }
   U = (U == 1 || U == 2) ? 4 : U;
   for (i=U; i < N; i += U)
   {
      ATL_mmnode_t *p;
      unsigned int b;
      printf("   FINDING BEST CASE FOR %c=K=%u:\n", ch, i);
      p = CloneMMNode(mp);
      if (NEK)
         p->nbB = p->kbB = i;
      else
         p->mbB = p->kbB = i;
      MMExpandMorN(verb, pre, tflag, 1, p, !NEK, 512);
      printf("   BEST CASE FOR %c=K=%u: B=(%u,%u,%u), mf=%.2f\n", ch, i, 
             p->mbB, p->nbB, p->kbB, p->mflop[0]);
      p->next = mb;
      mb = p;
   }
   mp->next = mb;
   mb = mp;
   mb = ReverseMMQ(mb);
   MMPruneMflopTol(mb, 0, 1.0);
   WriteMMFileWithPath(pre, "res", fn, mb);
   KillAllMMNodes(mb);
}

ATL_mmnode_t *opsrch_rng
   (int verb, char pre, int flag, double runBon, int kb0, int kbN, int maxB,
    unsigned long sz, int (*wrkSetOK)(unsigned long, ATL_mmnode_t*,int,int,int),
    ATL_mmnode_t *mpB, /* best kernel for top of this range */
    ATL_mmnode_t *mmb) /* list of other kerns to try */
/*
 * Does (relatively) quick search for outer product in range K=[kb0,kbN].
 * It will first choose a kernel for kbN.  This kernel will then be blindly
 * used for all K%ku==0 cases.  If ku <= 4, we will consider using it for
 * *all* cases.  We will try K=kBn-(ku-1), and if it wins, this one kernel
 * will be used for call cases, otherwise the winning kernel is chosen for
 * all % = ku-1 cases, and now we check ku-2, and so on.
 * RETURNS: list of kerns with specialized MB,NB for each [kb0,kbN], sorted
 *          in increasing KB order.
 */
{
   unsigned int KU=mpB->ku, kbB=mpB->kbB, k;
   ATL_mmnode_t *mp, *mkb=NULL;
   ATL_mmnode_t **bKs;

   bKs = calloc(KU, sizeof(ATL_mmnode_t*));
   assert(bKs);
   *bKs = mpB;
   printf("SEARCHING FOR DEFAULT CASES FOR ALL KU=%u REMAINDER CASES\n", KU);
   for (k=1; k < KU; k++) /* remainders */
   {
      int kb = kbB - k;
      printf("   FINDING BEST AMM KERNEL FOR KB=%u, REMAINDER=%u\n", kb, k);
      bKs[k] = bestNearMNK(pre, verb, mmb, mpB->mbB, mpB->nbB, kb, 4, 0, 1.015);
      mp = bKs[k];
      printf("   BEST ID=%d, '%s', B=(%d,%d,%d) mf=%.2f\n", mp->ID,
             GetMMLabelName(pre, mp), mp->mbB, mp->nbB, mp->kbB,mp->mflop[0]);
   }
   printf("DONE SEARCH OF ALL KU=%u CASES\n\n", KU);

   printf("SEARCHING FOR TUNED M&N FOR ALL %u <= K <= %u:\n", kb0, kbN); 
   for (k=kbN; k >= kb0; k--)
   {
      mp = CloneMMNode(bKs[k%KU]);
      printf("   FINDING BEST M/N-B FOR KB=%u\n", k);
      mp->kbB = k;
      MMExpandMN(verb, pre, 4, 0, maxB, mp);
      printf("   BEST ID=%d, '%s', B=(%d,%d,%d) mf=%.2f\n", mp->ID,
             GetMMLabelName(pre, mp), mp->mbB, mp->nbB, mp->kbB,mp->mflop[0]);
      mp->next = mkb;
      mkb = mp;
   }
   printf("DONE TUNING FOR ALL %u <= K <= %u.\n\n", kb0, kbN); 
   for (k=1; k < KU; k++)
      KillMMNode(bKs[k]);
   free(bKs);
@BEGINSKIP
   mmb = SortListByIval_G2L(mmb, GetOffset(mmb, &mmb->next), 
                            GetOffset(mmb, &mmb->ku);
   if (mpB->ku > 4) /* find a candidate that can be padded to all K */
   {
      int kb = mpB-> kbB;
      kb = (kb > 4) ? (kb & (~0x3)) : 4;
      for (mp=mmb; mp && mp->ku > 4; mp = mp->next);
      mp4 = bestNearMNK(pre, verb, mp, mpB->mbB, mpB->nbB, kb, 4, 0, 1.015);
   }
   for (i=4; i < KU; i += 4)
      bKs[i] = mp4;
@ENDSKIP
   return(mkb);
}

/*
 * This search forms the backbone of ATLAS outer-product support.  It will
 * find all the kernels needed to support 3 categories of degenerate dims:
 *    opk.sum : K is degenerate, M&N can be varied for performance
 *    opmk.sum: M&K are degenerate, N can be varied for performance
 *    opnk.sum: N&K are degenerate, M can be varied for performance
 *    opsq.sum: all dims degenerate, force true square, does not cover all K
 *
 * For mn/nk, increasing the other dim will not improve performance, because
 * any intra-kernel reuse is already being achieved via inter-kernel reuse.
 * Therefore, we will increase the free dim only for very small probs where
 * it may help with function call overhead.
 *
 * For sq, all dims must be same so that we can use same storage for any
 * array.  This is the only search where some K cannot be handled, because
 * it should only be used by algorithms that can choose K
 *
 * For true rank-K, where only K is degenerate, increasing M will just
 * transfer inter-kernel reuse of B to intra-kernel reuse, and so it will
 * always be set to near-square with K.  Increasing N, however, will allow
 * more reuse of A, and so will be fully searched.
 */
/*
 * This search's job is to find all the kernels we are going to use in
 * building the rank-K update where K is the only degenerate dimension.
 * It searches using near-square block factors, where we split B into diff
 * regions.  The first region is tiny B where performance is discontinuous.
 * For this small region, we try all available kernels at all proposed sizes.
 *
 * For regions with larger blocks, we pick a midrange problem, and then 
 * compare all available kernels at that rough size, and pick the best
 * performing.  Call this kernel RCK (Regional Champion Kernel).  The RCK
 * must have the ability to vary KB for the entire region (though it can have
 * any ku <= 32), either as runtime or compile-time KB.  Kernels that can
 * only handle a subset of the range  will be moved to a different queue, 
 * and then later compared to the RCK in the subset of ranges where they work,
 * and they can displace the RCK's use for any place where they are faster.
 * Call these kernels RRK (Restricted Range Kernels).  All other kernels
 * are GPK (General Population Kernels).  These files are eventually written
 * out as op[rck,rrk,gpk].sum, though not until later refinements are finished.
 *
 * Of particular interest is the RCK of the largest region, which is used
 * to find the maximum KB that increases performance.  
 *
 * If the RCK of two adjacent regions is the same kernel, then those regions
 * will be combined together.
 *
 * We now attempt to bound the regions more precisely, by comparing the RCK's
 * of adjacent regions, and finding when one takes over from the other as
 * precisely as possible.  
 * 
 * We now consider the RRK.  For each such kernel, we pick a particular
 * size that it handles, and compare it head-to-head vs the RCK at a mutually
 * compatible KB, if any.  If they have no compatible KB, it will be compared
 * to clost RKB of smaller size.  Any RRK that loses to the RCK is put back
 * into GPK.  We now tourney the RRK at all KB it handles against the RCK: 
 * any KB for which it wins gets a new node in the oprrk.sum, which is
 * written out long with opgpk.sum at the end of this step.
 *
 * We now have good kernels for entire range, but only believe we've got the
 * best we can do when KB%ku, or we're at a KB where a RRK was used.  We now
 * discover all KUs that are not within 4 (or VLEN if the kern is vectorized
 * along the K dim) of the RRK+RCK kernels.  For such KBs, we discover the KUs
 * that could serve them, and then time all the GPK at a large KB, and
 * eliminate all GPK that don't win one of those KU contests.  We now have
 * the best kerns found for each KU, with possible kerns from RCK+RRK+GPK,
 * but only the kerns known to win somewhere.
 *
 * We now have kernels that can cover the entire range, and we now time all
 * surviving kernels at any unhandled KB and take the best.  This result is
 * written out as oprkk.sum.
 * 
 * NOTE: stoped working here, because I suspect what we really want for rank-K
 *       is MB=MU, and NB=KB in order to maximize reuse of A while filling the
 *       cache with B, which is reused across amm calls.  Need to write a BFI
 *       search to prove/disprove.
 *
 * is written out as oprkk.sum, sorted by KB.  We do not presently have
 * all KBs in oprkk.sum, but merely all the kernels we expect to use to handle
 * the range.  We won't finalize this kernel list until we have sear
 *
 * The output file of this search will be a list of kernels sorted on KB.
 * Other dims are chosen near KB, but may not match KB, and so may not be
 * strictly increasing.  The first region is the only one with all KB filled
 * in.  Other regions have a single mention of the champion kernel when the
 * range begins, and that kernel is then used until the next region begins.
 * The final range will have a 2nd mention of the champion kernel at the
 * largest block factor that improved performance.  If all regions except the
 * first use the same kernel, then there will be only two regions according
 * to the ouput file.
 *
 * With this search complete, we know the largest square block factor that
 * We first do all rank-K searches using this regions idea, and all of the
 * used kernels will comprise our rank-K amm compilations.  This subset of
 * kernels will then be used to complete the kernels
 * greatest to least by KB (other dims are chosen near KB, but do not have
 * to be exactly KB; this means
 */
void do_opk(int verb, char pre, char *fnam, int maxK)
{
   long i, nelt_llpc, nelt_llc, nelt=L1C_SZ>>3;
   unsigned int b0=60;   /* largest kb where we brute-force search */
   unsigned int bP;      /* largest square block fitting in LLPC */
   unsigned int bL;      /* largest square block fitting in LLC */
   unsigned int MB, NB, KB, maxB;
   unsigned int eltsh=0;
   double mf;
   const char upr = (pre == 'z' || pre == 'd') ? 'd' : 's';
   ATL_mmnode_t *mb, *mp, *tb, *mpB;

   tb = TimeMMFileWithPath(pre, "res", "opFNL.sum", 0, verb|1, 0, 0, 0, -1);
   if (tb)
   {
      KillAllMMNodes(tb);
      return;
   }
   nelt_llc = (pre == 'd' || pre == 'z') ? (LLC_SZ>>3) : (LLC_SZ>>2);
   eltsh = (upr == 'd') ? 3 : 2;
   tb = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   assert(tb);
/*
 * Get best-performing kernel, and add it and a kruntime-enabled copy of it
 * to list
 */
   mp = FindMaxMflopMMQ(tb, 0);
   mb = CloneMMNode(mp);
   if (!FLAG_IS_SET(mb->flag, MMF_KRUNTIME))
   {
      mp = CloneMMNode(mb);
      mp->flag |= 1<<MMF_KRUNTIME;
      mp->next = mb;
      mb = mp;
   }
   mb = AddUniqueMMKernCompList(mb, tb);
   KillAllMMNodes(tb);
   mp = ATL_LastMMNode(mb);
   mp->next = GetWorkingUserCases(verb, upr);
   for (mp=mb; mp; mp = mp->next)
      mp->flag = (mp->flag & ~MMF_MVSET) |
                 ((1<<MMF_MVA)|(1<<MMF_MVC)|(1<<MMF_CPC));
   WriteMMFile("res/tmp.sum", mb);
/*
 * If the L1 is the last level of private cache, fitting all blocks necessary
 * to generate no traffic to non-private busses beyond the forced movement
 * is of interest.  This fits both wC/C blks + A,B and next A in the cache:
 *   2MN + K*(MU+M+N) -> 2b^2 +2b^2 + MU*b -> 4b^2 + MU*b - L1elts = 0
 * Applying quadratic equations give: b = (-MU + sqrt(MU*MU+4*4*L1elts))/8
 * --> b = (-MU + sqrt(MU^2 + 16*L1elts))/8 ~= -1 + sqrt(1+16*L1elts))/8
 * --> b ~= sqrt(16*L1elts)/8 = 4/8 sqrt(L1elts) = sqrt(L1elts)/2
 * The above approximations will give us too large a block factor to fit
 * everything in theory, but in practice non-LRU caches will retain large
 * amounts of data well beyond this region, and this is just a search bound,
 * not a performance prediction, so it is OK.
 *
 * For the low end of this region, performance varies unpredictably, and 
 * can occasionally do so even towards the end of the region.  Therefore,
 * since this is the shared-traffice minimizing region for this arch, brute-
 * force search the entire region.
 */
/*
 * Find best case for LLC.  We will first solve KB for largest square case
 * that fits, and use this size to find the best-performing kernel with a
 * fixed-K-unroll (to avoid i-cache thrashing for huge block sizes). 
 */
   if (pre == 'z' || pre == 'c')
   {
      nelt=L1C_SZ >> eltsh;
      for (i=12; i*i <= nelt; i += 4);
      b0 = (i-4)>>1;
      #if !defined(LLPC_LVL) || LLPC_LVL == 1
         bP = b0;
      #else
         nelt = LLPC_SZ >> eltsh;
         for (i=b0; i*i <= nelt; i += 4);
         bP = (i-4)>>1;
      #endif
   }
   else
   {
   #if !defined(LLPC_LVL) || LLPC_LVL == 1
      nelt=L1C_SZ >> eltsh;
      for (i=12; i*i <= nelt; i += 4);
      bP = b0 = (i-4)>>1;
/*
 * If there is another private cache above L1, then this region is mainly
 * of interest for tiny problems, and is less critical overall, so just brute
 * force the search in the beginning region where perf is so unpredictable.
 */
   #else
      b0 = 32;
      nelt = LLPC_SZ >> eltsh;
      for (i=b0; i*i <= nelt; i += 4);
      bP = (i-4)>>1;
   #endif
   }
   do_bfi(pre, 3, b0, 1, "res/tmp.sum", "opL1.sum", -1.0);

/*
 * For large problems, fully unrolling K may result in i-cache thrashing,
 * so we want to explore very large problems using loops with KU < KB.
 * tb will contain all fully-unrolled kernels, while mb will be those with
 * fixed KU.  We will use mb to explore large blocking factors, but will
 * then need to time fully-unrolled to find best-performing case once rough
 * blocking is established.
 */
   nelt = LLC_SZ >> eltsh;
   for (i=bP; i*i <= nelt; i += 4);
   bL = (i-4)>>1;
   tb = NULL;
   MMSplitByFlagAny((1<<MMF_KUISKB), &mb, &tb); /* tb gets fully unrolled K */
   WriteMMFile("res/tmp.sum", mb);
/*
 * Find best with KB near max for square problem
 */
   printf("   FINDING BEST ROLLED KERNEL FOR BOUND SEARCH, B=%d\n", bL);
   mp = bestNearSquare(pre, verb, mb, bL, 4, 0, 1.015);
   mf = mp->mflop[0];
   printf("   BEST ID=%d, '%s', B=(%d,%d,%d) mf=%.2f\n", mp->ID, 
          GetMMLabelName(pre, mp), mp->mbB, mp->nbB, mp->kbB, mp->mflop[0]);
/*
 * Now find largest blocking in all dim that improves performance
 */
   printf("   FINDING BEST MAX BLOCK FACTORS, current=(%d,%d,%d):\n", 
          mp->mbB, mp->nbB, mp->kbB);
   MMExpandMNK(verb, pre, 4, 0, nelt_llc, opWorkSetOK, 512, mp);
   MB = mp->mbB; NB = mp->nbB; KB = mp->kbB;
   printf("   BEST B=(%d,%d,%d), mf=%.2f, speedup=%.2f\n", MB, NB, KB, 
          mp->mflop[0], mp->mflop[0] / mf);
/*
 * Now find best performance at around this size using any kernel
 */
   mb = ATL_JoinMMQs(mb, tb);
   printf("   FINDING BEST KERNEL FOR ROUGH BLOCK=(%d,%d,%d):\n", MB, NB, KB);
   mpB = bestNearMNK(pre, verb, mb, MB, NB, KB, 4, 0, 1.015);
   printf("   BEST ID=%d, '%s', B=(%d,%d,%d) mf=%.2f\n", mpB->ID, 
          GetMMLabelName(pre, mpB), mpB->mbB, mpB->nbB, mpB->kbB,mpB->mflop[0]);
/*
 * If we changed kernel, re-search best block factors
 */
   if (!MMKernsSame(mpB, mp))
   {
      KillMMNode(mp);
      mp = mpB;
      printf("   FINDING BEST MAX BLOCK FACTORS, current=(%d,%d,%d):\n", 
             mp->mbB, mp->nbB, mp->kbB);
      MMExpandMNK(verb, pre, 4, 0, nelt_llc, opWorkSetOK, 512, mp);
      MB = mp->mbB; NB = mp->nbB; KB = mp->kbB;
      printf("   BEST B=(%d,%d,%d), mf=%.2f, speedup=%.2f\n", MB, NB, KB, 
             mp->mflop[0], mp->mflop[0] / mf);
      mpB = bestNearMNK(pre, verb, mb, MB, NB, KB, 4, 0, 1.015);
      KillMMNode(mpB);
   }
   else
      KillMMNode(mpB);

   mpB = mp;
   WriteMMFileWithPath(pre, "res", "opASYMP.sum", mpB);
   maxB = mp->mbB;
   maxB = Mmax(maxB, mp->nbB);
   maxB = Mmax(maxB, mp->kbB);
/*
 * Get temporary queue, eliminate kerns not providing unique KU speedup,
 * then do search for all problems between [bP,bL]
 */
   if (bP >= KB)
      bP = b0;
   if (bP < KB)
   {
      tb = CloneMMQueue(mb);
      tb = MMWinnowByKU(tb, bP, 1.05);
      if (FULLSRCH)
      {
         WriteMMFile("res/tmp.sum", mb);
         printf("FINDING BEST RANK-K KERNELS FOR LLC:\n");
         do_bfi(pre, bP+1, KB, 1, "res/tmp.sum", "opLLC.sum", 1.015);
         printf("DONE\n");
      }
      else
      {
         ATL_mmnode_t *rb;
         rb = opsrch_rng(verb, pre, 4, 1.015, bP+1, KB, maxB, nelt_llc,
                         opWorkSetOK, mpB, tb);
         WriteMMFileWithPath(pre, "res", "opLLC.sum", rb);
         KillAllMMNodes(rb);
      }
      KillAllMMNodes(tb);
   }
   else
      assert(0);
   KillMMNode(mpB);
/*
 * Finally, find best-performing kernels in LLPC region.  Do our winnowing
 * search on problem well-within LLPC
 */
   #if defined(LLPC_LVL) && LLPC_LVL > 1 && LLPC_LVL < LLC_LVL
   if (bP > b0)
   {
      KB = bP - b0;
      if (KB > 16)
         KB = bP-8;
      else
         KB = b0 + (KB>>1);
      printf("   FINDING BEST KERNEL FOR LLPC BOUND SEARCH, B=%d\n", KB);
      mp = bestNearSquare(pre, verb, mb, KB, 4, 0, 1.015);
      mf = mp->mflop[0];
      printf("   BEST ID=%d, '%s', B=(%d,%d,%d) mf=%.2f\n", mp->ID, 
             GetMMLabelName(pre, mp), mp->mbB, mp->nbB, mp->kbB, mp->mflop[0]);
/*
 *    Now find largest blocking in all dim that improves performance
 */
      printf("   FINDING BEST MAX BLOCK FACTORS, current=(%d,%d,%d):\n", 
             mp->mbB, mp->nbB, mp->kbB);
      MMExpandMN(verb, pre, 4, 0, maxB, mp);
      MB = mp->mbB; NB = mp->nbB; KB = mp->kbB;
      printf("   BEST B=(%d,%d,%d), mf=%.2f, speedup=%.2f\n", MB, NB, KB, 
             mp->mflop[0], mp->mflop[0] / mf);
/* 
 *    Find best-performing kernel around this size
 */
      printf("   FINDING BEST KERNEL FOR ROUGH BLOCK=(%d,%d,%d):\n", MB,NB,KB);
      mpB = bestNearMNK(pre, verb, mb, MB, NB, KB, 4, 0, 1.015);
      printf("   BEST ID=%d, '%s', B=(%d,%d,%d) mf=%.2f\n", mpB->ID, 
             GetMMLabelName(pre, mpB),mpB->mbB,mpB->nbB,mpB->kbB,mpB->mflop[0]);
/*
 *     If we changed kernel, re-search best block factors
 */
      if (!MMKernsSame(mpB, mp))
      {
         KillMMNode(mp);
         mp = mpB;
         printf("   FINDING BEST MAX BLOCK FACTORS, current=(%d,%d,%d):\n", 
                mp->mbB, mp->nbB, mp->kbB);
         MMExpandMN(verb, pre, 4, 0, maxB, mp);
         MB = mp->mbB; NB = mp->nbB; KB = mp->kbB;
         printf("   BEST B=(%d,%d,%d), mf=%.2f, speedup=%.2f\n", MB, NB, KB, 
                mp->mflop[0], mp->mflop[0] / mf);
         mpB = bestNearMNK(pre, verb, mb, MB, NB, KB, 4, 0, 1.015);
         KillMMNode(mpB);
      }
      else
         KillMMNode(mpB);
      mpB = mp;
      mb = MMWinnowByKU(mb, b0, 1.10);
      if (FULLSRCH)
      {
         WriteMMFile("res/tmp.sum", mb);
         printf("FINDING BEST RANK-K KERNELS FOR LLPC:\n");
         do_bfi(pre, b0+1, bP, 1, "res/tmp.sum", "opLLPC.sum", 1.015);
         printf("DONE\n");
      }
      else
      {
         ATL_mmnode_t *rb;
         tb = CloneMMQueue(mb);
         tb = MMWinnowByKU(tb, bP, 1.05);
         nelt_llpc = (pre == 'd' || pre == 'z') ? (LLPC_SZ>>3) : (LLPC_SZ>>2);
         rb = opsrch_rng(verb, pre, 4, 1.015, b0+1, bP, maxB, nelt_llpc,
                         opWorkSetOK, mpB, tb);
         KillAllMMNodes(tb);
         WriteMMFileWithPath(pre, "res", "opLLPC.sum", rb);
         KillAllMMNodes(rb);
      }
      KillMMNode(mpB);
   }
   #endif
   KillAllMMNodes(mb);
   GetMMLabelName(pre, NULL);
   mb = ReadMMFileWithPath(pre, "res", "opL1.sum");
   assert(mb);
   mp = ATL_LastMMNode(mb);
   tb = ReadMMFileWithPath(pre, "res", "opLLPC.sum");
   if (tb)
   {
      mp->next = tb;
      mp = ATL_LastMMNode(tb);
   }
   tb = ReadMMFileWithPath(pre, "res", "opLLC.sum");
   mp->next = tb;
   WriteMMFileWithPath(pre, "res", "opFNL.sum", mb);
   KillAllMMNodes(mb);
}

/* 
 * For small sizes, want to just try all kernels because there can be
 * unpredictable effects due to cleanup and related.  For larger problems,
 * we'd like to restrict the number of kernels searched a bit, based on the
 * idea that once FLOPS dominate, only raw performance should matter, and
 * so we can take a rough size in the middle of a "region" and only retain
 * kernels that are competitive at that size for all timings within the
 * region.  We have several regions of interest (greatest-to-least):
 * (1) Outer product working set fits in LLC, b <= (sqrt(1+LLC_elts/4) - 1)/2
 * (2) B fits in LLC: b <= sqrt(LLPC_elts) -> N <= LLPC_elts/K
 * (2) Outer produce wrk set fits in LLPC, b <= (sqrt(1+LLPC_elts/4) - 1)/2
 * we can eliminate kernels wt inadequate performance on a certain szi
 */
int main(int nargs, char **args)
{
   unsigned long llc_elts;
   unsigned eltsz = 8;
   int maxK, verb=0;
   char pre, upr;
   pre = GetFlags(nargs, args);
/*
 * For outer product, K is fixed, and you can vary at most 2 dimensions.
 * in practice, wt K fixed, you mainly want to increase NB to maximize
 * A reuse within a amm call.  Changing MB has smaller affects on performance,
 * because if we reduce MB, we reduce B reuse within one kernel, but increase
 * its's reuse over the M/MB amm calls that compute a colpan of C.  These
 * timings not needed for for degenerate M, which forces you to compute a 
 * row-panel of C instead (and thus potentially have TLB problems).
 *
 * For this search, we break the possible block factors into several regions.
 * Minimally, consider a small region where operands fit in the L1, and
 * one where operands fit in the last-level of cache.  Another important
 * region last level private cache (cache that cores don't share).  Caches
 * that are shared between cores may be much more strongly bandwidth-limited
 * than private caches when all cores are running at maixmal rates, and so
 * this region may provide the best performance on some systems.
 *
 * In practice, since caches are often high associativity and random replacement
 * the boundaries between regions will not be distinct, and best performance
 * may be found when operands exceed the cache.
 */
/*
 * Biggest outer-produce case that makes sense is: 2MN + K*(MU+M+N) == LLC_elts
 * In this way, we should be able to resuse both Cb (C in block form) and
 * Bb from cache, despite moving both C & A ptrs, and copying Cb->Cc.  In
 * practice, the copy to col-major C will knock stuff out due to cache 
 * conflicts, which may cause unpredictable affects.  If we set b=M=N=K, and
 * assume the best case of MU=1, the above becomes:
 *    4b^2 + b - (LLC_elts/4), or b = (sqrt(1+LLC_elts/4) - 1)/2 frm quad equ.
 */
   if (pre == 's' || pre == 's')
      eltsz = 4;
   maxK = (sqrt(1 + ((LLC_SZ / eltsz)>>2)) - 3.0)/2.0;
   maxK = Mmin(480, maxK);
   do_opk(verb, pre, NULL, maxK);
   do_opdek(verb, pre, 0);
   do_opdek(verb, pre, 1);
   return(0);
}
@ROUT bfisrch trsmsrch
#define ATL_GETFLAGS
#include "atlas_genparse.h"
#include "atlas_mmtesttime.h"
@ROUT trsmsrch `#include "atlas_cache.h"`

void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
   fprintf(stderr, "   -o <resfile>: (stdout) fastest kernels found\n");
   fprintf(stderr, 
   "   -O : same as -o, but deletes any existing file with <resfile> name\n");
   fprintf(stderr, "   -i <input file>: list of kernel to consider\n");
@ROUT bfisrch
   fprintf(stderr, "   -r <runBonus> : (1.0) timing bonus to give runtime-K\n");
   fprintf(stderr, "   -b[m,n,k] # b1 ... b#: specify desired blocking for"
                   " given dim as list\n");
   fprintf(stderr, "   -B[m,n,k] B0 BN incB: specify desired blocking for\n"
                   "                         given dim as inclusive range\n");
   fprintf(stderr, "   -s [f,p] [O,o,i] [C,R]: specify search type:\n");
   fprintf(stderr, "      p: precise search, performance may be reduced"
                   " by dims\n");
   fprintf(stderr, "      f: fuzzy search, storage may exceed dims\n");
   fprintf(stderr, "      O: outer product including C copy\n");
   fprintf(stderr, "      o: outer product gemm-time only\n");
   fprintf(stderr, "      i: inner product gemm-time only\n");
   fprintf(stderr, "      C: try timing runtime-K C files as compile-time K\n");
   fprintf(stderr, "      R: only time runtime-K as runtime\n");
   fprintf(stderr, "   -MNK <idx>: take kern idx frm file fnin &"
                   " tune all dims\n");
   fprintf(stderr, "   -MN <idx> <KB>: take kern idx frm fnin &"
                   " tune MB&NB\n");
@ROUT trsmsrch
   fprintf(stderr, "   -n 0/1 <NB>: quick/full trsmsrch at N=NB\n");
@ROUT bfisrch trsmsrch
   fprintf(stderr, "   -N <idx> <KB> <MB> <maxN>\n");
   fprintf(stderr, "   -e [exclusion clause]: exclude kernels from search:\n");
   fprintf(stderr, "      V=[K,M] : exclude K- or M-vectorized kernels\n");
   fprintf(stderr, "      V=# : exclude all kerns whose vlen != #\n");
   fprintf(stderr, "      K=C : exclude all compile-time K kernels\n");
   fprintf(stderr, "      K=F : exclude fully unrolled K-loop kernels\n");
   fprintf(stderr, "      K=# : exclude all kernels with KU >= #\n");
   fprintf(stderr, "      repeat -e to exclude multiple kern types\n");
   fprintf(stderr, "   -v <verb> : set verbosity (1)\n");
   exit(ierr ? ierr : -1);
}

#define FLG_FUZZY   2  /* 1st two bit pos are for verb */ 
#define FLG_OPCPY   3  /* outer-product search including C put time */
#define FLG_OP      4  /* if these two not set, use inner-prod search */
#define FLG_NOKVEC  5  /* don't use k-vectorized kernels */
#define FLG_NOMVEC  6  /* don't use m-vectorized kernels */
#define FLG_NOKCOMP 7  /* don't use kernels needing compile-time K */
#define FLG_NOKFULL 8  /* don't use fully-unrolled K kernels */
#define FLG_NOBIGKU 9  /* exclude kernels with KU > III */
#define FLG_MKCOMP  10 /* try compiling runtime-K as compile-time */
@ROUT trsmsrch
#define FLG_FULLSRCH 11 /* do not prune; time all kerns directly */

char *GetFlags(int nargs, char **args, char *PRE, int *FLAG, int *MAXKU,
               int *REQVL, char **FNIN, int *KB)
@ROUT bfisrch
#define ALLSRCH ( (1<<FLG_EXPMN)|(1<<FLG_EXPMNK) )
#define FLG_EXPMN  30  /* do ExpandMN search on 1 kern */
#define FLG_EXPMNK 31  /* do ExpandMNK search on 1 kern */
char *GetFlags(int nargs, char **args, char *PRE, int *FLAG, int *MAXKU,
               int *REQVL, char **FNIN, int **MBS, int **NBS, int **KBS, 
               double *runBon)
@ROUT bfisrch trsmsrch
/*
 * RETURNS: name of output file as malloced string
 */
{
   char *fout=NULL;
   int *mbs=NULL, *nbs=NULL, *kbs=NULL;
   int i, flag, verb=0, FUZZY=1, OPCPY=1, OP=0, MKCOMP=0;
   int NOKVEC=0, NOMVEC=0, NOKCOMP=0, NOKFULL=0;
   char pre='d';

   *REQVL = *MAXKU = 0;
   *FNIN = NULL;
@ROUT trsmsrch
   *KB = 120;
@ROUT bfisrch
   *runBon = 1.0;
@ROUT bfisrch trsmsrch
   for (i=1; i < nargs; i++)
   {
      int wch, *ip, **ipp, TST=0;
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        break;
      case 'e': /* -e V=[K,M,#] or  K=[C,F,#] */
         if (++i >= nargs)
             PrintUsage(args[0], i-1, NULL);
         wch = args[i][0];
         if (wch != 'V' && wch != 'K')
            PrintUsage(args[0], i-1, "expecting 'V' or 'K' after -e");
         if (args[i][1] != '=')
            PrintUsage(args[0], i-1, "expecting '=' after -e V/K");
         if (wch == 'V')
         {
            wch = args[i][2];
            if (wch == 'K')
               NOKVEC = 1;
            else if (wch == 'M')
               NOMVEC = 1;
            else if (isdigit(wch))
               *REQVL = atoi(args[i]+2);
            else
               PrintUsage(args[0], i-1, "expecting M,K,# after -e V=");
         }
         else /* wch == 'K' K=[C,F,#] */
         {
            wch = args[i][2];
            if (wch == 'F')
               NOKFULL = 1;
            else if (wch == 'C')
               NOKCOMP = 1;
            else if (isdigit(wch))
               *MAXKU = atoi(args[i]+2);
            else
               PrintUsage(args[0], i-1, "expecting F,C,# after -e K=");
         }
         break;
      case 'i':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *FNIN = args[i];
        break;
      case 'v':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        verb = atoi(args[i]);
        verb = (verb > 3) ? 3 : verb;
        break;
      case 'O':
        TST=1;
      case 'o':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        fout = args[i];
        if (TST)
           remove(fout);
        break;
@ROUT trsmsrch
      case 'n': /* -n <NB> */
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         TST = atoi(args[i]);
         if (TST)
            flag |= 1<<FLG_FULLSRCH;
         if (++i >= nargs)
             PrintUsage(args[0], i-1, NULL);
         *KB = atoi(args[i]);
         break;
@ROUT bfisrch
      case 's': /* -s [f,p] [O,o,i] [C,R] */
         if (++i >= nargs)
             PrintUsage(args[0], i-1, NULL);
         wch = args[i][0];
         if (wch != 'f' && wch != 'F' && wch != 'p' && wch != 'P')
             PrintUsage(args[0], i-1, "bad fuzzy/precice to -s");
         if (wch == 'p' || wch == 'P')
            FUZZY = 0;
         if (++i >= nargs)
             PrintUsage(args[0], i-1, NULL);
         wch = args[i][0];
         if (wch != 'O' && wch != 'o' && wch != 'i' && wch != 'I')
             PrintUsage(args[0], i-1, "bad inner/outer to -s");
         OPCPY = (wch == 'O');
         OP = (wch == 'o');
         if (++i >= nargs)
             PrintUsage(args[0], i-1, NULL);
         wch = args[i][0];
         if (wch != 'C' && wch != 'c' && wch != 'r' && wch != 'R')
             PrintUsage(args[0], i-1, "bad runcomp to -s");
         MKCOMP = (wch == 'C' || wch == 'c');
         break;
      case 'r':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *runBon = atof(args[i]);
        break;
      case 'M':  /* -MN idx KB or -MNK idx */
         if (args[i][2] != 'N')
            PrintUsage(args[0], i, args[i]);
         if (args[i][3] == 'K')
            TST=1;
         else if (args[i][3] == '\0')
            TST=2;
         else
            PrintUsage(args[0], i, args[i]);
         nbs = malloc(TST*sizeof(int));
         assert(nbs);
         for (wch=0; wch < TST; wch++)
         {
            if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            nbs[wch] = atoi(args[i]);
         }
         if (TST == 1) /* for full search, put info in MBs not NBs */
         {
            mbs = nbs;
            nbs = NULL;
         }
         break;
      case 'N':
         nbs = malloc(4*sizeof(int));
         assert(nbs);
         for (wch=0; wch < 4; wch++)
         {
            if (++i >= nargs)
                PrintUsage(args[0], i-1, NULL);
            nbs[wch] = atoi(args[i]);
         }
         break;
      case 'B':                                 /* -B[m,n,k] B0, BN, incB */
         TST=1;
      case 'b':                                 /* -b[m,n,k] # b1 ... b# */
         wch = tolower(args[i][2]);
         if (wch == 'm')
            ipp = &mbs;
         else if (wch == 'n')
            ipp = &nbs;
         else if (wch == 'k')
            ipp = &kbs;
         else
         {
            fprintf(stderr, "Expecting dim of m n or k!");
            PrintUsage(args[0], i, args[i]);
         }
         if (TST)
         {
            int B0, BN, incB;
            if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            B0 = atoi(args[i]);
            if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            BN = atoi(args[i]);
            if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            incB = atoi(args[i]);
            ip = GF_IntRange2IntList(B0, BN, incB);
         }
         else
         {
            ip = GF_GetIntList(nargs, args, i, 1);
            i += *ip + 1;
         }
         if (*ipp)
            free(*ipp);
         *ipp = ip;
         break;
@ROUT bfisrch trsmsrch
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   flag = 0;
@multidef flg NOKVEC NOMVEC NOKCOMP NOKFULL
@whiledef flg FUZZY OPCPY OP MKCOMP
   flag |= @(flg)<<FLG_@(flg);
@endwhile
   *FLAG = flag;
   if (fout)
      fout = DupString(fout);
   *PRE = pre;
@ROUT bfisrch
   *MBS = mbs;
   *NBS = nbs;
   *KBS = kbs;
@ROUT bfisrch trsmsrch
   return(fout);
}

ATL_mmnode_t *ApplyRules(ATL_mmnode_t *ob, int flag, int maxKU, int reqVL)
{
   ATL_mmnode_t *nb=NULL;
   while(ob)
   {
      int KILL=0, REGEN=0, KILLFIX=0;
      if (reqVL)
         KILL = (ob->vlen != reqVL);

      if (!KILL && maxKU && ob->ku > maxKU)
      {
         REGEN = KILL = 1;
         if (!ob->ID) /* for genned codes, see if we can reset KU */
         {
            if (FLAG_IS_SET(ob->flag, MMF_KVEC))
            {
               if (maxKU >= ob->vlen)
               {
                  KILL = 0;
                  ob->ku = ob->vlen;
               }
            }
            else
            {
               KILL = 0;
               ob->ku = 1;
            }
         }
      }
      if (!KILL&&(flag&(1<<FLG_NOKFULL))&&FLAG_IS_SET(ob->flag, MMF_KUISKB))
      {
         REGEN = KILL = 1;
         if (!ob->ID) /* genned codes poss changed to runtime */
         {
            KILL = 0;
            if (FLAG_IS_SET(ob->flag, MMF_KVEC))
            {
               ob->ku = ob->vlen;
               ob->flag ^= 1<<MMF_KUISKB;
            }
            else
            {
               ob->ku = 1;
               ob->flag ^= 1<<MMF_KUISKB;
            }
         }
      }
      if (!KILL&&(flag&(1<<FLG_NOKCOMP))&&!FLAG_IS_SET(ob->flag, MMF_KRUNTIME))
      {
         REGEN = KILL = 1;
         if (!ob->ID) /* genned codes poss changed to runtime */
         {
            KILL = 0;
            if (FLAG_IS_SET(ob->flag, MMF_KVEC))
            {
               if (ob->ku < ob->vlen)
                  ob->ku = ob->vlen;
               else
                  while (ob->ku % ob->vlen)
                     ob->ku--;
@ROUT bfisrch
            }
@ROUT trsmsrch
               if (ob->mu % ob->vlen == 0 || ob->nu % ob->vlen == 0)
               {
                  while ((ob->mu % ob->ku != 0)&&(ob->nu % ob->ku != 0))
                     ob->ku -= ob->vlen;
               }
            }
@ROUT trsmsrch
            else
            {
               while (ob->mu % ob->ku && ob->nu % ob->ku)
                  ob->ku--;
            }
@ROUT bfisrch trsmsrch
            ob->flag |= 1<<MMF_KRUNTIME;
         }
      }
      if ((flag&(1<<FLG_NOKVEC)) && FLAG_IS_SET(ob->flag, MMF_KVEC))
         KILL = 1;
      else if ((flag&(1<<FLG_NOMVEC)) && !FLAG_IS_SET(ob->flag, MMF_KVEC))
         KILL = 1;
      if (KILL)
         ob = KillMMNode(ob);
      else /* add to queue, and set it to use selected search type */
      {
         ATL_mmnode_t *nxt=ob->next;
         ob->flag &= ~MMF_MVSET;
@ROUT trsmsrch
         ob->flag |= (1<<MMF_MVC) | (1<<MMF_MVA);
@ROUT bfisrch
         if (flag&((1<<FLG_OPCPY)|(1<<FLG_OP)))
            ob->flag |= (1<<MMF_MVA) | (1<<MMF_MVC) | (1<<MMF_CPC);
         else
            ob->flag |= (1<<MMF_MVA) | (1<<MMF_MVB);
@ROUT bfisrch trsmsrch
         if (!ob->ID)
         {
            if (ob->genstr)
            {
               free(ob->genstr);
               ob->genstr = NULL;
            }
            if (ob->rout)
               free(ob->rout);
            ob->rout = DupString("ATL_tmp.c");
            if (flag&(1<<FLG_MKCOMP)) /* want to try run- & compile-time K */
            {
               ATL_mmnode_t *np=NULL;
               if (FLAG_IS_SET(ob->flag, MMF_KVEC))
               {
                  if (ob->ku == ob->vlen)
                     np = CloneMMNode(ob);
               }
               else if (ob->ku == 1)
                  np = CloneMMNode(ob);
               if (np)
               {
                  if (FLAG_IS_SET(ob->flag, MMF_KRUNTIME))
                     np->flag ^= 1<<MMF_KRUNTIME;
                  else
                     np->flag |= 1<<MMF_KRUNTIME;
                  np->next = nb;
                  nb = np;
               }
            }
         }     /* end if this is generated kern */
         ob->next = nb;
         nb = ob;
         ob = nxt;
      }     /* end else for keeper case */
   }        /* end while(ob); */
   return(nb);
}

@ROUT bfisrch
void prepOP(ATL_mmnode_t *mb)
/*
 * Modifies MOV bits for rank-K timings
 */
{
   ATL_mmnode_t *mp;
   for (mp=mb; mp; mp = mp->next)
      mp->flag = (mp->flag&(~MMF_MVSET)) |
                 ((1<<MMF_MVA)|(1<<MMF_MVC)|(1<<MMF_CPC));
}
/*
 * This search takes idx kern from fnin, and then finds the best performing
 * dimensions.  If KB==0, all three dims are tuned, else KB is fixed, and 
 * only MB&NB are varied.
 */
void DoSrchD(char pre, int flag, int KB, char *fnin, int idx, char *fnout)
{
   ATL_mmnode_t *cb, *mp;
   double mf;
   int i, nu, NB;
   const int verb = flag&3;
   const unsigned int flg = ((flag>>FLG_OPCPY)&1)<<2;
/*
 * Get the idx kernel from the input file, and use it for all timings
 */
   cb = ReadMMFile(fnin);
   assert(cb);
   for (i=0, mp=cb; mp && i < idx; i++, mp = mp->next);
   assert(mp);
   cb = RemoveMMNodeFromQ(cb, mp);
   KillAllMMNodes(cb);

   prepOP(mp);

   if (KB)
      mp->kbB = KB;
   printf("   TUNING B FOR %s, PRESENT B=(%u,%u,%u), mf=%.2f:\n", 
          GetMMLabelName(pre, mp), mp->mbB, mp->nbB, mp->kbB,
          mp->mflop ? mp->mflop[0]:0.0);
   GetMMLabelName(pre, NULL);
   if (KB)
      mf = MMExpandMN(verb, pre, flg, 0, 512, mp);
   else
      mf = MMExpandMNK(verb, pre, flg, 0, 0, NULL, 512, mp);
   printf("   BEST B=(%u,%u,%u), MFLOPS=%.2f\n", mp->mbB, mp->nbB, mp->kbB, mf);
   PrintMMLine(stdout, mp);
   if (fnout)
      WriteMMFile(fnout, mp);
   printf("\nB=(%d,%d,%d), MFLOPS=%.2f\n", mp->mbB, mp->nbB, mp->kbB, mf);
   KillMMNode(mp);
}
/*
 * This search takes a kernel mp, sets MB=MB, KB=KB, and finds the best
 * performing NB, which is restricted only by maxN
 */
void DoSrchN(char pre, int flag, int MB, int KB, int maxN, char *fnin, int idx)
{
   ATL_mmnode_t *cb, *mp;
   double mf;
   int i, nu, NB;
   const int verb = flag&3;
   const unsigned int flg = ((flag>>FLG_OPCPY)&1)<<2;
/*
 * Get the idx kernel from the input file, and use it for all timings
 */
   cb = ReadMMFile(fnin);
   assert(cb);
   for (i=0, mp=cb; mp && i < idx; i++, mp = mp->next);
   assert(mp);
   cb = RemoveMMNodeFromQ(cb, mp);
   KillAllMMNodes(cb);

   assert(MB % mp->mu == 0);
   nu = mp->nu;
   i = maxN % nu;
   if (i)
      maxN += nu-i;
   mp->mbB = MB;
   mp->kbB = KB;
   prepOP(mp);

   printf("   TUNING NB FOR BEST KERN, PRESENT NB=%d:\n", mp->nbB);
   NB = MMVaryDim(verb, pre, flg, 0, maxN, 0, mp);
   mf = mp->mflop[1];
   printf("   BEST NB=%u, MFLOPS=%.2f\n", NB, mf);
   mp->nbB = NB;
   mp->mflop[0] = mf;
   mp->mflop[1] = 0.0;
   PrintMMLine(stdout, mp);
   printf("\nB=(%d,%d,%d), MFLOPS=%.2f\n", MB, KB, NB, mf);
}

/*
 * This search is used for outer produce with unrestricted N & M.  In this
 * case, we get our reuse of B between amm calls, leaving A reuse the only
 * reuse that is important intra-kernel.  Therefore, this search takes a 
 * list of kernels, and a specific KB.  It then sorts the kern by ascending MU.
 * For each MU, it then sets N=MAX(maxN,maxNU), and compares all kerns wt 
 * target MU.  The winning kern is then tuned to find the best NB given
 * M=MU & K=KB, and then placed in the bb (base ptr to Best list).
 * As we add larger MUs we refuse to add those that don't beat any smaller
 * MU that evenly divide the new MU.  First do hand-written case above.
 */

/*
 * This search used for outer-product.  A kernel is found for each listed KB.
 * MB can be be forced to roughly match KB, or freely chosen, in which case
 * we will usually make it roughly match KB unless KB is small, and then
 * we may enlarge it to help with loop overhead.
 */
void opsrch(char pre, int flag, char *outnm, int *KBs, double runBon)
{
   ATL_mmnode_t *tb=NULL, *bb=NULL;  /* try and best base ptrs */
   ATL_mmnode_t *mp;
   double mf, mfB;
   const int verb = flag&3;
   int i;  
   const unsigned int nKB=(*KBs);
   unsigned int maxKB, maxD, flg, MB, NB;  /* flag for TimeMMKernel */

   flg = ((flag>>FLG_OPCPY)&1)<<2;
   if (outnm)  /* if outnm exists, just time negative mflop and return */
   {
      ATL_mmnode_t *mb;
      mb = TimeMMFile(pre, outnm, 0, 1, flg, 0, 0, -1);
      if (mb)
      {
         KillAllMMNodes(mb);
         return;
      }
   }
/*
 * Sort KBs greatest-to-least, then peel largest block factor in order to
 * find good initial MB/NB
 */
   ATL_isortG2L(nKB, ++KBs);
   maxKB = *KBs;
   maxD = Mmax(maxKB, 120);

   tb = GetWorkingUserCases(verb, pre);
/*
 * Our normal list is all user kerns + best generated kerns.  We may add
 * special generated kerns later.
 */
   mp = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   tb = ATL_JoinMMQs(tb, mp);
   #if 0
   for (mp=tb; mp; mp = mp->next)
      mp->flag = (mp->flag & ~MMF_MVSET)|((1<<MMF_MVA)|(1<<MMF_MVC));
   #else
      tb = ApplyRules(tb, flag, 0, 0);
   #endif
   printf("SEARCHING FOR BEST KERNEL AMONGST %u KERNELS AND %u KBs:\n",
          ATL_CountNumberOfMMNodes(tb), nKB);

   printf("   SEARCHINGS KERNS FOR MAXKB=%u\n", maxKB);
   mp = bestNearSquare(pre, verb, tb, maxKB, flg, 0, runBon);
   assert(mp);  /* for now, later gen a case */
   mf = mp->mflop[0];
   printf("   BEST KERN KB=%u: ID=%d '%s' mf=%.2f\n", maxKB, mp->ID, 
          GetMMLabelName(pre, mp), mf);
   printf("   TUNING M/NB FOR BEST KERN, PRESENT B=(%u,%u):\n", 
          mp->mbB, mp->nbB);
   mfB = MMExpandMN(verb, pre, flg, 0, 512, mp);
   printf("   B=(%u,%u,%u) GIVES SPEEDUP: %.2f\n", mp->mbB, mp->nbB, mp->kbB,
          mfB/mf);
   KillMMNode(mp);
   MB = mp->mbB;
   NB = mp->nbB;
/*
 * We purposely re-search maxKB, because enlarged MB/NB often picks higher
 * performing kernel
 */
   for (i=0; i < nKB; i++)
   {
      const int kb=KBs[i];

      printf("   SEARCHINGS KERNS FOR KB=%u\n", kb);
      mp = bestNearMNK(pre, verb, tb, MB, NB, kb, flg, 0, runBon);
      assert(mp);  /* for now, later gen a case */
      mf = mp->mflop[0];
      printf("   BEST KERN KB=%u: ID=%d '%s' mf=%.2f\n", kb, mp->ID, 
             GetMMLabelName(pre, mp), mf);
      printf("   TUNING M/NB FOR BEST KERN, PRESENT B=(%u,%u):\n", 
             mp->mbB, mp->nbB);
      mfB = MMExpandMN(verb, pre, flg, 0, 512, mp);
      printf("   B=(%u,%u,%u) GIVES SPEEDUP: %.2f\n", mp->mbB, mp->nbB, mp->kbB,
             mfB/mf);
      mp->next = bb;
      bb = mp;
   }
   printf("DONE.\n\n");
   KillAllMMNodes(tb);

   GetMMLabelName(pre, NULL);
   WriteMMFile(outnm, bb);
   KillAllMMNodes(bb);
}
/*
 * Brute-fource and ignorance search just tries every kernel for every 
 * candidate size.  It is primarily used for small sizes where things like
 * cleanup or doing strange things like targeting multiple operands to the L1
 * cache can have unpredictable performance affects.
 *
 * BFI supports two types of searches:
 *  fuzzy: finds kernel that performs best for given size, with non-matching
 *         unrolling flops not counted in the flop rate.  It often requires
 *         over-allocating for A/B/C workspace.
 *  exact: finds kernel performs best for precise size, but bad sizes may
 *         have terrible performance (eg., prime sizes eliminating almost
 *         all non-generated kernels, and forcing generated kernels to use
 *         terrible register blockings).
 */
int main(int nargs, char **args)
{
   char *fnin, *fnout;
   int *MBs, *NBs, *KBs;
   double runBon;
   int flag, maxKU, reqVL;
   char pre;

   fnout = GetFlags(nargs, args, &pre, &flag, &maxKU, &reqVL, &fnin, 
                    &MBs, &NBs, &KBs, &runBon);
@skip   assert(flag & (1<<FLG_FUZZY)); /* currently only supporte srch type */

   if (KBs)
   {
      assert(!MBs && !NBs);          /* currently, unsupported */
      assert(KBs);
      opsrch(pre, flag, fnout, KBs, runBon);
   }
   else if (NBs)
      DoSrchD(pre, 1<<FLG_OPCPY, NBs[1], fnin, NBs[0], fnout);
   else if (MBs)
      DoSrchD(pre, 1<<FLG_OPCPY, 0, fnin, MBs[0], fnout);

   if (fnout)
      free(fnout);
   if (MBs)
      free(MBs);
   if (NBs)
      free(NBs);
   if (KBs)
      free(KBs);
   return(0);
}
@ROUT trsmsrch
void smsrch(char pre, int flag, char *fnin, char *outnm, int NB, 
            int maxKU, int reqVL)
{
   ATL_mmnode_t *mb, *mp, *tb=NULL;
   double mfB;
   const int verb=flag&3;
   if (!fnin)
   {
      mb = GetWorkingUserCases(verb, pre);
      mp = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
      mb = ATL_JoinMMQs(mb, mp);
   }
   else
      mb = ReadMMFile(fnin);
   assert(mb);
   mb = ApplyRules(mb, flag|(1<<FLG_NOKCOMP)|(1<<FLG_NOKFULL), maxKU, reqVL);
   assert(mb);
/*
 * Get rid of all kerns where MU,NU are not multiples of KU
 */
   mp = mb;
   while (mp)
   {
      if ((mp->mu % mp->ku) && (mp->nu % mp->ku))
      {
         mb = (mp == mb) ? mb->next : mb;
         mp->next = KillMMNode(mp);
      }
      else
         mp = mp->next;
   }
   assert(mb);
   if (!(flag&(1<<FLG_FULLSRCH)))
   {
      printf("REDUCING %u KERNELS FOR GEMM-BASED TRSM KERNEL\n", 
             ATL_CountNumberOfMMNodes(mb));
      mp = bestNearMNK(pre, verb, mb, 1, 1, NB>>1, 0, 0, 1.0);
      mfB = mp->mflop[0];
      KillMMNode(mp);
      while (mb->mflop[0]*1.25 < mfB)
         mb = KillMMNode(mb);
      mp = mb;
      while (mp)
      {
         ATL_mmnode_t *nxt = mp->next;
         if (mp->mflop[0]*1.25 < mfB)
         {
            RemoveMMNodeFromQ(mb, mp);
            KillMMNode(mp);
         }
         mp = nxt;
      }
   }
   printf("SEARCHING %u KERNELS FOR GEMM-BASED TRSM KERNEL\n", 
          ATL_CountNumberOfMMNodes(mb));
   for (mp=mb; mp; mp = mp->next)
   {
      unsigned int U = mp->mu, UMAX;
      ATL_mmnode_t *tp;
      if (mp->mu % mp->ku == 0 || mp->nu % mp->ku == 0)
      {
         tp = CloneMMNode(mp);
         tp->TA = AtlasNoTrans;
         if (U > NB)
            UMAX = U;
         else
            UMAX = (NB/U)*U - U;
         tp->mflop[0] = MMTimeRangeK(verb, 4, tp, pre, tp->mu, tp->nu,
                                     U, UMAX, U, 0, 0, L1C_SZ);
         printf("   %s, B=(%u,%u), K=[%u,%u] mf=%.2f\n", 
                GetMMLabelName(pre, mp), tp->mu, tp->nu, U, UMAX, tp->mflop[0]);
         tp->next = tb;
         tb = tp;
      }
      U = mp->nu;
      if (U % mp->ku == 0 && U != mp->mu) /* can try trans case, diff notrans */
      {
         tp = CloneMMNode(mp);
         tp->TA = AtlasTrans;
         tp->flag |= 1<<MMF_ALLTRANS;
         if (U > NB)
            UMAX = U;
         else
            UMAX = (NB/U)*U - U;
         tp->mflop[0] = MMTimeRangeK(verb, 4, tp, pre, tp->mu, tp->nu, 
                                     U, UMAX, U, 0, 0, -1);
         printf("   %s, B=(%u,%u), K=[%u,%u] mf=%.2f\n", 
                GetMMLabelName(pre, mp), tp->mu, tp->nu, U, UMAX, tp->mflop[0]);
         tp->next = tb;
         tb = tp;
      }
   }
   assert(tb);
   GetMMLabelName(pre, NULL);
   KillAllMMNodes(mb);
   WriteMMFile(outnm, tb);
   KillAllMMNodes(tb);
}

int main(int nargs, char **args)
{
   char *fnin, *fnout;
   unsigned int NB, flag, maxKU, reqVL;
   char pre;

   fnout = GetFlags(nargs, args, &pre, &flag, &maxKU, &reqVL, &fnin, &NB);
   smsrch(pre, flag, fnin, fnout, NB, maxKU, reqVL);
   return(0);
}
@ROUT ammkgen
/*
 * Takes all amm kernels to be used for anything in ATLAS, and build master
 * index of kernel structures.  This contains no performance info; that is
 * handled by views that reference these structures
 */
#include "atlas_mmgen.h"
#include "atlas_type.h"

ATL_cpnode_t *GetKernCopies(char pre, char *outd, ATL_mmnode_t *kb)
/*
 * Creates a copy node for each amm-incompatible copy needed by kerns in kb
 * RETURNS: queue of kern-spec copies to gen & compile
 */
{
   ATL_cpnode_t *cb=NULL;
   ATL_mmnode_t *mp;
   char *fnd, *fn;
   int dlen;
   dlen = strlen(outd) + 1;
   fnd = malloc(dlen+24);
   assert(fnd);
   fn = fnd + dlen;
   sprintf(fnd, "%s/ATL_XssSyrkIntoC_aXbX.c", outd);
   for (mp=kb; mp; mp = mp->next)
   {
      ATL_cpnode_t *cp;
      int cpflag, ib, ia;
      char cpr = pre;
      char bn[4] = {'1', 'N', 'X', '0'};
      cpflag = (pre == 's' || pre == 'c') ? (1<<CPF_SINGLE) : 0;
      if (FLAG_IS_SET(mp->flag, MMF_COMPLEX))
         cpr = (pre == 's') ? 'c' : 'z';
      else
         cpflag |= 1 << CPF_REAL;
      switch(mp->blask)
      {
      case ATL_KSYRK:  /* SYRK needs C copies for all alpha,beta */
         cpflag |= (1<<CPF_SYRK) | (1<<CPF_CBLK);
         cp = GetCopyNodeFromMM(cpflag, mp, NULL);
/*
 *       Node for each (alpha,beta) case, ->rout=kern name
 */
         for (ib=0; ib < 4; ib++)
         {
            for (ia=0; ia < 3; ia++)
            {
               ATL_cpnode_t *p;
               p = CloneCPNode(cp);
               p->flag |= (1<<(CPF_BE1+ib))|(1<<(CPF_AL1+ia));
               p->rout = fnd;
               assert(p->rout);
               fn[4] = cpr;
               if (mp->mu == mp->nu)
               {
                  fn[5] = 's';
                  fn[6] = 'q';
               }
               else
               {
                  fn[5] = 'u';
                  fn[6] = 'm';
               }
               fn[18] = bn[ia];
               fn[20] = bn[ib];
               p->genstr = GetCopyGenStr(p);
               fn[21] = '\0';
               p->rout = DupString(fn);
               fn[21] = '.';
               p->next = cb;
               cb = p;
            }
         }
         KillCPNode(cp);
         break;
      default:
         fprintf(stderr, "UNKNOWN KERN TYPE %d!\n", mp->blask);
         assert(0);
      }
   }
   free(fnd);
   return(cb);
}

void GenSyrkPerfH(char pre, char *outd, ATL_mmnode_t *sq, ATL_mmnode_t *um)
{
   FILE *fp;
   
   fp = OpenMMGenHeader(outd, 0, pre, NULL, "amm", "syrkPerf", NULL);
   fprintf(fp, "   #define ATL_sqsyrkMF %e\n", sq->mflop[0]);
   if (um)
   {
      double syMF=*um->mflop, mmMF=um->mflop[1];
      fprintf(fp, "   #define ATL_umsyrkMF %e\n", syMF);
      fprintf(fp, "   #define ATL_umgemmMF %e\n", mmMF);
      fprintf(fp, "   #define ATL_umratio %f\n", syMF/mmMF);
   }
   CloseGenHeader(fp);
}
void GenSyrkH(char pre, char *outd, ATL_mmnode_t *mb, unsigned int bv)
/*
 * Generate syrk-specific header file
 */
{
   ATL_cpnode_t *cb;
   FILE *fp;
   const int RCSAME=bv&1, UM=bv&2;
   const int ntr = (pre == 'd' || pre == 's') ? 2 : 4;
   const char *sh = (UM) ? "um" : "sq";
   const char *SH = (UM) ? "UM" : "SQ";
   const char *ums = (UM) ? "UM":"";
   int ial, ibe, itr, flg;
   const char be[3] = {'0', '1', 'n'};
   char bes[4] = {'1', 'N', 'X', '0'};
   char trs[4] = {'N', 'T', 'C', 'H'};
   char rcs[4] = {'c', 'r', 'c', 'r'};
   char cjs[4] = {' ', ' ', 'C', 'C'};
   char *sfx[2] = {"", "_L2UT"};
   char *hfx[2] = {"", "_L2UH"};


   if (!mb)
      return;
   fp = OpenMMGenHeader(outd, 0, pre, NULL, "amm", UM?"umsyrk":"sqsyrk", NULL);
   fprintf(fp, "#define ATL_%sSYRKK_VLEN %d\n", SH, mb->vlen);
   fprintf(fp, "#define ATL_%sSYRKK_KVEC %d\n", SH,
           FLAG_IS_SET(mb->flag, MMF_KVEC) ? mb->vlen:0);
   if (UM)
      fprintf(fp, "#define ATL_%sSYRKK_MU %d\n", SH, mb->mu);
   fprintf(fp, "#define ATL_%sSYRKK_NU %d\n", SH, mb->nu);
   fprintf(fp, "#define ATL_%sSYRKK_KU %d\n", SH, mb->ku);

   fprintf(fp, "/*\n * Generic names for syrk info\n */\n");
   @whiledef mn VLEN KVEC NU KU
   fprintf(fp, "#ifndef ATL_SYRKK_@(mn)\n  #define ATL_SYRKK_@(mn) "
           "ATL_%sSYRKK_@(mn)\n#endif\n", SH);
   @endwhile
   fprintf(fp, "#ifndef ATL_SYRKK_MU\n  #define ATL_SYRKK_MU "
           "ATL_%sSYRKK_%s\n#endif\n", SH, UM?"MU":"NU");
/*
 * Prototype ATL_<pre>_[sq,um]syrkK kernel
 */
   if (RCSAME && (pre == 'c' || pre == 'z'))
   {
      const char upr = (pre == 'z') ? 'd' : 's';
      for (ibe=0; ibe < 3; ibe++)
      {
         fprintf(fp, "#define ATL_%c%ssyrkK_b%c ATL_%c%ssyrkK_b%c\n",
                 pre, sh, be[ibe], upr, sh, be[ibe]);
      }
   }
   for (ibe=0; ibe < 3; ibe++)
   {
      fprintf(fp,
"void ATL_%c%ssyrkK_b%c(ATL_CSZT,ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,\n",
              pre, sh, be[ibe]);
      fprintf(fp,
      "                     TYPE*, const TYPE*, const TYPE*, const TYPE*);\n");
      fprintf(fp, "#ifndef ATL_%camsyrkK_b%c\n   "
                  "#define ATL_%camsyrkK_b%c ATL_%c%ssyrkK_b%c\n#endif\n", 
               pre, be[ibe], pre, be[ibe], pre, sh, be[ibe]);
   }
/*
 * Prototype/rename all A cpy routs: ATL_<pre>cm2am_syrk<TA>
 * UM case uses gemm's A/B copy, so no need for UM
 */
   if (!UM)
   {
      flg = (1<<CPF_TOBLK)|(1<<CPF_AL1);
      flg |= (pre == 'd' || pre == 's') ? (1<<CPF_REAL):0;
      flg |= (pre == 'c' || pre == 's') ? (1<<CPF_SINGLE):0;
      cb = GetCopyNodeFromMM(flg, mb, NULL);
      cb->rout = GetCopyName(cb, 0);
      fprintf(fp, "#define ATL_%ca2blk_%ssyrkN %s\n",
              pre, sh, cb->rout);
      free(cb->rout);
      cb->flag |= 1<<CPF_TRANS;
      cb->rout = GetCopyName(cb, 0);
      fprintf(fp, "#define ATL_%ca2blk_%ssyrkT %s\n",
              pre, sh, cb->rout);
      KillAllCopyNodes(cb);
      for (itr=0; itr < 2; itr++)
      {
         char tr = itr ? 'T' : 'N';
         fprintf(fp, "void ATL_%ca2blk_%ssyrk%c", pre, sh, tr);
         if (pre == 'd' || pre == 's')
            fprintf(fp,
            "(ATL_CSZT,ATL_CSZT,const TYPE,const TYPE*,ATL_CSZT,TYPE*);\n");
         else
            fprintf(fp, "(ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,"
                        "ATL_CSZT,TYPE*,TYPE*);\n");
         fprintf(fp, "#ifndef ATL_%ca2blk_syrk%c\n   #define "
         "ATL_%ca2blk_syrk%c ATL_%ca2blk_%ssyrk%c\n#endif\n",
            pre, tr,  pre, tr,  pre, sh, tr);
      }
   }
/*
 * Prototype all C cpy routs: ATL_<pre>[sq,um]SyrkIntoC_a<alp>_b<bet>
 */
   for (ial=0; ial < 3; ial++)
   {
      for (ibe=0; ibe < 4; ibe++)
      {
         int is;
         for (is=0; is < 2; is++)
         {
            fprintf(fp, "#ifdef Conj_\n");
            fprintf(fp, "#define ATL_%c%sSyrkIntoC_a%cb%c%s "
                    "ATL_%c%sHerkIntoC_a%cb%c%s\n", 
                     pre, sh, bes[ial], bes[ibe], sfx[is],
                     pre, sh, bes[ial], bes[ibe], hfx[is]);
            fprintf(fp, "#endif\n");
            fprintf(fp, "void ATL_%c%sSyrkIntoC_a%cb%c%s\n", pre, sh, bes[ial],
                    bes[ibe], sfx[is]);
            if (pre == 's' || pre == 'd')
               fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const SCALAR, TYPE *,ATL_CSZT);\n");
            else
               fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,"
                       "const TYPE*,const SCALAR, TYPE *,ATL_CSZT);\n");

            fprintf(fp, "#ifndef ATL_%cSyrkIntoC_a%cb%c%s\n   #define "
            "ATL_%cSyrkIntoC_a%cb%c%s ATL_%c%sSyrkIntoC_a%cb%c%s\n#endif\n",  
               pre, bes[ial], bes[ibe], sfx[is],
               pre, bes[ial], bes[ibe], sfx[is],
               pre, sh, bes[ial], bes[ibe], sfx[is]);
         }
      }
   }
   
   CloseGenHeader(fp);
}

void PrintUsage(char *name, int ierr, char *flag)
{
   fprintf(stderr,
"This routine creates master list of kernel IDs to use, and generates them.\n"
"It expects all input kerns in [s,d]FNLK1.sum, with K-cleaners in ivar.\n");
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);

   fprintf(stderr,"USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -b <blasK.sum>: non-gemm kerns file; can be repeated\n");
@skip   fprintf(stderr, "   -i : input sumfile (stdin); can be repeated\n");
   fprintf(stderr, "   -o <path>: what directory to output all files to?\n");
   fprintf(stderr, "   -p [s,d]: set type/precision prefix (d) \n"
           "      s/d will generate for complex (c/z) as well\n");

   exit(ierr ? ierr : -1);
}

ATL_mmnode_t *GetFlags
   (int nargs, char **args, char *PRE, char **OUTD, ATL_mmnode_t **BKB)
{
   FILE *fpin=stdin;
   ATL_mmnode_t *mb=NULL, *bkb=NULL, *mp;
   char *outd=NULL;
   int i;
   char pre='d';

   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        if (pre == 'z')
           pre = 'd';
        else if (pre == 'c')
           pre = 's';
        break;
      case 'o':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         outd = DupString(args[i]); 
         break;
      case 'i':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         if (mb)
            KillAllMMNodes(mb);
         mb = ReadMMFile(args[i]);
@beginskip
         mp = ReadMMFile(args[i]);
         assert(mp);
         mb = AddUniqueMMKernCompList(mb, mp);
         KillAllMMNodes(mp);
@endskip
         break;
      case 'b': /* -b <blasK.sum> */
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         mp = ReadMMFile(args[i]);
         assert(mp);
         bkb = ATL_JoinMMQs(bkb, mp);
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (!mb)
   {
      mb = ReadMMFileWithPath(pre, "res", "FNLK1.sum");
      assert(mb);
   }
   if (!outd)
      outd = DupString("tmp");

   *BKB = bkb;
   *OUTD = outd;
   *PRE = pre;
   return(mb);
}

int numBitsNeeded(int N)
{
   int i;
   if (N <= 0)
      return(0);
   for (i=0; (1<<i) <= N; i++);
   return(i);
}
#define NFLGBITS 2  /* KRUNTIME, KMAJOR */
#define NIVAR 8
int *getBitsNeeded(ATL_mmnode_t *mb, int *NINT)
/*
 * 1st NIVAR entries has number of bits required after subtracting MINVALs
 * which are stoted in 2nd NIVAR entries 
 */
{
   ATL_mmnode_t *mp;
   unsigned int cnt=1, i, nint, nbits, pbits;
   static unsigned int ib[NIVAR*2];

   assert(mb);
   ib[0] = NFLGBITS;
   ib[NIVAR] = 0;
   @iexp iv 1
   @whiledef vv ivar kbmax kbmin vlen ku nu mu
   ib[@(iv)] = ib[@(iv)+NIVAR] = mb->@(vv);
         @iexp iv @(iv) 1 +
   @endwhile
   for (mp=mb->next; mp; mp=mp->next)
   {
      cnt++;
      @iexp iv 1
      @whiledef vv ivar kbmax kbmin vlen ku nu mu
      ib[@(iv)] = Mmax(ib[@(iv)],mp->@(vv));
      ib[@(iv)+NIVAR] = Mmin(ib[@(iv)+NIVAR],mp->@(vv));
         @iexp iv @(iv) 1 +
      @endwhile
   }
   nint=1;
   nbits = NFLGBITS;
   pbits = ATL_PSIZE<<3;
   for (i=1; i < NIVAR; i++)
   {
      int bits;
      ib[i] = bits = numBitsNeeded(ib[i]-ib[i+NIVAR]);
      nbits += bits;
      if (nbits > pbits) /* not enough room left in int */
      {
         nbits = bits;
         nint++;
      }
   }
   assert(nint <= 3);
   *NINT = nint;
   return(ib);
}

int PrintIntsHex(FILE *fp, ATL_mmnode_t *mp, int nint, int *nbits)
/* RETURNS: flag stored */
{
   ATL_iptr_t ib, ish;
   int flag;

   ib = FLAG_IS_SET(mp->flag, MMF_KRUNTIME);
   ib |= FLAG_IS_SET(mp->flag, MMF_KVEC) ? 2 : 0;
   flag = ib;
   ish = nbits[0];
   @iexp iv 1
   @whiledef vv ivar kbmax kbmin vlen ku nu mu
   if (ish+nbits[@(iv)] > ATL_PSIZE*8)
   {
      fprintf(fp, ", 0x%lxL", ib);
      ib = ish = 0;
   }
   ib |= ((ATL_iptr_t)(mp->@(vv)-nbits[@(iv)+NIVAR])) << ish;
   ish += nbits[@(iv)];
      @iexp iv @(iv) 1 +
   @endwhile
   if (ish)
      fprintf(fp, ", 0x%lxL", ib);
   return(flag);
}

void GenKernArr(char pre, char *outd, ATL_mmnode_t *mb)
{
   FILE *fpout;
   ATL_mmnode_t *mp;
   char *VN[8]={"FLAG", "MU", "NU", "KU", "VLEN", "KBMIN", "KBMAX","K1IDX"};
   unsigned int *nbits;
   unsigned int k, i, nint, N, nkvec;
   ATL_iptr_t ibt;

   assert(sizeof(ATL_iptr_t) == ATL_psize);
   N = ATL_CountNumberOfMMNodes(mb);
   fpout = OpenMMGenHeader(outd, 0, pre, "amm", NULL, "kern", mb);
   fprintf(fpout, "#include \"atlas_%camm_proto.h\"\n\n", pre);

   nbits = getBitsNeeded(mb, &nint);
   k = nint + 3;
   fprintf(fpout, "#define ATL_ENTRYN %u\n", k);
   for (i=0; i < 32 && !((1<<i)&k); i++);
   if (k^(1<<i) == 0)
      fprintf(fpout, "#define ATL_AMM_Idx2Entry(i_) ((i_)<<%u)\n", i);
   else if (k == 5)
      fprintf(fpout, "#define ATL_AMM_Idx2Entry(i_) (((i_)<<2)+(i_))\n");
   else if (k == 6)
      fprintf(fpout, "#define ATL_AMM_Idx2Entry(i_) (((i_)<<2)+((i_)<<1))\n");
   else
      fprintf(fpout, "#define ATL_AMM_Idx2Entry(i_) ((i_)*%u)\n", k);
   fprintf(fpout, "#define ATL_NINTPACK %u\n\n", nint);
   for (i=0; i < NIVAR; i++)
   {
      fprintf(fpout, "#define ATL_AMM_MIN_%s  %u\n", VN[i], nbits[i+NIVAR]);
      fprintf(fpout, "#define ATL_AMM_NBIT_%s %u\n", VN[i], nbits[i]);
   }
   fprintf(fpout, "\n");
   fprintf(fpout, "#define ATL_AMM_ML ATL_%cAMM_ML\n", pre);
   fprintf(fpout, 
           "#ifndef ATL_DECL_\n   extern const ATL_iptr_t ATL_AMM_ML[%u];\n",
           N*(3+nint));
   fprintf(fpout, "#else\nconst ATL_iptr_t ATL_AMM_ML[%u]=\n{\n", N*(3+nint));

   mp = mb;
   fprintf(fpout, "(ATL_iptr_t)%s_b1,\n(ATL_iptr_t)%s_b0,\n(ATL_iptr_t)%s_bn\n",
           mp->auth, mp->auth, mp->auth);
   i = PrintIntsHex(fpout, mp, nint, nbits);
   fprintf(fpout, "/* %2u: FL=%x, U=(%u,%u,%u), VL=%u, KB=(%u,%u) KclnI=%d */",
           0, i, mp->mu, mp->nu, mp->ku, mp->vlen, mp->kbmin, mp->kbmax, 
           mp->ivar-1);
   nkvec = FLAG_IS_SET(mp->flag, MMF_KVEC);
   for (i=1,mp=mb->next; mp; mp = mp->next, i++)
   {
      fprintf(fpout, 
              ",\n(ATL_iptr_t)%s_b1,\n(ATL_iptr_t)%s_b0,\n(ATL_iptr_t)%s_bn\n",
              mp->auth, mp->auth, mp->auth);
      k = PrintIntsHex(fpout, mp, nint, nbits);
      fprintf(fpout, 
              "/* %2u: FL=%x, U=(%u,%u,%u), VL=%u, KB=(%u,%u), KclnI=%d */",
              i, k, mp->mu, mp->nu, mp->ku, mp->vlen, mp->kbmin, mp->kbmax, 
              mp->ivar-1);
      nkvec += FLAG_IS_SET(mp->flag, MMF_KVEC);
   }
   fprintf(fpout, "\n};\n#endif /* end else of ATL_DECL */\n\n");


   if (nbits[3] == 0)
      fprintf(fpout, "#define ATL_AMM_GetKU(idx_) ATL_AMM_MIN_KU\n");
   else
   {
      fprintf(fpout, "#define ATL_AMM_GetKU(idx_) \\\n");
      if (nbits[0]+nbits[1]+nbits[2]+nbits[3] <= sizeof(ATL_iptr_t)*8)
         fprintf(fpout, 
                 "   ((((ATL_AMM_ML[ATL_AMM_Idx2Entry(idx_)+3])>>%u)&0x%x)",
                 nbits[0]+nbits[1]+nbits[2], (1<<(nbits[3]))-1);
      else
      {
         assert(nbits[0]+nbits[1]+nbits[2] <= sizeof(ATL_iptr_t)*8);
         fprintf(fpout, "   (((ATL_AMM_ML[ATL_AMM_Idx2Entry(idx_)+4])&0x%x)",
                 (1<<(nbits[3]))-1);
      }
      if (nbits[3+NIVAR])
         fprintf(fpout, "+ATL_AMM_MIN_KU)\n");
      else
         fprintf(fpout, ")\n");
   }
   fprintf(fpout, "#define ATL_AMM_GetMNU(idx_, MU_, NU_) \\\n{\\\n");
   fprintf(fpout, 
      "   ATL_iptr_t v_ = (ATL_AMM_ML[ATL_AMM_Idx2Entry(idx_)+3])>>%u; \\\n",
            nbits[0]);
   if (nbits[1])
   {
      fprintf(fpout, "   MU_ = ATL_AMM_MIN_MU + (v_ & 0x%x); \\\n", 
              (1<<nbits[1])-1);
      fprintf(fpout, "   v_ >>= %u; \\\n", nbits[1]);
   }
   else
      fprintf(fpout, "   MU_ = ATL_AMM_MIN_MU; \\\n");
   if (nbits[2])
      fprintf(fpout, "   NU_ = ATL_AMM_MIN_NU + (v_ & 0x%x); \\\n", 
              (1<<nbits[2])-1);
   else
      fprintf(fpout, "   NU_ = ATL_AMM_MIN_NU; \\\n");
   fprintf(fpout, "}\n\n");

   fprintf(fpout, "#define ATL_AMM_iinfo(ia_,FLAG_,MU_,NU_,KU_,VLEN_,"
                  "KBMIN_,KBMAX_,K1IDX_) \\\n");
   fprintf(fpout, "{ \\\n   ATL_iptr_t v_ = *(ia_); \\\n");
   for (nint=k=i=0; i < 8; i++)
   {
      int nb=nbits[i];
      if (nb)
      {
         if (k + nb > ATL_PSIZE*8)
         {
            fprintf(fpout, "   v_ = (ia_)[%u]; \\\n", ++nint);
            k = 0;
         }
         if (nbits[i+NIVAR])
            fprintf(fpout, "   %s_ = ATL_AMM_MIN_%s + (v_&0x%x); \\\n", 
                    VN[i], VN[i], (1<<nb)-1);
         else
            fprintf(fpout, "   %s_ = v_ & 0x%x; \\\n", VN[i], (1<<nb)-1);
         if (i != 7)
            fprintf(fpout, "   v_ >>= %u; \\\n", nb);
      }
      else
         fprintf(fpout, "   %s_ = ATL_AMM_MIN_%s; \\\n", VN[i], VN[i]);
   }
   fprintf(fpout, "} /* end ATL_AMM_iinfo definition */\n");

   fprintf(fpout, "\n#define ATL_AMM_kinfo(id_, mm0_, mm1_, mmN_) \\\n");
   fprintf(fpout, "{ \\\n   const ATL_iptr_t *ip_=ATL_AMM_ML + "
                  "ATL_AMM_Idx2Entry(id_); \\\n");
   fprintf(fpout, "   *((ATL_iptr_t*)(mm1_)) = *ip_; \\\n");
   fprintf(fpout, "   *((ATL_iptr_t*)(mm0_)) = ip_[1]; \\\n");
   fprintf(fpout, "   *((ATL_iptr_t*)(mmN_)) = ip_[2]; \\\n");
   fprintf(fpout, "} /* end ATL_AMM_kinfo definition */\n");

   fprintf(fpout, "\n#define ATL_AMM_info(id_,mm0_, mm1_, mmN_,FLAG_,"
                  "MU_,NU_,KU_,VLEN_,KBMIN_,KBMAX_,K1IDX_) \\\n");
   fprintf(fpout, "{ \\\n   const ATL_iptr_t *ip_=ATL_AMM_ML + "
                  "ATL_AMM_Idx2Entry(id_); \\\n");
   fprintf(fpout, "   *((ATL_iptr_t*)(mm1_)) = *ip_; \\\n");
   fprintf(fpout, "   *((ATL_iptr_t*)(mm0_)) = ip_[1]; \\\n");
   fprintf(fpout, "   *((ATL_iptr_t*)(mmN_)) = ip_[2]; \\\n");
   fprintf(fpout, "   ATL_AMM_iinfo(ip_+3,FLAG_,MU_,NU_,KU_,VLEN_,"
                  "KBMIN_,KBMAX_,K1IDX_); \\\n");
   fprintf(fpout, "} /* end ATL_AMM_info definition */\n");
   
   fprintf(fpout, 
           "/*\n * Following macros return 1 if flag set, else 0\n */\n");
   fprintf(fpout, "#define ATL_AMM_KRUNTIME(flg_) ((flg_)&1)\n");
   fprintf(fpout, "#define ATL_AMM_KMAJOR(flg_) (((flg_)>>1)&1)\n");
   CloseGenHeader(fpout);
}
/*
 * generate:
 * ATL_AmmKernbyIdx(idx_, k0_,k1_,kn_, cpidx, flg_, vlen_, mu_, nu_, ku_, 
 *                  kbmin_, kbmax_)
 */
void GenKernInf(ATL_mmnode_t *mb)
{
   ATL_mmnode_t *mp;
   FILE *fpout=NULL;
   unsigned int MAXs[8];
   char *nms[8] = {"flg", "vlen", "mu", "nu", "ku", "kbmin", "kbmax"};
   unsigned int MU, NU, KU, VLEN, KBMAX, KBMIN, KCleanIdx;
   unsigned int nbits, pbits, nint, iv, i;

   assert(mb);
   MAXs[0] = NFLGBITS;
   @iexp iv 1
   @whiledef vv kbmax kbmin vlen ku nu mu
   MAXs[@(iv)] = mb->@(vv);
         @iexp iv @(iv) 1 +
   @endwhile
   for (mp=mb->next; mp; mp=mp->next)
   {
      @iexp iv 0
      @whiledef vv kbmax kbmin vlen ku nu mu
      MAXs[@(iv)] = Mmax(MAXs[@(iv)],mp->@(vv));
         @iexp iv @(iv) 1 +
      @endwhile
   }
   nint=1;
   nbits = NFLGBITS;
   pbits = ATL_PSIZE<<3;
   for (i=1; i < 7; i++)
   {
      int bits;
      MAXs[i] = bits = numBitsNeeded(MAXs[i]);
      nbits += bits;
      if (nbits > pbits) /* not enough room left in int */
      {
         nbits = bits;
         nint++;
      }
   }
   assert(nint <= 3);
   fprintf(fpout, "ATL_AmmKernbyIdx(idx_, k0_, k1_, kn_, flg_, vlen_, "
           "mu_, nu_, ku_, kbmin_, kbmax_)\\\n{\\\n");
   if (nint = 1)
      fprintf(fpout, "const ATL_iptr_t id_=(idx_)<<1; \\\n");
   else if (nint = 2)
      fprintf(fpout, "const ATL_iptr_t id_=(idx_)+((idx_)<<1);\\\n");
   else if (nint = 3)
      fprintf(fpout, "const ATL_iptr_t id_=(idx_)<<2;\\\n");
   fprintf(fpout, "ATL_iptr_t bits_;\\\n");
   fprintf(fpout, "   (k0_) = (void*) (ATL_AMM_KERN[id_]);\n");
   fprintf(fpout, "   (k1_) = (void*) (ATL_AMM_KERN[id_+1]);\n");
   fprintf(fpout, "   (kn_) = (void*) (ATL_AMM_KERN[id_+2]);\n");
   fprintf(fpout, "   bits_ = ATL_AMM_KERN[id_+3];\\\n");
   fprintf(fpout, "   flg_ = bits_ & 0x%x;\\\n", 1<<(NFLGBITS+1)-1);
   nbits = NFLGBITS;
   nint=3;
   for (i=1; i < 7; i++)
   {
      int bits = MAXs[iv];
      if (nbits + bits > pbits)
      {
         fprintf(fpout, "bits_ = ATL_AMM_KERN[id_+%d];\\\n", ++nint);
         nbits = 0;
      }
      if (!nbits)
         fprintf(fpout, "   %s_ = bits_ & 0x%x;\\\n", nms[i], (1<<(bits+1))-1);
      else
         fprintf(fpout, "   %s_ = ((bits_)>>%u) & 0x%x;\\\n", nms[i], 
                 nbits, (1<<(bits+1))-1);
      nbits += bits;
   }
   fprintf(fpout, "} /* end ATL_AmmKernByIdx macro def */\n");
}

void GenKerns(char pre, char *outd, ATL_mmnode_t *mb, ATL_mmnode_t *bkb,
              ATL_cpnode_t *cb)
{
   ATL_mmnode_t *ub, *mp;
   ATL_cpnode_t *cp;
   char *sgen=NULL;
   int i, len, dlen;
   char pr=pre;

   dlen = strlen(outd);
   len = 0;
/*
 * mb has unique compilations, reduce this to unique files, and then generate
 */
   ub = AddUniquePerfMMKernsToList(NULL, mb);
   ub = AddUniquePerfMMKernsToList(ub, bkb);
/*
 * Generate/copy all required kernels. 
 */
   printf("\nGENERATING AMM KERNS:\n");
   for (cp=cb; cp; cp=cp->next)
   {
      if ( (i=system(cp->genstr)) )
      {
         fprintf(stderr, "GENSTR RETURNS %d:\n'%s'\n", i, cp->genstr);
         exit(i);
      }
   }
   for (mp=ub; mp; mp = mp->next)
   {
      const int id=mp->ID;
      if (!id)
      {
         printf("   -> %s\n", mp->rout);
         assert(mp->genstr);
         if ( (i=system(mp->genstr)) )
         {
            fprintf(stderr, "GENSTR RETURNS %d:\n'%s'\n", i, mp->genstr);
            exit(i);
         }
      }
      else /* user-supplied kernel */
      {
         ATL_mmnode_t *p;
         printf("   %s -> %s\n", mp->genstr, mp->rout);
         i = strlen(mp->genstr) + strlen(mp->rout) + dlen + 16;
         if (i > len)
         {
            if (sgen)
               free(sgen);
            sgen = malloc(i*sizeof(char));
            assert(sgen);
            len = i;
         }
         sprintf(sgen, "cp AMMCASES/%s %s/%s", mp->genstr, outd, mp->rout);

         if ( (i=system(sgen)) )
         {
            fprintf(stderr, "FAILED CP='%s'\n", sgen);
            exit(i);
         }
      }
   }
   printf("DONE GENERATING AMM KERNS.\n");
   free(sgen);
   KillAllMMNodes(ub);
}

void GenMake(char pre, char *outd, ATL_mmnode_t *mb, ATL_mmnode_t *bkb,
             ATL_cpnode_t *cb)
/*
 * mb files have already been made at least compile-time unique (same source
 * file might occur multiple times due to need to compile with -DKB)
 */
{
   FILE *fp;
   char *fn;
   ATL_mmnode_t *mp, *MB;
   ATL_cpnode_t *cp;
   char *sals[3] = {"1", "N1", "X"};
   char als[3] = {'1', 'n', 'X'};
   char *sbes[4] = {"0", "1", "N1", "X"};
   char bes[4] = {'0', '1', 'n', 'X'};  /* use 1st 3 for mmkerns */
   char ctas[4] = {'N', 'T', 'C', 'H'};
   char dcomp[8] = {'$', '(', 'D', 'M', 'C', ')', '\0'};
   char dflags[12] = {'$','(','D','M','C','F','L','A','G','S',')','\0'};


   MB = AddUniqueMMKernCompList(NULL, mb);
   MB = ATL_JoinMMQs(MB, bkb);
   fn = malloc(strlen(outd)+11);
   assert(fn);
   sprintf(fn, "%s/%cMake_amm", outd, pre);
   fp = fopen(fn, "w");
   assert(fp);
   free(fn);
   fprintf(fp, "include ../Make.inc\n");
   fprintf(fp, "CDEFS2=$(CDEFS)\n\n");
/*
 * Spew out kernels to be compiled
 */
   fprintf(fp, "objs =");
   for (mp=MB; mp; mp = mp->next)
   {
      int ib;
      for (ib=0; ib < 3; ib++)
         fprintf(fp, " \\\n       %s_b%c.o", mp->auth, bes[ib]);
   }
   for (cp=cb; cp; cp = cp->next)
   {
      char *sp;
      fprintf(fp, " \\\n       %s.o", cp->rout);
      sp = strstr(cp->rout, "SyrkIntoC");
      if (sp)
      {
         char pre = sp[-3];
         if (pre == 'z' || pre == 'c')
         {
            sp[0] = '\0'; 
            fprintf(fp, " \\\n       %sHerk%s.o", cp->rout, sp+4);
            sp[0] = 'S';
         }
      }
   }
   fprintf(fp, "\n");
/*
 * library make targets
 */
   fprintf(fp, "\n\nlib : %clib.grd\nall : %clib.grd\n%clib : %clib.grd\n",
           pre, pre, pre, pre);
   fprintf(fp, "%clib.grd : $(objs)\n", pre);
   fprintf(fp, "\t$(ARCHIVER) $(ARFLAGS) $(ATLASlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(ATLASlib)\n");
   fprintf(fp, "\t touch %clib.grd\n", pre);
   fprintf(fp, "clean : %cclean\n", pre);
   fprintf(fp, "%cclean:\n\t- rm -f $(objs)\n", pre);
   fprintf(fp, "killall : %ckillall\n", pre);
   fprintf(fp, "%ckillall : %cclean\n", pre, pre);
   fprintf(fp, "\t- $(ARCHIVER) d $(ATLASlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(ATLASlib)\n");
   fprintf(fp, "\t- rm -f ATL_%c*.[S,c]\n\n", pre);
/*
 * Make targets for amm kerns
 */
   fprintf(fp, "#\n#  AMM kernel rules\n#\n");
   fn = (pre == 'd' || pre == 'z') ?  "-DDREAL=1" : "-DSREAL";
   for (mp=MB; mp; mp = mp->next)
   {
      int ib;
      char *comp, *flgs;

      comp = GetMMKernComp(mp, dcomp, dflags, &flgs);
      for (ib=0; ib < 3; ib++)
      {
         char *sp=" ";
         fprintf(fp, "%s_b%c.o : %s\n", mp->auth, bes[ib], mp->rout);
         fprintf(fp, "\t%s $(CDEFS2) %s -DBETA%s=1 \\\n", comp, fn, sbes[ib]);
         if (!FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
            fprintf(fp, "        -DMB=%d -DNB=%d -DKB=%d",
                    mp->mbB, mp->nbB, ((mp->kbB+mp->ku-1)/mp->ku)*mp->ku);
         else
            sp = "        ";
         if (FLAG_IS_SET(mp->flag, MMF_MVA))
         {
            fprintf(fp, "%s-DATL_MOVEA", sp);
            sp = " ";
         }
         if (FLAG_IS_SET(mp->flag, MMF_MVB))
         {
            fprintf(fp, "%s-DATL_MOVEB", sp);
            sp = " ";
         }
         if (FLAG_IS_SET(mp->flag, MMF_MVC))
         {
            fprintf(fp, "%s-DATL_MOVEC", sp);
            sp = " ";
         }
         fprintf(fp, " \\\n        %s \\\n", flgs);
         fprintf(fp,
                 "        -DATL_USERMM=%s_b%c \\\n        -c -o %s_b%c.o \\\n",
                 mp->auth, bes[ib], mp->auth, bes[ib]);
         fprintf(fp, "        %s\n", mp->rout);
      }
   }
   fprintf(fp, "#\n#  non-AMM kernel copy rules\n#\n");
   for (cp=cb; cp; cp = cp->next)
   {
      char *ts;
      if (pre == 'd')
        ts = (cp->flag & (1<<CPF_REAL)) ? "DREAL" : "DCPLX";
      else
        ts = (cp->flag & (1<<CPF_REAL)) ? "SREAL" : "SCPLX";
      fprintf(fp, "%s.o : %s.c\n", cp->rout, cp->rout);
      fprintf(fp, "\t$(KC) $(CDEFS2) -D%s=1 -DATL_USERCPMM=%s $(KCFLAGS) \\\n",
              ts, cp->rout);
      fprintf(fp, "        -c %s.c\n", cp->rout);
      if (!(cp->flag & (1<<CPF_REAL)))
      {
         char *sp;
         sp = strstr(cp->rout, "SyrkIntoC");
         if (sp);
         {
            sp[0]='\0';
            fprintf(fp, "%sHerk%s.o : %sSyrk%s.c\n", cp->rout, sp+4, 
                    cp->rout, sp+4);
            if (pre == 'd')
               ts = "-DDCPLX=1 -DConj_=1";
            else
               ts = "-DSCPLX=1 -DConj_=1";
            fprintf(fp, 
            "\t$(KC) $(CDEFS2) %s -DATL_USERCPMM=%sHerk%s \\\n",
                    ts, cp->rout, sp+4);
            fprintf(fp, "        $(KCFLAGS) -o $@ -c %sSyrk%s.c\n", 
                    cp->rout, sp+4);
            sp[0]='S';
         }
      }
   }
   KillAllMMNodes(MB);
   fclose(fp);
}

@BEGINSKIP
void GetUnrolls(ATL_mmnode_t *mb, int *NMU, int **MUS, int *NNU, int **NUS)
{
   ATL_mmnode_t *mp;
   int *mus, *nus, nmu=0, nnu=0;
   int N;

   N = ATL_CountNumberOfMMNodes(mb);
   mus = malloc(2*N*sizeof(int));
   assert(mus);
   nus = mus + N;
   for (mp=mb; mp; mp = mp->next)
   {
      int i, U;
      U = mp->mu;
      for (i=0; i < nmu; i++)
         if (mus[i] == U)
            break;
      if (i == nmu)
         mus[nmu++] = U;
      U = mp->nu;
      for (i=0; i < nnu; i++)
         if (nus[i] == U)
            break;
      if (i == nnu)
         nus[nnu++] = U;
   }
   *NMU = nmu;
   *NNU = nnu;
   *MUS = malloc(nmu*sizeof(int));
   assert(*MUS);
   memcpy(*MUS, mus, nmu*sizeof(int));
   *NUS = malloc(nnu*sizeof(int));
   assert(*NUS);
   memcpy(*NUS, nus, nnu*sizeof(int));
   free(mus);
}
@ENDSKIP

void GenTrsmALLT(char pre, char *outd, char sd, ATL_mmnode_t *mb)
{
   char *of;
   FILE *fp;
   ATL_mmnode_t *mp;
   unsigned long long flg=0;
   int k, L, n;
   L = strlen(outd) + 24;
   of = malloc(L);
   assert(of);

   for (n=0, mp=mb; mp; n++, mp=mp->next)
   {
      if (mp->TA == AtlasTrans && mp->TB == AtlasTrans)
         flg |= (1L<<n);
   }
   assert((sizeof(long)<<3) >= n);
   k = sprintf(of, "%s/atlas_%ctrsm%cLN_ALLT.h", outd, pre, sd);
   assert(k<L);
   fp = fopen(of, "w");
   assert(fp);
   fprintf(fp, "#ifndef ATLAS_%cTRSM%cLN_ALLT_H\n", 
           toupper(pre), toupper(sd));
   fprintf(fp, "   #define ATLAS_%cTRSM%cLN_ALLT_H 1\n", 
           toupper(pre), toupper(sd));
   fprintf(fp, "   #define ATL_trsm_allT(i_) ((0x%lxL>>(i_))&1)\n", flg);
   fprintf(fp, "#endif /* end multiple inclusion guard */\n");
   fclose(fp);
   free(of);
}

ATL_mmnode_t *GenAllSyrkH(char pre, char *outd, ATL_mmnode_t **BKB)
{
   ATL_mmnode_t *rp, *cp, *rU, *cU, *ret, *bkb=(*BKB);
   unsigned int bv;
   char cpr = (pre == 's') ? 'c' : 'z';

   for (bv=0,ret=bkb; ret && ret->blask == ATL_KSYRK; ret = ret->next, bv++);
   assert(bv == 2 || bv == 4);
   for (rp=bkb; rp && (rp->mu != rp->nu); rp = rp->next);
   assert(rp);
   assert(rp->blask == ATL_KSYRK);
   for (cp=rp->next; cp && (cp->mu != cp->nu); cp = cp->next);
   assert(cp);
   assert(cp->blask == ATL_KSYRK);
   for (rU=bkb; rU && (rU->mu == rU->nu); rU = rU->next);
   assert(rU);
   if (rU)
   {
      for (cU=rU->next; cU && (cU->mu == cU->nu); cU = cU->next);
      assert(cU);
      if (FLAG_IS_SET(rU->flag, MMF_COMPLEX)) /* cplx first */
      {
         ATL_mmnode_t *tp;
         assert(!FLAG_IS_SET(cU->flag, MMF_COMPLEX));
         tp = cU;
         cU = rU;
         rU = tp;
      }
      else /* real first */
      {
         assert(FLAG_IS_SET(cU->flag, MMF_COMPLEX));
      }
   }
   else
      cU = NULL;
   if (FLAG_IS_SET(rp->flag, MMF_COMPLEX)) /* cplx first */
   {
      ATL_mmnode_t *tp;
      assert(!FLAG_IS_SET(cp->flag, MMF_COMPLEX));
      tp = cp;
      cp = rp;
      rp = tp;
   }
   else /* real first */
   {
      assert(FLAG_IS_SET(cp->flag, MMF_COMPLEX));
   }
   bv = MMKernsPerfSame(rp, cp);
   GenSyrkH(pre, outd, rp, bv);
   GenSyrkH(cpr, outd, cp, bv);
   GenSyrkPerfH(pre, outd, rp, rU);
   GenSyrkPerfH(cpr, outd, cp, cU);
   if (bv) /* if real & cplx same, take cplx out to avoid double compile */
   {
      bkb = RemoveMMNodeFromQ(bkb, cp);
      KillMMNode(cp);
   }
   if (rU)
   {
      unsigned int bvU;
      bvU = MMKernsPerfSame(rU, cU) | 2;
      GenSyrkH(pre, outd, rU, bvU);
      GenSyrkH(cpr, outd, cU, bvU);
      if (bvU & 1)
      {
         bkb = RemoveMMNodeFromQ(bkb, cU);
         KillMMNode(cU);
      }
   }
   *BKB = bkb;
   return(ret);
}

void GenAllFiles(char pre, char *outd, ATL_mmnode_t *mb, ATL_mmnode_t *bkb,
                 ATL_cpnode_t *cb)
{
   FILE *fpout;
   ATL_mmnode_t *mp;
   int ib, inxt, iaut;
   char bes[3] = {'0', '1', 'n'};
   char fn[24];

   mp = bkb;
   while (mp)
   {
      ATL_mmnode_t *nxt = mp->next;
      char cpr = (pre == 's') ? 'c' : 'z';
      switch(mp->blask)
      {
         ATL_mmnode_t *cp;
         int i;
/*
 *    For SYRK, we expect 4 kernels, with each pair being the real & complex
 *    versions of the same kernel, with the first pair being the mu=nu case
 *    used by pure inner-product and cases ip when diagonal C block's A are
 *    stored in different format than gemm's.  The second pair is for when
 *    ipmenUM is used for gemm.
 */
      case ATL_KSYRK:
         i = mp == bkb;
         nxt = GenAllSyrkH(pre, outd, &mp);
         bkb = (i) ? mp : bkb;
         break;
      default:
         assert(0);
      }
      mp =  nxt;
   }
   fpout = OpenMMGenHeader(outd, 0, pre, "amm", NULL, "proto", mb);
   assert(fpout);
   inxt = GetOffset(&mb->next, mb);
   iaut = GetOffset(&mb->auth, mb);
   for (ib=0; ib < 3; ib++)
      PrintMMProtos(fpout, pre, "KERN", mb, iaut, bes[ib]);
   CloseGenHeader(fpout);
   GenKerns(pre, outd, mb, bkb, cb);
   GenMake(pre, outd, mb, bkb, cb);
   GenKernArr(pre, outd, mb);
}

int main(int nargs, char **args)
{
   char pre;
   char *outd;
   ATL_mmnode_t *mb, *ub, *bkb;
   ATL_cpnode_t *cb=NULL;

   mb = GetFlags(nargs, args, &pre, &outd, &bkb);
/*
 * Prep file for generation.  Free present values, and replace with:
 * ->auth  : kernel name without _b[1,n,0] suffix
 * ->genstr: for ID=0: genstr, else user kernel name (came in ->rout)
 * ->rout  : correct present filename
 */
   PrepMMForGen(pre, outd, "amm", mb);
   if (bkb)
   {
      PrepMMForGen(pre, outd, "amm", bkb);
      bkb = SortListByIval_G2L(bkb, GetOffset(bkb, &bkb->next), 
                               GetOffset(bkb, &bkb->blask));
      cb = GetKernCopies(pre, outd, bkb);
   }
   GenAllFiles(pre, outd, mb, bkb, cb);

   free(outd);
   KillAllCPNodes(cb);
   KillAllMMNodes(mb);
   return(0);
}
@ROUT ATL_ipinfo `@define vwf @ipgen@`
@ROUT ATL_ipsyrkinfo ATL_ipmeninfo `@define vwf @ipmen@` 
@ROUT ATL_ipmekinfo `@define vwf @ipmek@` 
@ROUT ATL_ipnekinfo `@define vwf @ipnek@`
@ROUT ATL_opinfo ATL_ipinfo ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo ATL_opsyrkInfo ATL_opsyr2kInfo ATL_opsymmInfo
#include "atlas_cache.h"
#include "atlas_amm.h"
@ROUT ATL_ipinfo ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo 
#include Mstr(Mjoin(ATLAS_UPR,amm_kern.h))
#define  ATL_DECL_ 1
@ROUT ATL_ipmeninfo
#ifdef MUNUMUL_
   #include Mstr(Mjoin(ATLAS_PRE,@(vwf)UM_view.h))
   #define ipInfo Mjoin(PATL,ipmenUMInfo)
   #define ipPop  Mjoin(PATL,ipmenUMInfoPop)
   #define ATL_GetVW@(vwf)Info ATL_GetVW@(vwf)UMInfo 
#else
   #include Mstr(Mjoin(ATLAS_PRE,@(vwf)_view.h))
   #define ipInfo Mjoin(PATL,ipmenInfo)
   #define ipPop  Mjoin(PATL,ipmenInfoPop)
#endif
@ROUT ATL_ipinfo ATL_ipmekinfo ATL_ipnekinfo 
#include Mstr(Mjoin(ATLAS_PRE,@(vwf)_view.h))
@ROUT ATL_ipinfo ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo
#undef ATL_DECL_
@ROUT ATL_opsyrkInfo ATL_opsyr2kInfo
#define ATL_WANT_ILCM
#include "atlas_iopt.h"
@ROUT ATL_opinfo
#ifdef TREAL
   #define  ATL_DECL_ 1
#endif
@ROUT ATL_opinfo ATL_opsyrkInfo ATL_opsyr2kInfo ATL_opsymmInfo
#include Mstr(Mjoin(ATLAS_UPR,amm_kern.h))
@ROUT ATL_opinfo
#ifndef TREAL
   #define  ATL_DECL_ 1
#endif
@ROUT ATL_opinfo ATL_opsyrkInfo ATL_opsyr2kInfo ATL_opsymmInfo
#include Mstr(Mjoin(ATLAS_PRE,opgen_view.h))
@ROUT ATL_opsyr2kInfo
@whiledef be 0 1
#include Mstr(COPY/Mjoin(ATLAS_PRE,IntoCNg_a1b@(be).h))
@endwhile
@ROUT ATL_opsyrkInfo ATL_opsymmInfo
@whiledef be 0 1 N X
#include Mstr(COPY/Mjoin(ATLAS_PRE,IntoCNg_a1b@(be).h))
@endwhile
@ROUT ATL_opsymmInfo
#ifdef TCPLX
   #include Mstr(COPY/Mjoin(ATLAS_PRE,FromANg_aX.h))
   #include Mstr(COPY/Mjoin(ATLAS_PRE,FromATg_aX.h))
#endif
#include Mstr(COPY/Mjoin(ATLAS_PRE,FromATg_a1.h))
#include Mstr(COPY/Mjoin(ATLAS_PRE,FromANg_a1.h))
@ROUT ATL_opinfo ATL_ipinfo ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo ATL_opsyrkInfo ATL_opsyr2kInfo
@whiledef al 1 N X
   @whiledef ta N T
#include Mstr(COPY/Mjoin(ATLAS_PRE,FromA@(ta)g_a@(al).h))
   @endwhile
#ifdef TCPLX
   @whiledef ta C H
#include Mstr(COPY/Mjoin(ATLAS_PRE,FromA@(ta)g_a@(al).h))
   @endwhile
#endif
@ROUT ATL_opinfo ATL_ipinfo ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo 
   @whiledef be 0 1 N X
#include Mstr(COPY/Mjoin(ATLAS_PRE,IntoCNg_a@(al)b@(be).h))
   @endwhile
@ROUT ATL_opinfo ATL_ipinfo ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo ATL_opsyrkInfo ATL_opsyr2kInfo

@endwhile
@ROUT ATL_opinfo

void Mjoin(PATL,opinfo) /* pop opinfo_t using atlas_opgen_view K-3 idx */
   (opinfo_t *out, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta)
{
   ammkern_t amm1, amm0, ammN;
   ATL_cparr_t *cp = (ATL_cparr_t *)&out->a2blk;
   double spmfMM, spmfCP;
   size_t nfmblks, npmblks, nfnblks, npnblks;
   unsigned int icpA, icpB, icpC, imm, k, mu, nu, ku, vlen, flgK;
   unsigned int sz, nmu, nnu, pnmu, pnnu, mb, pmb, nb, pnb, MB, NB, kb;
   const unsigned int iv=K-3;
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      ATL_iptr_t iptmp;
      #define CONE ATL_rone
   #endif

   ATL_assert(iv < ATL_VWopgen_NCASES);
   ATL_GetVWopgenInfo(iv, spmfMM, MB, NB, k, imm, icpA, icpB, icpC, k, k, k);
   ATL_assert(imm < ATL_AMM_NCASES);
   icpA += icpA;
   icpB += icpB;
   icpC += icpC;
   #ifdef TCPLX
      ATL_AMM_info(imm, &out->amm_b0, &out->amm_b1, &out->amm_bn, flgK, 
                   mu, nu, ku, vlen, k, k, k);
   #else
      ATL_AMM_info(imm, &out->amm_b0, &iptmp, &iptmp, flgK, 
                   mu, nu, ku, vlen, k, k, k);
   #endif

   if (M > MB)
   {
      mb = MB;
      nfmblks = M / MB;
      nmu = MB / mu;
      out->mF = pmb = M - nfmblks*MB;
      pnmu = (pmb+mu-1)/mu;
      pmb = pnmu * mu;
      npmblks = (pmb) ? 1 : 0;
   }
   else
   {
      npmblks = 1;
      pnmu = nmu = (M+mu-1)/mu;
      pmb = mb = nmu * mu;
      nfmblks = 0;
      out->mF = M;
   }
   if (N > NB)
   {
      nb = NB;
      nfnblks = N / NB;
      nnu = NB / nu;
      out->nF = pnb = N - nfnblks*NB;
      pnnu = (pnb+nu-1)/nu;
      pnb = pnnu * nu;
      npnblks = (pnb) ? 1 : 0;
   }
   else
   {
      npnblks = 1;
      pnnu = nnu = (N+nu-1)/nu;
      pnb = nb = nnu * nu;
      nfnblks = 0;
      out->nF = N;
   }

   kb = ((K+ku-1)/ku)*ku;
   out->nfmblks = nfmblks;
   out->npmblks = npmblks;
   out->mb = mb;
   out->pmb = pmb;
   out->nfnblks = nfnblks;
   out->npnblks = npnblks;
   out->nb = nb;
   out->pnb = pnb;
   out->mu = mu;
   out->nu = nu;
   out->ku = ku;
   out->vlen = vlen;
   out->lda = lda;
   out->ldb = ldb;
   out->ldc = ldc;

   out->nmu = nmu;
   out->nmuF = out->pnmu = pnmu;
   out->nnu = nnu;
   out->nnuF = out->pnnu = pnnu;

   sz = ((mu*nu+vlen-1)/vlen)*vlen;
   sz *= (out->nmu) ? out->nmu : out->pnmu;
   sz *= (out->nnu) ? out->nnu : out->pnnu;
   out->szC = sz;
   out->exsz = (mu*nu)<<1;
   out->idx = iv;
   out->kb = K;
   out->KB = kb;
   out->lda = lda;
   out->ldb = ldb;
   out->ldc = ldc;
   out->pszA = pmb*kb;
   out->szA = kb * mb;
   out->pszB = kb*pnb;
   out->szB = kb * nb;
   if (vlen > 1)
   {
      @whiledef sz pszA pszB szA szB
      out->@(sz) = ((out->@(sz)+vlen-1)/vlen)*vlen;
      @endwhile
   }
   out->alpA = out->alpB = CONE;
   out->beta = beta;
   #ifdef TCPLX
      out->ONE = CONE;
   if (TA == AtlasNoTrans || TA == AtlasConj)
   #else
   if (TA == AtlasNoTrans)
   #endif
   {
      out->incAm  = mb SHIFT;
      out->pincAm = pmb SHIFT;
   }
   else
   {
      out->incAm = lda*(mb SHIFT);
      out->pincAm = lda*(pmb SHIFT);
   }
   #ifdef TCPLX
   if (TB == AtlasNoTrans || TB == AtlasConj)
   #else
   if (TB == AtlasNoTrans)
   #endif
   {
      out->incBn = ldb*(nb SHIFT);
      out->pincBn = ldb*(pnb SHIFT);
   }
   else
   {
      out->incBn  = nb SHIFT;
      out->pincBn = pnb SHIFT;
   }
/*
 * Once we have ATL_ammmN written, put alpha on A if there's only 1 blk of
 * of B.  For now, always put on B and use ATL_ammmM
 */
   #if 0
   if (nnblks > 1 && nmblks < 2) /* If we only have row panel of C */
   {                             /* apply alpha to A */
      #ifdef TCPLX
         if (TB == AtlasNoTrans)
            out->b2blk = ATL_AMM_BN2BLK_a1[idx];
         else if (TB == AtlasTrans)
            out->b2blk = ATL_AMM_BT2BLK_a1[idx];
         else
            out->b2blk = (TB == AtlasConjTrans) ?
               ATL_AMM_BH2BLK_a1[idx] : ATL_AMM_BC2BLK_a1[idx];

         if (SCALAR_IS_ONE(alpha))
         {
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_a1[idx];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_a1[idx];
            else
               out->a2blk = (TA == AtlasConjTrans) ?
                  ATL_AMM_AC2BLK_a1[idx] : ATL_AMM_AH2BLK_a1[idx];
         }
         else if (SCALAR_IS_NONE(alpha))
         {
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_an[idx];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_an[idx];
            else
               out->a2blk = (TA == AtlasConjTrans) ?
                  ATL_AMM_AC2BLK_an[idx] : ATL_AMM_AH2BLK_an[idx];
         }
         else
         {
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_aX[idx];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_aX[idx];
            else
               out->a2blk = (TA == AtlasConjTrans) ?
                       ATL_AMM_AC2BLK_aX[idx] : ATL_AMM_AH2BLK_aX[idx];
         }
      #else
         out->b2blk = (TB == AtlasNoTrans) ?
                      ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
         if (SCALAR_IS_ONE(alpha))
            out->a2blk = (TA == AtlasNoTrans) ?
                      ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
         else if (SCALAR_IS_NONE(alpha))
            out->a2blk = (TA == AtlasNoTrans) ?
                      ATL_AMM_AT2BLK_an[idx] : ATL_AMM_AN2BLK_an[idx];
         else
            out->a2blk = (TA == AtlasNoTrans) ?
                      ATL_AMM_AT2BLK_aX[idx] : ATL_AMM_AN2BLK_aX[idx];
      #endif
   }
   else  /* apply alpha to B */
   #endif
   {
      out->alpB = alpha;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            *cp = ATL_CpyFromATg_a1[icpA];
         else if (TA == AtlasTrans)
            *cp = ATL_CpyFromANg_a1[icpA];
         else
            *cp = (TA == AtlasConjTrans) ?  
                  ATL_CpyFromACg_a1[icpA]: ATL_CpyFromAHg_a1[icpA];

         cp = (ATL_cparr_t *)&out->b2blk;
         if (SCALAR_IS_ONE(alpha))
         {
            if (TB == AtlasNoTrans)
               *cp = ATL_CpyFromANg_a1[icpB];
            else if (TB == AtlasTrans)
               *cp = ATL_CpyFromATg_a1[icpB];
            else
               *cp = (TB == AtlasConjTrans) ?  
                     ATL_CpyFromAHg_a1[icpB]: ATL_CpyFromACg_a1[icpB];
         }
         else if (SCALAR_IS_NONE(alpha))
         {
            if (TB == AtlasNoTrans)
               *cp = ATL_CpyFromANg_aN[icpB];
            else if (TB == AtlasTrans)
               *cp = ATL_CpyFromATg_aN[icpB];
            else
               *cp = (TB == AtlasConjTrans) ?  
                     ATL_CpyFromAHg_aN[icpB]: ATL_CpyFromACg_aN[icpB];
         }
         else
         {
            if (TB == AtlasNoTrans)
               *cp = ATL_CpyFromANg_aX[icpB];
            else if (TB == AtlasTrans)
               *cp = ATL_CpyFromATg_aX[icpB];
            else
               *cp = (TB == AtlasConjTrans) ?  
                     ATL_CpyFromAHg_aX[icpB]: ATL_CpyFromACg_aN[icpB];
         }
      #else
         *cp = (TA == AtlasNoTrans) ? 
               ATL_CpyFromATg_a1[icpA]:ATL_CpyFromANg_a1[icpA];
         cp = (ATL_cparr_t *) &out->b2blk;
         if (SCALAR_IS_ONE(alpha))
            *cp = (TB == AtlasNoTrans) ? 
                  ATL_CpyFromANg_a1[icpB]:ATL_CpyFromATg_a1[icpB];
         else if (SCALAR_IS_NONE(alpha))
            *cp = (TB == AtlasNoTrans) ? 
                  ATL_CpyFromANg_aN[icpB]:ATL_CpyFromATg_aN[icpB];
         else
            *cp = (TB == AtlasNoTrans) ? 
                  ATL_CpyFromANg_aX[icpB]:ATL_CpyFromATg_aX[icpB];
      #endif
   }
   cp = (ATL_cparr_t *) &out->blk2C;
   if (SCALAR_IS_NONE(beta))
      *cp = ATL_CpyIntoCNg_a1bN[icpC];
   else if (SCALAR_IS_ONE(beta))
      *cp = ATL_CpyIntoCNg_a1b1[icpC];
   else
      *cp = (SCALAR_IS_ZERO(beta)) ? 
            ATL_CpyIntoCNg_a1b0[icpC] : ATL_CpyIntoCNg_a1bX[icpC];
}

@ROUT ATL_opsymmInfo

int Mjoin(PATL,opsymmInfo) /* pop opinfo_t wt atlas_opgen_view K-3 */
   (opinfo_t *op, ATL_UINT bv,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT lda, ATL_CSZT ldb, ATL_CSZT ldc,
    const SCALAR alpha, const SCALAR beta)
/*
 * bv: 0:Left, 1:Upper, 2:HEMM
 * RETURNS: 0 if A fits in cache for outer-product, else non-zero.
@skip *          the transpose copy for the cross-diagonal copy of A, else NULL.
@skip *          If NULL is returned, out may not be fully populated.
 */
{
   ATL_cparr_t *cp = (ATL_cparr_t *)&op->blk2C;
   ATL_iptr_t szSet;
   double spmfMM;
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      #define CONE ATL_rone
   #endif
   ATL_CUINT K = (bv&1) ? M:N, iv=K-3;
   ATL_UINT MB, NB, KB, mb, nb, k, imm, icpA, icpB, icpC, mu, nu, ku, nmu, nnu;

   if (iv >= ATL_VWopgen_NCASES)
         return(1);
   ATL_GetVWopgenInfo(iv, spmfMM, MB, NB, k, imm, icpA, icpB, icpC, k, k, k);
   ATL_assert(imm < ATL_AMM_NCASES);
   icpA += icpA;
   icpB += icpB;
   icpC += icpC;
   #ifdef TCPLX
      ATL_AMM_info(imm, &op->amm_b0, &op->amm_b1, &op->amm_bn, k,
                   mu, nu, ku, op->vlen, k, k, k);
   #else
      ATL_AMM_info(imm, &op->amm_b0, &szSet, &szSet, k,
                   mu, nu, ku, op->vlen, k, k, k);
   #endif
   op->idx = iv;
   op->mu = mu;
   op->nu = nu;
   op->ku = ku;
   op->exsz = (mu*nu)<<1;
   op->ldc = ldc;
   op->alpA = op->alpB = CONE;
   cp = (ATL_cparr_t *) &op->blk2C;
   if (SCALAR_IS_NONE(beta))
      *cp = ATL_CpyIntoCNg_a1bN[icpC];
   else if (SCALAR_IS_ONE(beta))
      *cp = ATL_CpyIntoCNg_a1b1[icpC];
   else
      *cp = (SCALAR_IS_ZERO(beta)) ?
         ATL_CpyIntoCNg_a1b0[icpC] : ATL_CpyIntoCNg_a1bX[icpC];
/*
 * If M==K ask at least A fit in LLPC
 */
   KB = ((K+ku-1)/ku)*ku;
   if (bv&1)  /* Left, M=K, symmetric matrix A is gemm's A */
   {
      nmu = (M+mu-1)/mu;
      mb = nmu*mu;
      if (mb > MB) /* must shrink NB to keep working set same */
      {
         ATL_UINT t;
         szSet = (MB+NB)*KB + MB*NB;
         t = mb*KB;
         if (szSet < t)
            return(2);
         nb = (szSet - t) / (KB+mb);
         if (nb < nu)
            return(2);
      }
      else
         nb = NB;
      nnu = nb / nu;
      nb = nnu*nu;
      op->lda = lda;
      op->ldb = ldb;
      op->kb = M;
/*
 *    For complex, hermitian makes it so we need worry about transpose on the
 *    herimitian matrix, and we also cannot apply a complex alpha with an
 *    imaginary component to A, since it won't appear in known-zero imag diag
 */
      cp = (ATL_cparr_t *)&op->a2blk;
      #ifdef TCPLX
         if (bv&4)  /* hermitian, not symmetric! */
         {
            *cp = ATL_CpyFromATg_a1[icpA];
            cp = (ATL_cparr_t *)&op->b2blk;
            if (alpha[1] == ATL_rzero)
               *cp = ATL_CpyFromANg_a1[icpB];
            else
            {
               *cp = ATL_CpyFromANg_aX[icpB];
               op->alpB = alpha;
            }
         }
         else
      #endif
      {
         *cp = ATL_CpyFromANg_a1[icpA];
         cp = (ATL_cparr_t *)&op->b2blk;
         *cp = ATL_CpyFromANg_a1[icpB];
      }
   }
   else      /* Right, N=K, symm's symmetric A is gemm's B */
   {
      nnu = (N+nu-1)/nu;
      nb = nnu*nu;
      if (nb > NB) /* must shrink MB to keep working set same */
      {
         ATL_CUINT t = nb*KB;
         szSet = (MB+NB)*KB + MB*NB;
         if (szSet < t)
            return(2);
         mb = (szSet - t) / (KB+nb);
         if (mb < mu)
            return(2);
      }
      else
         mb = MB;
      nmu = mb / mu;
      mb = nmu*mu;
      op->pincBn = op->incBn = 0;  /* not used for 1 blk opsymm */
      op->lda = ldb;
      op->ldb = lda;
      op->kb = N;
      cp = (ATL_cparr_t *)&op->b2blk;
      #ifdef TCPLX
         if (bv&4)  /* hermitian, not symmetric! */
         {
            *cp = ATL_CpyFromANg_a1[icpB];
            cp = (ATL_cparr_t *)&op->a2blk;
            if (alpha[1] == ATL_rzero)
               *cp = ATL_CpyFromATg_a1[icpA];
            else
            {
               *cp = ATL_CpyFromATg_aX[icpA];
               op->alpA = alpha;
            }
         }
         else
      #endif
      {
         *cp = ATL_CpyFromANg_a1[icpB];
         cp = (ATL_cparr_t *)&op->a2blk;
         *cp = ATL_CpyFromATg_a1[icpA];
      }
   }
   op->KB = KB;
   op->beta = beta;
   #ifdef TCPLX
      op->ONE = CONE;
   #endif
   if (M > mb)
   {
      op->mb = mb;
      op->nmu = nmu;
      op->nfmblks = M / mb;
      op->mF = M - mb*op->nfmblks;
      if (op->mF)
      {
         op->nmuF = (op->mF+mu-1)/mu;
         op->pmb = op->nmuF * mu;
         op->npmblks = 1;
      }
      else
         op->nmuF = op->pmb = op->npmblks = 0;
      op->npmblks = (op->pmb) ? 1 : 0;
      op->pnmu = op->nmuF;
   }
   else
   {
      nmu = (M+mu-1)/mu;
      op->npmblks = 1;
      op->nfmblks = 0;
      op->nmuF = op->pnmu = op->nmu = nmu;
      op->mb = op->pmb = nmu*mu;
      op->mF = M;
   }
   if (N > nb)
   {
      op->nb = nb;
      op->nnu = nnu;
      op->nfnblks = N / nb;
      op->nF = N - nb*op->nfnblks;
      if (op->nF)
      {
         op->nnuF = (op->nF+nu-1)/nu;
         op->pnb = op->nnuF * nu;
         op->npnblks = 1;
      }
      else
         op->nnuF = op->pnb = op->npnblks = 0;
      op->npnblks = (op->pnb) ? 1 : 0;
      op->pnnu = op->nnuF;
   }
   else
   {
      nnu = (N+nu-1)/nu;
      op->npnblks = 1;
      op->nfnblks = 0;
      op->nnuF = op->pnnu = op->nnu = nnu;
      op->nb = op->pnb = nnu*nu;
      op->nF = N;
   }
   op->szA = op->mb * op->KB;
   op->szB = op->nb * op->KB;
   op->pszA = op->pmb * op->KB;
   op->pszB = op->pnb * op->KB;
   op->szC = op->mb * op->nb;
   if (bv&1)  /* Left,  M=K, symm matrix A is gemm's A */
   {
      op->incBn = op->nb * (ldb SHIFT);
      op->pincBn = op->pnb * (ldb SHIFT);
      op->incAm = op->pincAm = 0;  /* not used for opsymm */
   }
   else       /* Right, N=K, symm matrix A is gemm's B */
   {
      op->incAm = op->mb SHIFT;
      op->pincAm = op->pmb SHIFT;
      op->incBn = op->pincBn = 0;  /* not used for opsymm */
   }
   if (op->vlen > 1)
   {
      ATL_CUINT vlen=op->vlen;
      @whiledef sz pszA pszB szA szB
      op->@(sz) = ((op->@(sz)+vlen-1)/vlen)*vlen;
      @endwhile
   }
   #if 0
   printf("symmB=(%u,%u,%u),(%u,%u,%u), OB=(%u,%u)\n", op->mb, op->nb, op->KB, 
          op->pmb, op->pnb, op->kb, MB, NB);
   #endif
   return(0);
}
@ROUT ATL_opsyr2kInfo
ablk2cmat_t Mjoin(PATL,opsyr2kInfo) /* pop opinfo_t wt atlas_opgen_view K-3 */
   (opinfo_t *out, int flag, enum ATLAS_TRANS TA,
    ATL_CSZT N, ATL_CSZT K, ATL_CSZT lda, ATL_CSZT ldb, ATL_CSZT ldc,
    const SCALAR alpha, const SCALAR beta)
/*
 * RETURNS: If syr2k_OP can do this problem, C2blk_b0, else NULL
 *          If NULL is returned, out may not be fully populated.
 */
@ROUT ATL_opsyrkInfo

int Mjoin(PATL,opsyrkInfo) /* pop opinfo_t using atlas_opgen_view K-3 idx */
   (opinfo_t *out, int flag, enum ATLAS_TRANS TA,
    ATL_CSZT N, ATL_CSZT K, ATL_CSZT lda, ATL_CSZT ldc,
    const SCALAR alpha, const SCALAR beta)
/*
 * RETURNS: 0 if opsyrk can do this, problem, non-zero if it can't.
 *          If non-zero is returned, out may not be fully populated.
 */
@ROUT ATL_opsyrkInfo ATL_opsyr2kInfo
{
   ammkern_t amm1, amm0, ammN;
   ATL_cparr_t *cp = (ATL_cparr_t *)&out->a2blk;
   double spmfMM, spmfCP;
   const int CONJ=flag&1;
   size_t nfmblks, npmblks, nfnblks, npnblks;
   unsigned int icpA, icpB, icpC, imm, k, mu, nu, ku, vlen, flgK;
   unsigned int sz, nmu, nnu, pnmu, pnnu, mb, pmb, nb, pnb, MB, NB, kb;
   const unsigned int iv=K-3;
@ROUT ATL_opsyr2kinfo `   ATL_UINT U;`
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      ATL_iptr_t iptmp;
      #define CONE ATL_rone
   #endif

   if (iv >= ATL_VWopgen_NCASES)
@ROUT ATL_opsyrkInfo `      return(1);`
@ROUT ATL_opsyr2kInfo `      return(NULL);`
   ATL_GetVWopgenInfo(iv, spmfMM, MB, NB, k, imm, icpA, icpB, icpC, k, k, k);
   ATL_assert(imm < ATL_AMM_NCASES);
   icpA += icpA;
   icpB += icpB;
   icpC += icpC;
   #ifdef TCPLX
      ATL_AMM_info(imm, &out->amm_b0, &out->amm_b1, &out->amm_bn, flgK, 
                   mu, nu, ku, vlen, k, k, k);
   #else
      ATL_AMM_info(imm, &out->amm_b0, &iptmp, &iptmp, flgK, 
                   mu, nu, ku, vlen, k, k, k);
   #endif

@ROUT ATL_opsyrkInfo
   if (MB != NB)   /* need to make square */
   {
      int U;
      U = ATL_iLCM(mu, nu);  /* square NB must be multiple of U */
      if (N < U)
        return(2);
      NB = (MB+NB)>>1;       /* average B keeps cache usage similar */
      NB = Mmin(NB, N);
      if (NB <= U)
         NB = U;
      else if (NB >= 3*U)
         NB = (NB/U)*U;
      else
         NB = ((NB+U-1)/U)*U;
   }
@ROUT ATL_opsyr2kInfo
   U = ATL_iLCM(mu,nu);  /* square NB must be multiple of U */
   if (MB != NB)
   {
      NB = (MB+NB)>>2;
      if (NB <= U)
         NB = U;
      else if (NB >= (U<<1)+U)
         NB = (NB/U)*U;
      else
         NB = ((NB+U-1)/U)*U;
   }
   #if defined(LLPC_SZ) && LLPC_SZ > 0 && LLPC_SZ > L1C_SZ
      while (ATL_MulBySize(3*NB*NB+2*NB*K) > LLPC_SZ && NB >= U+U)
         NB -= U;
   #endif
@ROUT ATL_opsyrkInfo ATL_opsyr2kInfo
   if (N > NB)  /* if we have more than 1 block, set everything up */
   {
      mb = nb = NB;
      nfnblks = N / NB;
      nmu = NB / mu;
      nnu = NB / nu;
      out->mF = out->nF = pnb = N - nfnblks*NB;
      pnmu = (pnb+mu-1)/mu;
      pnnu = (pnb+nu-1)/nu;
      pmb = pnmu * mu;
      pnb = pnnu * nu;
      npnblks = (pnb) ? 1 : 0;
   }
   else   /* else only one, perhaps partial, block */
   {
      npnblks = 1;
      pnnu = nnu = (N+nu-1)/nu;
      pnmu = nmu = (N+mu-1)/mu;
      pnb = nb = nnu * nu;
      pmb = mb = pnmu * mu;
      nfnblks = 0;
      out->mF = out->nF = N;
   }

   kb = ((K+ku-1)/ku)*ku;

   out->nfmblks = out->nfnblks = nfnblks;
   out->npmblks = out->npnblks = npnblks;
   out->mb = mb;
   out->nb = nb;
   out->pmb = pmb;
   out->pnb = pnb;
   out->mu = mu;
   out->nu = nu;
   out->ku = ku;
   out->vlen = vlen;
@ROUT ATL_opsyrkInfo
   out->ldb = out->lda = lda;
@ROUT ATL_opsyr2kInfo
   out->lda = lda;
   out->ldb = ldb;
@ROUT ATL_opsyrkInfo ATL_opsyr2kInfo
   out->ldc = ldc;

   out->nmu = nmu;
   out->nnu = nnu;
   out->nmuF = out->pnmu = pnmu;
   out->nnuF = out->pnnu = pnnu;

   sz = ((mu*nu+vlen-1)/vlen)*vlen;
   sz *= (nnu) ? nmu*nnu : pnmu*pnnu;
   out->szC = sz;
   out->exsz = (mu*nu)<<1;
   out->idx = iv;
   out->kb = K;
   out->KB = kb;
@ROUT ATL_opsyr2kInfo
   out->pszA = pmb*kb;
   out->szA = kb * mb;
   out->pszB = pnb*kb;
   out->szB = kb * nb;
@ROUT ATL_opsyrkInfo
   out->pszA = pmb*kb;
   out->pszB = pnb*kb;
   out->szB = out->szA = kb * nb;
@ROUT ATL_opsyrkInfo ATL_opsyr2kInfo
   if (vlen > 1)
   {
      @whiledef sz pszA pszB szA szB
      out->@(sz) = ((out->@(sz)+vlen-1)/vlen)*vlen;
      @endwhile
   }
   out->alpA = out->alpB = CONE;
   out->beta = beta;
   out->alpB = alpha;
   #ifdef TCPLX
      out->ONE = CONE;
   if (TA == AtlasNoTrans || TA == AtlasConj)
   #else
   if (TA == AtlasNoTrans)
   #endif
   {  /* A noTrans, B Trans */
      *cp = ATL_CpyFromATg_a1[icpA];
      cp = (ATL_cparr_t *)&out->b2blk;
      #ifdef TCPLX
         if (SCALAR_IS_NONE(alpha))
            *cp = (CONJ) ? ATL_CpyFromAHg_aN[icpB] : ATL_CpyFromATg_aN[icpB];
         else if (SCALAR_IS_ONE(alpha))
            *cp = (CONJ) ? ATL_CpyFromAHg_a1[icpB] : ATL_CpyFromATg_a1[icpB];
         else
            *cp = (CONJ) ? ATL_CpyFromAHg_aX[icpB] : ATL_CpyFromATg_aX[icpB];
      #else
         if (SCALAR_IS_NONE(alpha))
            *cp = ATL_CpyFromATg_aN[icpB];
         else
            *cp = (SCALAR_IS_ONE(alpha))? ATL_CpyFromATg_a1[icpB]
                                         :ATL_CpyFromATg_aX[icpB];
      #endif
      out->incAm  = mb SHIFT;
      out->pincAm = pmb SHIFT;
      out->incBn  = nb SHIFT;
      out->pincBn = pnb SHIFT;
   }
   else  /* A (Conj)transpose, B no trans */
   {
      #ifdef TCPLX
         *cp = CONJ ? ATL_CpyFromACg_a1[icpA]:ATL_CpyFromANg_a1[icpA];
      #else
         *cp = ATL_CpyFromANg_a1[icpA];
      #endif
      cp = (ATL_cparr_t *)&out->b2blk;
      if (SCALAR_IS_NONE(alpha))
         *cp = ATL_CpyFromANg_aN[icpB];
      else
         *cp = (SCALAR_IS_ONE(alpha)) ?  ATL_CpyFromANg_a1[icpB]
                                       : ATL_CpyFromANg_aX[icpB];
      out->incAm = lda*(mb SHIFT);
      out->pincAm = lda*(pmb SHIFT);
      out->incBn = lda*(nb SHIFT);
      out->pincBn = lda*(pnb SHIFT);
   }
   cp = (ATL_cparr_t *) &out->blk2C;
@ROUT ATL_opsyr2kInfo
   *cp = ATL_CpyIntoCNg_a1b1[icpC];
   return((ablk2cmat_t)ATL_CpyIntoCNg_a1b0[icpC]);
@ROUT ATL_opsyrkInfo
   if (SCALAR_IS_NONE(beta))
      *cp = ATL_CpyIntoCNg_a1bN[icpC];
   else if (SCALAR_IS_ONE(beta))
      *cp = ATL_CpyIntoCNg_a1b1[icpC];
   else
      *cp = (SCALAR_IS_ZERO(beta)) ? 
            ATL_CpyIntoCNg_a1b0[icpC] : ATL_CpyIntoCNg_a1bX[icpC];
   return(0);
@ROUT ATL_opsyrkInfo ATL_opsyr2kInfo
}
@ROUT ATL_ipmeninfo
void ipPop  /* populate ip wt given params */
@ROUT ATL_ipinfo ATL_ipmekinfo ATL_ipnekinfo 
void Mjoin(PATL,@(vwf)InfoPop)  /* populate ip wt given params */
@ROUT ATL_ipinfo ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo 
(
   ipinfo_t *ip,        /* output */
   int idx,             /* what amm kernel index to use */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   size_t M,
   size_t N,
   size_t K,
   size_t lda,
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta,
   size_t nfmblks,
   size_t npmblks,
   ATL_UINT mb,
   ATL_UINT pmb,
   size_t nfnblks,
   size_t npnblks,
   ATL_UINT nb,
   ATL_UINT pnb
)
{
   ATL_cparr_t *cp = (ATL_cparr_t *)&(ip->a2blk);
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      ATL_iptr_t iptmp;
      #define CONE ATL_rone
   #endif
   ATL_UINT vlen, mu, nu, ku, kb, nkblks, KB0, kb0, szC; 
   ATL_UINT imm, ik1, icpA, icpB, icpC, flgK, kbmin, k;
   float spmf;

   ATL_GetVW@(vwf)Info(idx, spmf, k, k, kb, imm, icpA, icpB, icpC, k, 
                      kbmin, k);
   icpA += icpA;
   icpB += icpB;
   icpC += icpC;
   #ifdef TCPLX
      ATL_AMM_info(imm, &ip->amm_b0, &ip->amm_b1, &ip->amm_bn, flgK,
                   mu, nu, ku, vlen, k, k, ik1);
   #else
      ATL_AMM_info(imm, &ip->amm_b0, &ip->amm_b1, &iptmp, flgK,
                   mu, nu, ku, vlen, k, k, ik1);
   #endif
   ip->mu = mu;
   ip->nu = nu;
   ip->ku = ku;
   ip->kb = kb;
   ip->vlen = vlen;
   ip->lda = lda;
   ip->ldb = ldb;
   ip->ldc = ldc;

   ip->nfmblks = nfmblks;
   ip->npmblks = npmblks;
   ip->nfnblks = nfnblks;
   ip->npnblks = npnblks;
   ip->mb = mb;
   ip->pmb = pmb;
   ip->nmu = mb / mu;
   ip->pnmu = pmb / mu;
   if (npmblks)
      ip->mF = M - nfmblks*mb - (npmblks-1)*pmb;
   else
      ip->mF = M - (nfmblks-1)*mb;
   ip->nmuF = (ip->mF+mu-1) / mu;

   ip->nb = nb;
   ip->pnb = pnb;
   ip->nnu = nb / nu;
   ip->pnnu = pnb / nu;
   if (npnblks)
      ip->nF = N - nfnblks*nb - (npnblks-1)*pnb;
   else
      ip->nF = N - (nfnblks-1)*nb;
   ip->nnuF = (ip->nF+nu-1) / nu;

/*
 * Compute K remainder block, and how it affects kernel to use
 */
   nkblks = K / kb;
   KB0 = kb0 = K - nkblks*kb;
   ip->ammK1_b0 = ip->amm_b0;  /* hope: normal kerns for K-clean */
   #ifdef TCPLX
      ip->ONE = CONE;
   #endif
   if (kb0)  /* K not a multiple of kb, need initial block */
   {
      if (ATL_AMM_KMAJOR(flgK))  
      {
         KB0 = ((kb0+vlen-1)/vlen)*vlen; /* k-maj req K mul of vlen */
         if (KB0 != kb)
         {
            if (ATL_AMM_KRUNTIME(flgK))
            {
               if ((kbmin && KB0 < kbmin) || (KB0/ku)*ku != KB0)
                  ip->ammK1_b0 = NULL;
            }
            else
               ip->ammK1_b0 = NULL;
         }
      }
      else if (ATL_AMM_KRUNTIME(flgK))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if ((kbmin && kb0 < kbmin) || KB0-kb0 > ku)
            ip->ammK1_b0 = NULL;
      }
      else /* compile-time K needs K1 clean whenever KB0 != kb0 */
@skip      if (kb0+3 < kb) /* comp-time K works only if we pad to kb! */
         ip->ammK1_b0 = NULL;
      if (!ip->ammK1_b0) /* must use ik1 kerns instead! */
      {
         ATL_assert(ik1);
         ik1--;
         #ifdef TCPLX
            ATL_AMM_kinfo(ik1, &ip->ammK1_b0, &ip->ammK1_b1, &ip->ammK1_bn);
         #else
            ATL_AMM_kinfo(ik1, &ip->ammK1_b0, &ip->ammK1_b1, &iptmp);
         #endif
         KB0 = ATL_AMM_GetKU(ik1);
         KB0 = ((kb0+KB0-1)/KB0)*KB0;
      }
      else
      {
         ip->ammK1_b1 = ip->amm_b1;
         #ifdef TCPLX
            ip->ammK1_bn = ip->amm_bn;
         #endif
      }
   }
   else
   {
      ip->ammK1_b1 = ip->amm_b1;
      #ifdef TCPLX
         ip->ammK1_bn = ip->amm_bn;
      #endif
      kb0 = KB0 = kb;
      nkblks--;
      ATL_assert(nkblks >= 0);
   }
   ip->KB0 = KB0;
   ip->kb0 = kb0;
   ip->exsz = (mu+mu)*nu;
   szC = ((mu*nu+vlen-1)/vlen)*vlen;
   szC *= ip->nnu * ip->nmu;
   ip->szC = szC;


   ip->alpA = ip->alpB = ip->alpC = CONE;
   if (M < N)  /* alpha goes on A or C */
   {
      if (M < K)
         ip->alpC = alpha;
      else
         ip->alpA = alpha;
   }
   else if (N < K)
      ip->alpC = alpha;
   else
      ip->alpB = alpha;
   if (SCALAR_IS_NONE(ip->alpA))
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         *cp = ATL_CpyFromACg_aN[icpA];
      else if (TA == AtlasConj)
         *cp = ATL_CpyFromAHg_aN[icpA];
      else
      #endif
         *cp = (TA == AtlasNoTrans) ?
               ATL_CpyFromATg_aN[icpA] : ATL_CpyFromANg_aN[icpA];
   }
   else if (SCALAR_IS_ONE(ip->alpA))
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         *cp = ATL_CpyFromACg_a1[icpA];
      else if (TA == AtlasConj)
         *cp = ATL_CpyFromAHg_a1[icpA];
      else
      #endif
         *cp = (TA == AtlasNoTrans) ?
               ATL_CpyFromATg_a1[icpA] : ATL_CpyFromANg_a1[icpA];
   }
   else  /* alphaA = X */
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         *cp = ATL_CpyFromACg_aX[icpA];
      else if (TA == AtlasConj)
         *cp = ATL_CpyFromAHg_aX[icpA];
      else
      #endif
         *cp = (TA == AtlasNoTrans) ?
               ATL_CpyFromATg_aX[icpA] : ATL_CpyFromANg_aX[icpA];
   }

   cp = (ATL_cparr_t *) &(ip->b2blk);
   if (SCALAR_IS_NONE(ip->alpB))
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         *cp = ATL_CpyFromAHg_aN[icpB];
      else if (TB == AtlasConj)
         *cp = ATL_CpyFromACg_aN[icpB];
      else
      #endif
         *cp = (TB == AtlasNoTrans) ?
            ATL_CpyFromANg_aN[icpB] : ATL_CpyFromATg_aN[icpB];
   }
   else if (SCALAR_IS_ONE(ip->alpB))
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         *cp = ATL_CpyFromAHg_a1[icpB];
      else if (TB == AtlasConj)
         *cp = ATL_CpyFromACg_a1[icpB];
      else
      #endif
         *cp = (TB == AtlasNoTrans) ?
            ATL_CpyFromANg_a1[icpB] : ATL_CpyFromATg_a1[icpB];
   }
   else  /* alphaB = X */
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         *cp = ATL_CpyFromAHg_aX[icpB];
      else if (TB == AtlasConj)
         *cp = ATL_CpyFromACg_aX[icpB];
      else
      #endif
         *cp = (TB == AtlasNoTrans) ?
            ATL_CpyFromANg_aX[icpB] : ATL_CpyFromATg_aX[icpB];
   }

   cp = (ATL_cparr_t *) &(ip->blk2c_b1);
   if (SCALAR_IS_ONE(ip->alpC))
   {
      *cp = ATL_CpyIntoCNg_a1b1[icpC];
      cp = (ATL_cparr_t *) &(ip->blk2c);
      if (SCALAR_IS_NONE(beta))
         *cp = ATL_CpyIntoCNg_a1bN[icpC];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         *cp = (SCALAR_IS_ZERO(beta)) ?
            ATL_CpyIntoCNg_a1b0[icpC] : ATL_CpyIntoCNg_a1bX[icpC];
   }
   else if (SCALAR_IS_NONE(ip->alpC))
   {
      *cp = ATL_CpyIntoCNg_aNb1[icpC];
      cp = (ATL_cparr_t *) &(ip->blk2c);
      if (SCALAR_IS_NONE(beta))
         *cp = ATL_CpyIntoCNg_aNbN[icpC];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         *cp = (SCALAR_IS_ZERO(beta)) ?
            ATL_CpyIntoCNg_aNb0[icpC] : ATL_CpyIntoCNg_aNbX[icpC];
   }
   else /* alphaC = X */
   {
      *cp = ATL_CpyIntoCNg_aXb1[icpC];
      cp = (ATL_cparr_t *) &(ip->blk2c);
      if (SCALAR_IS_NONE(beta))
         *cp = ATL_CpyIntoCNg_aXbN[icpC];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         *cp = (SCALAR_IS_ZERO(beta)) ?
            ATL_CpyIntoCNg_aXb0[icpC] : ATL_CpyIntoCNg_aXbX[icpC];
   }

   ip->nfkblks = nkblks;
   if (IS_COLMAJ(TA))
   {
      ip->incAk  = (kb SHIFT)*lda;
      ip->incAm  = (mb SHIFT);
      ip->pincAm = (pmb SHIFT);
   }
   else
   {
      ip->incAk  = (kb SHIFT);
      ip->incAm  = (mb SHIFT)*lda;
      ip->pincAm = (pmb SHIFT)*lda;
   }
   if (IS_COLMAJ(TB))
   {
      ip->incBk  = (kb SHIFT);
      ip->incBn  = (nb SHIFT)*ldb;
      ip->pincBn = (pnb SHIFT)*ldb;
   }
   else
   {
      ip->incBk  = (kb SHIFT)*ldb;
      ip->incBn  = (nb SHIFT);
      ip->pincBn = (pnb SHIFT);
   }
   ip->szA = mb*kb;
   ip->szB = kb*nb;
   ip->pszA = pmb*kb;
   ip->pszB = kb*pnb;
   if (vlen > 1)
   {
      @whiledef sz pszA pszB szA szB
      ip->@(sz) = ((ip->@(sz)+vlen-1)/vlen)*vlen;
      @endwhile
   }
}
#ifndef TCPLX
   #undef CONE
#endif
@ROUT
@ROUT ATL_ipmeninfo
void ipInfo
@ROUT ATL_ipinfo ATL_ipmekinfo ATL_ipnekinfo 
void Mjoin(PATL,@(vwf)Info)
@ROUT ATL_ipinfo ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo 
(
   ipinfo_t *ip,        /* output */
@ROUT ATL_ipinfo `   int flg,             /* bitvec, see below */`
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   size_t M,
   size_t N,
   size_t K,
   size_t lda,
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
@ROUT ATL_ipinfo
/*
 * flg: bitvec, with bitpos set meaning (unset opposite):
 *   0: Force mb=M
 *   1: Force nb=N
 */
@ROUT ATL_ipinfo ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo 
{
   size_t nfmblks, npmblks, nfnblks, npnblks;
   const ATL_iptr_t *ipp;
   ATL_UINT mb, pmb, nb, pnb, mu, nu, nmu, pnmu, nnu, pnnu;
   ATL_UINT MB, NB, KB, k, imm, idx=ATL_VIEW_BEST_IDX;
   float spf;

   #if ATL_VIEW_NCASES > 1
   if (K < ATL_VIEW_BEST_KB)
   {
      for (idx=0; idx < ATL_VIEW_LAST_IDX; idx++)
         if (ATL_GetViewKB(idx) >= K)
            break;
   }
   #endif
   ATL_GetViewInfo(idx, spf, MB, NB, KB, imm, k, k, k, k, k, k);
   ipp = ATL_AMM_ML + ATL_AMM_Idx2Entry(imm) + 3;
   ATL_AMM_iinfo(ipp, k, mu, nu, k, k, k, k, k);
@BEGINSKIP
@ROUT ATL_ipmeninfo
   NB = Mmax(M,N);
/*
 * This routine called whenever we need MB=NB (eg. SYRK) but we are doing
 * an inner product (usually, K > ATL_VWopgen_BEST_KB).
 * Use best NB unless M or N or smaller than that, in which case we use
 * first square block that can contain them both.
 */
   if (NB < ATL_VIEW_BEST_NB && ATL_VIEW_BEST_IDX)
   {
      for (idx--; idx; idx--)
         if (ATL_GetViewMB(idx) < NB)
            break;
      idx++;
   }
   ATL_GetViewInfo(idx, spf, MB, NB, k, imm, k, k, k, k, k, k);
   ipp = ATL_AMM_ML + ATL_AMM_Idx2Entry(imm) + 3;
   ATL_AMM_iinfo(ipp, k, mu, nu, k, k, k, k, k);
   npnblks = npmblks = 1;
   nfnblks = nfmblks = 0;
   pnmu = nmu = (M+mu-1)/mu;
   pnnu = nnu = (N+nu-1)/nu;
   mb = pmb = nmu * mu;
   nb = pnb = nnu * nu;
@ENDSKIP
/*
 * Consider expanding M/N block to cover whole C if best block factor is 
 * already close in size, to avoid having one large block, and one tiny
 */
   if (NB+NB > N && MB+MB > M)
   {
      mb = ((M+mu-1)/mu)*mu;
      nb = ((N+nu-1)/nu)*nu;
      if (ATL_MulBySize(mb*nb + 2*(mb+nb)*KB) <= LLPC_SZ)
      {
         MB = mb;
         NB = nb;
@ROUT ATL_ipmekinfo `         KB = MB; /* KB must be equal to MB for mek */`
@ROUT ATL_ipnekinfo `         KB = NB; /* KB must be equal to NB for nek */`
      }
   }
@ROUT ATL_ipinfo 
   if ((flg&1) || MB >= M)
@ROUT ATL_ipmeninfo ATL_ipmekinfo @ROUT ATL_ipnekinfo 
   if (MB >= M)
@ROUT ATL_ipinfo ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo 
   {
      npmblks = 1;
      nfmblks = 0;
      pnmu = nmu = (M+mu-1)/mu;
      mb = pmb = nmu * mu;
   }
   else
   {
      mb = MB;
      nfmblks = M / MB;
      nmu = MB / mu;
      pmb = M - nfmblks*MB;
      if (pmb)
      {
         npmblks = 1;
         pnmu = (pmb+mu-1) / mu;
         pmb = pnmu * mu;
      }
      else
         npmblks = pnmu = pmb = 0;
   }
@ROUT ATL_ipinfo    
   if ((flg&2) || NB >= N)
@ROUT ATL_ipmeninfo @ROUT ATL_ipmekinfo @ROUT ATL_ipnekinfo 
   if (NB >= N)
@ROUT ATL_ipinfo ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo 
   {
      npnblks = 1;
      nfnblks = 0;
      pnnu = nnu = (N+nu-1)/nu;
      nb = pnb = nnu * nu;
   }
   else
   {
      nb = NB;
      nfnblks = N / NB;
      nnu = NB / nu;
      pnb = N - nfnblks*NB;
      if (pnb)
      {
         npnblks = 1;
         pnnu = (pnb+nu-1) / nu;
         pnb = pnnu * nu;
      }
      else
         npnblks = pnnu = pnb = 0;
   }
@ROUT ATL_ipmeninfo
   ipPop(ip, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta, 
         nfmblks, npmblks, mb, pmb, nfnblks, npnblks, nb, pnb);
@ROUT ATL_ipinfo ATL_ipmekinfo ATL_ipnekinfo 
   Mjoin(PATL,@(vwf)InfoPop)(ip, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha,
                             beta, nfmblks, npmblks, mb, pmb, nfnblks,
                             npnblks, nb, pnb);
@ROUT ATL_ipinfo  ATL_ipmeninfo ATL_ipmekinfo ATL_ipnekinfo 
}
@ROUT ATL_ipsyrkInfo
#include "atlas_amm.h"
#include Mstr(Mjoin(ATLAS_UPR,amm_kern.h))
#include Mstr(Mjoin(ATLAS_PRE,amm_sqsyrk.h))
#include Mstr(Mjoin(ATLAS_PRE,amm_umsyrk.h))
#include Mstr(Mjoin(ATLAS_PRE,ipmen_view.h))
#include Mstr(Mjoin(ATLAS_PRE,syrk_view.h))
#include Mstr(COPY/Mjoin(ATLAS_PRE,FromANg_a1.h))
#ifdef TCPLX
   #include Mstr(COPY/Mjoin(ATLAS_PRE,FromAHg_a1.h))
#endif
#include Mstr(COPY/Mjoin(ATLAS_PRE,FromATg_a1.h))
/* #define DEBUG 1 */
double Mjoin(PATL,ipsyrkInfo)
(
   ipinfo_t *ip,        /* output */
   int flag,            /* 0:HERK */
   enum ATLAS_TRANS TA,
   size_t N,
   size_t K,
   size_t lda,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
{
   size_t nfnblks;
   unsigned int npnblks, mb, nb, pnb, pmb, mu, nu;
   unsigned int idB=ATL_VIEW_BEST_IDX, nbB=0;
   int i;
   double timB=N*N*K;
   #ifdef TCPLX
      const int CONJ = flag&1;
      enum ATLAS_TRANS TB;
   #else
      const enum ATLAS_TRANS TB = (TA==AtlasNoTrans) ? AtlasTrans:AtlasNoTrans;
   #endif
   @BEGINSKIP
   const enum ATLAS_TRANS TB = (TA == AtlasNoTrans) ? 
      #ifdef Conj_
          AtlasConjTrans : AtlasNoTrans;
      #else
          AtlasTrans : AtlasNoTrans;
      #endif
   @ENDSKIP
   for (i=ATL_VIEW_BEST_IDX; i >= 0; i--)
   {
      double tim;
      float *tpf, *stpf;
      ATL_iptr_t nfdiag, ngblk;
      unsigned int nb, pnb;

      nb = ATL_GetVWipmenNB(i);
      if (i && nb+nb > N)
         continue;
      nfdiag = N / nb;
      pnb = N - nb*nfdiag;
      ngblk = ((nfdiag-1)*nfdiag)>>1;
      tim = nb*nb;
      tim *= K;
      tpf  = (float*)(ATL_VIEW_ipmen+ATL_VWipmen_IDXMUL(i));
      stpf = (float*)(ATL_VIEW_syrk+ATL_VWsyrk_IDXMUL(i));
      tim *= (*tpf * 2.0*ngblk) + (*stpf * nfdiag);
/*
 *    For partial block, guess performance poor (half normal) if pnb <= 3*U,
 *    and good (.85 normal) if bigger than that.
 */
      if (pnb)
      {
         unsigned int imm;
         double tg, ts, nf;
         imm = ATL_GetVWipmenAMMI(i);
         ATL_AMM_GetMNU(imm, mu, nu);
         nf = (pnb*1.0)*pnb * K;
         tg = (pnb >= 3*Mmax(mu,nu)) ? .85 : .5;
         ts = (pnb >= 3*ATL_SYRKK_NU) ? .85 : .5;
         tg *= *tpf * (nf+nf);
         ts *= *stpf * nf;
         tim += tg + ts;
      }
      #ifdef DEBUG
         printf("%u: D=(%u,%u), NB=%u(%u) tim=%e\n", i, N, K, nb, pnb, tim);
      #endif
      if (tim > timB)  /* don't keep looking if we are getting slower */
         break;        /* assume get smaller to reduce SYRK cost */
@skip      if (tim < timB)
      {
         idB = i;
         nbB = nb;
         nfnblks = nfdiag;
         timB = tim;
      }
   }
   i = ATL_GetVWipmenAMMI(idB);
   ATL_AMM_GetMNU(i, mu, nu);
   if (nbB >= N)
   {
      npnblks = 1;
      nfnblks = 0;
      pmb = mb = ((N+mu-1)/mu)*mu;
      pnb = nb = ((N+nu-1)/nu)*nu;
   }
   else
   {
      mb = nb = nbB;
      pnb = N - nfnblks*nbB;
      if (pnb)
      {
         npnblks = 1;
         pnb = N - nfnblks*nbB;
         pmb = ((pnb+mu-1)/mu)*mu;
         pnb = ((pnb+nu-1)/nu)*nu;
      }
      else
         npnblks = pnb = pmb = 0;
   }
   #ifdef DEBUG
      printf("F%u: D=(%u,%u), NB=%u(%u)\n", idB, N, K, nbB, pnb);
   #endif
   #ifdef TCPLX
      if (CONJ)
         TB = (TA == AtlasNoTrans) ? AtlasConjTrans : AtlasNoTrans;
      else
         TB = (TA == AtlasNoTrans) ? AtlasTrans : AtlasNoTrans;
   #endif
/*
 * Consider if it would be better to use inner-product version that uses
 * only syrk instead of both syrk+gemm.  Need to include copy cost in time
 * estimate, since syrk+gemm requires up to 3 A/B copies, while syrk 1.
 */
   if (N <= ATL_VWsyrk_MAX_NB)
   {
      double timS;
      unsigned int nbS;
      float *tpf;
      for (i=ATL_VWsyrk_NCASES-1; i; i--)
      {
         nbS = ATL_GetVWipmenNB(i);
         if (nbS <= N)
            break;
      }
      if (nbS != N) /* see if this or bigger NB closer to N */
      {
         unsigned int nbL;
         nbL = ATL_GetVWipmenNB(i+1);
         i = (nbL-nb > nb-nbS) ? i+1 : i;
         nbS = ((N+ATL_SYRKK_NU-1)/ATL_SYRKK_NU)*ATL_SYRKK_NU;
      }
      if (nbS >= N)
         return(-1.0);
      tpf = (float*)(ATL_VIEW_syrk+ATL_VWsyrk_IDXMUL(i));
      timS = (*tpf*nbS)*nbS*K;
      #ifdef DEBUG
         printf("tim[G,S]=%e, %e\n", timB, timS);
      #endif
      if (timS <= timB)  /* if syrk wins w/o including copy cost */
         return(-timS);  /* save expense of computing copy cost */
      else               /* see if syrk wins incl copy A/B estimate */
      {
         const ATL_cparr_t *cpA;  
         @SKIP *cpB;
         ATL_cpflt_t *cpT;
         double ne, timCP;

         cpA = (TA == AtlasNoTrans) ? ATL_CpyFromANg_a1 : ATL_CpyFromATg_a1;
         @BEGINSKIP
         if (TA == AtlasNoTrans)
         {
            cpA = ATL_CpyFromANg_a1;
            #ifdef TCPLX
               cpB = (CONJ) ? ATL_CpyFromAHg_a1:ATL_CpyFromATg_a1;
            #else
               cpB = ATL_CpyFromATg_a1;
            #endif
         }
         else
         {
            #ifdef TCPLX
               cpA = (CONJ) ? ATL_CpyFromAHg_a1:ATL_CpyFromATg_a1;
            #else
               cpA = ATL_CpyFromATg_a1;
            #endif
            cpB = ATL_CpyFromANg_a1;
         }
         @ENDSKIP
         cpT = (ATL_cpflt_t*)(cpA+ATL_VWsyrk_MIN_A2BLK+ATL_VWsyrk_MIN_A2BLK+1);
         timCP = *cpT * nbS*K;
         #ifdef DEBUG
            printf("timS=%e+%e\n", timS, timCP);
         #endif
         timS += timCP;
         nbS = ((N+nu-1)/nu)*nu;
         ne = nbS;
         ne *= K;
         ATL_GetVWipmenA2BLK(i);
         cpT = (ATL_cpflt_t*)(cpA+i+i+1);
         timCP = *cpT * ne * 1.1;
         @BEGINSKIP
         ATL_GetVWipmenB2BLK(i);
         cpT = (ATL_cpflt_t*)(cpB+i+i+1);
         timCP += *cpT * ne;
         @ENDSKIP
         #ifdef DEBUG
            printf("timB=%e+%e\n", timB, timCP);
         #endif
         timB += timCP;
         if (timS <= timB) 
            return(-timS);
      }
   }
   Mjoin(PATL,@(vwf)InfoPop)(ip, idB, TA, TB, N, N, K, lda, lda, ldc, alpha,
                             beta, nfnblks, npnblks, mb, pmb, nfnblks,
                             npnblks, nb, pnb);
   return(timB);
}
