@ROUT damcases.idx samcases.idx
#
# In this file, any line beginning with a '#' is ignored, but the # must be in
# column 0.  All multiple whitespace is reduced to one space (i.e. used only
# to distinguish where words begin/end).  Lines may be extended by putting '\'
# as the *last* character of line.
#
# This file indexes the user-supplied matmul kernels, and has the 
# following format:
# ROUT='routine name' AUTH='author names' COMP='compiler name' CFLAGS='flags'
# ID=<id> NU=<nu> MU=<mu> KU=<ku> KBMAX=<kbmax> KBMIN=<kbmin>
# SSE=[0,1,2,3] X87=[0,1] BMABC=<0/1> BMAB=<0/1> JKMAB=<0/1> JKMABC=<0/1>
# AOUTER=<0/1> BETAN1=<0/1> KRUNTIME=<0/1> LDCTOP=<0/1> X87=<0/1>
# ASM=[asmlist], eg., asmlist is "GAS_x8664,GAS_x8632" or "GAS_SPARC"
# ASM defaults to no assembly dialect required.
# If NU/MU is negative, then the routine can only handle multiples of NU/MU.
#
@ROUT damcases.idx
ID=1 MU=4 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm2x4x1_sse2.S' \
     SSE=3 VLEN=2 KRUNTIME=1 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=2 MU=4 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm2x4x256_sse2.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=3 MU=6 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm3x3x256_sse2.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
#ID=4 MU=4 NU=1 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_dammm_nb4_sse2.S' \
#     SSE=3 KBMIN=4 KBMAX=4 ASM=GAS_x8664 KUISKB=1 \
#     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
ID=5 MU=2 NU=12 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm2x12x2_sse2.S' \
     SSE=3 VLEN=2 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=6 MU=2 NU=12 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm2x12x256_sse2.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=7 MU=12 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm12x3x256_avx.S' \
     SSE=3 VLEN=4 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=8 MU=6 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm6x3x256_sse3.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=9 MU=6 NU=3 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_damm6x3x4_sse3.S' \
     SSE=3 VLEN=2 KBMIN=4 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=10 MU=2 NU=12 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm2x12x2_sse2.S' \
     SSE=3 VLEN=2 KRUNTIME=1 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
ID=11 MU=12 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm12x3x1_avx.S' \
     SSE=3 VLEN=2 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=12 MU=4 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm4x4x2rp_arm.S' \
     ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=13 MU=12 NU=3 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm12x3x2_avx.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=1 KBMIN=6 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=14 MU=16 NU=2 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_damm16x2_kb4_avx.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=0 KBMIN=4 KBMAX=4 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=15 MU=5 NU=5 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm5x5x2_arm.S' \
     KBMIN=2 ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=16 MU=6 NU=1 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_amm6x1x1_x87.S' \
     ASM=GAS_x8664,GAS_x8632 KRUNTIME=1 x87=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=17 MU=24 NU=1 KU=8 AUTH='R. Clint Whaley' ROUT='ATL_damm24x1x8_sse2.S' \
     SSE=3 VLEN=2 KRUNTIME=1 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=18 MU=24 NU=1 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm24x1x1_sse2.S' \
     SSE=3 VLEN=2 KRUNTIME=1 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=19 MU=5 NU=5 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm5x5x2_armpf.S' \
     KBMIN=2 ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=20 MU=5 NU=5 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm5x5x1_armpf.S' \
     KBMIN=2 ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=21 MU=12 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm12x4x1_fma3.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx -mfma'
ID=22 MU=3 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm3x4x1_armpf.S' \
     KBMIN=2 ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3-fp16'
ID=23 MU=4 NU=2 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_amm4x2x4_kb4.c' \
     KRUNTIME=0 KBMIN=4 KBMAX=4 
ID=24 MU=6 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm6x4x1_fma3.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx -mfma'
ID=25 MU=6 NU=3 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm6x3x2_sse3.S' \
     SSE=3 VLEN=2 KBMIN=4 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=26 MU=4 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm4x4x256_sse3.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=27 MU=24 NU=1 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm24x1x256_sse3.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=28 MU=6 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm6x4x256_fma3.S' \
     SSE=5 VLEN=4 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3 -mfma'
ID=29 MU=12 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm12x4x256_fma3.S' \
     SSE=5 VLEN=4 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3 -mfma'
ID=30 MU=12 NU=4 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm12x4x2_fma3.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx -mfma'
ID=31 MU=6 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_dammm6x3r2x256_sse3.S' \
     SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=32 MU=14 NU=1 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_dkmmm14x1x256_sse3.S' \
     SSE=3 VLEN=2 KMAJ=2 ASM=GAS_x8664 KBMIN=2 KBMAX=256 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=33 MU=14 NU=1 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_dkmmm14x1x2_sse3.S' \
     SSE=3 VLEN=2 KMAJ=2 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=34 MU=24 NU=8 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm24x8x1_avxz.S' \
      ASM=GAS_x8664 VLEN=8 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=35 MU=32 NU=4 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm32x4x2rp_avxz.S' \
      ASM=GAS_x8664 VLEN=8 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
#ID=36 MU=32 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm32x4x256_avxz.S' \
#      ASM=GAS_x8664 KBMAX=320 COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=37 MU=32 NU=6 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm32x6x1_avxz.S' \
      ASM=GAS_x8664 VLEN=8 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=38 MU=16 NU=8 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_damm16x8x4_avxz.S' \
      ASM=GAS_x8664 VLEN=8 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=40 MU=24 NU=8 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm24x8x2_avxz.S' \
      ASM=GAS_x8664 VLEN = 8 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=41 MU=8 NU=8 KU=8 AUTH='R. Clint Whaley' ROUT='ATL_amm8x8x8_avxz.S' \
      VLEN=8 KRUNTIME=0 KBMAX=8 KBMIN=8 ASM=GAS_x8664 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=42 MU=5 NU=5 KU=2 AUTH="Whaley & Nuechterlein" \
      ROUT='ATL_damm5x5x2_aarch64.S' \
      KBMIN=2 ASM=GAS_ARM64 KRUNTIME=1 \
      COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=43 MU=4 NU=3 KU=6 AUTH='R. Clint Whaley' ROUT='ATL_dammm4x3x6_arm64.S' \
      KRUNTIME=1 KBMIN=12 ASM=GAS_ARM64 \
      COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=44 MU=4 NU=2 KU=2 AUTH="Whaley & Voronenko" ROUT='ATL_kmmm4x2x256_sse3.S' \
     KMAJ=2 KVEC=1 SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=45 MU=8 NU=1 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_kmmm8x1x256_L1pf.S' \
     KMAJ=2 KVEC=1 SSE=3 VLEN=2 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=46 MU=8 NU=6 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm8x6x2_fma3.S' \
     SSE=3 VLEN=4 ASM=GAS_x8664 KRUNTIME=1 LDCTOP=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx -mfma'
ID=47 MU=12 NU=6 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_dammm12x6x2_vsx.S' \
     VLEN=2 ASM=GAS_PPC KRUNTIME=1 LDCTOP=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mcpu=power8 -mvsx'
ID=48 MU=12 NU=4 KU=6 AUTH="Rakib Hasan" ROUT='ATL_damm12x4x6_aarch64-A57.S' \
     KBMIN=6 ASM=GAS_ARM64 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=49 MU=12 NU=4 KU=1 AUTH="Rakib Hasan" ROUT='ATL_damm12x4x1_aarch64-A53.S' \
     KBMIN=1 ASM=GAS_ARM64 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
@ROUT samcases.idx
@ROUT samcases.idx
ID=1 MU=16 NU=4 VLEN=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_samm16x4x1_av.c' \
     KRUNTIME=1 COMP='gcc' CFLAGS='-Os -maltivec -mabi=altivec -mcpu=970 -mtune=970 -mvrsave -fschedule-insns2 -fno-schedule-insns'
ID=2 MU=4 NU=6 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_samm4x6x2_arm.S' \
     ASM=GAS_ARM KRUNTIME=1 KBMIN=4 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=3 MU=4 NU=6 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_samm4x6x1_arm.S' \
     ASM=GAS_ARM KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mfpu=vfpv3'
ID=7 MU=24 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_samm24x3x256_avx.S' \
     SSE=3 VLEN=8 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=8 MU=8 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_sammm8x4x256_sse2.S' \
     SSE=2 VLEN=4 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
ID=11 MU=24 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm12x3x1_avx.S' \
     SSE=3 VLEN=8 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=13 MU=24 NU=3 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm12x3x2_avx.S' \
     SSE=3 VLEN=8 ASM=GAS_x8664 KRUNTIME=1 KBMIN=6 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx'
ID=16 MU=6 NU=1 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_amm6x1x1_x87.S' \
     ASM=GAS_x8664,GAS_x8632 KRUNTIME=1 x87=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=23 MU=4 NU=2 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_amm4x2x4_kb4.c' \
     KRUNTIME=0 KBMIN=4 KBMAX=4 
ID=24 MU=24 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_sammm24x4x256_fma3.S' \
     SSE=5 VLEN=8 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3 -mfma'
ID=25 MU=24 NU=4 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_samm24x4x2_fma3.S' \
     SSE=5 VLEN=8 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -mavx -mfma'
ID=26 MU=12 NU=1 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_skmmm12x1x4_sse3.S' \
     SSE=3 VLEN=4 KVEC=1 KMAJ=4 ASM=GAS_x8664 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
ID=27 MU=12 NU=1 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_skmmm12x1x256_sse3.S' \
     SSE=3 KVEC=1 KMAJ=4 VLEN=4 ASM=GAS_x8664 KRUNTIME=0 KBMIN=4 KBMAX=256 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
#ID=26 MU=12 NU=3 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_sammm12x3d2x256_sse3.S' \
#     SSE=3 DUPB=2 KBMAX=256 ASM=GAS_x8664 \
#     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse2'
ID=34 MU=48 NU=8 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm24x8x1_avxz.S' \
      VLEN=16 ASM=GAS_x8664 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=35 MU=64 NU=4 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm32x4x2rp_avxz.S' \
      VLEN=16 ASM=GAS_x8664 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
#ID=36 MU=64 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm32x4x256_avxz.S' \
#      ASM=GAS_x8664 KBMAX=320 COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=37 MU=64 NU=6 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_damm32x6x1_avxz.S' \
      VLEN=16 ASM=GAS_x8664 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=38 MU=32 NU=8 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_damm16x8x4_avxz.S' \
      VLEN=16 ASM=GAS_x8664 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=40 MU=48 NU=8 KU=2 AUTH='R. Clint Whaley' ROUT='ATL_damm24x8x2_avxz.S' \
      VLEN=16 ASM=GAS_x8664 KRUNTIME=1 \
      COMP='icc' CFLAGS='-x assembler-with-cpp -mmic'
ID=42 MU=4 NU=6 KU=2 AUTH="Nuechterlein & Whaley" \
      ROUT='ATL_samm4x6x2b_aarch64.S' \
      ASM=GAS_ARM64 KRUNTIME=1 KBMIN=4 \
      COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=43 MU=8 NU=4 KU=1 AUTH='R. Clint Whaley' ROUT='ATL_sammm8x4x256_sdup.S' \
      SSE=3 VLEN=4 KBMAX=256 ASM=GAS_x8664 \
      COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=44 MU=4 NU=2 KU=4 AUTH="Whaley & Voronenko" ROUT='ATL_kmmm4x2x256_sse3.S' \
      KMAJ=4 KVEC=1 VLEN=4 SSE=3 KBMAX=256 ASM=GAS_x8664 \
      COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=45 MU=8 NU=1 KU=4 AUTH='R. Clint Whaley' ROUT='ATL_kmmm8x1x256_L1pf.S' \
     KMAJ=4 KVEC=1 VLEN=4 SSE=3 KBMAX=256 ASM=GAS_x8664 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp -msse3'
ID=48 MU=24 NU=4 KU=6 AUTH="Rakib Hasan" ROUT='ATL_damm12x4x6_aarch64-A57.S' \
     KBMIN=6 ASM=GAS_ARM64 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
ID=49 MU=24 NU=4 KU=1 AUTH="Rakib Hasan" ROUT='ATL_damm12x4x1_aarch64-A53.S' \
     KBMIN=1 ASM=GAS_ARM64 KRUNTIME=1 \
     COMP='gcc' CFLAGS='-x assembler-with-cpp'
@ROUT samcases.idx
@ROUT atlas_gnuvec.h
#ifndef ATLAS_GNUVEC
   #define ATLAS_GNUVEC 1
   #ifndef TYPE
      #if defined(SREAL) || defined(SCPLX)
         #define TYPE float
      #else
         #define TYPE double
      #endif
   #endif
   #ifdef ATL_VSX
      #define ATL_NVREG 64
      #ifndef ATL_VLEN
         #define ATL_VLENb 16
         #if defined(SREAL) || defined (SCPLX)
            #define ATL_VLEN 4
         #else
            #define ATL_VLEN 2
         #endif
      #endif
   #elif defined(ATL_AltiVec)
      #define ATL_NVREG 32
      #ifndef ATL_VLEN
         #define ATL_VLENb 16
         #if defined(SREAL) || defined (SCPLX)
            #define ATL_VLEN 4
         #else
            #define ATL_VLEN 2
         #endif
      #endif
   #elif defined(ATL_AVXZ)
      #include "immintrin.h"
      #define ATL_NVREG 32
      #define ATL_VLENb 64
      #if defined(SREAL) || defined (SCPLX)
          #define ATL_VLEN 16
      #else
          #define ATL_VLEN 8
      #endif
      #if defined(SREAL) || defined (SCPLX)
         #define ATL_gvbcast(ptr_, v_) \
            v_ = _mm512_extload_ps((void*)(ptr_), _MM_UPCONV_PS_NONE, \
                                   _MM_BROADCAST_1X16, 0)
      #else
         #define ATL_gvbcast(ptr_, v_) \
            v_ = _mm512_extload_pd((void*)(ptr_), _MM_UPCONV_PD_NONE, \
                                   _MM_BROADCAST_1X8, 0)
      #endif
   #elif defined(ATL_AVXMAC) || defined(ATL_AVXFMA4) || defined(ATL_AVX)
      #ifdef ATL_GAS_x8664
         #define ATL_NVREG 16
      #else
         #define ATL_NVREG 8
      #endif
      #ifndef ATL_VLEN
         #define ATL_VLENb 32
         #if defined(SREAL) || defined (SCPLX)
            #define ATL_VLEN 8
         #else
            #define ATL_VLEN 4
         #endif
      #endif
      #if ATL_VLENb == 32
         #define ATL_gvbcast(ptr_, v_) \
            (v_) = __builtin_ia32_vbroadcastsd256((void*)(ptr_));
      #elif ATL_VLENb == 16 && defined(ATL_SSE3)
         #include "immintrin.h"
         #define ATL_gvbcast(ptr_, v_) \
            (v_) = _mm_loaddup_pd(ptr_);
@skip            (v_) = __builtin_ia32_movddup(ptr_);
      #endif
   #elif defined(ATL_SSE3) || defined(ATL_SSE2)
      #ifdef ATL_GAS_x8664
         #define ATL_NVREG 16
      #else
         #define ATL_NVREG 8
      #endif
      #ifndef ATL_VLEN
         #define ATL_VLENb 16
         #if defined(SREAL) || defined (SCPLX)
            #define ATL_VLEN 4
         #else
            #define ATL_VLEN 2
         #endif
      #endif
      #if defined(DREAL) || defined(DCPLX)
         #if defined(ATL_SSE3) && ATL_VLEN == 2
         #include "immintrin.h"
            #define ATL_gvbcast(ptr_, v_) \
            (v_) = _mm_loaddup_pd(ptr_);
@skip               (v_) = __builtin_ia32_movddup(ptr_);
         #endif
      #endif
   #elif defined(SREAL) || defined(SCPLX)   /* single-only stuff */
      #ifdef ATL_AltiVec
         #define ATL_NVREG 32
         #ifndef ATL_VLEN
            #define ATL_VLENb 16
            #define ATL_VLEN 4
         #endif
      #elif defined(ATL_SSE1)
         #ifdef ATL_GAS_x8664
            #define ATL_NVREG 16
         #else
            #define ATL_NVREG 8
         #endif
         #ifndef ATL_VLEN
            #define ATL_VLENb 16
            #define ATL_VLEN 4
         #endif
      #elif defined(ATL_NONIEEE) && ATL_NONIEEE != 0
         #ifdef ATL_NEON
            #define ATL_NVREG 16
            #ifndef ATL_VLEN
               #define ATL_VLENb 8
               #define ATL_VLEN 2
            #endif
         #elif defined(ATL_3DNow)
            #define ATL_NVREG 8
            #ifndef ATL_VLEN
               #define ATL_VLENb 16
               #define ATL_VLEN 4
            #endif
         #endif
      #endif
   #endif
   #if defined(ATL_VLEN) && !defined(ATL_VLENb)
      #if defined(SREAL) || defined (SCPLX)
         @iexp i 0 2 +
         @iwhile i < 32
            @iexp j @(i) 4 *
         #if ATL_VLEN == @(i)
            #define ATL_VLENb @(j)
         #endif
            @iexp i @(i) 2 *
         @endiwhile
      #else
         @iexp i 0 2 +
         @iwhile i < 64
            @iexp j @(i) 8 *
         #if ATL_VLEN == @(i)
            #define ATL_VLENb @(j)
         #endif
            @iexp i @(i) 2 *
         @endiwhile
      #endif
   #endif
   #ifndef ATL_VLENb
      #define ATL_VLEN 1
      #if defined(SREAL) || defined (SCPLX)
         #define ATL_VLENb 4
      #else
         #define ATL_VLENb 8
      #endif
      #if defined(ATL_GAS_x8664) || defined(ATL_GAS_x8632)
         #define ATL_NVREG 8
      #else
         #define ATL_NVREG 32
      #endif
   #endif
   #ifndef ATL_vec_t
      #if ATL_VLEN > 1
         typedef TYPE ATL_vec_t  __attribute__ ((vector_size (ATL_VLENb)));
      #else
         #define ATL_vec_t TYPE
      #endif
   #endif
/*
 * Setup macros to multiply and divide by VLEN using shifts
 */
   #if ATL_VLEN == 1
      #define ATL_DivByVLEN(i_) (i_)
      #define ATL_MulByVLEN(i_) (i_)
@iexp s 1 0 +
@iexp i 2 0 +
@iwhile i < 64
   #elif ATL_VLEN == @(i)
      #define ATL_DivByVLEN(i_) ((i_)>>@(s))
      #define ATL_MulByVLEN(i_) ((i_)<<@(s))
   @iexp s @(s) 1 +
   @iexp i @(i) 2 *
@endiwhile
   #else
      #define ATL_DivByVLEN(i_) ((i_)/ATL_VLEN)
      #define ATL_MulByVLEN(i_) ((i_)*ATL_VLEN)
   #endif
   #ifndef ATL_gvbcast
      #if ATL_VLEN == 1
         #define ATL_gvbcast(ptr_, v_) \
            { ATL_vec_t z={*(ptr_)}; v_ = z; }
      #elif ATL_VLEN == 2
         #define ATL_gvbcast(ptr_, v_) \
            { ATL_vec_t z={*(ptr_),*(ptr_)}; v_ = z; }
      #elif ATL_VLEN == 4
         #define ATL_gvbcast(ptr_, v_) \
            { ATL_vec_t z={*(ptr_),*(ptr_),*(ptr_),*(ptr_)}; v_ = z; }
      #elif ATL_VLEN == 8
         #define ATL_gvbcast(ptr_, v_) \
            v_ = {*(ptr_), *(ptr_), *(ptr_), *(ptr_), \
                  *(ptr_), *(ptr_), *(ptr_), *(ptr_)}
      #elif ATL_VLEN == 16
         #define ATL_gvbcast(ptr_, v_) \
         { \
            ATL_vec_t z_ = {*(ptr_), *(ptr_), *(ptr_), *(ptr_), \
                  *(ptr_), *(ptr_), *(ptr_), *(ptr_), \
                  *(ptr_), *(ptr_), *(ptr_), *(ptr_), \
                  *(ptr_), *(ptr_), *(ptr_), *(ptr_), \
                 }; \
            v_ = z_; \
         }
      #else
         #error "Cannot create gvbcast"
      #endif
   #endif
   
#endif
@ROUT atlas_amm.h
#ifndef ATLAS_AMM_H
   #define ATLAS_AMM_H
#include "atlas_misc.h"
#ifndef ATL_MaxMalloc
   #include "atlas_maxmalloc.h"
#endif
#ifndef ATL_MaxMalloc
   #define ATL_MaxMalloc 268435456UL
#endif
#include "atlas_misc.h"

#ifdef TREAL
   typedef void (*cm2am_t)(const size_t, const size_t, const SCALAR,
                           const TYPE*, const size_t, TYPE*);
   typedef void (*am2cm_t)(const size_t, const size_t, const SCALAR,
                           TYPE*, const size_t, const TYPE*);
   typedef void (*ablk2cmat_t)(const size_t, const size_t, const SCALAR,
                               const TYPE*, const SCALAR, TYPE *, const size_t);
   typedef void (*cmat2ablk_t)(const size_t, const size_t, const SCALAR,
                               const TYPE*, const size_t, const SCALAR,TYPE*);
   typedef void (*ammswp_t)(ATL_CINT, TYPE*,ATL_CSZT,TYPE*);
#else
   typedef void (*cm2am_t)(const size_t, const size_t, const SCALAR,
                           const TYPE*, const size_t, TYPE*, TYPE*);
   typedef void (*am2cm_t)(const size_t, const size_t, const SCALAR,
                           TYPE*, const size_t, const TYPE*, const TYPE*);
   typedef void (*ablk2cmat_t)(const size_t, const size_t, const SCALAR,
                               const TYPE*, const TYPE*, const SCALAR, 
                               TYPE *, const size_t);
   typedef void (*cmat2ablk_t)(const size_t, const size_t, const SCALAR,
                               const TYPE*, const size_t, const SCALAR,
                               TYPE*,TYPE*);
   typedef void (*ammswp_t)(ATL_CINT, TYPE*,ATL_CSZT,TYPE*,TYPE*);
#endif
typedef void (*ammkern_t)(ATL_CSZT,ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,
                          TYPE*, const TYPE*, const TYPE*, const TYPE*);
#define ushort unsigned short
#define uint unsigned int
#define uchar unsigned char
typedef struct amminfo amminfo_t;
struct amminfo
{
   cm2am_t a2blk, b2blk;
   ablk2cmat_t Cblk2cm, Cblk2cm_b1;
   cmat2ablk_t cm2Cblk;
   ammkern_t amm_b0, amm_b1, amm_bn, amm_k1_b0, amm_k1_b1, amm_k1_bn;
   ushort IDX, mb, nb, kb, kbmin, kbmax;
   uchar flag, mu, nu, ku, vlen;
};

typedef struct ipinfo ipinfo_t;  /* struct for inner-product based gemm */
struct ipinfo
{
   ammkern_t ammK1_b0, ammK1_b1; /* amm safe to use for KB0 calc */
   ammkern_t amm_b0, amm_b1;     /* amm to use after first K peel */
   cm2am_t a2blk, b2blk;         /* A/B copy funcs */
   ablk2cmat_t blk2c, blk2c_b1;  /* cpy from acc-maj blk to col-maj C */
   #ifdef TCPLX
      ammkern_t ammK1_bn;
      ammkern_t amm_bn;
      const TYPE *alpA, *alpB, *alpC, *ONE;
   #endif
   size_t nfnblks, npnblks; /* # of of full and partial blks along N */
   size_t nfmblks, npmblks; /* # of of full and partial blks along M */
   size_t nfkblks;          /* # of full kblks = (K-kb0)/kb */
   size_t incAk, incBk;     /* block-kb increment for A/B ptrs */
   size_t pincAm, incAm;    /* partial & full mb-block increment */
   size_t pincBn, incBn;    /* partial & full nb-block increment */
   size_t lda, ldb, ldc;    /* leading dim for all 3 matrices */
   #ifndef TCPLX
      TYPE alpA, alpB, alpC;
   #endif
   uint szC;                /* size of real portion of C workspace */
   uint pszA, szA;          /* size of real portion of part & full blks of A */
   uint pszB, szB;          /* size of real portion of part & full blks of B */
   ushort mF, nF;           /* size of final part of mat before copy */
   ushort mb, pmb, nb, pnb; /* full & partial blk factors for M & N */
   ushort kb;               /* sz of all K blks except first */
   ushort kb0;              /* K%kb or if zero, kb */
   ushort KB0;              /* if amm k-vec, ((kb0+ku-1)/ku)*ku, else kb0 */
   uchar nmu, nnu;          /* # of unrollings along each dim */
   uchar pnmu, pnnu;        /* # of unrollings in partial blocks */
   uchar nmuF, nnuF;        /* # of unrolling for final (remainder) block */
   uchar mu, nu, ku;        /* unrolling for each dim used by amm */
   uchar vlen;              /* vector length (needed for KVEC kerns) */
};
typedef struct rkinfo rkinfo_t;
struct rkinfo
{
   cm2am_t a2blk, b2blk;    /* A/B copy routs */
   ablk2cmat_t blk2C;       /* cpy from acc-maj blk to col-maj C */
   ammkern_t amm_b0;        /* beta=0 amm kern */
   #ifdef TCPLX
      ammkern_t amm_b1;     /* beta=1 amm kern (needed for complex) */
      ammkern_t amm_bn;     /* beta=n amm kern (needed for complex) */
      const TYPE *alpA, *alpB, *beta, *ONE;
   #endif
   size_t nfnblks, npnblks; /* # of of full and partial blks along N */
   size_t nfmblks, npmblks; /* # of of full and partial blks along M */
   size_t pincAm, incAm;    /* partial & full mb-block increment */
   size_t pincBn, incBn;    /* partial & full nb-block increment */
   size_t lda, ldb, ldc;    /* stride between row elts for each mat */
   #ifndef TCPLX
      TYPE alpA, alpB, beta;
   #endif
   uint szC;                /* size of real C blk in workspace */
   uint pszA, szA;          /* size of real portion of part & full blks of A */
   uint pszB, szB;          /* size of real portion of part & full blks of B */
   ushort idx;              /* kern array index */
   ushort mF, nF;           /* size of final part of mat before copy */
   ushort mb, pmb, nb, pnb; /* full & partial blk factors for M & N */
   ushort kb;               /* K from original problem */
   ushort KB;               /* ((kb+ku-1)/vl)*vl if kvec, else kb */
   uchar nmuF, nnuF;        /* # of unrollings in final M/N blocks */
   uchar nmu, nnu;          /* # of unrollings along each dim */
   uchar pnmu, pnnu;        /* # of unrollings in partial blocks */
   uchar mu, nu, ku;        /* unrolling for each dim used by amm */
   uchar vlen;              /* vector length (needed for KVEC kerns) */
};
#undef ushort
#undef uchar
#undef uint

enum ATL_AMMALG {ATL_amm1b, ATL_ammrkK, ATL_NMK};

int Mjoin(PATL,geGetAmmmIndx)(size_t M, size_t N, size_t K);
void Mjoin(PATL,geFillInIPInfo)
   (ipinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta, 
    size_t nfmblks, size_t npmblks, ATL_UINT mb, ATL_UINT pmb,
    size_t nfnblks, size_t npnblks, ATL_UINT nb, ATL_UINT pnb);
void Mjoin(PATL,sqFillInIPInfo)
   (ipinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta, ATL_UINT nb);
int Mjoin(PATL,tGetParCIndx)(ipinfo_t *ip, int P, size_t M, size_t N, size_t K);
int Mjoin(PATL,tGetParTriCIndx)(int P, int flg, size_t N, size_t K, int *NB);

int Mjoin(PATL,tGetIPInfo_tMN)
   (ipinfo_t *ip, int P, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, 
    size_t M, size_t N, size_t K, const SCALAR alpha, size_t lda, size_t ldb,
    const SCALAR beta, size_t ldc);
@whiledef sh ge sq
void Mjoin(PATL,@(sh)ComputeIPInfo)
   (ipinfo_t *ip, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, 
    size_t M, size_t N, size_t K, size_t lda, size_t ldb, size_t ldc, 
    const SCALAR alpha, const SCALAR beta);
@endwhile
@whiledef rt iploopsNK iploopsMK iploopsK iploopsNMK iploopsNMK
void Mjoin(PATL,@(rt))
   (ipinfo_t *ip, size_t i, size_t j, const TYPE *A, const TYPE *B, TYPE *C, 
    const int MVS, TYPE *a, TYPE *b, TYPE *rC, TYPE *iC, 
    const SCALAR beta, const ablk2cmat_t blk2c);
@endwhile
@whiledef rt ge sq rk
int Mjoin(PATL,@(rt)GetAmmInfoInt)(char wh, int idx);
void *Mjoin(PATL,@(rt)GetAmmInfoPtr)(int idx, int what, int alp, int bet);
@endwhile
@beginskip
void Mjoin(PATL,GetBestKBInfo)
   (rkinfo_t*,rkinfo_t*,enum ATLAS_TRANS,enum ATLAS_TRANS,ATL_CSZT,
    ATL_CSZT,ATL_CSZT,size_t,size_t,size_t,const SCALAR,const SCALAR);
@endskip
@whiledef sf _tNK _tK
int Mjoin(PATL,tGetRKInfo@(sf))
   (rkinfo_t*, int, enum ATLAS_TRANS, enum ATLAS_TRANS,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta);
@endwhile
void Mjoin(PATL,GetRKInfo)
   (rkinfo_t*, int, enum ATLAS_TRANS, enum ATLAS_TRANS,
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta);
int Mjoin(PATL,GetSyrkIdx)(unsigned int flg, ATL_CSZT N, ATL_CSZT K, double);
double Mjoin(PATL,sSyrkTimeEst)
   (int id, unsigned int flg, size_t N, size_t K, double symul);
int Mjoin(PATL,GetSyrkInfo)
   (amminfo_t*,int, enum ATLAS_TRANS,ATL_CSZT,ATL_CSZT,int);
void Mjoin(PATL,GetSyrkOP)
   (rkinfo_t *out, int flag, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB,
    ATL_CSZT N, ATL_CSZT K, size_t lda, size_t ldc, 
    const SCALAR alpha, const SCALAR beta);
@whiledef info GetAmmmInfo GetRankKInfo
int Mjoin(PATL,@(info))
   (amminfo_t *out, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, ATL_CSZT M, 
    ATL_CSZT N, ATL_CSZT K, const SCALAR alpha, const SCALAR beta);
@endwhile
#ifdef TREAL
int Mjoin(PATL,GetTrsmInfo)
   (amminfo_t *out, int ialp, enum ATLAS_TRANS TA, ATL_CSZT M, ATL_CSZT N, 
    const SCALAR beta);
#endif
int Mjoin(PATL,tGetAmmmInfo)
   (amminfo_t *out, const unsigned int P, enum ATLAS_TRANS TA, 
    enum ATLAS_TRANS TB, ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, 
    const SCALAR alpha, const SCALAR beta);
ablk2cmat_t Mjoin(PATL,tGetSyammInfo)
   (amminfo_t *out, const int P, enum ATLAS_TRANS TA, ATL_CSZT N, ATL_CSZT K,
    const SCALAR alpha, const SCALAR beta);
ablk2cmat_t Mjoin(PATL,tGetSyammInfo_K)
   (amminfo_t *out, const int P, enum ATLAS_TRANS TA, ATL_CSZT N, ATL_CSZT K);


int Mjoin(PATL,ammm_syrk)
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT,ATL_CSZT,
    const SCALAR,const TYPE*,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT);
void Mjoin(PATL,oploopsM)
   (rkinfo_t *rkinf, size_t i, size_t j, const TYPE *A, const TYPE *B, TYPE *C,
    int MV, TYPE *a, TYPE *b, TYPE *rC, TYPE *iC);
void Mjoin(PATL,oploopsN)
   (rkinfo_t *rkinf, size_t i, size_t j, const TYPE *A, const TYPE *B, TYPE *C,
    int MV, TYPE *a, TYPE *b, TYPE *rC, TYPE *iC);
void Mjoin(PATL,opblk)
   (rkinfo_t *op, size_t i, size_t j, const TYPE *A, const TYPE *B, TYPE *C,
    TYPE *pA, TYPE *pAn, TYPE *pB, TYPE *pBn, TYPE *rC, TYPE *iC);
@beginskip
void Mjoin(PATL,ammmM)
   (rkinfo_t *rkinf, int N, int nb, int nnu, TYPE *a, int INCA,
    const TYPE *b, TYPE *c, const TYPE *A, TYPE *C, const SCALAR beta);
void Mjoin(PATL,ammmN)
   (rkinfo_t *rkinf, int M, int mb, int nmu, const TYPE *a, TYPE *b, int INCB,
    TYPE *c, const TYPE *B, TYPE *C, const SCALAR beta);
@endskip

void Mjoin(PATL,ammmK)
   (amminfo_t*, const int mb, const int nmu, const int nb, const int nnu, 
    ATL_CINT nfkblks, const int kb, const int kb0, const int KB0, const TYPE *A,
    const size_t lda, const size_t incAk, const TYPE*B, const size_t ldb, 
    const size_t incBk, const ablk2cmat_t blkc2c, TYPE*, const size_t ldc, 
    TYPE *a, ATL_CINT inca, TYPE *b, ATL_CINT incb, TYPE *rC, TYPE *iC, 
    const SCALAR alpA, const SCALAR alpB, const SCALAR alpC, const SCALAR beta);

void Mjoin(PATL,gemm)
   (const enum ATLAS_TRANS,const enum ATLAS_TRANS,ATL_CINT,ATL_CINT,ATL_CINT, 
    const SCALAR, const TYPE*,ATL_CINT,const TYPE*,ATL_CINT,const SCALAR,
    TYPE*,ATL_CINT);
void Mjoin(PATL,ammm)
   (enum ATLAS_TRANS,enum ATLAS_TRANS,ATL_CSZT,ATL_CSZT,ATL_CSZT, const SCALAR,
    const TYPE*,ATL_CSZT,const TYPE*,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT);
#ifdef TREAL
int Mjoin(PATL,rk4n4)(enum ATLAS_TRANS,ATL_CSZT,const SCALAR,const TYPE*,
                      ATL_CSZT,const TYPE*,ATL_CSZT,TYPE*,ATL_CSZT);
#endif
int Mjoin(PATL,ammm_rk2)
   (enum ATLAS_TRANS,enum ATLAS_TRANS,ATL_CSZT,ATL_CSZT, const SCALAR,
    const TYPE*,ATL_CSZT,const TYPE*,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT);
@multidef rt ammmNKM ammmKNMK ammmKMNK
@whiledef rt ammm_1b ammm_rkK ammm_IP ammm_tN ammm_aliased_rkK ammmMNK ammmREC
int Mjoin(PATL,@(rt))
   (enum ATLAS_TRANS,enum ATLAS_TRANS,ATL_CSZT,ATL_CSZT,ATL_CSZT, const SCALAR,
    const TYPE*,ATL_CSZT,const TYPE*,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT);
@endwhile
int Mjoin(PATL,ammmNMK)
   (enum ATLAS_TRANS,enum ATLAS_TRANS,ATL_CSZT,ATL_CSZT,ATL_CSZT, 
    const SCALAR,const TYPE*,ATL_CSZT,const TYPE*,ATL_CSZT,const SCALAR,
    TYPE*,ATL_CSZT);
void Mjoin(PATL,syrk_IP)
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const SCALAR, const TYPE*, ATL_CSZT, const SCALAR, TYPE*,ATL_CSZT);
#ifdef TCPLX
void Mjoin(PATL,herk_IP)
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const TYPE, const TYPE*, ATL_CSZT, const TYPE, TYPE*,ATL_CSZT);
#endif
@whiledef rt OP amm
int Mjoin(PATL,syrk_@(rt))
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const SCALAR, const TYPE*, ATL_CSZT, const SCALAR, TYPE*,ATL_CSZT);
#ifdef TCPLX
int Mjoin(PATL,herk_@(rt))
   (const enum ATLAS_UPLO, const enum ATLAS_TRANS, ATL_CSZT, ATL_CSZT,
    const TYPE, const TYPE*, ATL_CSZT, const TYPE, TYPE*,ATL_CSZT);
#endif
@endwhile
/*
 * Functions for testing Info return flag
 */
#define ATL_AMMFLG_KRUNTIME(flg_) ((flg_) & 1)
#define ATL_AMMFLG_KMAJOR(flg_) ((flg_) & 2)
/*
 * Helper functions we'd like to inline
 */
#ifdef ATL_GLOBIDX
static TYPE INLINE *IdxAw_rkK(rkinfo_t *op, TYPE *A, size_t i)
{  /* index A workspace for ith block for rank-K (only 1 kb) */
   size_t m;

   m = op->nfmblks;
   m = Mmin(m, i);
   i -= m;
   A += (m * op->szA + i * op->pszA)SHIFT;
   return(A);
}

static TYPE INLINE *IdxAw_ip(ipinfo_t *ip, TYPE *A, size_t i, size_t k)
{  /* index A workspace for inner-product gemm */
   const size_t nfmblks = ip->nfmblks, szA = (i < nfmblks) ? ip->szA:ip->pszA;
   size_t m;

   m = Mmin(nfmblks, i);
   i -= m;
   m = (m * ip->szA + i * szA) * (ip->nfkblks+1);  /* offset to kpan */
   m = (m+k*szA)SHIFT;
   return(A+m);
}

static TYPE INLINE *IdxBw_ip(ipinfo_t *ip, TYPE *B, size_t k, size_t j)
{  /* index B workspace for inner-product gemm */
   const size_t nfnblks = ip->nfnblks, szB = (j < nfnblks) ? ip->szB:ip->pszB;
   size_t n;

   n = Mmin(nfnblks, j);
   j -= n;
   n = (n * ip->szB + j * szB) * (ip->nfkblks+1);  /* offset to kpan */
   n = (n+k*szB)SHIFT;
   return(B+n);
}

static const TYPE INLINE *IdxA_ip
   (ipinfo_t *ip, const TYPE *A, size_t i, size_t k)
{  /* index global A base-pointer to find (i,k) block for inner-product gemm */
   size_t m;

   m = ip->nfmblks;
   m = Mmin(m, i);
   i -= m;
   A += m * ip->incAm + i * ip->pincAm;
   A += k * ip->incAk;
   return(A);
}

static const INLINE TYPE *IdxB_ip
   (ipinfo_t *ip, const TYPE *B, size_t k, size_t j)
{  /* index global A base-pointer to find (i,k) block for inner-product gemm */
   size_t n;

   n = ip->nfnblks;
   n = Mmin(n, j);
   j -= n;
   B += ip->incBn * n + ip->pincBn * j;
   B += k * ip->incBk;
   return(B);
}
static INLINE TYPE *IdxC_ip(ipinfo_t *ip, TYPE *C, size_t i, size_t j)
{
   size_t n;

   n = ip->nfmblks;
   n = Mmin(n, i);
   i -= n;
   C += (ip->mb * n + ip->pmb * i)SHIFT;
   n = ip->nfnblks;
   n = Mmin(n, j);
   j -= n;
   C += (ip->nb * n + ip->pnb * j)*((ip->ldc) SHIFT);
   return(C);
}
#endif

#endif  /* end include file guard */
@ROUT emit_uamm
@extract -b @(topd)/cw.inc lang=C -def cwdate 2012 -def cwdate 2013  -def cwdate 2014 
#include "atlas_misc.h"
#include "atlas_mmparse.h"
#include "atlas_sys.h"
   static int UID=0, UIL=1;
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
   fprintf(stderr, "   -d <outdir>: directory to dump files to\n");
   fprintf(stderr, "   -i <infile> : can be repeated for multiple files\n");
   fprintf(stderr, "   -k <unique K cleanup index file> : \n");
   fprintf(stderr, "   -K <K cleanup by NB file> \n");
   fprintf(stderr, "   -r <rank-K kernel file> \n");
   fprintf(stderr, "   -s <square-case kernel file>\n");

   fprintf(stderr,
      "   -I <ID> : unique non-negative ID for header/kern files\n");
   exit(ierr ? ierr : -1);
}

ATL_mmnode_t *GetFlags(int nargs, char **args, char *PRE, char **DOUT,
                       char **UKIN, char **KCIN, char **RKIN, char **SQIN)
{
   int i, j=0, n, k;
   char pre='d';
   *SQIN = *RKIN = *UKIN = *KCIN = *DOUT = NULL;
   ATL_mmnode_t *mmb=NULL, *mmp, *mp;

   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        break;
      case 's':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *SQIN = DupString(args[i]);
        break;
      case 'k':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *UKIN = DupString(args[i]);
        break;
      case 'K':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *KCIN = DupString(args[i]);
        break;
      case 'I':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        UID = atol(args[i]);
        for (k=10; k <= UID; k *= 10)
           UIL++;
        break;
      case 'd':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *DOUT = DupString(args[i]);
        break;
      case 'i':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        mmp = ReadMMFile(args[i]);
        if (mmb)
        {
           ATL_mmnode_t *mp;
           for (mp=mmb; mp->next; mp = mp->next);
           mp->next = mmp;
        }
        else
           mmb = mmp;
        break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   *PRE = pre;
   if (!(*DOUT))
   {
      *DOUT = DupString("dMake_amm");
      (*DOUT)[0] = pre;
   }
   return(mmb);
}

char *GetVecStr(char pre, int vlen)
{
   if (vlen == 1)
      return("scalar");
   #ifdef ATL_AVX
      if (pre == 'd' || pre == 'z')
      {
         if (vlen == 4)
            return("avx");
         else if (vlen == 2)
            return("sse");
      }
      else if (pre == 's' || pre == 'c')
      {
         if (vlen == 8)
            return("avx");
         else if (vlen == 4)
            return("sse");
      }
   #elif defined(ATL_SSE1)
      #ifdef ATL_SSE2
         if ((pre == 'd' || pre == 'z') && vlen == 2)
               return("sse");
      #endif
      if ((pre == 's' || pre == 'c') && vlen == 4)
         return("sse");
   #endif
/*
 * Any vector length > 1 that isn't one of our known cases uses gnuvec
 */
   return("gvec");
}

void PrintBegBlock(char pre, ATL_mmnode_t *mmb, char *nam, FILE *fp)
{
   ATL_mmnode_t *mp;
   char PRE = toupper(pre);
   int i;

   if (nam)
   {
      fprintf(fp, "#ifndef ATLAS_%cUAMM_%s_H\n   #define ATLAS_%cUAMM_%s_H\n\n",
              PRE, nam, PRE, nam);
      fprintf(fp, "#include \"atlas_amm.h\"\n");
   }
   else
      fprintf(fp, "#ifndef ATLAS_%cUAMM_H\n   #define ATLAS_%cUAMM_H\n\n",
              PRE, PRE);
/*
 * Count mmb, and print def of NCASES
 */
   if (!nam || strstr(nam, "RANKK") == NULL)
   {
      for (mp=mmb,i=0; mp; i++, mp = mp->next);

      fprintf(fp, "#ifdef ATL_UAMM_NCASES\n");
      fprintf(fp, "   #if ATL_UAMM_NCASES != %d\n", i);
      fprintf(fp, "      #error \"NCASES MISMATCH!\"\n");
      fprintf(fp, "   #endif\n");
      fprintf(fp, "#else\n");
      fprintf(fp, "   #define ATL_UAMM_NCASES %d\n", i);
      fprintf(fp, "#endif\n");
   }
}

char *GetHName(char pre, char *outd, char *bnam)
{
   int i, NOBASE=0;
   char *fnam;
   if (!bnam)
   {
      NOBASE = 1;
      bnam = "";
   }
   i = strlen(outd) + strlen(bnam) + 16+UIL;

   fnam = malloc(i*sizeof(char));
   assert(fnam);
   if (NOBASE)
      sprintf(fnam, "%s/atlas_%cu%damm.h", outd, pre, UID);
   else
      sprintf(fnam, "%s/atlas_%cu%damm_%s.h", outd, pre, UID, bnam);
   return(fnam);
}

FILE *StandHStart(char pre, ATL_mmnode_t *mmb, char *outd, char *bnam)
{
   char *fnam;
   FILE *fp;
   int i;

   assert(outd);
   fnam = GetHName(pre, outd, bnam);
   fp = fopen(fnam, "w");
   assert(fp);
   if (bnam)
   {
      for (i=0; bnam[i]; i++)
         fnam[i] = toupper(bnam[i]);
      fnam[i] = '\0';
      PrintBegBlock(pre, mmb, fnam, fp);
   }
   else
      PrintBegBlock(pre, mmb, NULL, fp);
   free(fnam);
   return(fp);
}

static int Mylcm(const int M, const int N)
/*
 * Returns least common multiple (LCM) of two positive integers M & N by
 * computing greatest common divisor (GCD) and using the property that
 * M*N = GCD*LCM.
 */
{
   register int tmp, max, min, gcd=0;

   if (M != N)
   {
      if (M > N) { max = M; min = N; }
      else { max = N; min = M; }
      if (min > 0)  /* undefined for negative numbers */
      {
         do  /* while (min) */
         {
            if ( !(min & 1) ) /* min is even */
            {
               if ( !(max & 1) ) /* max is also even */
               {
                  do
                  {
                     min >>= 1;
                     max >>= 1;
                     gcd++;
                     if (min & 1) goto MinIsOdd;
                  }
                  while ( !(max & 1) );
               }
               do min >>=1 ; while ( !(min & 1) );
            }
/*
 *          Once min is odd, halve max until it too is odd.  Then, use
 *          property that gcd(max, min) = gcd(max, (max-min)/2)
 *          for odd max & min
 */
MinIsOdd:
            if (min != 1)
            {
               do  /* while (max >= min */
               {
                  max -= (max & 1) ? min : 0;
                  max >>= 1;
               }
               while (max >= min);
            }
            else return( (M*N) / (1<<gcd) );
            tmp = max;
            max = min;
            min = tmp;
         }
         while(tmp);
      }
      return( (M*N) / (max<<gcd) );
   }
   else return(M);
}

void GenAmmSum(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *rkb, char *outd)
{
   ATL_mmnode_t *mp, *p66;
   char *fnam;
   FILE *fp;
   char *type = "unsigned short";
   int i, n, maxb, maxNB, maxMB, maxKB, maxkmaj;
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};
   double mfB;

   fp = StandHStart(pre, mmb, outd, "sum");
   maxkmaj = maxNB = maxKB = maxMB = 0;
   mfB = 0.0;
   for (n=0,mp=mmb; mp; n++, mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         maxkmaj = Mmax(maxkmaj, mp->vlen);
      maxMB = Mmax(maxMB, mp->mbB);
      maxNB = Mmax(maxNB, mp->nbB);
      maxKB = Mmax(maxKB, mp->kbB);
      mfB = Mmax(mfB, mp->mflop[0]);
   }
   if (maxkmaj == 1)
      maxkmaj = 0;
   maxb = Mmax(maxMB, maxNB);
   maxb = Mmax(maxb, maxKB);
   fprintf(fp, "\n#define ATL_UAMM_MAXMB %d\n", maxMB);
   fprintf(fp, "#define ATL_UAMM_MAXNB %d\n", maxNB);
   fprintf(fp, "#define ATL_UAMM_MAXKB %d\n", maxKB);
   fprintf(fp, "#define ATL_UAMM_MAXKMAJ %d\n\n", maxkmaj);

   for (mp=mmb; mp && mp->next; mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_AMM_LMU %d\n", mp->mu);
   fprintf(fp, "#define ATL_AMM_LNU %d\n", mp->nu);
   fprintf(fp, "#define ATL_AMM_LKU %d\n", mp->ku);
   fprintf(fp, "#define ATL_AMM_LLCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_LLCMU %d\n\n",
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
/*
 * Find smallest case achieving 2/3 of maximal performance
 */
   for (i=0,mp=mmb; mp && mp->mflop[0]*1.5 < mfB; i++, mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_UAMM_66IDX %d\n", i);
   fprintf(fp, "#define ATL_UAMM_66MB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_UAMM_66NB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_UAMM_66KB %d\n", mp->kbB);
   fprintf(fp, "#define ATL_AMM_66LCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_66LCMU %d\n\n",
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   fprintf(fp, "#define ATL_UAMM_66RATIO %1.4lf\n\n", mp->mflop[0]/mfB);
/*
 * Find smallest case achieving 98% of maximal performance
 */
   for (i=0,mp=mmb; mp && mp->mflop[0] < 0.98*mfB; i++, mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_UAMM_98IDX %d\n", i);
   fprintf(fp, "#define ATL_UAMM_98MB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_UAMM_98NB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_UAMM_98KB %d\n", mp->kbB);
   fprintf(fp, "#define ATL_AMM_98LCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_98LCMU %d\n\n",
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   fprintf(fp, "#define ATL_UAMM_98RATIO %1.4lf\n\n", mp->mflop[0]/mfB);
   assert(rkb == NULL);

   fprintf(fp, "#define ATL_AMMFLG_KRUNTIME(flg_) ((flg_) & 1)\n");
   fprintf(fp, "#define ATL_AMMFLG_KMAJOR(flg_) ((flg_) & 2)\n");

   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenPerfFile(char pre, ATL_mmnode_t *mmb, char *outd, char *nm)
{
   ATL_mmnode_t *mp;
   #define NTHRSH 11
   int THRSH[NTHRSH] = {25, 33, 50, 66, 75, 80, 85, 90, 95, 98, 99};
   int idxT[NTHRSH];
   ATL_mmnode_t *mpT[NTHRSH];
   char *fnam;
   FILE *fp;
   char *type = "float";
   double mfMax=0.0;
   int i, j, n, maxb, maxNB, maxMB, maxKB, maxkmaj, idxMax=0;
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};

   for (i=0; i < NTHRSH; i++)
      mpT[i] = NULL;
   fp = StandHStart(pre, mmb, outd, nm);
   for (n=0,mp=mmb; mp; n++, mp = mp->next)
   {
      if (mp->mflop[0] > mfMax)
      {
         mfMax = mp->mflop[0];
         idxMax = n;
      }
   }
   fprintf(fp, "#define ATL_UAMM_MAXMFLOP %le /* (%.2f)*/ \n",
           mfMax, mfMax);
   fprintf(fp, "#define ATL_UAMM_MAXMFLOPIDX %d\n\n", idxMax);
   for (n=0,mp=mmb; mp; mp = mp->next, n++)
   {
      double mf = mp->mflop[0] / mfMax;
      for (i=0; i < NTHRSH; i++)
      {
         if (!mpT[i] && THRSH[i]*0.01*mfMax < mp->mflop[0])
         {
            mpT[i] = mp;
            idxT[i] = n;
         }
      }
   }
   for (i=0; i < NTHRSH; i++)
   {
      mp = mpT[i];
      fprintf(fp, "#define ATL_UAMM_%dLCMU %d\n", THRSH[i],
              Mylcm(Mylcm(mp->mu,mp->nu),mp->ku));
      fprintf(fp, "#define ATL_UAMM_%dLCMMN %d\n", THRSH[i],
              Mylcm(mp->mu,mp->nu));
      fprintf(fp, "#define ATL_UAMM_%dKB %d\n", THRSH[i],
              mp->kbB);
      fprintf(fp, "#define ATL_UAMM_%dNB %d\n", THRSH[i],
              mp->nbB);
      fprintf(fp, "#define ATL_UAMM_%dMB %d\n", THRSH[i],
              mp->mbB);
      fprintf(fp, "#define ATL_UAMM_%dIDX %d\n", THRSH[i],
              idxT[i]);
   }
   fprintf(fp, "\n");

   fprintf(fp, "static const float ATL_UAMM_PERF[%d] =", n);
   fprintf(fp, "   /* %% of performance of best kernel */\n{\n");
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d */\n", mp->mflop[0]/mfMax,
              (mp->next)?',':' ', j, mp->kbB);
   fprintf(fp, "};\n\n");

   fprintf(fp, "static const float ATL_UAMM_SPDUPNXT[%d] =", n);
   fprintf(fp, "   /* speedup of next higher NB */\n{\n");
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      double mf = (mp->next) ? mp->next->mflop[0] : mp->mflop[0];
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d vs. %d */\n", mf/mp->mflop[0],
              (mp->next)?',':' ', j, mp->kbB, mp->next?mp->next->kbB:mp->kbB);
   }
   fprintf(fp, "};\n\n");

   fprintf(fp, "#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenBlockingFile(char pre, ATL_mmnode_t *mmb, char *outd, char *nm)
{
   ATL_mmnode_t *mp;
   char *fnam;
   FILE *fp;
   char *type = "unsigned short";
   int i, n, maxb, maxNB, maxMB, maxKB, maxkmaj;
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};

   fp = StandHStart(pre, mmb, outd, nm);
   maxkmaj = maxNB = maxKB = maxMB = 0;
   for (n=0,mp=mmb; mp; n++, mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         maxkmaj = Mmax(maxkmaj, mp->vlen);
      maxMB = Mmax(maxMB, mp->mbB);
      maxNB = Mmax(maxNB, mp->nbB);
      maxKB = Mmax(maxKB, mp->kbB);
   }
   if (maxkmaj == 1)
      maxkmaj = 0;
   maxb = Mmax(maxMB, maxNB);
   maxb = Mmax(maxb, maxKB);
   fprintf(fp, "#define ATL_UAMM_MAXMB %d\n", maxMB);
   fprintf(fp, "#define ATL_UAMM_MAXNB %d\n", maxNB);
   fprintf(fp, "#define ATL_UAMM_MAXKB %d\n", maxKB);
   fprintf(fp, "#define ATL_UAMM_MAXKMAJ %d\n", maxkmaj);
   fprintf(fp, "\n");

   if (maxb <= 255)
      type = "unsigned char";
   for (i=0; i < 3; i++)
   {
      int j;
      fprintf(fp, "static const %s ATL_UAMM_%cBs[%d] =\n{\n",
              type, bc[i], n);
      for (j=0,mp=mmb; mp; j++,mp = mp->next)
      {
         int b;
         if (bc[i] == 'M')
            b = mp->mbB;
         else if (bc[i] == 'N')
            b = mp->nbB;
         else if (bc[i] == 'K')
            b = mp->kbB;
         if (mp->next)
            fprintf(fp, "%8d,  /* index %d */\n", b, j);
         else
            fprintf(fp, "%8d   /* index %d */\n", b, j);
      }
      fprintf(fp, "};\n\n");
   }
   for (i=0; i < 3; i++)
   {
      int j;
      fprintf(fp, "static const %s ATL_UAMM_%cUs[%d] =\n{\n",
              type, bc[i], n);
      for (j=0,mp=mmb; mp; j++,mp = mp->next)
      {
         int b;
         if (bc[i] == 'M')
            b = mp->mu;
         else if (bc[i] == 'N')
            b = mp->nu;
         else if (bc[i] == 'K')
         {
            if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
               b = mp->ku;
            else
               b = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->ku : mp->kbB;
         }
         if (mp->next)
            fprintf(fp, "%8d,  /* index %d */\n", b, j);
         else
            fprintf(fp, "%8d   /* index %d */\n", b, j);
      }
      fprintf(fp, "};\n\n");
   }
   fprintf(fp, "static const %s ATL_UAMM_KBMINs[%d] =\n{\n", type, n);
   for (i=0,mp=mmb; mp; i++,mp = mp->next)
   {
      if (mp->next)
         fprintf(fp, "%8d,  /* index %d */\n", mp->kbmin, i);
      else
         fprintf(fp, "%8d   /* index %d */\n", mp->kbmin, i);
   }
   fprintf(fp, "};\n\n");
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenFlagH(char pre, ATL_mmnode_t *mmb, char *outd, char *nm)
{
   FILE *fp;
   int j, n;
   ATL_mmnode_t *mp;

   fp = StandHStart(pre, mmb, outd, nm);

   for (n=0,mp=mmb; mp; n++,mp = mp->next);

   fprintf(fp, "static const unsigned char ATL_UAMM_KFLAG[%d] =\n{\n", n);
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      unsigned char flag=FLAG_IS_SET(mp->flag, MMF_KRUNTIME) ? 1 : 0;
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         flag |= 2;
      if (mp->next)
         fprintf(fp, "%6d,  /* index %d */\n", flag, j);
      else
         fprintf(fp, "%6d   /* index %d */\n", flag, j);
   }
   fprintf(fp, "};\n\n");
   fprintf(fp, "#define ATL_AMM_KRUNTIME(idx_) (ATL_AMM_KFLAG[idx_] & 1)\n");
   fprintf(fp, "#define ATL_AMM_KMAJOR(idx_) (ATL_AMM_KFLAG[idx_] & 2)\n");
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void SpewForthC2MProto(char pre, FILE *fp0, FILE *fp1, int mu, int nu)
{
   char ac[3] = {'1', 'n', 'X'};
   char bc[4] = {'0', '1', 'n', 'X'};
   int ia, ib;
   for (ia=0; ia < 3; ia ++)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp0, "void ATL_%cu%dablk2cmat_%dx%d_a%c_b%c\n",
                 pre, UID, mu, nu, ac[ia], bc[ib]);
         if (pre == 'z' || pre == 'c')
            fprintf(fp0, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         else
            fprintf(fp0, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         fprintf(fp1, "void ATL_%cu%dcmat2ablk_%dx%d_a%c_b%c\n",
                 pre, UID, mu, nu, ac[ia], bc[ib]);
         if (pre == 'z' || pre == 'c')
            fprintf(fp1, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,const SCALAR,TYPE*,TYPE*);\n");
         else
            fprintf(fp1, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,const SCALAR,TYPE*);\n");
      }
   }
}

void SpewForthC2BDecl(char pre, ATL_mmnode_t *mmb, FILE *fp, char *rt,
                      char alp, char bet)
{
   ATL_mmnode_t *mp;
   int j;

   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      fprintf(fp, "   ATL_%cu%d%s_%dx%d_a%c_b%c",
              pre, UID, rt, mp->mu,mp->nu, alp, bet);
      if (mp->next)
         fprintf(fp, ",  /* index %d */\n", j);
      else
         fprintf(fp, "   /* index %d */\n", j);
      }
      fprintf(fp, "};\n\n");
}

void GenC2BLK(char pre, ATL_mmnode_t *mmb, char *outd, char *suff)
{
   FILE *fp0, *fp1;
   ATL_mmnode_t *mp;
   int ia, ib;
   char ac[3] = {'1', 'n', 'X'};
   char bc[4] = {'0', '1', 'n', 'X'};
   char *fnam;

   if (!suff)
   {
      fp0 = StandHStart(pre, mmb, outd, "ablk2cmat");
      fp1 = StandHStart(pre, mmb, outd, "cmat2ablk");
   }
   else
   {
      fnam = malloc(sizeof(char)*(strlen(suff) + 10));
      assert(fnam);
      strncpy(fnam, "ablk2cmat", 9);
      strcpy(fnam+9, suff);
      fp0 = StandHStart(pre, mmb, outd, fnam);
      strncpy(fnam, "cmat2ablk", 9);
      fp1 = StandHStart(pre, mmb, outd, fnam);
   }
   fprintf(fp0, "\n");
   fprintf(fp1, "\n");
/*
 * Crank out prototypes
 */
   SpewForthC2MProto(pre, fp0, fp1, mmb->mu, mmb->nu);
   for (mp=mmb->next; mp; mp = mp->next)
   {
      ATL_mmnode_t *p;
      const int mu=mp->mu, nu=mp->nu;
      for (p=mmb; p->mu != mu || p->nu != nu; p = p->next);
      if (p == mp)  /* first occurance of this mu,nu pair */
         SpewForthC2MProto(pre, fp0, fp1, mp->mu, mp->nu);
   }
   fprintf(fp0, "\n");
   fprintf(fp1, "\n");
/*
 * Now, crank out funcptr arrays
 */
   for (ia=0; ia < 3; ia ++)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp0,
            "static const ablk2cmat_t ATL_UAMM_BLK2C_a%c_b%c[ATL_UAMM_NCASES] =\n{\n",
                 ac[ia], bc[ib]);
         SpewForthC2BDecl(pre, mmb, fp0, "ablk2cmat", ac[ia], bc[ib]);
         fprintf(fp1,
            "static const cmat2ablk_t ATL_UAMM_C2BLK_a%c_b%c[ATL_UAMM_NCASES] =\n{\n",
                 ac[ia], bc[ib]);
         SpewForthC2BDecl(pre, mmb, fp1, "cmat2ablk", ac[ia], bc[ib]);
      }
   }
   fprintf(fp0, "\n#endif  /* end include file guard */\n");
   fclose(fp0);
   fprintf(fp1, "\n#endif  /* end include file guard */\n");
   fclose(fp1);
}

void SpewForthRevCpProto(char pre, FILE *fp, char alp, int u, int kmaj)
{
   const int G = (pre == 'c' || pre == 'z') ? 2 : 1;
   const char *cst[2] = {"", "C"};
   int g;

   for (g=0; g < G; g++)
   {
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cu%dam2cm_a%c_%dx%d%s\n",
                 pre, UID, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cu%dam2cm_a%c_%d%s\n",pre, UID, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*,const TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*);\n");
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cu%dam2rm_a%c_%dx%d%s\n",
                 pre, UID, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cu%dam2rm_a%c_%d%s\n",pre, UID, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*,const TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*);\n");
   }
}

void SpewForthCpProto(char pre, FILE *fp, char alp, int u, int kmaj)
{
   const int G = (pre == 'c' || pre == 'z') ? 2 : 1;
   const char *cst[2] = {"", "C"};
   int g;

   for (g=0; g < G; g++)
   {
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cu%dcm2am_a%c_%dx%d%s\n",
                 pre, UID, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cu%dcm2am_a%c_%d%s\n",pre, UID, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp,
    "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*);\n");
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cu%drm2am_a%c_%dx%d%s\n",
                 pre, UID, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cu%drm2am_a%c_%d%s\n",pre, UID, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp,
     "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*);\n");
   }
}

void SpewForthCpConjDecl(char pre, int REVERSE, ATL_mmnode_t *mmb, FILE *fp,
                         char *arr, char *rt, char alp, int u)
{
   ATL_mmnode_t *mp;
   int j;

   fprintf(fp, "static const %s_t %s_a%c[%d] =\n{\n",
           REVERSE?"am2cm":"cm2am", arr, alp,  ATL_CountNumberOfMMNodes(mmb));
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (kmaj > 1)
         fprintf(fp, "   ATL_%cu%d%s_a%c_%dx%dC", pre, UID, rt, alp, kmaj,
                 u?mp->mu:mp->nu);
      else
         fprintf(fp, "   ATL_%cu%d%s_a%c_%dC", pre, UID, rt, alp,
                 u?mp->mu:mp->nu);
      if (mp->next)
         fprintf(fp, ",");
      else
         fprintf(fp, " ");
      fprintf(fp, "  /* index %d */\n", j);
   }
   fprintf(fp, "};\n\n");
}

void SpewForthCpDecl(char pre, int REVERSE, ATL_mmnode_t *mmb, FILE *fp,
                     char *arr, char *rt, char alp, int u)
{
   ATL_mmnode_t *mp;
   int j;

   fprintf(fp, "static const %s_t %s_a%c[%d] =\n{\n",
           REVERSE?"am2cm":"cm2am", arr, alp, ATL_CountNumberOfMMNodes(mmb));
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (kmaj > 1)
         fprintf(fp, "   ATL_%cu%d%s_a%c_%dx%d", pre, UID, rt, alp, kmaj,
                 u?mp->mu:mp->nu);
      else
         fprintf(fp, "   ATL_%cu%d%s_a%c_%d", pre, UID, rt, alp,
                 u?mp->mu:mp->nu);
      if (mp->next)
         fprintf(fp, ",");
      else
         fprintf(fp, " ");
      fprintf(fp, "  /* index %d */\n", j);
   }
   fprintf(fp, "};\n\n");
}


void GenAMAJ2CMAJ(char pre, ATL_mmnode_t *mmb, char *outd, char *suff)
/*
 * 3. atlas_<pre>amm_am2cm_a[1,X,n]:
 *    defines: ATL_AMM_NCASES
 *    prototypes all am2rm & am2cm routines
 *    1 indexible array giving which to use for each block factor
 */
{
   char ac[3] = {'1', 'n', 'X'};
   int ia, j;
   char *fnam, *sp, *np;
   ATL_mmnode_t *mp;

   if (!suff)
      suff = "";
   ia = strlen(outd) + strlen(suff) + 24+UIL;
   fnam = malloc(ia*sizeof(char));
   assert(fnam);
   sprintf(fnam, "%s/atlas_%cu%damm%s_am2cm_a1.h", outd, pre, UID, suff);
   np = fnam+ia-23+12;
   assert(*np == 'a' && np[1] == 'm');
   sp = fnam+ia-4;
   assert(*sp == '1');

   for (ia=0; ia < 3; ia++)
   {
      char *rt[2] = {"am2cm", "am2rm"};
      FILE *fp;
      int kmaj = FLAG_IS_SET(mmb->flag, MMF_KVEC) ? mmb->vlen:0;

      if (kmaj == 1)
         kmaj = 0;
      *sp = ac[ia];
      fp = fopen(fnam, "w");
      assert(fp);
      sp[1] = '\0';
      PrintBegBlock(pre, mmb, np, fp);
      sp[1] = '.';
      fprintf(fp, "/*\n * mat2blk prototypes\n */\n");
      SpewForthRevCpProto(pre, fp, ac[ia], mmb->mu, kmaj);
      if (mmb->nu != mmb->mu || kmaj > 1)
         SpewForthRevCpProto(pre, fp, ac[ia], mmb->nu, kmaj);
      for (mp=mmb->next; mp; mp = mp->next)
      {
         ATL_mmnode_t *p;
         int mu = mp->mu, nu = mp->nu;
         int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
         for (p=mmb; p != mp; p = p->next)
         {
            const int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if (mu == p->mu && km == kmaj)
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthRevCpProto(pre, fp, ac[ia], mu, kmaj);
         for (p=mmb; p != mp; p = p->next)
         {
            const int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if ((p->nu == nu && km == kmaj) ||
                (km == kmaj && p->mu == nu))
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthRevCpProto(pre, fp, ac[ia], nu, kmaj);
      }
      fprintf(fp, "\n");
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_UAMM_BLK2A", "am2cm", ac[ia], 1);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_UAMM_BLK2AT", "am2rm", ac[ia], 1);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_UAMM_BLK2B", "am2cm", ac[ia], 0);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_UAMM_BLK2BT", "am2rm", ac[ia], 0);
      if (pre == 'c' || pre == 'z')
      {
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_UAMM_BLKC2A",
                             "am2cm", ac[ia], 1);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_UAMM_BLKH2A",
                             "am2rm", ac[ia], 1);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_UAMM_BLKC2B",
                             "am2cm", ac[ia], 0);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_UAMM_BLKH2B",
                             "am2rm", ac[ia], 0);
      }
      fprintf(fp, "\n#endif  /* end include file guard */\n");
      fclose(fp);
   }
   free(fnam);
}
void GenCMAJ2AMAJ(char pre, ATL_mmnode_t *mmb, char *outd, char *suff)
/*
 * 3. atlas_<pre>amm_cm2am_a[1,X,n]:
 *    defines: ATL_AMM_NCASES
 *    prototypes all rm2am & cm2am routines
 *    1 indexible array giving which to use for each block factor
 */
{
   char ac[3] = {'1', 'n', 'X'};
   int ia, j;
   char *fnam, *sp, *np;
   ATL_mmnode_t *mp;

GenAMAJ2CMAJ(pre, mmb, outd, suff);
   if (!suff)
      suff = "";
   ia = strlen(outd) + strlen(suff) + 24+UIL;
   fnam = malloc(ia*sizeof(char));
   assert(fnam);
   sprintf(fnam, "%s/atlas_%cu%damm%s_cm2am_a1.h", outd, pre, UID, suff);
   np = fnam+ia-23+12;
   assert(*np == 'c' && np[1] == 'm');
   sp = fnam+ia-4;
   assert(*sp == '1');

   for (ia=0; ia < 3; ia++)
   {
      char *rt[2] = {"cm2am", "rm2am"};
      FILE *fp;
      int kmaj = FLAG_IS_SET(mmb->flag, MMF_KVEC) ? mmb->vlen:0;

      if (kmaj == 1)
         kmaj = 0;
      *sp = ac[ia];
      fp = fopen(fnam, "w");
      assert(fp);
      sp[1] = '\0';
      PrintBegBlock(pre, mmb, np, fp);
      sp[1] = '.';
      fprintf(fp, "/*\n * mat2blk prototypes\n */\n");
      SpewForthCpProto(pre, fp, ac[ia], mmb->mu, kmaj);
      if (mmb->nu != mmb->mu || kmaj > 1)
         SpewForthCpProto(pre, fp, ac[ia], mmb->nu, kmaj);
      for (mp=mmb->next; mp; mp = mp->next)
      {
         ATL_mmnode_t *p;
         int mu = mp->mu, nu = mp->nu;
         int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if (mu == p->mu && km == kmaj)
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthCpProto(pre, fp, ac[ia], mu, kmaj);
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if ((p->nu == nu && km == kmaj) ||
                (km == kmaj && p->mu == nu))
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthCpProto(pre, fp, ac[ia], nu, kmaj);
      }
      fprintf(fp, "\n");
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_UAMM_AN2BLK", "cm2am", ac[ia], 1);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_UAMM_AT2BLK", "rm2am", ac[ia], 1);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_UAMM_BN2BLK", "cm2am", ac[ia], 0);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_UAMM_BT2BLK", "rm2am", ac[ia], 0);
      if (pre == 'c' || pre == 'z')
      {
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_UAMM_AC2BLK",
                             "cm2am", ac[ia], 1);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_UAMM_AH2BLK",
                             "rm2am", ac[ia], 1);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_UAMM_BC2BLK",
                             "cm2am", ac[ia], 0);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_UAMM_BH2BLK",
                             "rm2am", ac[ia], 0);
      }
      fprintf(fp, "\n#endif  /* end include file guard */\n");
      fclose(fp);
   }
   free(fnam);
}

int KernelIsExactSame(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same including KB, 0 otherwise
 */
{
/*
 * Kernels aren't the same if one is being compiled with specific KB,
 * and the other has runtime
 */
   if (FLAG_IS_SET(p0->flag, MMF_KRUNTIME) !=
       FLAG_IS_SET(p1->flag, MMF_KRUNTIME))
      return(0);
   if (!FLAG_IS_SET(p0->flag, MMF_KRUNTIME) && (p0->kbB != p1->kbB))
      return(0);
/*
 * Kernels aren't same if they use different veclen
 */
   if (p0->vlen != p1->vlen)
      return(0);
/*
 * Kernels aren't same if the -DATL_MOVE bits don't match
 */
   if (ATL_MMF_MVGET(p0->flag) != ATL_MMF_MVGET(p1->flag))
      return(0);
/*
 * Genned kerns should match on flag,VLEN,mu,nu,ku.  Already checked vlen.
 * NOTE: if we make generator handle extra params, MUST UPDATE HERE!!!
 */
   if (p0->ID == 0 && p1->ID == 0) &&
      return(p0->mu == p1->mu && p0->nu == p1->nu && 
             p0->ku == p1->ku && p0->flag == p1->flag);
/*
 * If both are user kernels, then they may be repeats.  For user kernels,
 * they are the same if both ID and flag match, else they are not.
 */
   else if (p0->ID > 0 && p1->ID > 0)
      return(p0->ID == p1->ID && p0->flag == p1->flag);
   return(0);  /* Can't be the same if above criteria fails */
}

/*
 * RETURNS: flags that necessitate recompilation, not including KRUNTIME,
 * which is encoded in kb
 */
int GetCompTimeFlags(ATL_mmnode_t *mp)
{
   int iflg;
   iflg = ATL_MMF_MVGET(mp->flag);  /* MVbits change kern at comp time */
   iflg |=  (((mp->flag) & 1)<<3);  /* LDTOP/BOT could be compile-time dec */
   if (FLAG_IS_SET(mp->flag, MMF_KVEC))
      iflg |= 1<<4;
   return(iflg);
}
int ExactKernelInList(ATL_mmnode_t *mmb, ATL_mmnode_t *p)
/*
 * RETURNS: 1 if p is duplicated in mmb, else 0
 */
{
   ATL_mmnode_t *mp;
   if (!p || !mmb)
      return(0);
   for (mp=mmb; mp; mp = mp->next)
      if (KernelIsExactSame(mp, p))
         return(1);
    return(0);
}

void SpewForthKernProto(FILE *fp, char pre, ATL_mmnode_t *p, char bc)
{
   fprintf(fp, "void ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c\n", pre, UID, p->ID,
           FLAG_IS_SET(p->flag, MMF_KRUNTIME)?0:p->kbB, GetCompTimeFlags(p),
           p->mu, p->nu, p->ku,bc);
   fprintf(fp,
      "   (ATL_CSZT,ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,TYPE*,\n");
   fprintf(fp,
      "    const TYPE*,const TYPE*,const TYPE*);\n");
}

void SpewForthKernProtos(FILE *fp, char pre, ATL_mmnode_t *mmb, int nbet)
{
   ATL_mmnode_t *mp;
   for (mp=mmb; mp; mp = mp->next)
   {
      if (!ExactKernelInList(mp->next, mp))
      {
         char bc[3] = {'0', '1', 'n'};  /* 0 must come first */
         int ib;
         for (ib=0; ib < nbet; ib++)
            SpewForthKernProto(fp, pre, mp, bc[ib]);
      }
   }
}

void SpewForthKernArray(FILE *fp, char pre, ATL_mmnode_t *mmb,
                        char *vnam, char cbet)
{
   ATL_mmnode_t *mp;
   int n;

   for (n=0,mp=mmb; mp; n++, mp = mp->next);
   fprintf(fp, "static const ammkern_t ATL_UAMM_%s[%d] =\n", vnam, n);
   fprintf(fp, "{\n");
   for (mp=mmb; mp; mp = mp->next)
   {
      fprintf(fp, "   ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c", pre, UID, mp->ID,
              FLAG_IS_SET(mp->flag, MMF_KRUNTIME)?0:mp->kbB,
              GetCompTimeFlags(mp), mp->mu, mp->nu, mp->ku, cbet);
      if (mp->next)
         fprintf(fp, ",\n");
   }
   fprintf(fp, "\n};\n\n");
}

/*
 * RETURNS: possibly updated list of all unique mu/nu comboes
 */
typedef struct mnur mnur_t;
struct mnur {int mu; int nu; int kmaj; mnur_t *next;};
mnur_t *GetUniqueMNUnrolls(ATL_mmnode_t *mmb, mnur_t *urb)
{
   ATL_mmnode_t *mp;
   mnur_t *up;
/*
 * For each node in mmb, add to urb if mu/nu combo not already there
 * kmaj only affects A/B copy, and this is for C put, so ignore kmaj
 */
   for (mp = mmb; mp; mp = mp->next)
   {
      for (up=urb; up; up = up->next)
         if (mp->mu == up->mu && mp->nu == up->nu)
            break;
      if (!up)
      {
         up = malloc(sizeof(mnur_t));
         assert(up);
         up->mu = mp->mu;
         up->nu = mp->nu;
         up->kmaj = 0;
         up->next = urb;
         urb = up;
      }
   }
   return(urb);
}

/*
 * RETURNS: list of just unique MUs from mnb not already in mub
 */
mnur_t *GetUniqueMUnrolls(ATL_mmnode_t *mnb, mnur_t *mub)
{
   mnur_t *mup;
   ATL_mmnode_t *mnp;
   if (!mnb)
      return(mub);
   for (mnp=mnb; mnp; mnp = mnp->next)
   {
      const int kmaj = FLAG_IS_SET(mnp->flag, MMF_KVEC) ? mnp->vlen?0;
      for (mup=mub; mup; mup = mup->next)
         if (mup->mu == mnp->mu && mup->kmaj == kmaj)
            break;
      if (!mup)  /* a new mu */
      {
         mup = malloc(sizeof(mnur_t));
         assert(mup);
         mup->nu = mup->mu = mnp->mu;
         mup->next = mub;
         mup->kmaj = kmaj;
         mub = mup;
      }
   }
   return(mub);
}
/*
 * RETURNS: list of just unique NUs from mnb not already in mub
 */
mnur_t *GetUniqueNUnrolls(ATL_mmnode_t *mnb, mnur_t *mub)
{
   mnur_t *mup;
   ATL_mmnode_t *mnp;
   if (!mnb)
      return(mub);
   for (mnp=mnb; mnp; mnp = mnp->next)
   {
      const int kmaj = FLAG_IS_SET(mnp->flag, MMF_KVEC) ? mnp->vlen:0;
      for (mup=mub; mup; mup = mup->next)
         if (mup->mu == mnp->nu && kmaj == mup->kmaj)
            break;
      if (!mup)  /* a new nu */
      {
         mup = malloc(sizeof(mnur_t));
         assert(mup);
         mup->nu = mup->mu = mnp->nu;
         mup->next = mub;
         mup->kmaj = kmaj;
         mub = mup;
      }
   }
   return(mub);
}

void KillUnrollList(mnur_t *b)
{
   mnur_t *p;
   while (b)
   {
      p = b->next;
      free(b);
      b = p;
   }
}
void PrintSwapProto(FILE *fp, char pre, int mu, int nu)
{
   fprintf(fp, "void Mjoin(PATL,ammswp%dx%d)", mu, nu);
   if (pre == 'd' || pre == 's')
      fprintf(fp, "(ATL_CINT nnu, TYPE *A, ATL_CSZT lda, TYPE *b);\n");
   else
      fprintf(fp, "(ATL_CINT nnu, TYPE *A, ATL_CSZT lda, TYPE *r, TYPE *i);\n");
}


void zGenAmmSwp(char pre, FILE *fp, int mu, int nu)
{
}

void GenAmmSwp(char pre, FILE *fp, int mu, int nu)
{
   const int munu=mu*nu;
   int i, j, ib;

   if (pre == 'z' || pre == 'c')
   {
      zGenAmmSwp(pre, fp, mu, nu);
      return;
   }

   fprintf(fp, "#include \"atlas_misc.h\"\n");
   fprintf(fp, "void Mjoin(PATL,ammswp%dx%d)\n", mu, nu);
   fprintf(fp, "(\n");
   fprintf(fp, "   ATL_CINT nnu,   /* CEIL(rowlen / nu) */\n");
   fprintf(fp, "   TYPE *A,        /* col-maj matrix to swap wt b */\n");
   fprintf(fp, "   ATL_CSZT lda1,  /* stride between row elts in A */\n");
   fprintf(fp,
           "   TYPE *b         /* %dx%d C-format row ptr to be swapped */\n",
           mu, nu);
   fprintf(fp, ")\n{\n");

   fprintf(fp, "   register unsigned int j;\n");
   if (nu > 1)
   {
      fprintf(fp, "   const size_t lda2=lda1+lda1");
      for (i=3; i <= nu; i++)
         fprintf(fp, ", lda%d=lda1+lda%d", i, i-1);
      fprintf(fp, ";\n");
   }

   fprintf(fp, "   for (j=nnu; j; j--)\n   {\n");

   fprintf(fp, "      register TYPE a0");
   for (i=1; i < nu; i++)
      fprintf(fp, ", a%d", i);
   fprintf(fp, ";\n");

   fprintf(fp, "      a0 = *A;\n");
   for (i=1; i < nu; i++)
      fprintf(fp, "      a%d = A[lda%d];\n", i, i);
   fprintf(fp, "      *A = *b;\n");
   for (i=1; i < nu; i++)
      fprintf(fp, "      A[lda%d] = b[%d];\n", i, i*mu);
   fprintf(fp, "      *b = a0;\n");
   for (i=1; i < nu; i++)
      fprintf(fp, "      b[%d] = a%d;\n", i*mu, i);
   fprintf(fp, "      b += %d;\n", mu*nu);
   fprintf(fp, "      A += lda%d;\n", nu);

   fprintf(fp, "   }\n");

   fprintf(fp, "}\n");
}

void GenAmmSwapFiles(char pre, ATL_mmnode_t *mmb, char *outd)
{
   mnur_t *ub, *up;
   char *fnam;
   int ia;

   if (pre == 's')
      GenAmmSwapFiles('c', mmb, outd);
   else if (pre == 'd')
      GenAmmSwapFiles('z', mmb, outd);
   ia = strlen(outd) + 24+UIL;
   fnam = malloc(ia);
   assert(fnam);
   ub = GetUniqueMNUnrolls(mmb, NULL);
   for (up=ub; up; up = up->next)
   {
      FILE *fp;
      assert(up->mu < 100 && up->nu < 100);
      sprintf(fnam, "%s/ATL_%cammswp%dx%d.c", outd, pre, up->mu, up->nu);
      fp = fopen(fnam, "w");
      assert(fp);
      GenAmmSwp(pre, fp, up->mu, up->nu);
      fclose(fp);
   }
   KillUnrollList(ub);
   free(fnam);
}
void GenAmmSwapH(char pre, ATL_mmnode_t *mmb, char *outd)
{
   mnur_t *ub, *up;
   ATL_mmnode_t *mp;
   FILE *fp;
   int i;

   fp = StandHStart(pre, mmb, outd, "swp");

   fprintf(fp, "\n");
   ub = GetUniqueMNUnrolls(mmb, NULL);
   for (up=ub; up; up = up->next)
      PrintSwapProto(fp, pre, up->mu, up->nu);
   KillUnrollList(ub);
   fprintf(fp, "\n");

   fprintf(fp, "static const ammswp_t ATL_UAMM_SWP[ATL_UAMM_NCASES] =\n{\n");
   for (i=0, mp=mmb; mp; mp = mp->next, i++)
      if (mp->next)
         fprintf(fp, "   ATL_%cammswp%dx%d,  /* index %d */\n",
                 pre, mp->mu, mp->nu, i);
     else
         fprintf(fp, "   ATL_%cammswp%dx%d   /* index %d */\n",
                 pre, mp->mu, mp->nu, i);

   fprintf(fp, "};\n\n");
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

int KernelIsSame(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same except for blocking, 0 otherwise
 */
{
/*
 * Kernels aren't the same if one is being compiled with specific KB,
 * and the other has runtime
 */
   if (FLAG_IS_SET(p0->flag, MMF_KRUNTIME) !=
       FLAG_IS_SET(p1->flag, MMF_KRUNTIME))
      return(0);
/*
 * Two generated kernels are the same if mu,nu,ku,VLEN,flag are the same.
 * NOTE: if we make generator handle muladd, etc, MUST UPDATE HERE!!!
 */
   if (p0->ID == 0 && p1->ID == 0)
      return(p0->mu == p1->mu && p0->nu == p1->nu && p0->ku == p1->ku &&
             p0->vlen == p1->vlen && p0->flag == p1->flag);
/*
 * If both are user kernels, then they may be repeats.  For user kernels,
 * they are the same if both ID and flag match, else they are not.
 */
   else if (p0->ID > 0 && p1->ID > 0)
      return(p0->ID == p1->ID && p0->flag == p1->flag);
   return(0);  /* Can't be the same if above criteria fails */
}


void GenRankKH
(
   char pre,
   ATL_mmnode_t *sqb,  /* baseptr  of square-case AMMM kernels */
   ATL_mmnode_t *rkb,  /* rank-K kernels, one for each supported K */
   char *outd
)
{
   FILE *fp;
   mnur_t *putb, *cpyb, *up;
   ATL_mmnode_t *mp;
   int m, n, k;
   int ia, ib;
   char PRE = pre;
   char ac[3] =  {'1', 'n', 'X'};
   char bc[4] = {'1', 'n', '0', 'X'};
   if (pre == 'c')
      pre = 's';
   else  if (pre == 'z')
      pre = 'd';

   assert(sqb && rkb);
   fp = StandHStart(PRE, rkb, outd, "rankK");
   fprintf(fp, "\n");

   for (mp=sqb; mp->next; mp = mp->next);
   fprintf(fp, "#define ATL_rkAMM_LASTMB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_rkAMM_LASTNB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_rkAMM_LASTKB %d\n\n", mp->kbB);
/*
 * Prototype needed copy routines
 */
   putb = GetUniqueMNUnrolls(rkb, NULL);
   fprintf(fp, "/*\n * cblk2mat put function prototypes\n */\n");
   for (up=putb; up; up = up->next)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp, "void ATL_%cablk2cmat_%dx%d_a1_b%c\n",
                 PRE, up->mu, up->nu, bc[ib]);
         if (PRE == 'c' || PRE == 'z')
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         else
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
      }
   }
   KillUnrollList(putb);
   fprintf(fp,
      "/*\n * Column-major to access-major copy function prototypes\n */\n");
   cpyb = GetUniqueMUnrolls(rkb, NULL);
   cpyb = GetUniqueNUnrolls(rkb, cpyb);
   for (up=cpyb; up; up = up->next)
   {
      for (ia=0; ia < 3; ia++)
         SpewForthCpProto(PRE, fp, ac[ia], up->mu, up->kmaj);
   }
   KillUnrollList(cpyb);
/*
 * Prototype the rank-K functions
 */
   fprintf(fp, "/*\n * rank-K AMMM kernel prototypes\n */\n");
   for (mp=rkb; mp; mp = mp->next)
   {
/*
 *    For runtime kernels, only prototype 1st time they are seen in list
 */
      if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
      {
         ATL_mmnode_t *p;
         if (mp->ID > 0)
         {
            for (p=rkb; p != mp; p = p->next)
               if (p->ID == mp->ID)
                  break;
         }
         else
         {
            for (p=rkb; p != mp; p = p->next)
               if (KernelIsSame(mp, p))
                  break;
         }
         if (mp == p)
         {
            SpewForthKernProto(fp, pre, mp, '0');
            SpewForthKernProto(fp, pre, mp, '1');
            SpewForthKernProto(fp, pre, mp, 'n');
         }
      }
/*
 *    compile-time-K kernels get prototyped for each invocation
 */
      else
      {
         SpewForthKernProto(fp, pre, mp, '0');
         SpewForthKernProto(fp, pre, mp, '1');
         SpewForthKernProto(fp, pre, mp, 'n');
      }
   }
/*
 * Now, crank out funcptr arrays
 */
   for (ib=0; ib < 4; ib++)
   {
      fprintf(fp,
         "\nstatic const ablk2cmat_t ATL_AMM_BLK2C_a1_b%c[%d] =\n{\n",
              bc[ib], ATL_CountNumberOfMMNodes(rkb));
      SpewForthC2BDecl(PRE, rkb, fp, "ablk2cmat", '1', bc[ib]);
   }
   for (ia=0; ia < 3; ia++)
   {
      fprintf(fp, "\n");
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_AN2BLK", "cm2am", ac[ia], 1);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_AT2BLK", "rm2am", ac[ia], 1);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_BN2BLK", "cm2am", ac[ia], 0);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_BT2BLK", "rm2am", ac[ia], 0);
      if (PRE == 'z' || PRE == 'c')
      {
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_AC2BLK", "cm2am",ac[ia],1);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_AH2BLK", "rm2am",ac[ia],1);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_BC2BLK", "cm2am",ac[ia],0);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_BH2BLK", "rm2am",ac[ia],0);
      }
   }
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK", '0');
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK_b1", '1');
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK_bn", 'n');
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenSquareKH(char pre, ATL_mmnode_t *mmb, char *outd)
/*
 * 5. atlas_<pre>amm_kerns.h
 *    defines: ATL_AMM_NCASES
 *    prototypes all kernels, including K-cleanup
 *    1 indexible array gives kernel to use for each case as func ptr
 *    1 indexible array gives K-clean kernel
 */
{
   FILE *fp;
/*
 * Dump out standard header start and kernel prototypes
 */
   fp = StandHStart(pre, mmb, outd, "sqkern");
   fprintf(fp, "\n");
   SpewForthKernProtos(fp, pre, mmb, 3);
   fprintf(fp, "\n");
/*
 * Dump out kernel ptr arrays
 */
   SpewForthKernArray(fp, pre, mmb, "SQKERN_b0", '0');
   SpewForthKernArray(fp, pre, mmb, "SQKERN_b1", '1');
   SpewForthKernArray(fp, pre, mmb, "SQKERN_bn", 'n');

   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenKernH(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *ukb,
              ATL_mmnode_t *kcb, char *outd)
/*
 * 5. atlas_<pre>amm_kerns.h
 *    defines: ATL_AMM_NCASES
 *    prototypes all kernels, including K-cleanup
 *    1 indexible array gives kernel to use for each case as func ptr
 *    1 indexible array gives K-clean kernel
 */
{
   FILE *fp;
/*
 * Dump out standard header start and kernel prototypes
 */
   fp = StandHStart(pre, mmb, outd, "kern");
   fprintf(fp, "\n");
   SpewForthKernProtos(fp, pre, mmb, 3);
   if (ukb)
      SpewForthKernProtos(fp, pre, ukb, 3);
   fprintf(fp, "\n");
/*
 * Dump out kernel ptr arrays
 */
   SpewForthKernArray(fp, pre, mmb, "KERN_b0", '0');
   SpewForthKernArray(fp, pre, mmb, "KERN_b1", '1');
   SpewForthKernArray(fp, pre, mmb, "KERN_bn", 'n');
   if (kcb)
   {
      SpewForthKernArray(fp, pre, kcb, "KERN_K1", '0');
      SpewForthKernArray(fp, pre, kcb, "KERN_K1_b1", '1');
      SpewForthKernArray(fp, pre, kcb, "KERN_K1_bn", 'n');
   }

   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenCmplxHeaders(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *rkb, char *outd)
{
   GenCMAJ2AMAJ(pre, mmb, outd, NULL);
   GenC2BLK(pre, mmb, outd, NULL);
   if (rkb)
   {
      GenCMAJ2AMAJ(pre, rkb, outd, "rkk");
      GenC2BLK(pre, rkb, outd, "_rkk");
      GenRankKH(pre, mmb, rkb, outd);
   }
}

void GenHeaderFiles(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *ukb,
                    ATL_mmnode_t *kcb, ATL_mmnode_t *rkb, ATL_mmnode_t *urb,
                    ATL_mmnode_t *sqb, ATL_mmnode_t *usb, char *outd)
/*
 * Header files required to build full gemm (no timing):
 *X1. atlas_<pre>amm_blk.h :
 *X   defines: ATL_AMM_NCASES, ATL_AMM_MAX[M,N,K]B
 *X   3 arrays indexed by case give blocking
 *X2  atlas_<pre>amm_flag.h
 *X   defines: ATL_AMM_NCASES
 *X   1 indexible array giving KRUNTIME for now
 *X3. atlas_<pre>amm_cm2am_a[1,X,n]:
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all rm2am & cm2am routines
 *X   1 indexible array giving which to use for each block factor
 *X4. atlas_<pre>amm_ablk2cmat.h
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all ablk2cmat routines
 *X   1 indexible array for each alpha,beta combination
 *X   -> 3*4 = 12 indexible arrays total
 *X5. atlas_<pre>amm_kerns.h
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all kernels, including K-cleanup
 *X   1 indexible array gives kernel to use for each case as func ptr
 *X   1 indexible array gives K-clean kernel
 *X6. atlas_<pre>amm_cmat2ablk.h (I don't need, Rakib does)
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all cmat2ablk routines
 *X   1 indexible array for each alpha,beta combination
 *X   -> 3*4 = 12 indexible arrays total
 */
{
   if (rkb)
      GenAmmSum(pre, mmb, rkb, outd);
   GenAmmSwapH(pre, mmb, outd);
   GenBlockingFile(pre, mmb, outd, "blk");
   GenPerfFile(pre, mmb, outd, "perf");
   GenFlagH(pre, mmb, outd, "flag");
   GenCMAJ2AMAJ(pre, mmb, outd, NULL);
   GenC2BLK(pre, mmb, outd, NULL);
   GenKernH(pre, mmb, ukb, kcb, outd);
   if (rkb)
   {
      GenBlockingFile(pre, rkb, outd, "rkkblk");
      GenFlagH(pre, rkb, outd, "rkkflag");
      GenCMAJ2AMAJ(pre, rkb, outd, "rkk");
      GenC2BLK(pre, rkb, outd, "_rkk");
      GenRankKH(pre, mmb, rkb, outd);
   }
   if (sqb)
   {
      GenBlockingFile(pre, rkb, outd, "sqblk");
      GenFlagH(pre, rkb, outd, "sqflag");
      GenCMAJ2AMAJ(pre, rkb, outd, "sq");
      GenC2BLK(pre, rkb, outd, "_sq");
      GenSquareKH(pre, sqb, outd);
   }
}

/*
 * Splits rkb into two lists: (1) Routines with runtime K (RUNB),
 * (2) Routines with fixed-KB (returned)
 * NOTE: original list rkb is unchanged
 */
ATL_mmnode_t *SplitRankK(ATL_mmnode_t *rkb, ATL_mmnode_t **RUNB)
{
   ATL_mmnode_t *runb=NULL, *fixb=NULL, *p, *np;
   for (p=rkb; p; p = p->next)
   {
      np = CloneMMNode(p);
      if (FLAG_IS_SET(np->flag, MMF_KRUNTIME))
      {
         np->next = runb;
         runb = np;
      }
      else
      {
         np->next = fixb;
         fixb = np;
      }
   }
   *RUNB = runb;
   return(fixb);
}

char *GetKernComp(ATL_mmnode_t *mmp, char *dcomp, char *dflags, char **flgs)
{
   char *comp = dcomp;
   if (mmp->comp)
   {
      comp = (mmp->comp[0] == 'g' && mmp->comp[1] == 'c' &&
              mmp->comp[2] == 'c' &&
             (mmp->comp[3] == '\0' || mmp->comp[3] == ' '))
             ? "$(GOODGCC)" : mmp->comp;
      *flgs = mmp->cflags;
   }
   else
      *flgs = dflags;
   return(comp);
}
void PrintKernComp
(
   FILE *fp,            /* file to print to */
   char pre,
   ATL_mmnode_t *mmp,   /* kernel compile rule is for */
   int UID,             /* user-ID for user-determined kerns */
   char *comp,          /* compiler to use */
   char *cflags,        /* compiler flags to use */
   char *styp,          /* string defining type (eg. "-DSREAL") */
   char cbet,           /* character with beta name ('1', '0', 'n') */
   char *sbet           /* string wt full beta name ("1", "N1", "0") */
)
{
   const int kb = FLAG_IS_SET(mmp->flag, MMF_KRUNTIME)?0:mmp->kbB;
   const int flg = GetCompTimeFlags(mmp);
   if (pre == 'z')
      styp = "-DDREAL=1";
   else if (pre == 'c')
      styp = "-DSREAL=1";
   fprintf(fp, "ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c.o : %s\n", pre,
           UID, mmp->ID, kb, flg, mmp->mu, mmp->nu, mmp->ku, cbet, mmp->rout);
   fprintf(fp, "\t%s $(CDEFS2) %s -DBETA%s=1", comp, styp, sbet);
   if (!FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      fprintf(fp, " -DMB=%d -DNB=%d, -DKB=%d", mmp->mbB, mmp->nbB, mmp->kbB);
   if (FLAG_IS_SET(mmp->flag, MMF_MVA))
      fprintf(fp, " -DATL_MOVEA");
   if (FLAG_IS_SET(mmp->flag, MMF_MVB))
      fprintf(fp, " -DATL_MOVEB");
   if (FLAG_IS_SET(mmp->flag, MMF_MVC))
      fprintf(fp, " -DATL_MOVEC");
         fprintf(fp,
         " -DATL_USERMM=ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c -DATL_UAMMID=%d",
                 pre, UID, mmp->ID, kb, flg, mmp->mu, mmp->nu, mmp->ku, cbet,
                 UID);
         fprintf(fp, " %s -o ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c.o -c %s\n",
                 cflags, pre, UID, mmp->ID, kb, flg, mmp->mu, mmp->nu,
                 mmp->ku, cbet, mmp->rout);
}
void GenMakefile
(
   char pre,            /* type/precision prefix : s,d,c,z */
   ATL_mmnode_t *mmb,   /* main kernels for GEMM */
   ATL_mmnode_t *ukb,   /* unique kernels for doing K cleanup of kerns in mmb */
   ATL_mmnode_t *rkb,   /* list of kernels to doing rank-K update */
   ATL_mmnode_t *urb,   /* rank-K update kerns not existing in other lists */
   ATL_mmnode_t *usb,   /* square kernels not existing in other lists */
   char *outd
)
{
   ATL_mmnode_t *mmp, *p, *fixb, *runb;
   mnur_t *mnurb=NULL, *allub, *up;
   FILE *fp;
   char *comp, *cflags;
   char *ln;
   int i;
   char pres[2];
   char be[3] = {'1', 'n', '0'};
   char *bes[3] = {"1", "N1", "0"};
   char al[3] = {'1', 'n', 'X'};
   char dcomp[8] = {'$', '(', 'D', 'M', 'C', ')', '\0'};
   char dflags[12] = {'$', '(', 'D', 'M', 'C', 'F', 'L', 'A', 'G', 'S',
                     ')', '\0'};
   char *styps[2] = {"-DDREAL", "-DDCPLX"};
   char *styp = (pre == 'd' || pre == 'z') ? "-DDREAL" : "-DSREAL";

   pres[0] = pre;
   if (pre == 's' || pre == 'c')
   {
      styps[0] = "-DSREAL";
      styps[1] = "-DSCPLX";
      pres[1] = 'c';
   }
   else
      pres[1] = 'z';

   ln = malloc((strlen(outd)+11)*sizeof(char));
   assert(ln);
   sprintf(ln, "%s/%cMake_amm", outd, pre);
   fp = fopen(ln, "w");
   assert(fp);
   free(ln);
   fprintf(fp, "include ../Make.inc\n");
   fprintf(fp, "CDEFS2=$(CDEFS)\n\n");
   if (pre == 'c')
   {
      fprintf(fp, "CMC=$(SMC)\n");
      fprintf(fp, "CKCFLAGS=$(SKCFLAGS)\n");
      fprintf(fp, "CMCFLAGS=$(SMCFLAGS)\n");
   }
   else if (pre == 'z')
   {
      fprintf(fp, "ZMC=$(DMC)\n");
      fprintf(fp, "ZKCFLAGS=$(DKCFLAGS)\n");
      fprintf(fp, "ZMCFLAGS=$(DMCFLAGS)\n");
   }
/*
 * Build list of all unique MU/NU combos for copy routines
 * Square cases built from mmb, so they are all represented in mmb
 */
   mnurb = GetUniqueMNUnrolls(mmb, NULL);
   mnurb = GetUniqueMNUnrolls(urb, mnurb);
   allub = GetUniqueMUnrolls(mmb, NULL);
   allub = GetUniqueMUnrolls(urb, allub);
   allub = GetUniqueNUnrolls(mmb, allub);
   allub = GetUniqueNUnrolls(urb, allub);
/*
 * Spew out all filenames that must be compiled
 */
   fprintf(fp, "objs =");
/*
 * Routines to copy from MU/NU-major to column major output array
 */
   for (up=mnurb; up; up = up->next)
   {
      int j;
      const int mu=up->mu, nu=up->nu;

      for (j=0; j < 3; j++)
      {
         int k;
         char *rtn[2] = {"ablk2cmat", "cmat2ablk"};
         for (k=0; k < 2; k++)
         {
            int h;
            for (h=0; h < 2; h++)
            {
               if (pre != pres[h])
                  continue;
               if (j == 0)
                  fprintf(fp, " \\\n       ATL_%cammswp%dx%d.o", pre, mu, nu);
               fprintf(fp, " \\\n       ATL_%cu%d%s_%dx%d_a%c_b1.o",
                       pre, UID, rtn[k], mu, nu, al[j]);
               fprintf(fp, " ATL_%cu%d%s_%dx%d_a%c_bX.o",
                       pre, UID, rtn[k], mu, nu, al[j]);
               fprintf(fp, " \\\n       ATL_%cu%d%s_%dx%d_a%c_b0.o",
                       pre, UID, rtn[k], mu, nu, al[j]);
               fprintf(fp, " ATL_%cu%d%s_%dx%d_a%c_bn.o",
                       pre, UID, rtn[k], mu, nu, al[j]);
            }
         }
      }
   }
/*
 * Routines to copy back and forth from A and B
 */
   for (up=allub; up; up = up->next)
   {
      int h;
      for (h=0; h < 2; h++)
      {
        if (pre != pres[h]) continue;
         int j;
         const int u = up->mu;
         for (j=0; j < 3; j++)
         {
            if (up->kmaj > 1)
            {
               fprintf(fp,
 " \\\n       ATL_%cu%drm2am_a%c_%dx%d.o ATL_%cu%dcm2am_a%c_%dx%d.o",
              pre, UID, al[j], up->kmaj, u, pre, UID, al[j], up->kmaj, u);
               fprintf(fp,
 " \\\n       ATL_%cu%dam2rm_a%c_%dx%d.o ATL_%cu%dam2cm_a%c_%dx%d.o",
              pre, UID, al[j], up->kmaj, u, pre, UID, al[j], up->kmaj, u);
            }
            else
            {
               fprintf(fp,
                  " \\\n       ATL_%cu%drm2am_a%c_%d.o ATL_%cu%dcm2am_a%c_%d.o",
                       pre, UID, al[j], u, pre, UID, al[j], u);
               fprintf(fp,
                  " \\\n       ATL_%cu%dam2rm_a%c_%d.o ATL_%cu%dam2cm_a%c_%d.o",
                       pre, UID, al[j], u, pre, UID, al[j], u);
            }
            if (pre == 'c' || pre == 'z')
            {
               if (up->kmaj > 1)
               {
                  fprintf(fp,
 " \\\n       ATL_%cu%drm2am_a%c_%dx%dC.o ATL_%cu%dcm2am_a%c_%dx%dC.o",
                  pre, UID, al[j], up->kmaj, u, pre, UID, al[j], up->kmaj, u);
                  fprintf(fp,
 " \\\n       ATL_%cu%dam2rm_a%c_%dx%dC.o ATL_%cu%dam2cm_a%c_%dx%dC.o",
                  pre, UID, al[j], up->kmaj, u, pre, UID, al[j], up->kmaj, u);
               }
               else
               {
                  fprintf(fp,
               " \\\n       ATL_%cu%drm2am_a%c_%dC.o ATL_%cu%dcm2am_a%c_%dC.o",
                          pre, UID, al[j], u, pre, UID, al[j], u);
                  fprintf(fp,
               " \\\n       ATL_%cu%dam2rm_a%c_%dC.o ATL_%cu%dam2cm_a%c_%dC.o",
                          pre, UID, al[j], u, pre, UID, al[j], u);
               }
            }
         }
      }
   }
/*
 * AMM kernel routines
 */
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      int kb = mmp->kbB;
/*
 *    Kernels that take runtime K are only compiled once, so don't repeat them
 *    for every KB.  Only generate a statement if this is the first one.
 */
      if (FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      {
         const int id = mmp->ID;
         for (p=mmb; p != mmp; p = p->next)
            if (p->ID == id && FLAG_IS_SET(p->flag, MMF_KRUNTIME))
               break;
         if (p != mmp)
            continue;
         kb = 0;
      }
/*
 *    ATL_<pre>UAMMM_<ID>_<kb>_<flg>_<mu>x<nu>x<ku>_b<X>
 */
      for (i=0; i < 3; i++)
         fprintf(fp, " \\\n       ATL_%cu%dAMMM_%d_%d_%x_%dx%dx%d_b%c.o",
                 pre, UID, mmp->ID, kb, GetCompTimeFlags(mmp),
                 mmp->mu, mmp->nu, mmp->ku, be[i]);
   }
/*
 * AMM K-cleanup kernel routines are all unique, so no checking for repeats
 *    ATL_<pre>UAMMM_<ID>_<kb>_<flg>_<mu>x<nu>x<ku>_b0
 */
   for (mmp=ukb; mmp; mmp = mmp->next)
      for (i=0; i < 3; i++)
         fprintf(fp, " \\\n       ATL_%cu%dAMMM_%d_0_%x_%dx%dx%d_b%c.o", pre,
                 UID, mmp->ID, GetCompTimeFlags(mmp), mmp->mu, mmp->nu,
                 mmp->ku, be[i]);
/*
 * library make targets
 */
   fprintf(fp, "\n\nlib : %clib.grd\nall : %clib.grd\n%clib : %clib.grd\n",
           pre, pre, pre, pre);
   fprintf(fp, "%clib.grd : $(objs)\n", pre);
   fprintf(fp, "\t$(ARCHIVER) $(ARFLAGS) $(UAMMlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(UAMMlib)\n");
   fprintf(fp, "\t touch %clib.grd\n", pre);
   fprintf(fp, "clean : %cclean\n", pre);
   fprintf(fp, "%cclean:\n\t- rm -f $(objs)\n", pre);
   fprintf(fp, "killall : %ckillall\n", pre);
   fprintf(fp, "%ckillall : %cclean\n", pre, pre);
   fprintf(fp, "\t- $(ARCHIVER) d $(UAMMlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(UAMMlib)\n");
   fprintf(fp, "\t- rm -f ATL_%c*.[S,c]\n", pre);

/*
 * Print out the individual rules for each needed copy function
 */
   dcomp[2] = dflags[2] = toupper(pre);
   dflags[3] = dcomp[3] = 'K';
   fprintf(fp, "\ntsth.o : tsth.c\n");
   fprintf(fp, "\t%s %s $(CDEFS) %s -c tsth.c\n\n", dcomp, dflags, styp);
   fprintf(fp, "#\n# Data copy rules\n#\n");
/*
 * Print out 2-D ablk2Cmat, cmat2ablk and ammswp targets
 */
   for (up=mnurb; up; up = up->next)
   {
      const int mu=up->mu, nu = up->nu;
      char cbe[4] = {'0', '1', 'n', 'X'};
      int ibe[4] =  {0,    1,  -1,  2};
      int i, j;

      for (i=0; i < 4; i++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            if (pre != pres[h])
               continue;
            if (i == 0)
            {
               fprintf(fp, "ATL_%cammswp%dx%d.o : ATL_%cammswp%dx%d.c\n",
                       pre, mu, nu, pre, mu, nu);
               fprintf(fp, "\t%s %s %s $(CDEFS) -c ATL_%cammswp%dx%d.c\n",
                       dcomp, dflags, styp, pre, mu, nu);
            }
            char pre=pres[h];
            char *styp=styps[h];
            for (j=0; j < 3; j++)
            {
               int k;
               char *rtn[2] = {"ablk2cmat", "cmat2ablk"};
               for (k=0; k < 2; k++)
               {
                  char rn[64];
                  sprintf(rn, "ATL_%cu%d%s_%dx%d_a%c_b%c",
                          pre, UID, rtn[k], mu, nu, al[j], cbe[i]);
                  fprintf(fp, "%s.o : %s.c\n", rn, rn);
                  fprintf(fp, "\t%s %s $(CDEFS) %s -c -DATL_%c%s=%s \\\n",
                          dcomp, dflags, styp, rn[4], rn+6+UIL, rn);
                  fprintf(fp, "          -c %s.c\n", rn);
               }
            }
         }
      }
   }
   KillUnrollList(mnurb);
/*
 * Print out 1-D copy-in routine rules
 */
   for (up=allub; up; up = up->next)
   {
      const int u = up->mu, kmaj=up->kmaj;
      int j;
      for (j=0; j < 3; j++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            if (pre != pres[h]) continue;
            char *styp=styps[h];
            char *cst[2] = {"", "C"};
            char *cdef[2] = {"", "-DConj_=1 "};
            int g;
            const int G = (pre == 'c' || pre == 'z') ? 2:1;
            for (g=0; g < G; g++)
            {
               int kk;
               int nmI, nmI0=5;
               char *sp;
               char rout[32], rt0[32];
               if (kmaj > 1)
               {
                  sprintf(rout, "ATL_%cu%drm2am_a%c_%dx%d",
                          pre, UID, al[j], kmaj, u);
                  sprintf(rt0, "ATL_%crm2am_a%c_%dx%d", pre, al[j], kmaj, u);
               }
               else
               {
                  sprintf(rout, "ATL_%cu%drm2am_a%c_%d", pre, UID, al[j], u);
                  sprintf(rt0, "ATL_%crm2am_a%c_%d", pre, al[j], u);
               }
               sp = strstr(rout, "rm2am");
               nmI = sp - rout;
               for (kk=0; kk < 4; kk++)
               {
                  if (kk == 1)
                     rt0[5] = rout[6+UIL] = 'c';
                  else if (kk == 2)
                  {
                     rt0[5] = rout[6+UIL] = 'a';
                     rt0[8] = rout[9+UIL] = 'r';
                  }
                  else if (kk == 3)
                      rt0[8] = rout[9+UIL] = 'c';

                  fprintf(fp, "%s%s.o : %s.c\n", rout, cst[g], rout);
               fprintf(fp,
                       "\t%s %s $(CDEFS) %s%s -D%s%s=%s%s -o %s%s.o -c %s.c\n",
                       dcomp, dflags, cdef[g], styp, rt0, cst[g], rout, cst[g],
                       rout, cst[g], rout);
               }
            }
         }
      }
   }
   KillUnrollList(allub);
/*
 * Print out the individual rules for each kernel compile
 */
   dflags[3] = dcomp[3] = 'M';
   fprintf(fp, "#\n#  AMM kernel rules\n#\n");
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
/*
 *    Kernels that take runtime K are only compiled once, so print rules on
 *    only the first encounter of that ID
 */
      if (FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      {
         const int id = mmp->ID;
         for (p=mmb; p != mmp; p = p->next)
            if (p->ID == id && FLAG_IS_SET(p->flag, MMF_KRUNTIME))
               break;
         if (p != mmp)
            continue;
      }
      comp = GetKernComp(mmp, dcomp, dflags, &cflags);
/*
 *    ATL_<pre>UAMMM_<ID>_<kb>_<flg>_<mu>x<nu>x<ku>_b<X>,
 *    kerns in all 3 beta cases
 */
      for (i=0; i < 3; i++)
         PrintKernComp(fp, pre, mmp, UID, comp, cflags, styp, be[i], bes[i]);
   }
/*
 * K-cleanup needs only the kernel compile rule
 */
   fprintf(fp, "#\n#  K-cleanup rules\n#\n");
   for (mmp=ukb; mmp; mmp = mmp->next)
   {
      comp = GetKernComp(mmp, dcomp, dflags, &cflags);
      for (i=0; i < 3; i++)
         PrintKernComp(fp, pre, mmp, UID, comp, cflags, styp, be[i], bes[i]);
   }
   fclose(fp);
}

void GenKerns(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *ukb, ATL_mmnode_t *urb,
              char *outd)
/*
 * Creates/copies all required matmul kernels into outd using specified names
 */
{
   ATL_mmnode_t *mmp, *p;
   mnur_t *mnurb=NULL, *allub, *up;
   char *ln=NULL;
   int lnlen=0, dlen;
   char al[3] = {'1', 'n', 'X'};
   int ial[3] = {1,   -1,   2};
   char pres[2];
   pres[0] = pre;
   pres[1] = (pre == 's') ? 'c' : 'z';

   GenAmmSwapFiles(pre, mmb, outd);
/*
 * Build list of all unique MU/NU combos for copy routines
 */
   mnurb = GetUniqueMNUnrolls(mmb, NULL);
   mnurb = GetUniqueMNUnrolls(urb, mnurb);
   allub = GetUniqueMUnrolls(mmb, NULL);
   allub = GetUniqueMUnrolls(urb, allub);
   allub = GetUniqueNUnrolls(mmb, allub);
   allub = GetUniqueNUnrolls(urb, allub);
   dlen = strlen(outd);
/*
 * Extract every unique block-copy routine
 */
   for (up=mnurb; up; up = up->next)
   {
      const int mu=up->mu, nu=up->nu;
      char cbe[4] = {'0', '1', 'n', 'X'};
      int ibe[4] =  {0,    1,  -1,  2};
      int i, j;
      j = 64+8 + strlen(outd);
      j = (j > 128) ? j : 128;
      if (lnlen < j)
      {
         free(ln);
         lnlen = j;
         ln = malloc(j*sizeof(char));
         assert(ln);
      }
      for (i=0; i < 4; i++)
      {
         for (j=0; j < 3; j++)
         {
            char rn[64];
            int ierr;
            int k;
            for (k=0; k < 2; k++)
            {
               int h=0;
                  if (!k)
                     sprintf(rn, "ATL_%cablk2cmat_%dx%d_a%c_b%c.c",
                             pre, mu, nu, al[j], cbe[i]);
                  else
                     sprintf(rn, "ATL_%ccmat2ablk_%dx%d_a%c_b%c.c",
                             pre, mu, nu, al[j], cbe[i]);
                  sprintf(ln,
                     "make %s pre=%c mu=%d nu=%d al=%c be=%c alpha=%d beta=%d",
                          rn, pre, mu, nu, al[j], cbe[i], ial[j], ibe[i]);
                  ierr = system(ln);
                  if (ierr)
                  {
                     fprintf(stderr, "FAILED CMND='%s'\n", ln);
                     exit(ierr);
                  }
                  sprintf(ln, "mv %s %s/ATL_%cu%d%s", rn, outd, pre, UID, rn+5);
                  ierr = system(ln);
                  if (ierr)
                  {
                     fprintf(stderr, "FAILED CMND='%s'\n", ln);
                     exit(ierr);
                  }
            }
         }
      }
   }
   KillUnrollList(mnurb);

/*
 * Routines to copy back and forth from A and B
 */
   for (up=allub; up; up = up->next)
   {
      const int u = up->mu, kmaj=up->kmaj;
      int j;
      j = 16 * 40 + (strlen(outd)<<1);
      j = (j > 90) ? j : 90;
      if (lnlen < j)
      {
         free(ln);
         lnlen = j;
         ln = malloc(j*sizeof(char));
         assert(ln);
      }
      for (j=0; j < 3; j++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            int ierr;
            if (h)
               continue;
            sprintf(ln,
                    "make ATL_%crm2am_a%c_%d.c ATL_%ccm2am_a%c_%d.c "
                    "ATL_%cam2rm_a%c_%d.c ATL_%cam2cm_a%c_%d.c "
                    "pre=%c UR=%d alpha=%d al=%c kmaj=%d",
                    pre, al[j], u, pre, al[j], u,
                    pre, al[j], u, pre, al[j], u,
                    pre, u, ial[j], al[j], kmaj);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
            if (kmaj > 1)
               sprintf(ln,
                       "mv ATL_%crm2am_a%c_%d.c %s/ATL_%cu%drm2am_a%c_%dx%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], kmaj, u);
            else
               sprintf(ln,
                       "mv ATL_%crm2am_a%c_%d.c %s/ATL_%cu%drm2am_a%c_%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], u);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
            if (kmaj > 1)
               sprintf(ln,
                       "mv ATL_%ccm2am_a%c_%d.c %s/ATL_%cu%dcm2am_a%c_%dx%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], kmaj, u);
            else
               sprintf(ln,
                       "mv ATL_%ccm2am_a%c_%d.c %s/ATL_%cu%dcm2am_a%c_%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], u);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
            if (kmaj > 1)
               sprintf(ln,
                       "mv ATL_%cam2rm_a%c_%d.c %s/ATL_%cu%dam2rm_a%c_%dx%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], kmaj, u);
            else
               sprintf(ln,
                       "mv ATL_%cam2rm_a%c_%d.c %s/ATL_%cu%dam2rm_a%c_%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], u);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
            if (kmaj > 1)
               sprintf(ln,
                       "mv ATL_%cam2cm_a%c_%d.c %s/ATL_%cu%dam2cm_a%c_%dx%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], kmaj, u);
            else
               sprintf(ln,
                       "mv ATL_%cam2cm_a%c_%d.c %s/ATL_%cu%dam2cm_a%c_%d.c",
                       pre, al[j], u, outd, pre, UID, al[j], u);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
         }
      }
   }
   KillUnrollList(allub);
/*
 * Copy/generate every unique file, but only once
 */
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      const int id=mmp->ID;
/*
 *    For generated files, just overwrite dups with same file, won't hurt
 */
      if (id == 0)
      {
         assert(mmp->genstr);
         assert(!system(mmp->genstr));
      }
      else  /* user-supplied files copied from AMMCASES directory */
      {
/*
 *       If this is the first time we've seen this ID, it must be copied
 */
         for (p=mmb; p != mmp && p->ID != id; p = p->next);
         if (p == mmp)
         {
            int i, ierr;
            i = strlen(mmp->rout) + dlen + 16;
            if (i > lnlen)
            {
               if (ln)
                  free(ln);
               ln = malloc(i*sizeof(char));
               assert(ln);
               lnlen = i;
            }
            sprintf(ln, "cp AMMCASES/%s %s/.", mmp->rout, outd);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
         }
      }
   }
/*
 * Copy/generate k-cleanup which is known to be unique
 */
   for (mmp=ukb; mmp; mmp = mmp->next)
   {
      const int id=mmp->ID;
/*
 *    For generated files, just generate it using genstr
 */
      if (id == 0)
      {
         assert(mmp->genstr);
         assert(!system(mmp->genstr));
      }
      else  /* user-supplied files copied from AMMCASES directory */
      {
         int i, ierr;
         i = strlen(mmp->rout) + dlen + 16;
         if (i > lnlen)
         {
            if (ln)
               free(ln);
            ln = malloc(i*sizeof(char));
            assert(ln);
            lnlen = i;
         }
         sprintf(ln, "cp AMMCASES/%s %s/.", mmp->rout, outd);
         ierr = system(ln);
         if (ierr)
         {
            fprintf(stderr, "FAILED CMND='%s'\n", ln);
            exit(ierr);
         }
      }
   }
   if (ln)
      free(ln);
}
void GenAllFiles(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *ukb,
                 ATL_mmnode_t *kcb, ATL_mmnode_t *rkb, ATL_mmnode_t *urb,
                 ATL_mmnode_t *sqb, ATL_mmnode_t *usb,
                 char *outd)
{
   GenHeaderFiles(pre, mmb, ukb, kcb, rkb, urb, sqb, usb, outd);
   GenMakefile(pre, mmb, ukb, rkb, urb, usb, outd);
   GenKerns(pre, mmb, ukb, urb, outd);
}


int KernelInList(ATL_mmnode_t *mmb, ATL_mmnode_t *p)
/*
 * RETURNS: 1 if p is duplicated in mmb, else 0
 */
{
   ATL_mmnode_t *mp;
   if (!p || !mmb)
      return(0);
   for (mp=mmb; mp; mp = mp->next)
      if (KernelIsSame(mp, p))
         return(1);
    return(0);
}

ATL_mmnode_t *StripNonUniqueKs(ATL_mmnode_t *ukb, ATL_mmnode_t *mmb)
/*
 * Deletes any ukb node that also appears in mmb,
 * RETURNS: possibly shortened ukb
 */
{
   ATL_mmnode_t *mp, *prev;
/*
 * Delete any repetitive nodes starting unique queue
 */
   while(ukb && KernelInList(mmb, ukb))
      ukb = KillMMNode(ukb);
   if (!ukb)
      return(ukb);
/*
 * Now, delete any internal non-unique K-cleanup
 */
   prev = ukb;
   mp = ukb->next;
   while (mp)
   {
      if (KernelInList(mmb, mp))
         mp = prev->next = KillMMNode(mp);
      else
      {
         prev = mp;
         mp = mp->next;
      }
   }
   return(ukb);
}
ATL_mmnode_t *StripExactMatchKs(ATL_mmnode_t *ukb, ATL_mmnode_t *mmb)
/*
 * Deletes any ukb node that also appears in mmb with same K-value,
 * RETURNS: possibly shortened ukb
 */
{
   ATL_mmnode_t *mp, *prev;
/*
 * Delete any repetitive nodes starting unique queue
 */
   while(ukb && ExactKernelInList(mmb, ukb))
      ukb = KillMMNode(ukb);
   if (!ukb)
      return(ukb);
/*
 * Now, delete any internal non-unique K-cleanup
 */
   prev = ukb;
   mp = ukb->next;
   while (mp)
   {
      if (ExactKernelInList(mmb, mp))
         mp = prev->next = KillMMNode(mp);
      else
      {
         prev = mp;
         mp = mp->next;
      }
   }
   return(ukb);
}
/*
 * RETURNS: mmb, with all repeated kernels removed
 */
ATL_mmnode_t *RemoveNonUniqueKernels(ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mp;
   if (!mmb || !mmb->next)
      return(mmb);
   for (mp=mmb; mp; mp = mp->next)
   {
      ATL_mmnode_t *p=mp->next, *prev=mp;
      while (p)
      {
         if (KernelIsSame(mp, p))
            prev->next = p = KillMMNode(p);
         else
         {
            prev = p;
            p = p->next;
         }
      }
   }
   return(mmb);
}

int main(int nargs, char **args)
{
   char pre='d';
   int verb=1;
   int *nbs;
   char *outd, *ukin, *kcin, *rkin, *sqin;
   ATL_mmnode_t *mmb, *mmp, *ukb=NULL, *kcb=NULL, *rkb=NULL, *urb=NULL,
                *sqb=NULL, *usb=NULL;

   mmb = GetFlags(nargs, args, &pre, &outd, &ukin, &kcin, &rkin, &sqin);
   assert(mmb);
   if (ukin)
   {
      ukb = ReadMMFile(ukin);
      free(ukin);
/*
 *    Now, strip off any ukb node that also appears in mmb, in order to
 *    make sure we don't repeat prototypes, generation, etc
 */
      ukb = StripNonUniqueKs(ukb, mmb);
   }
   if (kcin)
   {
      kcb = ReadMMFile(kcin);
      free(kcin);
   }
   if (rkin)
   {
      rkb = ReadMMFile(rkin);
      urb = CloneMMQueue(rkb);
      urb = RemoveNonUniqueKernels(urb);
      urb = StripExactMatchKs(urb, kcb);
      urb = StripExactMatchKs(urb, mmb);
      free(rkin);
   }
   if (sqin)
   {
      sqb = ReadMMFile(sqin);
      usb = CloneMMQueue(sqb);
      usb = RemoveNonUniqueKernels(usb);
      usb = StripExactMatchKs(usb, mmb);
      usb = StripExactMatchKs(usb, kcb);
      usb = StripExactMatchKs(usb, urb);
      free(sqin);
   }
   MMFillInGenStrings(pre, mmb, outd);
   MMFillInGenStrings(pre, ukb, outd);
   MMFillInGenStrings(pre, kcb, outd);
   MMFillInGenStrings(pre, rkb, outd);
   MMFillInGenStrings(pre, urb, outd);
   MMFillInGenStrings(pre, usb, outd);
   GenAllFiles(pre, mmb, ukb, kcb, rkb, urb, sqb, usb, outd);
   KillAllMMNodes(mmb);
   KillAllMMNodes(ukb);
   KillAllMMNodes(kcb);
   KillAllMMNodes(rkb);
   exit(0);
}
@ROUT emit_amm
@extract -b @(topd)/cw.inc lang=C -def cwdate 2012 -def cwdate 2013 -def cwdate 2015
#include "atlas_misc.h"
#include "atlas_mmparse.h"
#include "atlas_mmtesttime.h"
#include "atlas_sys.h"

ATL_mmnode_t *RemoveNonUniqueKernels(ATL_mmnode_t *mmb);

void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr, 
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
   fprintf(stderr, "   -d <outdir>: directory to dump files to\n");
   fprintf(stderr, "   -g <rect kern file> <geKCleanFile>\n");
   fprintf(stderr, "   -r <rank-K kernel file> \n");
   fprintf(stderr, "   -s <square-case kernel file> <sqKCleanFile>\n");
   fprintf(stderr, "   -t <trsm file> : should match -s\n");
   exit(ierr ? ierr : -1);
}

/*
 * RETURNS: precision prefix [s,d,c,z]
 */
char GetFlags(int nargs, char **args, char **DOUT, 
              ATL_mmnode_t **GEMM, ATL_mmnode_t **GEK1,
              ATL_mmnode_t **SQMM, ATL_mmnode_t **SQK1,
              ATL_mmnode_t **RKMM, ATL_mmnode_t **TRSM,
              ATL_mmnode_t **cGEMM, ATL_mmnode_t **cGEK1,
              ATL_mmnode_t **cSQMM, ATL_mmnode_t **cSQK1,
              ATL_mmnode_t **cRKMM, ATL_mmnode_t **cTRSM)
{
   int i, j=0, n, k;
   char pre='d', cpre;
   ATL_mmnode_t *gemm=NULL, *gek1=NULL, *sqmm=NULL, *sqk1=NULL, *rkmm=NULL;
   ATL_mmnode_t *trsm=NULL, *mmb=NULL, *mmp, *mp;

   *DOUT = NULL;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);
      
      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        break;
      case 'g':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        gemm = ReadMMFile(args[i]);
        assert(gemm);
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        gek1 = ReadMMFile(args[i]);
        assert(gek1);
        break;
      case 't':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        trsm = ReadMMFile(args[i]);
        assert(trsm);
      case 's':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        sqmm = ReadMMFile(args[i]);
        assert(sqmm);
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        sqk1 = ReadMMFile(args[i]);
        assert(sqk1);
        break;
      case 'r':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        rkmm = ReadMMFile(args[i]);
        break;
      case 'd':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *DOUT = DupString(args[i]);
        break;
      case 'i':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        mmp = ReadMMFile(args[i]);
        if (mmb)
        {
           ATL_mmnode_t *mp;
           for (mp=mmb; mp->next; mp = mp->next);
           mp->next = mmp;
        }
        else
           mmb = mmp;
        break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (!gemm)
   {
      assert(!gek1);
      gemm = ReadMMFileWithPath(pre, "res", "geAMMRES.sum");
      assert(gemm);
      gek1 = ReadMMFileWithPath(pre, "res", "geAMMKCLEAN.sum");
      assert(gek1);
   }
   if (!sqmm)
   {
      assert(!sqk1);
      sqmm = ReadMMFileWithPath(pre, "res", "sqAMMRES.sum");
      assert(sqmm);
      sqk1 = ReadMMFileWithPath(pre, "res", "sqAMMKCLEAN.sum");
      assert(sqk1);
   }
   if (!trsm)
   {
      trsm = ReadMMFileWithPath(pre, "res", "tsAMMRES.sum");
      assert(trsm);
   }
   if (!rkmm)
   {
      rkmm = ReadMMFileWithPath(pre, "res", "rkAMMRES.sum");
      assert(rkmm);
   }
   if (!(*DOUT))
      *DOUT = DupString("KERNEL");
   cpre = (pre == 'd') ? 'z' : 'c';
   *cGEMM = ReadMMFileWithPath(cpre, "res", "geAMMRES.sum");
   *cGEK1 = ReadMMFileWithPath(cpre, "res", "geAMMKCLEAN.sum");
   *cSQMM = ReadMMFileWithPath(cpre, "res", "sqAMMRES.sum");
   *cSQK1 = ReadMMFileWithPath(cpre, "res", "sqAMMKCLEAN.sum");
   *cRKMM = ReadMMFileWithPath(cpre, "res", "rkAMMRES.sum");
   *cTRSM = ReadMMFileWithPath(cpre, "res", "tsAMMRES.sum");
   *GEMM = gemm;
   *GEK1 = gek1;
   *SQMM = sqmm;
   *SQK1 = sqk1;
   *RKMM = rkmm;
   *TRSM = trsm;
   return(pre);
}

char *GetVecStr(char pre, int vlen)
{
   if (vlen == 1)
      return("scalar");
   #ifdef ATL_AVX
      if (pre == 'd' || pre == 'z')
      {
         if (vlen == 4)
            return("avx");
         else if (vlen == 2)
            return("sse");
      }
      else if (pre == 's' || pre == 'c')
      {
         if (vlen == 8)
            return("avx");
         else if (vlen == 4)
            return("sse");
      }
   #elif defined(ATL_SSE1)
      #ifdef ATL_SSE2
         if ((pre == 'd' || pre == 'z') && vlen == 2)
               return("sse");
      #endif
      if ((pre == 's' || pre == 'c') && vlen == 4)
         return("sse");
   #endif
/*
 * Any vector length > 1 that isn't one of our known cases uses gnuvec
 */
   return("gvec");
}

void PrintBegBlock(char pre, ATL_mmnode_t *mmb, char *pfx, char *nam, FILE *fp)
{
   ATL_mmnode_t *mp;
   char PRE = toupper(pre);
   int i;

   if (nam)
   {
      if (pfx)
         fprintf(fp,
         "#ifndef ATLAS_%c%sAMM_%s_H\n   #define ATLAS_%c%sAMM_%s_H\n\n",
                 PRE, pfx, nam, PRE, pfx, nam);
      else
         fprintf(fp,"#ifndef ATLAS_%cAMM_%s_H\n   #define ATLAS_%cAMM_%s_H\n\n",
                 PRE, nam, PRE, nam);
      fprintf(fp, "#include \"atlas_amm.h\"\n");
   }
   else
      fprintf(fp, "#ifndef ATLAS_%cAMM_H\n   #define ATLAS_%cAMM_H\n\n",
              PRE, PRE);
/*
 * Count mmb, and print def of NCASES
 */
   for (mp=mmb,i=0; mp; i++, mp = mp->next);
   if (pfx)
      fprintf(fp, "#define ATL_%c%sAMM_NCASES %d\n", pre, pfx, i);
   else if (!nam || strstr(nam, "RANKK") == NULL)
   {
      fprintf(fp, "#ifdef ATL_AMM_NCASES\n");
      fprintf(fp, "   #if ATL_AMM_NCASES != %d\n", i);
      fprintf(fp, "      #error \"NCASES MISMATCH!\"\n");
      fprintf(fp, "   #endif\n");
      fprintf(fp, "#else\n");
      fprintf(fp, "   #define ATL_AMM_NCASES %d\n", i);
      fprintf(fp, "#endif\n");
   }
}

char *GetHName(char pre, char *outd, char *pfx, char *bnam)
{
   int i, NOBASE=0;
   char *fnam;
   if (!bnam)
   {
      NOBASE = 1;
      bnam = "";
   }
   i = strlen(outd) + strlen(bnam) + strlen(pfx) + 16;

   fnam = malloc(i*sizeof(char));
   assert(fnam);
   if (NOBASE)
      sprintf(fnam, "%s/atlas_%c%samm.h", outd, pre, pfx);
   else
      sprintf(fnam, "%s/atlas_%c%samm_%s.h", outd, pre, pfx, bnam);
   return(fnam);
}

FILE *StandHStart(char pre, ATL_mmnode_t *mmb, char *pfx, 
                  char *outd,  char *bnam)
{
   char *fnam;
   FILE *fp;
   int i;

   assert(outd);
   fnam = GetHName(pre, outd, pfx, bnam);
   fp = fopen(fnam, "w");
   assert(fp);
   if (bnam)
   {
      for (i=0; bnam[i]; i++)
         fnam[i] = toupper(bnam[i]);
      fnam[i] = '\0';
      if (strstr(bnam, "perf"))
         PrintBegBlock(pre, mmb, pfx, fnam, fp);
      else
         PrintBegBlock(pre, mmb, NULL, fnam, fp);
   }
   else
      PrintBegBlock(pre, mmb, NULL, NULL, fp);
   free(fnam);
   return(fp);
}

@extract -b @(basd)/atlas.base rout=Mylcm

void GenAmmSum(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *rkb, 
               char *pfx, char *outd)
{
   ATL_mmnode_t *mp, *p66;
   char *fnam;
   FILE *fp;
   char *type = "unsigned short";
   int i, n, maxb, maxNB, maxMB, maxKB, maxkmaj;
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};
   double mfB;

   fp = StandHStart(pre, mmb, pfx, outd, "sum");
   maxkmaj = maxNB = maxKB = maxMB = 0;
   mfB = 0.0;
   for (n=0,mp=mmb; mp; n++, mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         maxkmaj = Mmax(maxkmaj, mp->vlen);
      maxMB = Mmax(maxMB, mp->mbB);
      maxNB = Mmax(maxNB, mp->nbB);
      maxKB = Mmax(maxKB, mp->kbB);
      mfB = Mmax(mfB, mp->mflop[0]);
   }
   if (maxkmaj == 1)
      maxkmaj = 0;
   maxb = Mmax(maxMB, maxNB);
   maxb = Mmax(maxb, maxKB);
   fprintf(fp, "\n#define ATL_AMM_MAXMB %d\n", maxMB);
   fprintf(fp, "#define ATL_AMM_MAXNB %d\n", maxNB);
   fprintf(fp, "#define ATL_AMM_MAXKB %d\n", maxKB);
   fprintf(fp, "#ifndef  ATL_geAMM_MAXKVEC\n", cn);
   fprintf(fp, "   #define ATL_geAMM_MAXKVEC %d\n\n", maxkmaj);
   fprintf(fp, "#endif\n");

   for (mp=mmb; mp && mp->next; mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_AMM_LMU %d\n", mp->mu);
   fprintf(fp, "#define ATL_AMM_LNU %d\n", mp->nu);
   fprintf(fp, "#define ATL_AMM_LKU %d\n", mp->ku);
   fprintf(fp, "#define ATL_AMM_LLCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_LLCMU %d\n\n", 
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
/*
 * Find smallest case achieving 2/3 of maximal performance
 */
   for (i=0,mp=mmb; mp && mp->mflop[0]*1.5 < mfB; i++, mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_AMM_66IDX %d\n", i);
   fprintf(fp, "#define ATL_AMM_66MB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_AMM_66NB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_AMM_66KB %d\n", mp->kbB);
   fprintf(fp, "#define ATL_AMM_66LCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_66LCMU %d\n\n", 
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   fprintf(fp, "#define ATL_AMM_66RATIO %1.4lf\n\n", mp->mflop[0]/mfB);
/*
 * Find smallest case achieving 98% of maximal performance
 */
   for (i=0,mp=mmb; mp && mp->mflop[0] < 0.98*mfB; i++, mp = mp->next);
   assert(mp);
   fprintf(fp, "#define ATL_AMM_98IDX %d\n", i);
   fprintf(fp, "#define ATL_AMM_98MB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_AMM_98NB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_AMM_98KB %d\n", mp->kbB);
   fprintf(fp, "#define ATL_AMM_98LCMMN %d\n\n", Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_AMM_98LCMU %d\n\n", 
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   fprintf(fp, "#define ATL_AMM_98RATIO %1.4lf\n\n", mp->mflop[0]/mfB);
   if (rkb)
   {
      maxkmaj = maxNB = maxKB = maxMB = 0;
      mfB = 0.0;
      for (n=0,mp=rkb; mp; n++, mp = mp->next)
      {
         if (FLAG_IS_SET(mp->flag, MMF_KVEC))
            maxkmaj = Mmax(maxkmaj, mp->vlen);
         maxMB = Mmax(maxMB, mp->mbB);
         maxNB = Mmax(maxNB, mp->nbB);
         maxKB = Mmax(maxKB, mp->kbB);
         mfB = Mmax(mfB, mp->mflop[0]);
      }
      if (maxkmaj == 1)
         maxkmaj = 0;
      fprintf(fp, "#define ATL_rkAMM_LASTMB %d\n", maxMB);
      fprintf(fp, "#define ATL_rkAMM_LASTNB %d\n", maxNB);
      fprintf(fp, "#define ATL_rkAMM_LASTKB %d\n", maxKB);
      fprintf(fp, "#define ATL_MAXKMAJ_RKK %d\n\n", maxkmaj);
/*
 *    Find smallest case achieving 2/3 of maximal performance
 */
      for (i=0,mp=rkb; mp && mp->mflop[0]*1.5 < mfB; i++, mp = mp->next);
      assert(mp);
      fprintf(fp, "#define ATL_66IDX_RKK %d\n", i);
      fprintf(fp, "#define ATL_66NB_RKK %d\n", mp->mbB);
      fprintf(fp, "#define ATL_66MB_RKK %d\n", mp->nbB);
      fprintf(fp, "#define ATL_66KB_RKK %d\n", mp->kbB);
      fprintf(fp, "#define ATL_66RATIO_RKK %1.4lf\n\n", mp->mflop[0]/mfB);
   }
   fprintf(fp, "#define ATL_AMMFLG_KRUNTIME(flg_) ((flg_) & 1)\n");
   fprintf(fp, "#define ATL_AMMFLG_KMAJOR(flg_) ((flg_) & 2)\n");

   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenPerfFile(char pre, ATL_mmnode_t *mmb, char *pfx, char *outd, 
                 double mfMax)
{
   ATL_mmnode_t *mp;
   #define NTHRSH 11
   int THRSH[NTHRSH] = {25, 33, 50, 66, 75, 80, 85, 90, 95, 98, 99};
   int idxT[NTHRSH];
   ATL_mmnode_t *mpT[NTHRSH];
   char *fnam;
   FILE *fp;
   char *type = "float";
   int i, j, n, maxb, maxNB, maxMB, maxKB, idxMax=0;
   const int FNDMAX = (mfMax == 0.0);
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};

   fp = StandHStart(pre, mmb, pfx, outd, "perf");

   if (FNDMAX)
   {
      for (i=0; i < NTHRSH; i++)
         mpT[i] = NULL;
      for (n=0,mp=mmb; mp; n++, mp = mp->next)
      {
         if (mp->mflop[0] > mfMax)
         {
            mfMax = mp->mflop[0];
            idxMax = n;
         }
      }
   }
   else
   {
      for (n=0,mp=mmb; mp; n++, mp = mp->next);
      idxMax = -1;
   }
   fprintf(fp, "#define ATL_%sAMM_DENOM %le /* (%.2f)*/ \n", pfx,
           mfMax, mfMax);
   fprintf(fp, "#define ATL_%sAMM_MAXMFLOPIDX %d\n\n", pfx, idxMax);
   if (FNDMAX)
   {
      for (n=0,mp=mmb; mp; mp = mp->next, n++)
      {
         double mf = mp->mflop[0] / mfMax;
         for (i=0; i < NTHRSH; i++)
         {
            if (!mpT[i] && THRSH[i]*0.01*mfMax < mp->mflop[0])
            {
               mpT[i] = mp;
               idxT[i] = n;
            }
         }
      }
      for (i=0; i < NTHRSH; i++)
      {
         mp = mpT[i];
      @multidef fd
         idxT[i] mp->mbB mp->nbB mp->kbB Mylcm(mp->mu,mp->nu) 
         Mylcm(Mylcm(mp->mu,mp->nu),mp->ku)
      @endmultidef
      @whiledef nm IDX MB NB KB LCMMN LCMU
         fprintf(fp, "#define ATL_AMM_%d@(nm) %d\n", THRSH[i],
                 @(fd));
         @undef fd
      @endwhile
      }
      fprintf(fp, "\n");
   }

   fprintf(fp, "static const float ATL_%sAMM_PERF[%d] =", pfx, n);
   fprintf(fp, "   /* %% of performance of best kernel */\n{\n");
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d */\n", mp->mflop[0]/mfMax,
              (mp->next)?',':' ', j, mp->kbB);
   fprintf(fp, "};\n\n");

   fprintf(fp, "static const float ATL_%sAMM_TIME[%d] =", pfx, n);
   fprintf(fp, "   /* %% of performance of best kernel */\n{\n");
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
      fprintf(fp, "   %e%c  /* IDX=%d, KB=%d */\n", 
              2.0*mp->mbB*mp->nbB*mp->kbB / (mp->mflop[0]*1.0e6),
              (mp->next)?',':' ', j, mp->kbB);
   fprintf(fp, "};\n\n");

   #if 0   /* found no use for this yet, so don't waste mem wt it */
   fprintf(fp, "static const float ATL_AMM_SPDUPNXT[%d] =", n);
   fprintf(fp, "   /* speedup of next higher NB */\n{\n");
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      double mf = (mp->next) ? mp->next->mflop[0] : mp->mflop[0];
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d vs. %d */\n", mf/mp->mflop[0],
              (mp->next)?',':' ', j, mp->kbB, mp->next?mp->next->kbB:mp->kbB);
   }
   fprintf(fp, "};\n\n");
   #endif

   fprintf(fp, "#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenBlockingFile(char pre, ATL_mmnode_t *mmb, char *pfx, char *outd)
{
   ATL_mmnode_t *mp;
   char *fnam;
   FILE *fp;
   char *type = "unsigned short";
   int i, n, maxb, maxNB, maxMB, maxKB, maxkmaj;
   char PRE = toupper(pre), bc[3] = {'M', 'N', 'K'};

   fp = StandHStart(pre, mmb, pfx, outd, "blk");
   maxkmaj = maxNB = maxKB = maxMB = 0;
   for (n=0,mp=mmb; mp; n++, mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         maxkmaj = Mmax(maxkmaj, mp->vlen);
      maxMB = Mmax(maxMB, mp->mbB);
      maxNB = Mmax(maxNB, mp->nbB);
      maxKB = Mmax(maxKB, mp->kbB);
   }
   if (maxkmaj == 1)
      maxkmaj = 0;
   maxb = Mmax(maxMB, maxNB);
   maxb = Mmax(maxb, maxKB);
   fprintf(fp, "#define ATL_AMM_MAXMB %d\n", maxMB);
   fprintf(fp, "#define ATL_AMM_MAXNB %d\n", maxNB);
   fprintf(fp, "#define ATL_AMM_MAXKB %d\n", maxKB);
   fprintf(fp, "#ifndef  ATL_AMM_MAXKVEC\n", cn);
   fprintf(fp, "   #define ATL_AMM_MAXKVEC %d\n", maxkmaj);
   fprintf(fp, "#endif\n");
   fprintf(fp, "\n");

   if (maxb <= 255)
      type = "unsigned char";
   for (i=0; i < 3; i++)
   {
      int j;
      fprintf(fp, "static const %s ATL_AMM_%cBs[%d] =\n{\n", 
              type, bc[i], n);
      for (j=0,mp=mmb; mp; j++,mp = mp->next)
      {
         int b;
         if (bc[i] == 'M')
            b = mp->mbB;
         else if (bc[i] == 'N')
            b = mp->nbB;
         else if (bc[i] == 'K')
            b = mp->kbB;
         if (mp->next)
            fprintf(fp, "%8d,  /* index %d */\n", b, j);
         else
            fprintf(fp, "%8d   /* index %d */\n", b, j);
      }
      fprintf(fp, "};\n\n");
   }
   for (i=0; i < 3; i++)
   {
      int j;
      fprintf(fp, "static const %s ATL_AMM_%cUs[%d] =\n{\n", 
              type, bc[i], n);
      for (j=0,mp=mmb; mp; j++,mp = mp->next)
      {
         int b;
         if (bc[i] == 'M')
            b = mp->mu;
         else if (bc[i] == 'N')
            b = mp->nu;
         else if (bc[i] == 'K')
         {
            if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
               b = mp->ku;
            else
               b = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->ku : mp->kbB;
         }
         if (mp->next)
            fprintf(fp, "%8d,  /* index %d */\n", b, j);
         else
            fprintf(fp, "%8d   /* index %d */\n", b, j);
      }
      fprintf(fp, "};\n\n");
   }
   fprintf(fp, "static const %s ATL_AMM_KBMINs[%d] =\n{\n", type, n);
   for (i=0,mp=mmb; mp; i++,mp = mp->next)
   {
      if (mp->next)
         fprintf(fp, "%8d,  /* index %d */\n", mp->kbmin, i);
      else
         fprintf(fp, "%8d   /* index %d */\n", mp->kbmin, i);
   }
   fprintf(fp, "};\n\n");
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenFlagH(char pre, ATL_mmnode_t *mmb, char *pfx, char *outd)
{
   FILE *fp;
   int j, n;
   ATL_mmnode_t *mp;

   fp = StandHStart(pre, mmb, pfx, outd, "flag");

   for (n=0,mp=mmb; mp; n++,mp = mp->next);

   fprintf(fp, "static const unsigned char ATL_AMM_KFLAG[%d] =\n{\n", n);
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      unsigned char flag=FLAG_IS_SET(mp->flag, MMF_KRUNTIME) ? 1 : 0;
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         flag |= 2;
      if (mp->next)
         fprintf(fp, "%6d,  /* index %d */\n", flag, j);
      else
         fprintf(fp, "%6d   /* index %d */\n", flag, j);
   }
   fprintf(fp, "};\n\n");
   fprintf(fp, "#define ATL_AMM_KRUNTIME(idx_) (ATL_AMM_KFLAG[idx_] & 1)\n");
   fprintf(fp, "#define ATL_AMM_KMAJOR(idx_) (ATL_AMM_KFLAG[idx_] & 2)\n");
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void SpewForthC2MProto(char pre, FILE *fp0, FILE *fp1, int mu, int nu)
{
   char ac[3] = {'1', 'n', 'X'};
   char bc[4] = {'0', '1', 'n', 'X'};
   int ia, ib;
   for (ia=0; ia < 3; ia ++)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp0, "void ATL_%cablk2cmat_%dx%d_a%c_b%c\n", 
                 pre, mu, nu, ac[ia], bc[ib]);
         if (pre == 'z' || pre == 'c')
            fprintf(fp0, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         else
            fprintf(fp0, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         fprintf(fp1, "void ATL_%ccmat2ablk_%dx%d_a%c_b%c\n", 
                 pre, mu, nu, ac[ia], bc[ib]);
         if (pre == 'z' || pre == 'c')
            fprintf(fp1, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,const SCALAR,TYPE*,TYPE*);\n");
         else
            fprintf(fp1, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,const SCALAR,TYPE*);\n");
      }
   }
}

void SpewForthC2BDecl(char pre, ATL_mmnode_t *mmb, FILE *fp, char *rt, 
                      char alp, char bet)
{
   ATL_mmnode_t *mp;
   int j;

   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      fprintf(fp, "   ATL_%c%s_%dx%d_a%c_b%c", 
              pre, rt, mp->mu,mp->nu, alp, bet);
      if (mp->next)
         fprintf(fp, ",  /* index %d */\n", j);
      else
         fprintf(fp, "   /* index %d */\n", j);
      }
      fprintf(fp, "};\n\n");
}

void GenC2BLK(char pre, ATL_mmnode_t *mmb, char *pfx, char *outd)
{
   FILE *fp0, *fp1;
   ATL_mmnode_t *mp;
   int ia, ib;
   char ac[3] = {'1', 'n', 'X'};
   char bc[4] = {'0', '1', 'n', 'X'};
   char *fnam;

   fp0 = StandHStart(pre, mmb, pfx, outd, "ablk2cmat");
   fp1 = StandHStart(pre, mmb, pfx, outd, "cmat2ablk");
   fprintf(fp0, "\n");
   fprintf(fp1, "\n");
/*
 * Crank out prototypes
 */
   SpewForthC2MProto(pre, fp0, fp1, mmb->mu, mmb->nu);
   for (mp=mmb->next; mp; mp = mp->next)
   {
      ATL_mmnode_t *p;
      const int mu=mp->mu, nu=mp->nu;
      for (p=mmb; p->mu != mu || p->nu != nu; p = p->next);
      if (p == mp)  /* first occurance of this mu,nu pair */
         SpewForthC2MProto(pre, fp0, fp1, mp->mu, mp->nu);
   }
   fprintf(fp0, "\n");
   fprintf(fp1, "\n");
/*
 * Now, crank out funcptr arrays
 */
   for (ia=0; ia < 3; ia ++)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp0, 
            "static const ablk2cmat_t ATL_AMM_BLK2C_a%c_b%c[ATL_AMM_NCASES] =\n{\n",
                 ac[ia], bc[ib]);
         SpewForthC2BDecl(pre, mmb, fp0, "ablk2cmat", ac[ia], bc[ib]);
         fprintf(fp1, 
            "static const cmat2ablk_t ATL_AMM_C2BLK_a%c_b%c[ATL_AMM_NCASES] =\n{\n",
                 ac[ia], bc[ib]);
         SpewForthC2BDecl(pre, mmb, fp1, "cmat2ablk", ac[ia], bc[ib]);
      }
   }
   fprintf(fp0, "\n#endif  /* end include file guard */\n");
   fclose(fp0);
   fprintf(fp1, "\n#endif  /* end include file guard */\n");
   fclose(fp1);
}

void SpewForthRevCpProto(char pre, FILE *fp, char alp, int u, int kmaj)
{
   const int G = (pre == 'c' || pre == 'z') ? 2 : 1;
   const char *cst[2] = {"", "C"};
   int g;

   for (g=0; g < G; g++)
   {
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cam2cm_a%c_%dx%d%s\n",
                 pre, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cam2cm_a%c_%d%s\n",pre, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*,const TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*);\n");
      if (kmaj > 1)
         fprintf(fp, "void ATL_%cam2rm_a%c_%dx%d%s\n",
                 pre, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%cam2rm_a%c_%d%s\n",pre, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*,const TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,TYPE*,ATL_CSZT,const TYPE*);\n");
   }
}

void SpewForthCpProto(char pre, FILE *fp, char alp, int u, int kmaj)
{
   const int G = (pre == 'c' || pre == 'z') ? 2 : 1;
   const char *cst[2] = {"", "C"};
   int g;

   for (g=0; g < G; g++)
   {
      if (kmaj > 1)
         fprintf(fp, "void ATL_%ccm2am_a%c_%dx%d%s\n", 
                 pre, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%ccm2am_a%c_%d%s\n", pre, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp,
    "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*);\n");
      if (kmaj > 1)
         fprintf(fp, "void ATL_%crm2am_a%c_%dx%d%s\n", 
                 pre, alp, kmaj, u, cst[g]);
      else
         fprintf(fp, "void ATL_%crm2am_a%c_%d%s\n", pre, alp, u, cst[g]);
      if (pre == 'z' || pre == 'c')
         fprintf(fp,
     "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
      else
         fprintf(fp,
         "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,ATL_CSZT,TYPE*);\n");
   }
}

void SpewForthCpConjDecl(char pre, int REVERSE, ATL_mmnode_t *mmb, FILE *fp, 
                         char *arr, char *rt, char alp, int u)
{
   ATL_mmnode_t *mp;
   int j;

   fprintf(fp, "static const %s_t %s_a%c[%d] =\n{\n",
           REVERSE?"am2cm":"cm2am", arr, alp,  ATL_CountNumberOfMMNodes(mmb));
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (kmaj > 1)
         fprintf(fp, "   ATL_%c%s_a%c_%dx%dC", pre, rt, alp, kmaj, 
                 u?mp->mu:mp->nu);
      else
         fprintf(fp, "   ATL_%c%s_a%c_%dC", pre, rt, alp, u?mp->mu:mp->nu);
      if (mp->next)
         fprintf(fp, ",");
      else
         fprintf(fp, " ");
      fprintf(fp, "  /* index %d */\n", j);
   }
   fprintf(fp, "};\n\n");
}

void SpewForthCpDecl(char pre, int REVERSE, ATL_mmnode_t *mmb, FILE *fp, 
                     char *arr, char *rt, char alp, int u)
{
   ATL_mmnode_t *mp;
   int j;

   fprintf(fp, "static const %s_t %s_a%c[%d] =\n{\n", 
           REVERSE?"am2cm":"cm2am", arr, alp, ATL_CountNumberOfMMNodes(mmb));
   for (j=0,mp=mmb; mp; j++,mp = mp->next)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (kmaj > 1)
         fprintf(fp, "   ATL_%c%s_a%c_%dx%d", pre, rt, alp, kmaj, 
                 u?mp->mu:mp->nu);
      else
         fprintf(fp, "   ATL_%c%s_a%c_%d", pre, rt, alp, u?mp->mu:mp->nu);
      if (mp->next)
         fprintf(fp, ",");
      else
         fprintf(fp, " ");
      fprintf(fp, "  /* index %d */\n", j);
   }
   fprintf(fp, "};\n\n");
}


@define len @23@
void GenAMAJ2CMAJ(char pre, ATL_mmnode_t *mmb, char *suff, char *outd)
/*
 * 3. atlas_<pre>amm_am2cm_a[1,X,n]: 
 *    defines: ATL_AMM_NCASES
 *    prototypes all am2rm & am2cm routines
 *    1 indexible array giving which to use for each block factor
 */
{
   char ac[3] = {'1', 'n', 'X'};
   int ia, j;
   char *fnam, *sp, *np;
   ATL_mmnode_t *mp;

   if (!suff)
      suff = "";
   ia = strlen(outd) + strlen(suff) + @(len);
   fnam = malloc(ia*sizeof(char));
   assert(fnam);
   sprintf(fnam, "%s/atlas_%c%samm_am2cm_a1.h", outd, pre, suff);
   np = fnam+ia-23+12;
   assert(*np == 'a' && np[1] == 'm');
   sp = fnam+ia-4;
   assert(*sp == '1');

   for (ia=0; ia < 3; ia++)
   {
      char *rt[2] = {"am2cm", "am2rm"};
      FILE *fp;
      int kmaj = FLAG_IS_SET(mmb->flag, MMF_KVEC) ? mmb->vlen:0;

      if (kmaj == 1)
         kmaj = 0;
      *sp = ac[ia];
      fp = fopen(fnam, "w");
      assert(fp);
      sp[1] = '\0';
      PrintBegBlock(pre, mmb, NULL, np, fp);
      sp[1] = '.';
      fprintf(fp, "/*\n * mat2blk prototypes\n */\n");
      SpewForthRevCpProto(pre, fp, ac[ia], mmb->mu, kmaj);
      if (mmb->nu != mmb->mu || kmaj > 1)
         SpewForthRevCpProto(pre, fp, ac[ia], mmb->nu, kmaj);
      for (mp=mmb->next; mp; mp = mp->next)
      {
         ATL_mmnode_t *p;
         int mu = mp->mu, nu = mp->nu;
         int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if (mu == p->mu && km == kmaj)
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthRevCpProto(pre, fp, ac[ia], mu, kmaj);
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if ((p->nu == nu && km == kmaj) || 
                (km == kmaj && p->mu == nu))
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthRevCpProto(pre, fp, ac[ia], nu, kmaj);
      }
      fprintf(fp, "\n");
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_AMM_BLK2A", "am2cm", ac[ia], 1);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_AMM_BLK2AT", "am2rm", ac[ia], 1);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_AMM_BLK2B", "am2cm", ac[ia], 0);
      SpewForthCpDecl(pre,1,mmb, fp, "ATL_AMM_BLK2BT", "am2rm", ac[ia], 0);
      if (pre == 'c' || pre == 'z')
      {
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_AMM_BLKC2A", 
                             "am2cm", ac[ia], 1);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_AMM_BLKH2A", 
                             "am2rm", ac[ia], 1);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_AMM_BLKC2B", 
                             "am2cm", ac[ia], 0);
         SpewForthCpConjDecl(pre, 1, mmb, fp, "ATL_AMM_BLKH2B", 
                             "am2rm", ac[ia], 0);
      }
      fprintf(fp, "\n#endif  /* end include file guard */\n");
      fclose(fp);
   }
   free(fnam);
}
void GenCMAJ2AMAJ(char pre, ATL_mmnode_t *mmb, char *pfx, char *outd)
/*
 * 3. atlas_<pre>amm_cm2am_a[1,X,n]: 
 *    defines: ATL_AMM_NCASES
 *    prototypes all rm2am & cm2am routines
 *    1 indexible array giving which to use for each block factor
 */
{
   char ac[3] = {'1', 'n', 'X'};
   int ia, j;
   char *fnam, *sp, *np;
   ATL_mmnode_t *mp;

   ia = strlen(outd) + strlen(pfx) + @(len);
   fnam = malloc(ia*sizeof(char));
   assert(fnam);
   sprintf(fnam, "%s/atlas_%c%samm_cm2am_a1.h", outd, pre, pfx);
   np = fnam+ia-23+12;
   assert(*np == 'c' && np[1] == 'm');
   sp = fnam+ia-4;
   assert(*sp == '1');

   for (ia=0; ia < 3; ia++)
   {
      char *rt[2] = {"cm2am", "rm2am"};
      FILE *fp;
      int kmaj = FLAG_IS_SET(mmb->flag, MMF_KVEC) ? mmb->vlen:0;

      if (kmaj == 1)
         kmaj = 0;
      *sp = ac[ia];
      fp = fopen(fnam, "w");
      assert(fp);
      sp[1] = '\0';
      PrintBegBlock(pre, mmb, NULL, np, fp);
      sp[1] = '.';
      fprintf(fp, "/*\n * mat2blk prototypes\n */\n");
      SpewForthCpProto(pre, fp, ac[ia], mmb->mu, kmaj);
      if (mmb->nu != mmb->mu || kmaj > 1)
         SpewForthCpProto(pre, fp, ac[ia], mmb->nu, kmaj);
      for (mp=mmb->next; mp; mp = mp->next)
      {
         ATL_mmnode_t *p;
         int mu = mp->mu, nu = mp->nu;
         int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if (mu == p->mu && km == kmaj)
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthCpProto(pre, fp, ac[ia], mu, kmaj);
         for (p=mmb; p != mp; p = p->next)
         {
            int km = FLAG_IS_SET(p->flag, MMF_KVEC) ? p->vlen:0;
            if ((p->nu == nu && km == kmaj) || 
                (km == kmaj && p->mu == nu))
               break;
         }
         if (p == mp) /* haven't seen before */
            SpewForthCpProto(pre, fp, ac[ia], nu, kmaj);
      }
      fprintf(fp, "\n");
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_AMM_AN2BLK", "cm2am", ac[ia], 1);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_AMM_AT2BLK", "rm2am", ac[ia], 1);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_AMM_BN2BLK", "cm2am", ac[ia], 0);
      SpewForthCpDecl(pre,0,mmb, fp, "ATL_AMM_BT2BLK", "rm2am", ac[ia], 0);
      if (pre == 'c' || pre == 'z')
      {
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_AMM_AC2BLK", 
                             "cm2am", ac[ia], 1);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_AMM_AH2BLK", 
                             "rm2am", ac[ia], 1);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_AMM_BC2BLK", 
                             "cm2am", ac[ia], 0);
         SpewForthCpConjDecl(pre, 0, mmb, fp, "ATL_AMM_BH2BLK", 
                             "rm2am", ac[ia], 0);
      }
      fprintf(fp, "\n#endif  /* end include file guard */\n");
      fclose(fp);
   }
   free(fnam);
}

int KernelIsExactSame(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same including KB, 0 otherwise
 */
{
/*
 * Kernels aren't the same if one is being compiled with specific KB,
 * and the other has runtime
 */
   if (FLAG_IS_SET(p0->flag, MMF_KRUNTIME) != 
       FLAG_IS_SET(p1->flag, MMF_KRUNTIME))
      return(0);
   if (!FLAG_IS_SET(p0->flag, MMF_KRUNTIME) && (p0->kbB != p1->kbB))
      return(0);
/*
 * Kernels aren't same if their vectorization strategy is different
 */
   if (FLAG_IS_SET(p0->flag, MMF_KVEC) != FLAG_IS_SET(p1->flag, MMF_KVEC))
      return(0);
   if (p0->vlen != p1->vlen)
      return(0);
/*
 * Kernels aren't same if the -DATL_MOVE bits don't match
 */
   if (ATL_MMF_MVGET(p0->flag) != ATL_MMF_MVGET(p1->flag))
      return(0);
/*
 * Two generated kernels are the same if mu,nu,kmaj,ku,VLEN,flag are the same.
 * NOTE: if we make generator handle muladd, etc, MUST UPDATE HERE!!!
 */
   if (p0->ID == 0 && p1->ID == 0)
      return(p0->mu == p1->mu && p0->nu == p1->nu && p0->ku == p1->ku && 
             p0->vlen == p1->vlen && p0->flag == p1->flag);
/*
 * If both are user kernels, then they may be repeats.  For user kernels,
 * they are the same if both ID and flag match, else they are not.
 */
   else if (p0->ID > 0 && p1->ID > 0)
      return(p0->ID == p1->ID && p0->flag == p1->flag);
   return(0);  /* Can't be the same if above criteria fails */
}

/*
 * RETURNS: flags that necessitate recompilation, not including KRUNTIME,
 * which is encoded in kb
 */
int GetCompTimeFlags(ATL_mmnode_t *mp)
{
   int iflg;
   iflg = ATL_MMF_MVGET(mp->flag);  /* MVbits change kern at comp time */
   iflg |=  (((mp->flag) & 1)<<3);  /* LDTOP/BOT could be compile-time dec */
   if (FLAG_IS_SET(mp->flag, MMF_KVEC))
      iflg |= 1<<4;
   return(iflg);
}

void FillInGenStrings
(
   char pre,
   ATL_mmnode_t *mmb,  /* queue to look through */
   char *dir           /* output directory to generate into */
)
/*
 * Creates GenString for any ID=0 in mmb
 */
{
   ATL_mmnode_t *mp;

   if (pre == 'z')
      pre = 'd';
   else if (pre == 'c')
      pre = 's';

   for (mp=mmb; mp; mp = mp->next)
   {
      if (mp->ID == 0)  /* is generated file */
      {
         int lr, ld;
         char *sp, *sp0=mp->rout;

         assert(sp0);  /* should have been filled in by search */
         lr = strlen(sp0);
         ld = strlen(dir);
         sp = malloc(ld+ld+2);
         assert(sp);
         strncpy(sp, dir, ld);
         sp[ld] = '/';
         strcpy(sp+ld+1, sp0);
         mp->rout = sp;
         mp->genstr = MMGetGenString(pre, mp);
         mp->rout = sp0;
         free(sp);
      }
   }
}

int ExactKernelInList(ATL_mmnode_t *mmb, ATL_mmnode_t *p)
/*
 * RETURNS: 1 if p is duplicated in mmb, else 0
 */
{
   ATL_mmnode_t *mp;
   if (!p || !mmb)
      return(0);
   for (mp=mmb; mp; mp = mp->next)
      if (KernelIsExactSame(mp, p))
         return(1);
    return(0);
}

void SpewForthKernProto(FILE *fp, char pre, char *nm, ATL_mmnode_t *p, char bc)
{
   fprintf(fp, "void ATL_%c%s_%d_%d_%x_%dx%dx%d_b%c\n", pre, nm, p->ID, 
           FLAG_IS_SET(p->flag, MMF_KRUNTIME)?0:p->kbB, GetCompTimeFlags(p),
           p->mu, p->nu, p->ku,bc);
   fprintf(fp, 
      "   (ATL_CSZT,ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,TYPE*,\n");
   fprintf(fp, 
      "    const TYPE*,const TYPE*,const TYPE*);\n");
}

void SpewForthKernProtos(FILE *fp, char pre, char *nm, ATL_mmnode_t *mmb, 
                         int nbet)
{
   ATL_mmnode_t *mp;
   for (mp=mmb; mp; mp = mp->next)
   {
      char bc[3] = {'0', '1', 'n'};  /* 0 must come first */
      int ib;
      for (ib=0; ib < nbet; ib++)
         SpewForthKernProto(fp, pre, nm, mp, bc[ib]);
   }
}

void SpewForthKernArray(FILE *fp, char pre, ATL_mmnode_t *mmb, 
                        char *vnam, char cbet)
{
   ATL_mmnode_t *mp;
   int n;
   char *nm = (vnam[5] == 'R' && vnam[6] == 'K') ? "AMRK":"AMMM";

   for (n=0,mp=mmb; mp; n++, mp = mp->next);
   fprintf(fp, "static const ammkern_t ATL_AMM_%s[%d] =\n", vnam, n);
   fprintf(fp, "{\n");
   for (mp=mmb; mp; mp = mp->next)
   {
      fprintf(fp, "   ATL_%c%s_%d_%d_%x_%dx%dx%d_b%c", pre, nm, mp->ID, 
              FLAG_IS_SET(mp->flag, MMF_KRUNTIME)?0:mp->kbB, 
              GetCompTimeFlags(mp), mp->mu, mp->nu, mp->ku, cbet);
      if (mp->next)
         fprintf(fp, ",\n");
   }
   fprintf(fp, "\n};\n\n");
}

/*
 * RETURNS: new list of K-cleanup kernels for mmb taken from mmk; 
 * mmb & mmk not changed
 */
ATL_mmnode_t *GetUniqueK1Kerns
(
   char pre,            /* z,c,d,s */
   ATL_mmnode_t *mmb,   /* list of kernels requiring K-cleanup */
   ATL_mmnode_t *mmk,   /* list of K-cleanup kernels */
   char *outd
)
{
   ATL_mmnode_t *kcb=NULL, *prev, *mp;
   for (mp=mmb; mp; mp = mp->next)
   {
      ATL_mmnode_t *kc;
      int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      for (kc=mmk; kc; kc = kc->next) /* search for matching cleanup routine */
      {
         int km = FLAG_IS_SET(kc->flag, MMF_KVEC) ? kc->vlen:0;
         if (kc->mu == mp->mu && kc->nu == mp->nu && km == kmaj)
            break;
      }
      if (!kc)  /* cleanup routine must be in original list! */
      {
         if (mp->ku == 1 && FLAG_IS_SET(mp->flag, MMF_KRUNTIME) &&
             (!mp->kbmin || mp->kbmin == 1))
            kc = mp;
         else
         {
            for (kc=mmb; kc; kc = kc->next)
            {
               int km = FLAG_IS_SET(kc->flag, MMF_KVEC) ? kc->vlen:0;
               if (kc->mu == mp->mu && kc->nu == mp->nu && km == kmaj
                   && kc->ku == 1 && FLAG_IS_SET(kc->flag, MMF_KRUNTIME) &&
                   (!kc->kbmin || kc->kbmin == 1) && 
                   (!kc->kbmax || kc->kbmax >= mp->kbB))
                  break;
            }
            assert(kc);
         }
      }
      assert(kc);
      kc = CloneMMNode(kc);
      kc->mbB = mp->mbB;
      kc->nbB = mp->nbB;
      kc->kbB = mp->kbB;
      if (kcb)
      {
         prev->next = kc;
         prev = prev->next;
      }
      else
         prev = kcb = kc;
      
   }
   FillInGenStrings(pre, kcb, outd);
   return(kcb);
}

/*
 * RETURNS: possibly updated list of all unique mu/nu comboes
 */
typedef struct mnur mnur_t;
struct mnur {int mu; int nu; int kmaj; mnur_t *next;};
mnur_t *GetUniqueMNUnrolls(ATL_mmnode_t *mmb, mnur_t *urb)
{
   ATL_mmnode_t *mp;
   mnur_t *up;
/*
 * For each node in mmb, add to urb if mu/nu combo not already there
 * kmaj only affects A/B copy, and this is for C put, so ignore kmaj
 */
   for (mp = mmb; mp; mp = mp->next)
   {
      for (up=urb; up; up = up->next)
         if (mp->mu == up->mu && mp->nu == up->nu)
            break;
      if (!up)
      {
         up = malloc(sizeof(mnur_t));
         assert(up);
         up->mu = mp->mu;
         up->nu = mp->nu;
         up->kmaj = 0;
         up->next = urb;
         urb = up;
      }
   }
   return(urb);
}

/*
 * RETURNS: list of just unique MUs from mnb not already in mub
 */
mnur_t *GetUniqueMUnrolls(ATL_mmnode_t *mnb, mnur_t *mub)
{
   mnur_t *mup;
   ATL_mmnode_t *mnp;
   if (!mnb)
      return(mub);
   for (mnp=mnb; mnp; mnp = mnp->next)
   {
      const int kmaj = FLAG_IS_SET(mnp->flag, MMF_KVEC) ? mnp->vlen:0;
      for (mup=mub; mup; mup = mup->next)
         if (mup->mu == mnp->mu && mup->kmaj == kmaj)
            break;
      if (!mup)  /* a new mu */
      {
         mup = malloc(sizeof(mnur_t));
         assert(mup);
         mup->nu = mup->mu = mnp->mu;
         mup->next = mub;
         mup->kmaj = kmaj;
         mub = mup;
      }
   }
   return(mub);
}
/*
 * RETURNS: list of just unique NUs from mnb not already in mub
 */
mnur_t *GetUniqueNUnrolls(ATL_mmnode_t *mnb, mnur_t *mub)
{
   mnur_t *mup;
   ATL_mmnode_t *mnp;
   if (!mnb)
      return(mub);
   for (mnp=mnb; mnp; mnp = mnp->next)
   {
      const int kmaj = FLAG_IS_SET(mnp->flag, MMF_KVEC) ? mnp->vlen:0;
      for (mup=mub; mup; mup = mup->next)
         if (mup->mu == mnp->nu && kmaj == mup->kmaj)
            break;
      if (!mup)  /* a new nu */
      {
         mup = malloc(sizeof(mnur_t));
         assert(mup);
         mup->nu = mup->mu = mnp->nu;
         mup->next = mub;
         mup->kmaj = kmaj;
         mub = mup;
      }
   }
   return(mub);
}

void KillUnrollList(mnur_t *b)
{
   mnur_t *p;
   while (b)
   {
      p = b->next;
      free(b);
      b = p;
   }
}

int MMKernsSame1(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same except for blocking, 0 otherwise
 */
{
/*
 * Kernels aren't the same if one is being compiled with specific KB,
 * and the other has runtime
 */
   if (FLAG_IS_SET(p0->flag, MMF_KRUNTIME) != 
       FLAG_IS_SET(p1->flag, MMF_KRUNTIME))
      return(0);
/*
 * Two generated kernels are the same if mu,nu,ku,VLEN,flag are the same.
 * NOTE: if we make generator handle muladd, etc, MUST UPDATE HERE!!!
 */
   if (p0->ID == 0 && p1->ID == 0)
      return(p0->mu == p1->mu && p0->nu == p1->nu && p0->ku == p1->ku &&
             p0->vlen == p1->vlen && p0->flag == p1->flag);
/*
 * If both are user kernels, then they may be repeats.  For user kernels,
 * they are the same if both ID and flag match, else they are not.
 */
   else if (p0->ID > 0 && p1->ID > 0)
      return(p0->ID == p1->ID && p0->flag == p1->flag);
   return(0);  /* Can't be the same if above criteria fails */
}

@beginskip
/*
 * This routine spits out the timing estimate for doing a muXnuXku portion
 * of the computation.  It is a wild estimate, in that assumes you are
 * using mbBxnbBxkbB blocking used during timings, but it's better than nothing.
 * Note we have a MFLOP measure, and mf = 2*M*N*K / (1e6*time)
 * so time = 2*M*N*K / (1e6*mf), which is time for full GEMM, so
 * time / M*N*K is time for 1 K iteration, or t1 = 2 / (1.e6*mf), which we
 * then multiply by mu*nu*ku to get t2 = 2*mu*nu*ku /1.e6*mf, which is the
 * time to do one unrolled iteration of the ku loop (the building block of
 * all usage of this kernel).  For k-major storage, total time can be
 * estimated at:
 *   T = CEIL(M/mu)*CEIL(N/nu)*CEIL(K/ku)*t3
 * For M-major storage it would instead be:
 *   T = CEIL(M/mu) * CEIL(N/nu) * (FLOOR(K/ku)*t3 + K%ku*t3_K1)
 * where t3_K1 is the t3 mentioned above for the KU=1 K-cleanup kernel.
 */
void SpewTimeEst
(
   ATL_mmnode_t *mmb,  /* baseptr  of AMMM kernel queue */
   char *arrnam,       /* name of array to create */
   FILE *fpout,        /* open file stream to print array to */
   int imf             /* which mflop elt to use for timing */
)
{
}
@endskip

void GenRankKH
(
   char pre, 
   ATL_mmnode_t *geb,  /* baseptr  of gemm kernels */
   ATL_mmnode_t *rkb,  /* rank-K kernels, one for each supported K */
   char *outd
)
{
   FILE *fp;
   mnur_t *putb, *cpyb, *up;
   ATL_mmnode_t *mp;
   int m, n, k;
   int ia, ib;
   char PRE = pre;
   char ac[3] =  {'1', 'n', 'X'};
   char bc[4] = {'1', 'n', '0', 'X'};
   if (pre == 'c')
      pre = 's';
   else  if (pre == 'z')
      pre = 'd';

   assert(geb && rkb);
   fp = StandHStart(PRE, rkb, "rk", outd, "kern");
   fprintf(fp, "\n");

   for (mp=geb; mp->next; mp = mp->next);
   fprintf(fp, "#define ATL_rkAMM_LASTMB %d\n", mp->mbB);
   fprintf(fp, "#define ATL_rkAMM_LASTNB %d\n", mp->nbB);
   fprintf(fp, "#define ATL_rkAMM_LASTKB %d\n\n", mp->kbB);
/*
 * Prototype needed copy routines
 */
   putb = GetUniqueMNUnrolls(rkb, NULL);
   fprintf(fp, "/*\n * cblk2mat put function prototypes\n */\n");
   for (up=putb; up; up = up->next)
   {
      for (ib=0; ib < 4; ib++)
      {
         fprintf(fp, "void ATL_%cablk2cmat_%dx%d_a1_b%c\n", 
                 PRE, up->mu, up->nu, bc[ib]);
         if (PRE == 'c' || PRE == 'z')
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
         else
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const SCALAR,TYPE *,ATL_CSZT);\n");
      }
   }
   KillUnrollList(putb);
   fprintf(fp, 
      "/*\n * Column-major to access-major copy function prototypes\n */\n");
   cpyb = GetUniqueMUnrolls(rkb, NULL);
   cpyb = GetUniqueNUnrolls(rkb, cpyb);
   for (up=cpyb; up; up = up->next)
   {
      for (ia=0; ia < 3; ia++)
         SpewForthCpProto(PRE, fp, ac[ia], up->mu, up->kmaj);
   }
   KillUnrollList(cpyb);
/*
 * Prototype the rank-K functions
 */
   fprintf(fp, "/*\n * rank-K AMMM kernel prototypes\n */\n");
   for (mp=rkb; mp; mp = mp->next)
   {
/*
 *    For runtime-K kernels, only prototype 1st time they are seen in list
 */
      if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
      {
         ATL_mmnode_t *p;
         if (mp->ID > 0)
         {
            for (p=rkb; p != mp; p = p->next)
               if (p->ID == mp->ID)
                  break;
         }
         else
         {
            for (p=rkb; p != mp; p = p->next)
               if (MMKernsSame(mp, p))
                  break;
         }
         if (mp == p)
         {
            SpewForthKernProto(fp, pre, "AMRK", mp, '0');
            SpewForthKernProto(fp, pre, "AMRK", mp, '1');
            SpewForthKernProto(fp, pre, "AMRK", mp, 'n');
         }
      }
/*
 *    compile-time-K kernels get prototyped for each invocation
 */
      else
      {
         SpewForthKernProto(fp, pre, "AMRK", mp, '0');
         SpewForthKernProto(fp, pre, "AMRK", mp, '1');
         SpewForthKernProto(fp, pre, "AMRK", mp, 'n');
      }
   }
/*
 * Now, crank out funcptr arrays
 */
   for (ib=0; ib < 4; ib++)
   {
      fprintf(fp,
         "\nstatic const ablk2cmat_t ATL_AMM_BLK2C_a1_b%c[%d] =\n{\n",
              bc[ib], ATL_CountNumberOfMMNodes(rkb));
      SpewForthC2BDecl(PRE, rkb, fp, "ablk2cmat", '1', bc[ib]);
   }
   for (ia=0; ia < 3; ia++)
   {
      fprintf(fp, "\n");
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_AN2BLK", "cm2am", ac[ia], 1);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_AT2BLK", "rm2am", ac[ia], 1);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_BN2BLK", "cm2am", ac[ia], 0);
      SpewForthCpDecl(PRE, 0, rkb, fp, "ATL_AMM_BT2BLK", "rm2am", ac[ia], 0);
      if (PRE == 'z' || PRE == 'c')
      {
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_AC2BLK", "cm2am",ac[ia],1);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_AH2BLK", "rm2am",ac[ia],1);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_BC2BLK", "cm2am",ac[ia],0);
         SpewForthCpConjDecl(PRE,0,rkb, fp, "ATL_AMM_BH2BLK", "rm2am",ac[ia],0);
      }
   }
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK", '0');
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK_b1", '1');
   SpewForthKernArray(fp, pre, rkb, "KERN_RKK_bn", 'n');
   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenKernH
(
   char pre, 
   char *outd, 
   char *pfx, 
   ATL_mmnode_t *mmb,  /* full kerns */
   ATL_mmnode_t *k1b   /* K cleanup kerns */
)
/*
 * 5. atlas_<pre>_<pfx>kern.h
 *    defines: ATL_AMM_NCASES
 *    prototypes all kernels, including K-cleanup
 *    1 indexible array gives kernel to use for each case as func ptr
 *    1 indexible array gives K-clean kernel
 */
{
   FILE *fp;
   ATL_mmnode_t *ukb;
   const char upr = (pre == 'z' || pre == 'd') ? 'd' : 's';

   fp = StandHStart(pre, mmb, pfx, outd, "kern");
   fprintf(fp, "\n");
/*
 * For prototyping, create a list of all full and cleanup kerns, and get
 * rid of duplicates
 */
   ukb = AddUniqueMMKernCompList(NULL, mmb);
   ukb = AddUniqueMMKernCompList(ukb, k1b);
   SpewForthKernProtos(fp, upr, "AMMM", ukb, 3);
   fprintf(fp, "\n");
   KillAllMMNodes(ukb);
/*
 * Dump out kernel ptr arrays
 */
   SpewForthKernArray(fp, upr, mmb, "KERN_b0", '0');
   SpewForthKernArray(fp, upr, mmb, "KERN_b1", '1');
   SpewForthKernArray(fp, upr, mmb, "KERN_bn", 'n');
   if (k1b)
   {
      SpewForthKernArray(fp, upr, k1b, "KERN_K1", '0');
      SpewForthKernArray(fp, upr, k1b, "KERN_K1_b1", '1');
      SpewForthKernArray(fp, upr, k1b, "KERN_K1_bn", 'n');
   }

   fprintf(fp, "\n#endif  /* end include file guard */\n");
   fclose(fp);
}

void GenCmplxHeaders(char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *rkb, 
                     char *pfx, char *outd)
{
@skip   GenAMAJ2CMAJ(pre, mmb, pfx, outd);
   GenCMAJ2AMAJ(pre, mmb, pfx, outd);
   GenC2BLK(pre, mmb, pfx, outd);
   if (rkb)
   {
@skip      GenAMAJ2CMAJ(pre, mmb, pfx, outd);
      GenCMAJ2AMAJ(pre, rkb, "rk", outd);
      GenC2BLK(pre, rkb, "rk", outd);
      GenRankKH(pre, mmb, rkb, outd);
   }
}

void GenHeaderFiles(char pre, char *outd, 
                    ATL_mmnode_t *geb, ATL_mmnode_t *gek1b,
                    ATL_mmnode_t *sqb, ATL_mmnode_t *sqk1b,
                    ATL_mmnode_t *rkb, ATL_mmnode_t *trsmb)
/*
 * Header files required to build full gemm (no timing):
 *X1. atlas_<pre>amm_blk.h : 
 *X   defines: ATL_AMM_NCASES, ATL_AMM_MAX[M,N,K]B
 *X   3 arrays indexed by case give blocking
 *X2  atlas_<pre>amm_flag.h
 *X   defines: ATL_AMM_NCASES
 *X   1 indexible array giving KRUNTIME for now
 *X3. atlas_<pre>amm_cm2am_a[1,X,n]: 
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all rm2am & cm2am routines
 *X   1 indexible array giving which to use for each block factor
 *X4. atlas_<pre>amm_ablk2cmat.h
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all ablk2cmat routines
 *X   1 indexible array for each alpha,beta combination
 *X   -> 3*4 = 12 indexible arrays total
 *X5. atlas_<pre>amm_kerns.h
 *X   defines: ATL_AMM_NCASES
 *X   prototypes all kernels, including K-cleanup
 *X   1 indexible array gives kernel to use for each case as func ptr
 *X   1 indexible array gives K-clean kernel
 *X6. atlas_<pre>amm_cmat2ablk.h (I don't need, Rakib does)
 *X   defines: ATL_AMM_NCASES 
 *X   prototypes all cmat2ablk routines
 *X   1 indexible array for each alpha,beta combination
 *X   -> 3*4 = 12 indexible arrays total
 */
{
   ATL_mmnode_t *mp;
   char *pfx;

   pfx = "ge";
   GenAmmSum(pre, geb, rkb, pfx, outd);
   GenBlockingFile(pre, geb, pfx, outd);
   GenPerfFile(pre, geb, pfx, outd, 0.0);
   GenFlagH(pre, geb, pfx, outd);
   GenCMAJ2AMAJ(pre, geb, pfx, outd);
   GenC2BLK(pre, geb, pfx, outd);
   GenKernH(pre, outd, pfx, geb, gek1b);
@skip   GenCmplxHeaders(pre=='s'?'c':'z', geb, rkb, pfx, outd);

   pfx = "sq";
   GenAmmSum(pre, sqb, rkb, pfx, outd);
   GenBlockingFile(pre, sqb, pfx, outd);
   GenPerfFile(pre, sqb, pfx, outd, 0.0);
   GenFlagH(pre, sqb, pfx, outd);
   GenAMAJ2CMAJ(pre, sqb, pfx, outd);
   GenCMAJ2AMAJ(pre, sqb, pfx, outd);
   GenC2BLK(pre, sqb, pfx, outd);
   GenKernH(pre, outd, pfx, sqb, sqk1b);
@skip   GenCmplxHeaders(pre=='s'?'c':'z', sqb, rkb, pfx, outd);

   if (trsmb)
   {
      double maxMF=0.0;
      for (mp=sqb; mp; mp = mp->next)
         if (mp->mflop[0] > maxMF)
             maxMF = mp->mflop[0];
      GenPerfFile(pre, trsmb, "ts", outd, maxMF);
   }
   if (rkb)
   {
      pfx = "rk";
      GenBlockingFile(pre, rkb, pfx, outd);
      GenPerfFile(pre, rkb, pfx, outd, 0.0);
      GenFlagH(pre, rkb, pfx, outd);
      GenCMAJ2AMAJ(pre, rkb, pfx, outd);
      GenC2BLK(pre, rkb, pfx, outd);
      GenRankKH(pre, geb, rkb, outd);
   }
}

/*
 * Splits rkb into two lists: (1) Routines with runtime K (RUNB),
 * (2) Routines with fixed-KB (returned)
 * NOTE: original list rkb is unchanged
 */
ATL_mmnode_t *SplitRankK(ATL_mmnode_t *rkb, ATL_mmnode_t **RUNB)
{
   ATL_mmnode_t *runb=NULL, *fixb=NULL, *p, *np;
   for (p=rkb; p; p = p->next)
   {
      np = CloneMMNode(p);
      if (FLAG_IS_SET(np->flag, MMF_KRUNTIME))
      {
         np->next = runb;
         runb = np;
      }
      else
      {
         np->next = fixb;
         fixb = np;
      }
   }
   *RUNB = runb;
   return(fixb);
}

char *GetKernComp(ATL_mmnode_t *mmp, char *dcomp, char *dflags, char **flgs)
{
   char *comp = dcomp;
   if (mmp->comp)
   {
      comp = (mmp->comp[0] == 'g' && mmp->comp[1] == 'c' &&
              mmp->comp[2] == 'c' && 
             (mmp->comp[3] == '\0' || mmp->comp[3] == ' '))
             ? "$(GOODGCC)" : mmp->comp;
      *flgs = mmp->cflags;
   }
   else
      *flgs = dflags;
   return(comp);
}
void PrintKernComp
(
   FILE *fp,            /* file to print to */
   char pre, 
   ATL_mmnode_t *mmp,   /* kernel compile rule is for */
   int UID,             /* user-ID for user-determined kerns */
   char *nam,           /* base name ("AMMM" or "AMRK") */
   char *comp,          /* compiler to use */
   char *cflags,        /* compiler flags to use */
   char *styp,          /* string defining type (eg. "-DSREAL") */
   char cbet,           /* character with beta name ('1', '0', 'n') */
   char *sbet           /* string wt full beta name ("1", "N1", "0") */
)
{
   const int kb = FLAG_IS_SET(mmp->flag, MMF_KRUNTIME)?0:mmp->kbB;
   const int flg = GetCompTimeFlags(mmp);
   fprintf(fp, "ATL_%c%s_%d_%d_%x_%dx%dx%d_b%c.o : %s\n", pre, nam,
           mmp->ID, kb, flg, mmp->mu, mmp->nu, mmp->ku, cbet, mmp->rout);
   fprintf(fp, "\t%s $(CDEFS2) %s -DBETA%s=1", comp, styp, sbet);
   if (!FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      fprintf(fp, " -DMB=%d -DNB=%d, -DKB=%d", mmp->mbB, mmp->nbB, mmp->kbB);
   if (FLAG_IS_SET(mmp->flag, MMF_MVA))
      fprintf(fp, " -DATL_MOVEA");
   if (FLAG_IS_SET(mmp->flag, MMF_MVB))
      fprintf(fp, " -DATL_MOVEB");
   if (FLAG_IS_SET(mmp->flag, MMF_MVC))
      fprintf(fp, " -DATL_MOVEC");
         fprintf(fp, " -DATL_USERMM=ATL_%c%s_%d_%d_%x_%dx%dx%d_b%c", pre, nam,
                 mmp->ID, kb, flg, mmp->mu, mmp->nu, mmp->ku, cbet);
         fprintf(fp, " %s -o ATL_%c%s_%d_%d_%x_%dx%dx%d_b%c.o -c %s\n", 
                 cflags, pre, nam, mmp->ID, kb, flg, mmp->mu, mmp->nu, mmp->ku, 
                 cbet, mmp->rout);
}
@define uid @-1@
@define lib @ATLAS@
void GenMakefile
(
   char pre,            /* type/precision prefix : s,d,c,z */
   char *outd,          /* directory to generate Makefile in */
   ATL_mmnode_t *geb,   /* main kernels for GEMM */
   ATL_mmnode_t *gek1b, /* K-cleanup for gemm kerns */
   ATL_mmnode_t *sqb,   /* kernels where MB=NB=KB */
   ATL_mmnode_t *sqk1b, /* K-cleanup for square kerns */
   ATL_mmnode_t *rkb    /* list of kernels to doing rank-K update */
)
{
   ATL_mmnode_t *mmb, *mmp, *p, *fixb, *runb;
   mnur_t *mnurb=NULL, *allub, *up;
   FILE *fp;
   char *comp, *cflags;
   char *ln;
   int i;
   char pres[2];
   char be[3] = {'1', 'n', '0'};
   char *bes[3] = {"1", "N1", "0"};
   char al[3] = {'1', 'n', 'X'};
   char dcomp[8] = {'$', '(', 'D', 'M', 'C', ')', '\0'};
   char dflags[12] = {'$', '(', 'D', 'M', 'C', 'F', 'L', 'A', 'G', 'S', 
                     ')', '\0'};
   char *styps[2] = {"-DDREAL", "-DDCPLX"};
   char *styp = (pre == 'd' || pre == 'z') ? "-DDREAL" : "-DSREAL";
/*
 * Square & rect kernels handled same way: going to be compiled once for
 * each compile-time K, and once if runtime, so combine them into one big
 * queue for Make generation, w/o repeating same compile-time kernel
 */
   mmb = AddUniqueMMKernCompList(NULL, geb);
   mmb = AddUniqueMMKernCompList(mmb, gek1b);
   mmb = AddUniqueMMKernCompList(mmb, sqk1b);
   mmb = AddUniqueMMKernCompList(mmb, sqb);

   pres[0] = pre;
   if (pre == 's' || pre == 'c')
   {
      styps[0] = "-DSREAL";
      styps[1] = "-DSCPLX";
      pres[1] = 'c';
   }
   else
      pres[1] = 'z';

   ln = malloc((strlen(outd)+11)*sizeof(char));
   assert(ln);
   sprintf(ln, "%s/%cMake_amm", outd, pre);
   fp = fopen(ln, "w");
   assert(fp);
   free(ln);
   fprintf(fp, "include ../Make.inc\n");
   fprintf(fp, "CDEFS2=$(CDEFS)\n\n");
   if (pre == 'c')
   {
      fprintf(fp, "CMC=$(SMC)\n");
      fprintf(fp, "CKCFLAGS=$(SKCFLAGS)\n");
      fprintf(fp, "CMCFLAGS=$(SMCFLAGS)\n");
   }
   else if (pre == 'z')
   {
      fprintf(fp, "ZMC=$(DMC)\n");
      fprintf(fp, "ZKCFLAGS=$(DKCFLAGS)\n");
      fprintf(fp, "ZMCFLAGS=$(DMCFLAGS)\n");
   }
/*
 * Build list of all unique MU/NU combos for copy routines
 */
   mnurb = GetUniqueMNUnrolls(mmb, NULL);
   mnurb = GetUniqueMNUnrolls(rkb, mnurb);
   allub = GetUniqueMUnrolls(mmb, NULL);
   allub = GetUniqueMUnrolls(rkb, allub);
   allub = GetUniqueNUnrolls(mmb, allub);
   allub = GetUniqueNUnrolls(rkb, allub);
/*
 * Spew out all filenames that must be compiled
 */
   fprintf(fp, "objs =");
/*
 * Routines to copy from MU/NU-major to column major output array
 */
   for (up=mnurb; up; up = up->next)
   {
      int j;
      const int mu=up->mu, nu=up->nu;

      for (j=0; j < 3; j++)
      {
         int k;
         char *rtn[2] = {"ablk2cmat", "cmat2ablk"};
         for (k=0; k < 2; k++)
         {
            int h;
            for (h=0; h < 2; h++)
            {
               char pre = pres[h];
               fprintf(fp, " \\\n       ATL_%c%s_%dx%d_a%c_b1.o",
                       pre, rtn[k], mu, nu, al[j]);
               fprintf(fp, " ATL_%c%s_%dx%d_a%c_bX.o",
                       pre, rtn[k], mu, nu, al[j]);
               fprintf(fp, " \\\n       ATL_%c%s_%dx%d_a%c_b0.o",
                       pre, rtn[k], mu, nu, al[j]);
               fprintf(fp, " ATL_%c%s_%dx%d_a%c_bn.o",
                       pre, rtn[k], mu, nu, al[j]);
            }
         }
      }
   }
/*
 * Routines to copy back and forth from A and B
 */
   for (up=allub; up; up = up->next)
   {
      int h;
      for (h=0; h < 2; h++)
      {
         char pre=pres[h];
         int j;
         const int u = up->mu;
         for (j=0; j < 3; j++)
         {
            if (up->kmaj > 1)
            {
               fprintf(fp, 
 " \\\n       ATL_%crm2am_a%c_%dx%d.o ATL_%ccm2am_a%c_%dx%d.o",
                       pre, al[j], up->kmaj, u, pre, al[j], up->kmaj, u);
               fprintf(fp, 
 " \\\n       ATL_%cam2rm_a%c_%dx%d.o ATL_%cam2cm_a%c_%dx%d.o",
                       pre, al[j], up->kmaj, u, pre, al[j], up->kmaj, u);
            }
            else
            {
               fprintf(fp, 
                       " \\\n       ATL_%crm2am_a%c_%d.o ATL_%ccm2am_a%c_%d.o",
                       pre, al[j], u, pre, al[j], u);
               fprintf(fp, 
                       " \\\n       ATL_%cam2rm_a%c_%d.o ATL_%cam2cm_a%c_%d.o",
                       pre, al[j], u, pre, al[j], u);
            }
            if (pre == 'c' || pre == 'z')
            {
               if (up->kmaj > 1)
               {
                  fprintf(fp, 
 " \\\n       ATL_%crm2am_a%c_%dx%dC.o ATL_%ccm2am_a%c_%dx%dC.o",
                          pre, al[j], up->kmaj, u, pre, al[j], up->kmaj, u);
                  fprintf(fp, 
 " \\\n       ATL_%cam2rm_a%c_%dx%dC.o ATL_%cam2cm_a%c_%dx%dC.o",
                          pre, al[j], up->kmaj, u, pre, al[j], up->kmaj, u);
               }
               else
               {
                  fprintf(fp, 
                     " \\\n       ATL_%crm2am_a%c_%dC.o ATL_%ccm2am_a%c_%dC.o",
                          pre, al[j], u, pre, al[j], u);
                  fprintf(fp, 
                     " \\\n       ATL_%cam2rm_a%c_%dC.o ATL_%cam2cm_a%c_%dC.o",
                          pre, al[j], u, pre, al[j], u);
               }
            }
         }
      }
   }
/*
 * AMM kernel routines
 */
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      int kb = mmp->kbB;
/*
 *    Kernels that take runtime K are only compiled once, so don't repeat them
 *    for every KB.  Only generate a statement if this is the first one.
 */
      if (FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      {
         const int id = mmp->ID;
         for (p=mmb; p != mmp; p = p->next)
            if (MMKernsSame(mmp, p))
               break;
         if (p != mmp)
            continue;
         kb = 0;
      }
/* 
 *    ATL_<pre>AMMM_<ID>_<kb>_<flg>_<mu>x<nu>x<ku>_b<X>
 */
      for (i=0; i < 3; i++)
         fprintf(fp, " \\\n       ATL_%cAMMM_%d_%d_%x_%dx%dx%d_b%c.o", 
                 pre, mmp->ID, kb, GetCompTimeFlags(mmp), mmp->mu, mmp->nu, 
                 mmp->ku, be[i]);
   }
/*
 * rank-K AMM routines where KB is runtime variable
 */
   fixb = SplitRankK(rkb, &runb);
   runb = RemoveNonUniqueKernels(runb);
   for (mmp=runb; mmp; mmp = mmp->next)
      for (i=0; i < 3; i++)
         fprintf(fp, " \\\n       ATL_%cAMRK_%d_0_%x_%dx%dx%d_b%c.o", pre, 
                 mmp->ID, GetCompTimeFlags(mmp),mmp->mu,mmp->nu,mmp->ku,be[i]);
/*
 * rank-K AMM routines where KB is compile-time, need obj for each unique kbB
 */
   for (mmp=fixb; mmp; mmp = mmp->next)
   {
      for (i=0; i < 3; i++)
         fprintf(fp, " \\\n       ATL_%cAMRK_%d_%d_%x_%dx%dx%d_b%c.o", 
                 pre, mmp->ID, mmp->kbB, GetCompTimeFlags(mmp), 
                 mmp->mu, mmp->nu, mmp->ku, be[i]);
   }
/*
 * library make targets
 */
   fprintf(fp, "\n\nlib : %clib.grd\nall : %clib.grd\n%clib : %clib.grd\n", 
           pre, pre, pre, pre);
   fprintf(fp, "%clib.grd : $(objs)\n", pre);
   fprintf(fp, "\t$(ARCHIVER) $(ARFLAGS) $(@(lib)lib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(@(lib)lib)\n");
   fprintf(fp, "\t touch %clib.grd\n", pre);
   fprintf(fp, "clean : %cclean\n", pre);
   fprintf(fp, "%cclean:\n\t- rm -f $(objs)\n", pre);
   fprintf(fp, "killall : %ckillall\n", pre);
   fprintf(fp, "%ckillall : %cclean\n", pre, pre);
   fprintf(fp, "\t- $(ARCHIVER) d $(@(lib)lib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(@(lib)lib)\n");
   fprintf(fp, "\t- rm -f ATL_%c*.[S,c]\n", pre);

/*
 * Print out the individual rules for each needed copy function
 */
   dcomp[2] = dflags[2] = toupper(pre);
   dflags[3] = dcomp[3] = 'K';
   fprintf(fp, "\ntsth.o : tsth.c\n");
   fprintf(fp, "\t%s %s $(CDEFS) %s -c tsth.c\n\n", dcomp, dflags, styp);
   fprintf(fp, "#\n# Data copy rules\n#\n");
/*
 * Print out 2-D ablk2Cmat, cmat2ablk and ammswp targets
 */
   for (up=mnurb; up; up = up->next)
   {
      const int mu=up->mu, nu = up->nu;
      char cbe[4] = {'0', '1', 'n', 'X'};
      int ibe[4] =  {0,    1,  -1,  2};
      int i, j;

      for (i=0; i < 4; i++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            char pre=pres[h];
            char *styp=styps[h];
            for (j=0; j < 3; j++)
            {
               int k;
               char *rtn[2] = {"ablk2cmat", "cmat2ablk"};
               for (k=0; k < 2; k++)
               {
                  char rn[64];
                  sprintf(rn, "ATL_%c%s_%dx%d_a%c_b%c",
                          pre, rtn[k], mu, nu, al[j], cbe[i]);
                  fprintf(fp, "%s.o : %s.c\n", rn, rn);
                  fprintf(fp, "\t%s %s $(CDEFS) %s -c %s.c\n", 
                          dcomp, dflags, styp, rn);
               }
            }
         }
      }
   }
   KillUnrollList(mnurb);
/*
 * Print out 1-D copy-in routine rules
 */
   for (up=allub; up; up = up->next)
   {
      const int u = up->mu, kmaj=up->kmaj;
      int j;
      for (j=0; j < 3; j++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            char pre=pres[h];
            char *styp=styps[h];
            char *cst[2] = {"", "C"};
            char *cdef[2] = {"", "-DConj_=1 "};
            int g;
            const int G = (pre == 'c' || pre == 'z') ? 2:1;
            for (g=0; g < G; g++)
            {
               int kk, r;
               const int nmI = 5;
               char rout[32];
               char *routs[4] = {"rm2am", "cm2am", "am2rm", "am2cm"};
               for (r=0; r < 4; r++)
               {
                  if (kmaj > 1)
                     sprintf(rout, "ATL_%c%s_a%c_%dx%d", 
                             pre, routs[r], al[j], kmaj, u);
                  else
                     sprintf(rout, "ATL_%c%s_a%c_%d", pre, routs[r], al[j], u);
                  fprintf(fp, "%s%s.o : %s.c\n", rout, cst[g], rout);
                  fprintf(fp, "\t%s %s $(CDEFS) %s%s -o %s%s.o -c %s.c\n", 
                          dcomp, dflags, cdef[g], styp, rout, cst[g], rout);
               }
            }
         }
      }
   }
   KillUnrollList(allub);
/*
 * Print out the individual rules for each kernel compile
 */
   dflags[3] = dcomp[3] = 'M';
   fprintf(fp, "#\n#  AMM kernel rules\n#\n");
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
/*
 *    Kernels that take runtime K are only compiled once, so print rules on
 *    only the first encounter of that ID
 */
      if (FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
      {
         const int id = mmp->ID;
         for (p=mmb; p != mmp; p = p->next)
            if (MMKernsSame(mmp, p))
               break;
         if (p != mmp)
            continue;
      }
      comp = GetKernComp(mmp, dcomp, dflags, &cflags);
/* 
 *    ATL_<pre>AMMM_<ID>_<kb>_<flg>_<mu>x<nu>x<ku>_b<X>, 
 *    kerns in all 3 beta cases
 */
      for (i=0; i < 3; i++)
         PrintKernComp(fp, pre, mmp, @(uid), "AMMM", comp, cflags, styp, 
                       be[i], bes[i]);
   }
/*
 * runtime-KB rank-K needs only one kernel compile rule
 */
   if (runb)
      fprintf(fp, "#\n#  rank-K kernels with run-time K\n#\n");
   for (mmp=runb; mmp; mmp = mmp->next)
   {
      comp = GetKernComp(mmp, dcomp, dflags, &cflags);
      for (i=0; i < 3; i++)
         PrintKernComp(fp, pre, mmp, @(uid), "AMRK", comp, cflags, styp, 
                       be[i], bes[i]);
   }
   
/*
 * Compile-time rank-K must be recompiled for each kbB
 */
   if (fixb)
      fprintf(fp, "#\n#  rank-K kernels with compile-time KB\n#\n");
   for (mmp=fixb; mmp; mmp = mmp->next)
   {
      const int kmaj = FLAG_IS_SET(mmp->flag, MMF_KVEC) ? mmp->vlen:0;
      comp = GetKernComp(mmp, dcomp, dflags, &cflags);
      for (i=0; i < 3; i++)
      {
         int kbG = mmp->kbB;
         if (kmaj)
            kbG = ((mmp->kbB + kmaj-1)/kmaj)*kmaj;
         fprintf(fp, "ATL_%cAMRK_%d_%d_%x_%dx%dx%d_b%c.o : %s\n", pre, mmp->ID, 
                 mmp->kbB, GetCompTimeFlags(mmp), mmp->mu, mmp->nu, mmp->ku,
                 be[i], mmp->rout);
         fprintf(fp, "\t%s $(CDEFS2) %s -DBETA%s=1", comp, styp, bes[i]);
         fprintf(fp, " -DKB=%d -DATL_USERMM=ATL_%cAMRK_%d_%d_%x_%dx%dx%d_b%c", 
                 kbG, pre, mmp->ID, mmp->kbB, GetCompTimeFlags(mmp), mmp->mu,
                 mmp->nu, mmp->ku, be[i]);
         fprintf(fp, " -DATL_MOVEA -DATL_MOVEC");
         fprintf(fp, " %s -o ATL_%cAMRK_%d_%d_%x_%dx%dx%d_b%c.o -c %s\n", 
                 cflags, pre, mmp->ID, mmp->kbB, GetCompTimeFlags(mmp), 
                 mmp->mu, mmp->nu, mmp->ku, be[i], mmp->rout);
      }
   }
   KillAllMMNodes(fixb);
   KillAllMMNodes(runb);
   KillAllMMNodes(mmb);
   fclose(fp);
}

void GenKerns(char pre, char *outd, ATL_mmnode_t *geb, ATL_mmnode_t *gek1b, 
              ATL_mmnode_t *sqb, ATL_mmnode_t *sqk1b, ATL_mmnode_t *rkb)
/*
 * Creates/copies all required matmul kernels into outd using specified names
 */
{
   ATL_mmnode_t *mmb, *mmp, *p;
   mnur_t *mnurb=NULL, *allub, *up;
   char *ln=NULL;
   int lnlen=0, dlen;
   char al[3] = {'1', 'n', 'X'};
   int ial[3] = {1,   -1,   2};
   char pres[2];
   pres[0] = pre;
   pres[1] = (pre == 's') ? 'c' : 'z';
/*
 * All non-rkK kerns are generated the same way, so combine them all into one
 * gigantic queue.  We then eliminate all the guys who aren't different
 * once we have compiled them, which still leaves duplicates that differ
 * only in their compilation options.  We'll go ahead and just generate
 * them multiple times (overwriting the file with the same file), so that
 * we don't have to write & support a stricter RemoveNonUnique
 */
   mmb = CloneMMQueue(geb);
   ATL_LastMMNode(mmb)->next = CloneMMQueue(sqb);
   ATL_LastMMNode(mmb)->next = CloneMMQueue(gek1b);
   ATL_LastMMNode(mmb)->next = CloneMMQueue(sqk1b);
   ATL_LastMMNode(mmb)->next = CloneMMQueue(rkb);
   mmb = RemoveNonUniqueKernels(mmb);
/*
 * Build list of all unique MU/NU combos for copy routines
 */
   mnurb = GetUniqueMNUnrolls(mmb, NULL);
   allub = GetUniqueMUnrolls(mmb, NULL);
   allub = GetUniqueNUnrolls(mmb, allub);
   dlen = strlen(outd);
/*
 * Extract every unique block-copy routine
 */
   for (up=mnurb; up; up = up->next)
   {
      const int mu=up->mu, nu=up->nu;
      char cbe[4] = {'0', '1', 'n', 'X'};
      int ibe[4] =  {0,    1,  -1,  2};
      int i, j;
      j = 64+8 + strlen(outd);
      j = (j > 128) ? j : 128;
      if (lnlen < j)
      {
         free(ln);
         lnlen = j;
         ln = malloc(j*sizeof(char));
         assert(ln);
      }
      for (i=0; i < 4; i++)
      {
         for (j=0; j < 3; j++)
         {
            char rn[64];
            int ierr;
            int k;
            for (k=0; k < 2; k++)
            {
               int h;
               for (h=0; h < 2; h++)
               {
                  char pre = pres[h];
                  if (!k)
                     sprintf(rn, "ATL_%cablk2cmat_%dx%d_a%c_b%c.c",
                             pre, mu, nu, al[j], cbe[i]);
                  else
                     sprintf(rn, "ATL_%ccmat2ablk_%dx%d_a%c_b%c.c",
                             pre, mu, nu, al[j], cbe[i]);
                  sprintf(ln, 
                     "make %s pre=%c mu=%d nu=%d al=%c be=%c alpha=%d beta=%d", 
                          rn, pre, mu, nu, al[j], cbe[i], ial[j], ibe[i]);
                  ierr = system(ln);
                  if (ierr)
                  {
                     fprintf(stderr, "FAILED CMND='%s'\n", ln);
                     exit(ierr);
                  }
                  sprintf(ln, "mv %s %s/.", rn, outd);
                  ierr = system(ln);
                  if (ierr)
                  {
                     fprintf(stderr, "FAILED CMND='%s'\n", ln);
                     exit(ierr);
                  }
               }
            }
         }
      }
   }
   KillUnrollList(mnurb);

/*
 * Routines to copy back and forth from A and B
 */
   for (up=allub; up; up = up->next)
   {
      const int u = up->mu, kmaj=up->kmaj;
      int j;
      j = 16 * 40 + (strlen(outd)<<1);
      j = (j > 90) ? j : 90;
      if (lnlen < j)
      {
         free(ln);
         lnlen = j;
         ln = malloc(j*sizeof(char));
         assert(ln);
      }
      for (j=0; j < 3; j++)
      {
         int h;
         for (h=0; h < 2; h++)
         {
            int ierr;
            char pre = pres[h];
            sprintf(ln, "make ATL_%crm2am_a%c_%d.c ATL_%ccm2am_a%c_%d.c "
                    "pre=%c UR=%d alpha=%d al=%c kmaj=%d",
                    pre, al[j], u, pre, al[j], u, pre, u, ial[j], al[j], kmaj);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
            sprintf(ln, "make ATL_%cam2rm_a%c_%d.c ATL_%cam2cm_a%c_%d.c "
                    "pre=%c UR=%d alpha=%d al=%c kmaj=%d",
                    pre, al[j], u, pre, al[j], u, pre, u, ial[j], al[j], kmaj);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
   @whiledef rt cm2am rm2am am2cm am2rm
            if (kmaj > 1)
               sprintf(ln, 
                       "mv ATL_%c@(rt)_a%c_%d.c %s/ATL_%c@(rt)_a%c_%dx%d.c",
                       pre, al[j], u, outd, pre, al[j], kmaj, u);
            else
               sprintf(ln, 
                       "mv ATL_%c@(rt)_a%c_%d.c %s/ATL_%c@(rt)_a%c_%d.c",
                       pre, al[j], u, outd, pre, al[j], u);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
   @endwhile
         }
      }
   }
   KillUnrollList(allub);
/*
 * Copy/generate every unique file, but only once
 */
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      const int id=mmp->ID;
/*
 *    For generated files, just overwrite dups with same file, won't hurt
 */
      if (id == 0)
      {
         assert(mmp->genstr);
         assert(!system(mmp->genstr));
      }
      else  /* user-supplied files copied from AMMCASES directory */
      {
/*
 *       If this is the first time we've seen this ID, it must be copied
 */
         for (p=mmb; p != mmp && p->ID != id; p = p->next);
         if (p == mmp)
         {
            int i, ierr;
            i = strlen(mmp->rout) + dlen + 16;
            if (i > lnlen)
            {
               if (ln)
                  free(ln);
               ln = malloc(i*sizeof(char));
               assert(ln);
               lnlen = i;
            }
            sprintf(ln, "cp AMMCASES/%s %s/.", mmp->rout, outd);
            ierr = system(ln);
            if (ierr)
            {
               fprintf(stderr, "FAILED CMND='%s'\n", ln);
               exit(ierr);
            }
         }
      }
   }
/*
 * Copy/generate rank-K kerns
 */
   for (mmp=rkb; mmp; mmp = mmp->next)
   {
      const int id=mmp->ID;
/*
 *    For generated files, just generate it using genstr
 */
      if (id == 0)
      {
         assert(mmp->genstr);
         assert(!system(mmp->genstr));
      }
      else  /* user-supplied files copied from AMMCASES directory */
      {
         int i, ierr;
         i = strlen(mmp->rout) + dlen + 16;
         if (i > lnlen)
         {
            if (ln)
               free(ln);
            ln = malloc(i*sizeof(char));
            assert(ln);
            lnlen = i;
         }
         sprintf(ln, "cp AMMCASES/%s %s/.", mmp->rout, outd);
         ierr = system(ln);
         if (ierr)
         {
            fprintf(stderr, "FAILED CMND='%s'\n", ln);
            exit(ierr);
         }
      }
   }
   KillAllMMNodes(mmb);
   if (ln)
      free(ln);
}

int KernelInList(ATL_mmnode_t *mmb, ATL_mmnode_t *p)
/*
 * RETURNS: 1 if p is duplicated in mmb, else 0
 */
{
   ATL_mmnode_t *mp;
   if (!p || !mmb)
      return(0);
   for (mp=mmb; mp; mp = mp->next)
      if (MMKernsSame1(mp, p))
         return(1);
    return(0);
}

ATL_mmnode_t *StripNonUniqueKs(ATL_mmnode_t *ukb, ATL_mmnode_t *mmb) 
/*
 * Deletes any ukb node that also appears in mmb,
 * RETURNS: possibly shortened ukb
 */
{
   ATL_mmnode_t *mp, *prev;
/*
 * Delete any repetitive nodes starting unique queue
 */
   while(ukb && KernelInList(mmb, ukb))
      ukb = KillMMNode(ukb);
   if (!ukb)
      return(ukb);
/*
 * Now, delete any internal non-unique K-cleanup
 */
   prev = ukb;
   mp = ukb->next;
   while (mp)
   {
      if (KernelInList(mmb, mp))
         mp = prev->next = KillMMNode(mp);
      else
      {
         prev = mp;
         mp = mp->next;
      }
   }
   return(ukb);
}
ATL_mmnode_t *StripExactMatchKs(ATL_mmnode_t *ukb, ATL_mmnode_t *mmb) 
/*
 * Deletes any ukb node that also appears in mmb with same K-value,
 * RETURNS: possibly shortened ukb
 */
{
   ATL_mmnode_t *mp, *prev;
/*
 * Delete any repetitive nodes starting unique queue
 */
   while(ukb && ExactKernelInList(mmb, ukb))
      ukb = KillMMNode(ukb);
   if (!ukb)
      return(ukb);
/*
 * Now, delete any internal non-unique K-cleanup
 */
   prev = ukb;
   mp = ukb->next;
   while (mp)
   {
      if (ExactKernelInList(mmb, mp))
         mp = prev->next = KillMMNode(mp);
      else
      {
         prev = mp;
         mp = mp->next;
      }
   }
   return(ukb);
}
/*
 * RETURNS: mmb, with all repeated kernels removed
 */
ATL_mmnode_t *RemoveNonUniqueKernels(ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mp;
   if (!mmb || !mmb->next)
      return(mmb);
   for (mp=mmb; mp; mp = mp->next)
   {
      ATL_mmnode_t *p=mp->next, *prev=mp;
      while (p)
      {
@skip    if (MMKernsSame(mp, p) && (FLAG_IS_SET(p->flag, MMF_KRUNTIME) ||
@skip        p->kbB == mp->kbB))
         if (MMKernsSame1(mp, p))
            prev->next = p = KillMMNode(p);
         else
         {
            prev = p;
            p = p->next;
         }
      }
   }
   return(mmb);
}

void GenAllFiles(char pre, char *outd, ATL_mmnode_t *geb, ATL_mmnode_t *gek1b, 
                 ATL_mmnode_t *sqb, ATL_mmnode_t *sqk1b, ATL_mmnode_t *rkb,
                 ATL_mmnode_t *trsmb, ATL_mmnode_t *cgeb, ATL_mmnode_t *cgek1b,
                 ATL_mmnode_t *csqb, ATL_mmnode_t *csqk1b, ATL_mmnode_t *crkb,
                 ATL_mmnode_t *ctrsmb)
{
   ATL_mmnode_t *uge, *usq, *urk;  /* lists w/o object repeats */
   ATL_mmnode_t *mp;
   const char cpr = (pre == 'd') ? 'z' : 'c';

   if (!ctrsmb)
      ctrsmb = trsmb;
   GenHeaderFiles(pre, outd, geb, gek1b, sqb, sqk1b, rkb, trsmb);
   GenHeaderFiles(cpr, outd, cgeb, cgek1b, csqb, csqk1b, crkb, ctrsmb);
/*
 * Link complex and real together: real/cplx don't matter for generation
 * or compiling
 */
   ATL_LastMMNode(geb)->next = cgeb;
   ATL_LastMMNode(gek1b)->next = cgek1b;
   ATL_LastMMNode(sqb)->next = csqb;
   ATL_LastMMNode(sqk1b)->next = csqk1b;
   mp = AddUniqueMMKernCompList(NULL, rkb);
   KillAllMMNodes(rkb);
   rkb = AddUniqueMMKernCompList(mp, crkb);
   KillAllMMNodes(crkb);

   GenMakefile(pre, outd, geb, gek1b, sqb, sqk1b, rkb);
   GenKerns(pre, outd, geb, gek1b, sqb, sqk1b, rkb);
   KillAllMMNodes(geb);
   KillAllMMNodes(gek1b);
   KillAllMMNodes(sqb);
   KillAllMMNodes(sqk1b);
   KillAllMMNodes(rkb);
   KillAllMMNodes(trsmb);
}

void Cplx2RealMM(char pre, ATL_mmnode_t *mmb, char *outd)
{
   ATL_mmnode_t *mp;
   const int mask = ~(1<<MMF_COMPLEX);
   char pfx[8];
   const char cpr = (pre == 'd') ? 'z' : 'c';
   pfx[0] = 'A'; pfx[1] = 'T'; pfx[2] = 'L'; pfx[3] = '_';
   pfx[4] = cpr; pfx[5] = 0;
   for (mp=mmb; mp; mp = mp->next)
   {
      char *sp;
      mp->flag &= mask;
      if (mp->rout)
      {
         sp = strstr(mp->rout, pfx);
         if (sp)
            sp[4] = pre;
      }
   }
   FillInGenStrings(pre, mmb, outd);
}

int main(int nargs, char **args)
{
   char pre='d';
   int verb=1;
   int *nbs;
   char *outd, *ukin, *kcin, *rkin, *sqin;
   ATL_mmnode_t *geb, *gek1b, *sqb, *sqk1b, *rkb, *trsm;
   ATL_mmnode_t *cgeb, *cgek1b, *csqb, *csqk1b, *crkb, *ctrsm;
/*
 * We expect to get a list of rectangular blocking factor kernels for gemm,
 * K-cleanup kernels for gemm, and square kernels for building amm-based L3BLAS,
 * and their K-cleanup kernels, and finally a list of kernels for rank-K
 */
   pre = GetFlags(nargs, args, &outd, &geb, &gek1b, &sqb, &sqk1b, &rkb, &trsm,
                  &cgeb, &cgek1b, &csqb, &csqk1b, &crkb, &ctrsm);
   assert(geb && gek1b);
   assert(sqb && sqk1b);
   assert(rkb);
/*
 * Complex actually handled by real
 */
   if (pre == 'c')
      pre = 's';
   else if (pre == 'z')
      pre = 'd';
/*
 * Fill in correct generator strings for all lists
 */
   FillInGenStrings(pre, geb, outd);
   FillInGenStrings(pre, gek1b, outd);
   FillInGenStrings(pre, sqb, outd);
   FillInGenStrings(pre, sqk1b, outd);
   FillInGenStrings(pre, rkb, outd);
   Cplx2RealMM(pre, cgeb, outd);
   Cplx2RealMM(pre, cgek1b, outd);
   Cplx2RealMM(pre, csqb, outd);
   Cplx2RealMM(pre, csqk1b, outd);
   Cplx2RealMM(pre, crkb, outd);

   GenAllFiles(pre, outd, geb, gek1b, sqb, sqk1b, rkb, trsm, 
               cgeb, cgek1b, csqb, csqk1b, crkb, ctrsm);

   return(0);
}
@ROUT gmmsearch
@extract -b @(topd)/cw.inc lang=C -def cwdate 2015
#include "atlas_misc.h"
#include "atlas_mmtesttime.h"

@extract -b @(basd)/atlas.base rout=Mylcm
@ROUT ammsearch uammsearch
@extract -b @(topd)/cw.inc lang=C -def cwdate 2012 -def cwdate 2013 -def cwdate 2015
#include "atlas_misc.h"
@skip #include "atlas_gnuvec.h"
#include "atlas_mmtesttime.h"

static int VLEN=0;
@beginskip
#define NVECS 4
static enum VECTYPE {VTAVXZ=0, VTAVX=1, VTSSE=2, VTGV=3, VTSC=4} VECi=VTSC;
static int VLEN[5] = {8, 4, 2, 2, 1};  /* assume double, fix later if nec */
static char *VECs[5] = {"avxz", "avx", "sse", "gvec", "scalar"};
@endskip
static int TSIZE=8;
@skip static char *MOVES=NULL;
static int IMVS=3;     /* move ptrs in timing encoded in last 3 bits: CBA */
#define KRUNMUL 1.02   /* KRUNTIME speedup increase over K-compile time */

@extract -b @(basd)/atlas.base rout=Mylcm

ATL_mmnode_t *GetGenCases(char pre)
{
   ATL_mmnode_t *mb, *mp;
   mb = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   if (!mb)
   {
      char ln[32];
      sprintf(ln, "make res/%cgAMMRES.sum", pre);
      assert(!system(ln));
      mb = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   }
   assert(mb);
   MMFillInGenStrings(pre, mb);
   return(mb);
}

@ROUT ammsearch uammsearch gmmsearch
double TimeMMKernel_KB
(
   int verb,                    /* 0: no output, 1 min output, 2: full output */
   int FORCETIME,               /* 1: ignore any prior output file */
   ATL_mmnode_t *mmp,           /* ptr to mmkern struct */
   char pre,                    /* type/prec prefix: z,c,d,s */
   int mb, int nb, int kb,      /* dimensions to time */
   int beta,                    /* beta to time */
   int mflop,                   /* >0: force mflop MFLOPs in each time interv */
   int cflush                   /* >=0: size of cache flush, else ignored */
)
/*
 * If kernel has property KRUNTIME, try timing it with compile- and run-time K,
 * and if compile-time is more than 2% faster, turn off KRUNTIME
 */
{
   double mf;
   const int kb0 = mmp->kbB;
   if (mmp->ID && mmp->kbmax && kb > mmp->kbmax)  /* genned codes can adapt */
      return(0.0);
   mmp->mbB = mb;
   mmp->nbB = nb;
   mmp->kbB = kb;
/*
 * If it's a generated kernel, regen in case we need KB to match KU, and
 * to specialize it to KB (assuming compile-time is faster)
 */
   if (!mmp->ID)
   {
      if (mmp->genstr)
         free(mmp->genstr);
      if (mmp->rout)
         free(mmp->rout);
      if (FLAG_IS_SET(mmp->flag, MMF_KUISKB))
         mmp->kbmax = mmp->kbmin = mmp->ku = kb;
      mmp->rout = DupString("ATL_tmp.c");
      mmp->genstr = MMGetGenString(pre, mmp);
   }
   mf = TimeMMKernel(verb, FORCETIME, mmp, pre, mb, nb, kb, beta, mflop,cflush);
   if (FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
   {
      double mfC;
      mmp->flag &= ~(1<<MMF_KRUNTIME);
      mfC = TimeMMKernel(verb, FORCETIME, mmp, pre, mb, nb, kb, beta, 
                         mflop, cflush);
      if (mfC <= 1.02*mf)
         mmp->flag |= (1<<MMF_KRUNTIME);
      else
      {
         if (verb)
            printf("      Forcing K compile-time, mfC=%.2f, mfR=%.2f\n", 
                   mfC, mf);
         mf = mfC;
      }
   }
   return(mf);
}
@ROUT ammsearch uammsearch
/*
 * Finds best blocking factors for kernel mmp trying all legal values
 * between [b0, bN]
 */
ATL_mmnode_t *BestBlocking_BFI
(
   int verb, 
   char pre, 
   ATL_mmnode_t *mmp, 
   int b0,
   int bN,
   int minInc,  /* minimum increment to use */
   int FORCE
)
/*
 * Times all legal block factors in all dims between [b0,bN].
 * RETURNS: ptr to best performing kernel, NULL if no legal block factors
 */
{
   ATL_mmnode_t *mp;
   int mbB=0, nbB=0, kbB=0;
   int mbS=0, nbS=0, kbS=0;
   int mu = mmp->mu, nu = mmp->nu, ku = mmp->ku;
   int k0, kn, m0, mn, n0, nn, m, n, k;
   double mfB=0.0, mfS=0.0;

   if (!mmp)
      return(NULL);
   if (minInc > mu)
      mu = ((minInc+mu-1)/mu)*mu;
   if (minInc > nu)
      nu = ((minInc+nu-1)/nu)*nu;
   if (minInc > ku)
      ku = ((minInc+ku-1)/ku)*ku;
   m0 = ((b0+mu-1)/mu)*mu;
   n0 = ((b0+nu-1)/nu)*nu;
   k0 = ((b0+ku-1)/ku)*ku;
   mn = ((bN+mu-1)/mu)*mu;
   nn = ((bN+nu-1)/nu)*nu;
   kn = ((bN+ku-1)/ku)*ku;
   mp = CloneMMNode(mmp);
   if (mp->kbmax && mp->kbmax < kn)
      kn = mp->kbmax;
   if (mp->kbmin && mp->kbmin > k0)
      k0 = mp->kbmin;


   printf("SEARCH BLKING [%d - %d] for %d.%s:\n\n", b0, bN, mp->ID, mp->rout);
   printf("  MB    NB    KB        MFLOP    mbB  nbB  kbB      mflopB\n");
   printf("====  ====  ====  ===========   ==== ==== ==== ===========\n");
   for (m=m0; m <= mn; m += mu)
   {
      for (n=m0; n <= nn; n += nu)
      {
         for (k=k0; k <= kn; k += ku)
         {
            double mf;
            mf = TimeMMKernel(verb, FORCE, mp, pre, m, n, k, 1, 0, -1);
            printf("%4d %5d %5d %11.1f %4d %4d %4d %11.1f\n", 
                   m, n, k, mf, mbB, nbB, kbB, mfB);
            if (mf > mfB)
            {
               mfB = mf;
               mbB = m;
               nbB = n;
               kbB = k;
            }
            if (m == n && m == k)
            {
               if (mf > mfS)
               {
                  mfS = mf;
                  mbS = m;
                  nbS = n;
                  kbS = k;
               }
            }
         }
      }
   }
   if (mfB == 0)
   {
      printf("NO KERNEL POSSIBLE FOR RANGE=[%d,%d]\n", b0, bN);
      KillMMNode(mp);
      return(NULL);
   }
   mp->mbB = mbB;
   mp->nbB = nbB;
   mp->kbB = kbB;
   mp->mflop[0] = mfB;
   printf("FOR %d.'%s': MB=%d, NB=%d, KB=%d, MFLOPS=%.1f\n",
          mp->ID, mp->rout, mbB, nbB, kbB, mfB);
   k = MMKernelFailsTest(pre, mbB, nbB, kbB, 0, mp);
   if (!k)
      k = MMKernelFailsTest(pre, mbB, nbB, kbB, 1, mp);
   if (!k)
      k = MMKernelFailsTest(pre, mbB, nbB, kbB, -1, mp);
   if (k)
   {
      printf("KERNEL FAILS TESTER FOR [M,N,K]B=%d,%d,%d\n", mbB, nbB, kbB);
      exit(k);
   }
   if (mbS == 0)
      mp->next = NULL;
   else
   {
      k = MMKernelFailsTest(pre, mbS, nbS, kbS, 0, mp);
      if (!k)
         k = MMKernelFailsTest(pre, mbS, nbS, kbS, 1, mp);
      if (!k)
         k = MMKernelFailsTest(pre, mbS, nbS, kbS, -1, mp);
      if (k)
         mp->next = NULL;
      else
      {
         mp->next = CloneMMNode(mp);
         mp->next->mbB = mbS;
         mp->next->nbB = nbS;
         mp->next->kbB = kbS;
         mp->next->mflop[0] = mfS;
      }
   }
   WriteRefreshedMMFileWithPath(pre, "res", "AMMEXBLKS.sum", mp);
   return(mp);
}

ATL_mmnode_t *TimeExtraBlockings(char pre, int verb)
{
   ATL_mmnode_t *eb;
   eb = ReadMMFileWithPath(pre, "res", "AMMEXBLKS.sum");
   if (!eb)
      return(eb);
   if (eb->mflop[0] < 0)
   {
      ATL_mmnode_t *mp;
      printf("EXTRA BLOCKING FACTOR TIMINGS:\n\n");
      if (verb)
      {
         printf("  MB    NB    KB        MFLOP\n");
         printf("====  ====  ====  ===========\n");
      }
      for (mp=eb; mp; mp = mp->next)
      {
         mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB,
                                     mp->kbB, 1, 0, -1);
         if (verb)
            printf("%4d %5d %5d %11.1f\n", 
                   mp->mbB, mp->nbB, mp->kbB, mp->mflop[0]);
      }
      WriteRefreshedMMFileWithPath(pre, "res", "AMMEXBLKS.sum", eb);
   }
   return(eb);
}

ATL_mmnode_t *GetGenKernForNB(char pre, int nb)
{
   static ATL_mmnode_t *mmb=NULL;
   ATL_mmnode_t *mp=NULL, *pM=NULL, *pK=NULL;
   char upr = pre;

   if (upr == 'z')
      upr = 'd';
   if (upr == 'c')
      upr = 's';

   if (!nb)
   {
      if (mmb)
         KillAllMMNodes(mmb);
      return(NULL);
   }
   if (!mmb)
   {
      mmb = ReadMMFileWithPath(upr, "res", "gAMMRES.sum");
      assert(mmb);
      for (mp=mmb; mp; mp = mp->next)
      {
         if (mp->genstr)
            free(mp->genstr);
         if (mp->rout)
            free(mp->rout);
         mp->genstr = mp->rout=NULL;
      }
   }
/*
 * See if any existing kernel can handle this case, modulo ku/kb
 */
   for (mp=mmb; mp; mp = mp->next)
   {
      if ((nb%(mp->mu) == 0) && (nb%(mp->nu) == 0))
      {
         if (!FLAG_IS_SET(mp->flag, MMF_KVEC))
         {
            if (!pM)
               pM = mp;
         }
         else if (!pK && (nb%mp->vlen == 0))  /* K-vec must match on vlen too */
            pK = mp;
      }
      if (pK && pM)
         break;
   }
/*
 * If we've got either pM or pK, all we need to do is possibly adjust kb/ku
 * With same vector length, we'll just take the first one that works.
 */
   if (pM || pK)
   {
      if (pM)
         mp = CloneMMNode(pM);
      else
         mp = CloneMMNode(pK);
      if (FLAG_IS_SET(mp->flag,MMF_KUISKB))
         mp->kbmax = mp->kbmin = mp->ku = mp->kbB = nb;
      else if (nb%(mp->ku))
         mp->ku = (pM) ? 1 : mp->vlen;
      mp->mbB = mp->nbB = mp->kbB = nb;
      mp->rout = MMGetGenName(pre, nb, mp);
      mp->genstr = MMGetGenString(pre, mp);
      return(mp);
   }
/*
 * If changing K info isn't enough, we'll have to make a new kernel that
 * changes possibly a bunch of stuff, including vlen
 *
 * Try to find both a M- & K-vec kernel as a candidate.  Since no kernel
 * working tends to happen more with small NB, prioritize end of queue.
 */
   for (mp=mmb; mp; mp = mp->next)
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         pK = mp;
      else
         pM = mp;
   }

/*
 * Find a legal M-vec (or unvectorized) kernel based on best M kernel
 */
   if (pM)
   {
      int vl=pM->vlen, u;
      mp = CloneMMNode(pM);
/*
 *    Find a vlen compatible with this MB; may become 1 -> unvectorized
 */
      while (vl > 1 && nb % vl)  /* make vlen evenly divide nb */
         vl >>= 1;
      mp->vlen = vl;
      mp->mu = (pM->mu / pM->vlen) * vl;  /* use same # of regs */
/*
 *    Make mu evenly divide MB (vl already does)
 */
      for (u=mp->mu; u > vl && nb%u; u -= vl);
      assert(nb%u == 0);
      mp->mu = u;
/*
 *    Make nu evenly divide NB
 */
      for (u=mp->nu; nb%u; u--);
      if (FLAG_IS_SET(mp->flag, MMF_NOBCAST))
      {
         if (u > vl)
            u = (u/vl)*vl;
         else
            mp->flag &= (1<<MMF_NOBCAST);
      }
      mp->nu = u;
/*
 *    Make ku evenly divide KB
 */
      if (nb%(mp->ku) != 0)
         mp->ku = 1;
@skip      for (u=mp->ku; nb%u; u--);
@skip      mp->ku = u;
      pM = mp;
   }
/*
 * Find a legal K-vec kernel if possible
 */
   if (pK)
   {
      int mu=0, nu=0, vl;
      mp = NULL;
/*
 *    Make vlen evenly divide KB
 */
      for(vl=pK->vlen; vl > 1 && nb%vl; vl >>= 1);
      if (vl > 1)
      {
         int i, j;
         float minrat=0.0;
/*
 *       Find mu & nu such that mu*nu % vl == 0
 */
         for (i=pK->mu; i > 0; i--)
         {
            for (j=pK->nu; j > 0; j--)
            {
               if ((i*j)%vl == 0 && i%nb == 0 && j%nb == 0)
               {
                  float ratio = (i+j)/(i*j);
                  if (minrat == 0.0 || ratio < minrat)
                  {
                     minrat = ratio;
                     mu = i;
                     nu = j;
                  }
               }
            }
         }
/*
 *       Do we have a legal k-vectorized kernel?
 */
         if (vl > 1 & mu > 1 && nu > 1)
         {
/*
 *          Make ku divide KB & vl
 */
            i = pK->ku;
            if (i%vl)
            {
               if (i > vl)
                  i = (i/vl)*vl;
               else
                  i = vl;
            }
            for (; i > vl && nb%i; i -= vl);
            if (nb%i)
            {
               mp = pK = CloneMMNode(pK);
               pK->vlen = vl;
               pK->mu = mu;
               pK->nu = nu;
               pK->ku = i;
            }
         }
      }
      pK = mp;
   }
/*
 * If we've found no legal kernel, create a scalar kernel that will work
 */
   if (!pM && !pK)
   {
      mp = pM = GetMMNode();
      mp->mu = (nb&3) ? 1 : 4;
      if (nb%6 == 0)
         mp->mu = 6;
      else if ((nb & 3) == 0)
         mp->mu = 4;
      if ((nb & 1) == 0)
         mp->mu = 2;
      else
         mp->mu = 1;
      mp->nu = mp->ku = mp->vlen = 1;
   }
/*
 * put best kernel in pM, free other
 */
   if (pM && pK)  /* wt both K & M, guess best */
   {
      if (pK->vlen > pM->vlen)
      {
         KillMMNode(pM);
         pM = pK;
      }
      else if (pM->vlen > pK->vlen)
         KillMMNode(pK);
      else /* vlen same, break tie on relative speed & load/use ratio */
      {
         double krat, mrat;
         krat = (pK->mu + pK->nu);
         krat /= (pK->mu * pK->nu);
         mrat = pK->mu / pK->vlen;
         mrat = (mrat+pK->nu) / (mrat*pK->nu);
         if (pM->mflop[0] != 0.0 && pK->mflop[0] != 0)
            krat *= pM->mflop[0] / pK->mflop[0];
         if (krat < 0.0)
            krat = -krat;
         if (krat < mrat)
         {
            KillMMNode(pM);
            pM = pK;
         }
         else
            KillMMNode(pK);
      }
   }
   else if (!pM)
      pM = pK;
   assert(pM);
   if (!FLAG_IS_SET(pM->flag,MMF_KRUNTIME))
      pM->kbB = nb;
   pM->rout = MMGetGenName(pre, nb, pM);
   pM->genstr = MMGetGenString(pre, pM);
   pM->mbB = pM->nbB = pM->kbB = nb;
   return(pM);
}
@beginskip
ATL_mmnode_t *GetGenKernForNB(char pre, int nb)
{
   static ATL_mmnode_t *mmM=NULL, *mmK=NULL;
   ATL_mmnode_t *mp=NULL, *kp=NULL;
   char upr = pre;

   if (upr == 'z')
      upr = 'd';
   if (upr == 'c')
      upr = 's';

   if (!nb)
   {
      if (mmM)
         KillAllMMNodes(mmM);
      if (mmK)
         KillAllMMNodes(mmK);
      return(NULL);
   }
   if (!mmM)
   {
      mmM = ReadMMFileWithPath(upr, "res", "gmvAMMUR.sum");
      if (mmM)
      {
         if (mmM->next)
         {
            KillAllMMNodes(mmM->next);
            mmM->next = NULL;
         }
         if (mmM->genstr)
            free(mmM->genstr);
         if (mmM->rout)
            free(mmM->rout);
         mmM->genstr = mmM->rout=NULL;
      }
   }
   if (!mmK)
   {
      mmK = ReadMMFileWithPath(upr, "res", "gkvAMMUR.sum");
      if (mmK)
      {
         if (mmK->next)
         {
            KillAllMMNodes(mmK->next);
            mmK->next = NULL;
         }
         if (mmK->genstr)
            free(mmK->genstr);
         if (mmK->rout)
            free(mmK->rout);
         mmK->genstr = mmK->rout=NULL;
      }
   }
   assert(mmM || mmK);
/*
 * Find a legal M-vec (or unvectorized) kernel based on best M kernel
 */
   if (mmM)
   {
      int vl=mmM->vlen, u;
      mp = CloneMMNode(mmM);
/*
 *    Find a vlen compatible with this MB; may become 1 -> unvectorized
 */
      while (vl > 1 && nb % vl)  /* make vlen evenly divide nb */
         vl >>= 1;
      mp->vlen = vl;
      mp->mu = (mmM->mu / mmM->vlen) * vl;  /* use same # of regs */
/*
 *    Make mu evenly divide MB (vl already does)
 */
      for (u=mp->mu; u > vl && nb%u; u -= vl);
      mp->mu = u;
/*
 *    Make nu evenly divide NB
 */
      for (u=mp->nu; nb%u; u--);
      if (FLAG_IS_SET(mp->flag, MMF_NOBCAST))
      {
         if (u > vl)
            u = (u/vl)*vl;
         else
            mp->flag &= (1<<MMF_NOBCAST);
      }
      mp->nu = u;
/*
 *    Make ku evenly divide KB
 */
      for (u=mp->ku; nb%u; u--);
      mp->ku = u;
   }
/*
 * Find a legal K-vec kernel if possible
 */
   if (mmK)
   {
      int mu=0, nu=0, vl;
/*
 *    Make vlen evenly divide KB
 */
      for(vl=mmK->vlen; vl > 1 && nb%vl; vl >>= 1);
      if (vl > 1)
      {
         int i, j;
         float minrat=0.0;
/*
 *       Find mu & nu such that mu*nu % vl == 0
 */
         for (i=mmK->mu; i > 0; i--)
         {
            for (j=mmK->nu; j > 0; j--)
            {
               if ((i*j)%vl == 0 && i%nb == 0 && j%nb == 0)
               {
                  float ratio = (i+j)/(i*j);
                  if (minrat == 0.0 || ratio < minrat)
                  {
                     minrat = ratio;
                     mu = i;
                     nu = j;
                  }
               }
            }
         }
/*
 *       Do we have a legal k-vectorized kernel?
 */
         if (vl > 1 & mu > 1 && nu > 1)
         {
/*
 *          Make ku divide KB & vl
 */
            i = mmK->ku;
            if (i%vl)
            {
               if (i > vl)
                  i = (i/vl)*vl;
               else
                  i = vl;
            }
            for (; i > vl && nb%i; i -= vl);
            if (nb%i)
            {
               kp = CloneMMNode(mmK);
               kp->vlen = vl;
               kp->mu = mu;
               kp->nu = nu;
               kp->ku = i;
            }
         }
      }
   }
/*
 * put best kernel in mp, free other
 */
   if (mp && kp)  /* wt both K & M, guess best */
   {
      if (kp->vlen > mp->vlen)
      {
         KillMMNode(mp);
         mp = kp;
      }
      else if (mp->vlen > kp->vlen)
         KillMMNode(kp);
      else /* vlen same, break tie on relative speed & load/use ratio */
      {
         double krat, mrat;
         krat = (kp->mu + kp->nu);
         krat /= (kp->mu * kp->nu);
         mrat = kp->mu / kp->vlen;
         mrat = (mrat+kp->nu) / (mrat*kp->nu);
         if (mmM->mflop[0] != 0.0 && mmK->mflop[0] != 0)
            krat *= mmM->mflop[0] / mmK->mflop[0];
         if (krat < 0.0)
            krat = -krat;
         if (krat < mrat)
         {
            KillMMNode(mp);
            mp = kp;
         }
         else
            KillMMNode(kp);
      }
   }
   else if (!mp)
      mp = kp;
   assert(mp);
   mp->rout = MMGetGenName(pre, nb, mp);
   mp->genstr = MMGetGenString(pre, mp);
   return(mp);
}
@endskip

void PrintGen0(FILE *fp, ATL_mmnode_t *mp, int mb, int nb, int kb)
{
   fprintf(fp, "B=(%d,%d,%d), U=(%d,%d,%d), pf=(%x,%d), flg=%x",
           mb?mb:mp->mbB, nb?nb:mp->nbB, kb?kb:mp->kbB, mp->mu, mp->nu,
           FLAG_IS_SET(mp->flag, MMF_KUISKB) ? -1:mp->ku, 
           mp->pref, mp->pfLS, mp->flag);
}

void PrintGen(FILE *fp, ATL_mmnode_t *mp, int mb, int nb, int kb, double mf)
/*
 * Prints single line description of mp to fp
 */
{
   fprintf(fp, "   0.");
   PrintGen0(fp, mp, mb, nb, kb);
   fprintf(fp, ": MFLOP=%.0f\n", mf);
}

ATL_mmnode_t *BestForThisNB
(
   int verb, 
   char pre, 
   ATL_mmnode_t *mmb, 
   int nb, 
   int pnb,  /* previous nb */
   int nnb   /* next nb */
)
/*
 * Times all kernels in mmb
 * RETURNS: ptr to best performing kernel, empty gen node if no user case wrks
 */
{
   ATL_mmnode_t *mmp, *mmB=NULL;
   double mf, mf0, mfB=0.0;

   printf("SCOPING FOR BEST PERFORMING KERNEL FOR NB=%d\n", nb);
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      const int kb0 = mmp->kbB, ku0 = mmp->ku;
      char *gs0=mmp->genstr;
      int kb, kbOK;
/*
 *    Choose kb, if forced only kb will do, so skip if kernel can't do it
 *    Genned kerns can be adapted, so are checked differently frm user kerns.
 */
      if (!mmp->ID)  /* kvec OK wt any mul of vlen, mvec OK wt any K */
         kbOK = FLAG_IS_SET(mmp->flag, MMF_KVEC) ? (nb%mmp->vlen == 0):1;
      else
      {
         kbOK = (mmp->kbmin) ? (nb >= mmp->kbmin) : 1;
         if (kbOK && mmp->kbmax)
            kbOK = nb <= mmp->kbmax;
      }
      if (!kbOK || ((nb/mmp->mu)*mmp->mu != nb) || ((nb/mmp->nu)*mmp->nu != nb)
          || ((nb/mmp->ku)*mmp->ku != nb) || (nb == pnb) || (nb == nnb))
      {
         
         printf("   %d. %s: SKIPPED, bad NB\n", mmp->ID, mmp->rout);
         continue;
      }
/*
 *    Generated files may need to get genstr and related info corrected
 */
      if (mmp->ID == 0)
      {
         if (FLAG_IS_SET(mmp->flag, MMF_KUISKB))
             mmp->kbmax = mmp->kbmin = mmp->ku = mmp->kbB = nb;
         if (!FLAG_IS_SET(mmp->flag, MMF_KRUNTIME))
             mmp->kbB = nb;
         mmp->genstr = MMGetGenString(pre, mmp);
      }
      mf0 = TimeMMKernel(verb, 0, mmp, pre, nb, nb, nb, 1, 0, -1);
      if (mmp->ID == 0)  /* put original info back in queue */
      {
         free(mmp->genstr);
         mmp->genstr = gs0;
         mmp->kbB = kb0;
         mmp->ku = ku0;
      }
/*
 *    Give bonus to K-runtime variable over K-compile time; K-runtime kernels
 *    can be used for some K-cleanup, and they can be used for any required KB
 *    as well as being typically much smaller instruction load, so they are
 *    strongly preferred
 */
      mf = FLAG_IS_SET(mmp->flag, MMF_KRUNTIME) ? mf0*KRUNMUL : mf0;
      if (mf > mfB)
      {
         mfB = mf;
         mmB = mmp;
         mmB->mbB = mmB->nbB = mmB->kbB = nb;
      }
      if (mmp->ID)
         printf("   %d. %s: kb=%d, flg=%x, MFLOP=%.2f\n", 
                mmp->ID, mmp->rout, nb, mmp->flag, mf0);
      else
         PrintGen(stdout, mmp, nb, nb, nb, mf0);
   }
   if (mmB)
   {
      mmB = CloneMMNode(mmB);
      mmB->mflop[0] = mfB;
      if (!mmB->ID)  /* specialize generated code for this KB */
      {
         if (mmB->genstr)
            free(mmB->genstr);
         if (mmB->rout)
            free(mmB->rout);
         mmB->mbB = mmB->nbB = mmB->kbB = nb;
         if (FLAG_IS_SET(mmB->flag, MMF_KUISKB))
             mmB->kbmin = mmB->kbmax = mmB->ku = nb;
         mmB->rout = MMGetGenName(pre, nb, mmB);
         mmB->genstr = MMGetGenString(pre, mmB);
      }
   }
   else
   {
      mmB = GetGenKernForNB(pre, nb);
      assert(mmB);
   }
   if (MMKernelFailsAnyBeta(pre, nb, nb, nb, mmB))
   {
      printf("BEST KERNEL FAILS TESTER FOR NB=%d\n", nb);
      exit(1);
   }
   mmB->mflop[0] = TimeMMKernel(verb, 0, mmB, pre, nb, nb, nb, 1, 0, -1);
   printf("BEST KERNEL FOUND FOR NB=%d: ID#%d '%s' %.2f MFLOPS\n\n", 
          nb, mmB->ID, mmB->rout, mmB->mflop[0]);
   return(mmB);
}

int DeleteBadBigNBs(ATL_mmnode_t *mmb, int *nbs)
{
   ATL_mmnode_t *best=NULL, *mmp;
   double mfB=0.0;
   int n=0;
/*
 * Find the best-performing kernel
 */
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      double mf;
      mf = mmp->mflop[0];
      if (mf > mfB)
      {
         mfB = mf;
         best = mmp;
      }
   }
/*
 * Delete all NBs larger than best
 */
   while (best->next)
   {
      best->next = KillMMNode(best->next);
      n++;
   }
   if (n)
   {
      int N = *nbs;
      N = (N >= 0) ? N : -N;
      printf("Deleted %d large, slow kernels starting at NB=%d\n", 
             n, nbs[N-n+1]);
   }
   return(n);
}

@ROUT uammsearch
ATL_mmnode_t *FindBestForEachNB(int verb, char pre, ATL_mmnode_t *mmb, int *nbs)
{
   int i, n, FORCE=0;
   ATL_mmnode_t *best, *bp;
/*
 * If # of nbs is negative, then each nb is required and that exact size
 * will be used, or no NB of that size if no kernel works.  The normal behavior
 * is the exact size of forced for all nb <= 16, and inexact for larger
 */
   n = nbs[0];
   if (n < 0)  /* negative # of nbs says force exact NB or nothing */
   {
      n = -n;
      FORCE = 1;
   }
   bp = best = BestForThisNB(verb, pre, mmb, nbs[1], 0, (n == 1)?nbs[1]:0,
                             FORCE);
   for (i=2; i <= n; i++)
   {
      int pnb = nbs[i-1], nnb = (i < n) ? nbs[i+1]:0;
      bp->next = BestForThisNB(verb, pre, mmb, nbs[i], pnb, nnb, FORCE);
      bp = bp->next;
   }
   if (!FORCE)
      i = DeleteBadBigNBs(best, nbs);
   return(best);
}

@ROUT ammsearch
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr, 
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
@skip    fprintf(stderr, "   -o <outfile>: output file (res/<pre>uAMMRES.sum)\n");
   fprintf(stderr, "   -n # nb1 ... nb# : NBs to try for\n");
   fprintf(stderr, "   -N # nb1 ... nb# : force exact NBs in search\n");
   fprintf(stderr, "   -r <nreg> : set max # of registers to try\n");
   fprintf(stderr, "   -b <nb>   : set initial block factor to try\n");
   fprintf(stderr, "   -v <verb> : set verbosity (1)\n");
   exit(ierr ? ierr : -1);
}

void GetFlags(int nargs, char **args, char *PRE, int *verb, int *NREG, 
              int *NB, int *CS)
{
   ATL_mmnode_t *mmb=NULL, *mp;
   int B0, BN;
   int i, j=0, n, k;
   char pre='d';
   int *nbs=NULL;
   *NREG = *NB = 0;
   *verb = 1;
   *CS = 0;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);
      
      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        break;
      case 'r':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *NREG = atoi(args[i]);
         break;
      case 'v':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *verb = atoi(args[i]);
         break;
      case 'b':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *NB = atoi(args[i]);
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   *PRE = pre;
/*
 * NREG has been stored by search in ivar.  Read it, and then zero ivar so
 * it won't propogate, making .sum files confusing
 */
   if (*NREG == 0)
   {
      ATL_mmnode_t *mp;
      char upr=pre;
      if (pre == 'z')
         upr = 'd';
      else if (pre == 'c')
         upr = 's';
      mp = ReadMMFileWithPath(upr, "res", "gmvAMMUR.sum");
      if (mp)
      {
         *NREG = mp->ivar;
         KillAllMMNodes(mp);
      }
   }
   if (*CS == 0)
      *CS = GetL1CacheElts(pre);
}
@ROUT ammsearch uammsearch
static INLINE void ApplyMoves2Flag
(
   ATL_mmnode_t *mmp,  /* kernel to set MMF_MV[A,B,C] flag bits */
   int mvBits          /* last 3 bits: MOVE_[CBA] */
)
{
   int flag = mmp->flag & (~MMF_MVSET);         /* zero existing move bits */
   mmp->flag = flag | ((mvBits & 7)<<MMF_MVA); /* put new move bits in */
}
static void ApplyMoves2Flags
(
   ATL_mmnode_t *mmb,  /* kernel to set MMF_MV[A,B,C] flag bits */
   int mvBits          /* last 3 bits: MOVE_[CBA] */
)
{
   const unsigned int mvMSK = ~MMF_MVSET, mvSET = (mvBits&7)<<MMF_MVA;
   ATL_mmnode_t *mmp;
   for (mmp=mmb; mmp; mmp = mmp->next)
      mmp->flag = ((mmp->flag) & mvMSK) | mvSET;
}

ATL_mmnode_t *GetNewKCleanGenNode
(
   char pre, 
   ATL_mmnode_t *kp,  /* kernel we are generating K-cleanup for */
   int mb, 
   int nb, 
   int kb
)
{
   ATL_mmnode_t *p;
   const int mu=kp->mu, nu=kp->nu;
   int kvec=0, ku=1, vl, vmu;
   int kmaj = FLAG_IS_SET(kp->flag, MMF_KVEC) ? kp->vlen:0;

   if (kmaj > 1)
   {
      kvec = 1;
      ku = vl = kmaj;
@skip      assert((mu*nu)%vl == 0);  /* impossible for legal code */
   }
   else
   {
      if (kp->vlen)
      {
         vl = kp->vlen;
         assert(mu%vl == 0);
      }
      else
         vl = 1;
   }
   printf("  TRY: mu=%d, nu=%d, ku=%d, vl=%d, kvec=%d\n", mu, nu, ku, vl, kvec);
   p = MMGetNodeGEN(pre, 0, 0, mu, nu, ku, vl, kvec, 0, 0, NULL);
   p->mbB = mb;
   p->nbB = nb;
   p->kbB = kb;
   return(p);
} 

ATL_mmnode_t *FindDefMUNU(int verb, char pre, int nreg, int lat, int nb, int ku,
                          int *MU, int *NU)
{
   ATL_mmnode_t *mmp;
   double mf, mfB=0.0;
   int n, i, j, kb, muB=1, nuB=1, VL, chkVL=0;

//   mmp = ReadMMFileWithPath(pre, "res", "gAMMMUNU.sum");
   mmp = NULL;
   if (mmp)
   {
      MMFillInGenStrings(pre, mmp);
      nb = mmp->kbB;
      if (mmp->mflop[0] < 0.0)
         mmp->mflop[0] = TimeMMKernel(verb, 1, mmp, pre, nb, nb, nb, 1, 0, -1);
      printf("READ IN BEST GENNED MU=%d, NU=%d, MFLOP=%.2f\n\n", 
             mmp->mu, mmp->nu, mmp->mflop[0]);
#if 0
/*
 *    See if there is a mismatch between vector settings
 */
      if (mmp->vlen != VLEN[VECi])
      {
         printf("\n\n!!! WARNING: TURNING OFF VECTORIZATION DUE TO MISMATCHED VLEN IN 'res/%cAMMMUNU.sum!!!!\n\n", pre);
         VECi = VTSC;
      }
      *MU = mmp->mu / VLEN[VECi];
      assert(*MU);
      *NU = mmp->nu;
@skip      KillMMNode(mmp);
#endif
      return (mmp);
   }
   VL = GetNativeVLEN(pre);
   if (!VL)
      chkVL = VL = (pre == 's' || pre == 'c') ? 4 : 2;  /* temp kludge */
   mmp = MMGetNodeGEN(pre, 0, nb, 1, 1, ku, 1, 0, 0, 0, 
                      DupString("ATL_Xamm_munu.c"));
   if (pre == 'z')
      mmp->rout[4] = 'd';
   else if (pre == 'c')
      mmp->rout[4] = 's';
   else
      mmp->rout[4] = pre;
   mmp->mbB = mmp->nbB = mmp->kbB = nb;
   mmp->vlen = VL;
/*
 * Try all near-square register blocking cases
 */
   printf("Finding best MUxNU case for nb=%d\n", nb);
   for (n=4; n < nreg; n++)
   {
      int mbu, nbu, mu, nu;
      for (j=1; j*j < n; j++);
      i = n / j;
      if (nb%i || nb%j)
         continue;
      mu = mmp->mu = i * VL;
      nu = mmp->nu = j;
      if (mmp->genstr)
        free(mmp->genstr);
      mbu = (nb >= mu) ? (nb/mu)*mu : mu;
      nbu = (nb >= nu) ? (nb/nu)*nu : nu;
      mmp->genstr = MMGetGenString(pre, mmp);
      mf = TimeMMKernel(verb, 1, mmp, pre, mbu, nbu, nb, 1, 0, -1);
      printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
      if (mf > mfB)
      {
         muB = i;
         nuB = j;
         mfB = mf;
      }
   }
/*
 * For non-AVX x86, try 1-D cases since they are 2-operand assemblies
 */
   #if (defined(ATL_GAS_x8664) || defined(ATL_GAS_x8632)) && !defined(ATL_AVX)
      printf("BEST NEAR-SQUARE CASE IS MU=%d, NU=%d, MFLOP=%.2f\n\n", 
             muB, nuB, mfB);
      printf("Finding best 1-D outer loop unrolling for nb=%d\n", nb);
      for (n=2; n < nreg; n++)
      {
         int mbu, nbu, mu, nu;
         i = 1; j = n;
         if (nb % n)
            continue;
         mu = mmp->mu = i*VL;
         nu = mmp->nu = j;
         if (mmp->genstr)
           free(mmp->genstr);
         mmp->genstr = MMGetGenString(pre, mmp);
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         mf = TimeMMKernel(verb, 1, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (mf > mfB)
         {
            muB = i;
            nuB = j;
            mfB = mf;
         }
         i = n; j = 1;
         mu = mmp->mu = i * VL;
         nu = mmp->nu = j;
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         if (mmp->genstr)
           free(mmp->genstr);
         mmp->genstr = MMGetGenString(pre, mmp);
         mf = TimeMMKernel(verb, 1, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (mf > mfB)
         {
            muB = i;
            nuB = j;
            mfB = mf;
         }
      }
   #endif

   i = FLAG_IS_SET(mmp->flag, MMF_KVEC);
   KillMMNode(mmp);
   mmp = MMGetNodeGEN(pre, 0, nb, (i)?muB:muB*VL, nuB, ku, VL, i, 0, 0, NULL);
   WriteRefreshedMMFileWithPath(pre, "res", "gAMMMUNU.sum", mmp);
@skip   KillMMNode(mmp);
   printf("BEST CASE IS MU=%d, NU=%d, MFLOP=%.2f (%.2f)\n\n", 
          muB, nuB, mf, mfB);
   *MU = muB;
   *NU = nuB;
   return(mmp);
}

#if 0
void GetMUNUbyNB(int nb, int nreg, int *MU, int *NU)
{
   int mu=(*MU), nu=(*NU), vmu=mu*VLEN;

   assert(mu && nu && !(nb%VLEN[VECi]));
   if (!(nb%vmu) && !(nb%nu))
      return;
   if (nu == 1) /* handle MUx1 by decreasing by VLEN */
   {
      int u = vmu, vlen = VLEN[VECi];
      while (u+u+1 <= nreg && nb%u)
         u += vlen;
      if (u+u+1 > nreg)
         u -= vlen;
      while (nb%u)
         u -= vlen;
      assert(u);
      *MU = u / vlen;
      return;
   }
   if (mu == 1 || nu == 1) /* handle 1-D cases by just inc/dec U */
   {
      int u = (mu == 1) ? nu : mu;
      while (u+u+1 <= nreg && nb%u)
         u++;
      if (u+u+1 > nreg)
         u--;
      while (nb%u)
         u--;
      if (mu == 1)
         *NU = u;
      else
         *MU = u;
      return;
   }
   if (nb%vmu)  /* mu can't handle NB */
   {
      int i;
/* 
 *    try increasing mu until we run out of registers
 */
      for (i=mu+1; i*nu+i+nu <= nreg; i++)
         if (!(nb%(i*VLEN[VECi])))
            break;
/*
 *    Try decreasing mu until it divides
 */
      if (nb%(i*VLEN[VECi]) || i*nu+i+nu > nreg)
      {
         for (mu--; mu; mu--)
            if (!(nb%(mu*VLEN[VECi])))
               break;
      }
      else
         mu = i;
   }
   if (nb%nu)  /* nu can't handle NB */
   {
      int i;
/* 
 *    try increasing nu until we run out of registers
 */
      for (i=nu+1; i*mu+i+mu <= nreg; i++)
         if (!(nb%i))
            break;
/*
 *    Try decreasing nu until it divides
 */
      if (nb%i || i*mu+i+mu > nreg)
      {
         for (nu--; nu; nu--)
            if (!(nb%nu))
               break;
      }
      else
         nu = i;
   }
   *MU = mu;
   *NU = nu;
}
#endif

int FindNBInArray(int nb, int *nbs)
/*
 * RETURNS: location+1, or 0 if not found
 */
{
   int i, n = (nbs[0] > 0) ? nbs[0] : -nbs[0];
   for (i=1; i <= n; i++)
       if (nbs[i] == nb)
          return(i);
   return(0);
}
#if 0
ATL_mmnode_t *CreateGenCasesFromNBs
(
   ATL_mmnode_t *mmb,   /* best user-contributed kernels */
   char pre,            /* precision: s/d */
   int *nbs,            /* list of desired NBs */
   int nreg,            /* upper bound on register use */
   int MU, int NU,      /* default M/N unrolling */
   int KU               /* -1 for fully unrolled, else unrolling factor */
)
/*
 * Generate a list of generated kernels, with the union of nb's in nbs
 * and mmb, and return the generated nodes for timing.
 * HERE HERE HERE: this code is crap, needs to merge both lists, not user
 * list twice.
 */
{
   ATL_mmnode_t *mp, *umb=NULL, *ap;
   int i, n = (nbs[0] > 0) ? nbs[0] : -nbs[0], ne=0, *enbs;

/*
 * Create new queue with an entry for all NBs; both lists (mmb & nbs) are
 * sorted in increasing size
 */
   if (!n && !mmb)
      return(NULL);
   n++;
   ap = mmb;  /* add ptr */
   i = 1;     /* ptr to normal block under consideration */
   do
   {
      int nb, mu=MU, nu=NU, ku;
      ATL_mmnode_t *p=NULL;
      if (ap && i < n)  /* must choose amongst blocks */
      {
         nb = ap->kbB;
         nb = Mmin(nb, nbs[i]);
         if (nb == ap->kbB)
            ap = ap->next;
         if (nb == nbs[i])
            i++;
      }
      else if (ap)
      {
         nb = ap->kbB;
         ap = ap->next;
      }
      else
         nb = nbs[i++];
      ku = (KU == -1) ? nb : KU;
   
/*
 *    If NB is not a multiple of VLEN, drop down to shorter ops
 */
      if (nb%VLEN[VECi])
      {
         int vl=VECi;
/*
 *       For AVX, see if dropping to SSE will fix problem
 */
         if (VECi == VTAVX && !(nb%VLEN[VTSSE]))  /* AVX can drop to SSE */
         {
            VECi = VTSSE;
            GetMUNUbyNB(nb, nreg, &mu, &nu);
            p = GetNewGenNode(pre, nb, 0, mu, nu, ku, 0);
         }
         if (!p)
         {
            VECi = VTSC;
            GetMUNUbyNB(nb, nreg, &mu, &nu);
            p = GetNewGenNode(pre, nb, 0, mu, nu, ku, 0);
         }
         VECi = vl;
      }
      else
      {
         GetMUNUbyNB(nb, nreg, &mu, &nu);
         p = GetNewGenNode(pre, nb, 0, mu, nu, ku, 0);
      }
      if (umb)
      {
         mp->next = p;
         mp = p;
      }
      else
         umb = mp = p;
   }
   while (i < n || ap);
   return(umb);
}
void SetGenVec(int verb, char pre)
/*
 * This routine uses a simple timing to be sure if vectorization helps or not
 */
{
   ATL_mmnode_t *mp;
/*
 * If vector operations are being used, make sure they work; compiler and
 * flag changes can mess them up, and in this case we'll fall back to
 * scalar generation.  Try to see if we can successfully test simplist
 * possible vector kernel, and fall back to scalar kernel if we can't
 */
   if (VLEN[VECi] < 2)
      return;
   mp = GetNewGenNode(pre, 32, 0, 1, 1, 1, 0);
   if (MMKernelFailsTest(pre, 32, 32, 32, 1, mp))
   {
      printf("ERROR: VEC='%s' FAILED, genstr='%s'!\n",VECs[VECi],mp->genstr);
      KillMMNode(mp);
/*
 *    For AVX, try falling back to SSE
 */
      if (VECi == VTAVX)
      {
         VECi = VTSSE;
         KillMMNode(mp);
         mp = GetNewGenNode(pre, 32, 0, 1, 1, 1, 0);
         if (MMKernelFailsTest(pre, 32, 32, 32, 1, mp))
            VECi = VTSC;
      }
      else
         VECi = VTSC;
   }
   KillMMNode(mp);
/*
 * For AVX, switch to SSE if AVX doesn't offer a performance advantage
 * (as on AMD Dozer), since SSE smaller code size and requires less cleanup 
 */
   if (VECi == VTAVX)
   {
      double mfA, mfS, mf;
      char *sp; 
      int vl;
      mp = GetNewGenNode(pre, 128, 0, 1, 4, 1, 0);
      mfA = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      KillMMNode(mp);
      mp = GetNewGenNode(pre, 128, 0, 2, 2, 1, 0);
      mf = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      KillMMNode(mp);
      if (mf > mfA)
         mfA = mf;
      vl = VECi;
      VECi = VTSSE;
      mp = GetNewGenNode(pre, 128, 0, 1, 4, 1, 0);
      mfS = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      KillMMNode(mp);
      mp = GetNewGenNode(pre, 128, 0, 2, 2, 1, 0);
      mf = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      if (mf > mfA)
         mfA = mf;
      KillMMNode(mp);
      if (mfA < 1.03*mfS)
         printf("USING SSE INSTEAD OF AVX, AVX=%.2f, SSE=%.2f\n", mfA, mfS);
      else
      {
         printf("AVX GOOD, AVX=%.2f, SSE=%.2f\n", mfA, mfS);
         VECi = vl;
      }
   }
/*
 * For any system, don't use vector instructions if they aren't faster than
 * scalar. 
 */
   if (VLEN[VECi] > 1)
   {
      double mfV, mfS;
      char *sp; 
      int vl;
      mp = GetNewGenNode(pre, 128, 0, 1, 4, 1, 0);
      mfV = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      KillMMNode(mp);
      vl = VECi;
      VECi = VTSC;
      mp = GetNewGenNode(pre, 128, 0, 1, 4, 1, 0);
      mfS = TimeMMKernel(verb, 1, mp, pre, 128, 128, 128, 1, 0, -1);
      KillMMNode(mp);
      if (mfV < 1.05*mfS)
         printf("USING SCALAR INSTEAD OF VECTOR, VEC=%.2f, SCALAR=%.2f\n", 
                mfV, mfS);
      else
      {
         printf("VEC GOOD, VEC=%.2f, SCALAR=%.2f\n", mfV, mfS);
         VECi = vl;
      }
   }
   printf("GENERATING WITH VEC='%s', VLEN=%d\n\n", VECs[VECi], VLEN[VECi]);
}
#endif

@beginskip
ATL_mmnode_t *FindBestGenCases(int verb, char pre, int nreg, 
                               int *nbs, ATL_mmnode_t *ummb)
{
   ATL_mmnode_t *mp, *gmmU, *gmmb;
   int MU, NU;

   gmmb = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   if (gmmb)
   {
      printf("Reading in generated cases for all NBs:\n");
      MMFillInGenStrings(pre, gmmb);
      for (mp=gmmb; mp; mp = mp->next)
      {
         const int mu = (mp->vlen) ? mp->mu / mp->vlen : mp->mu;
         int kb = mp->kbB, mb = Mmax(mp->mu,kb), nb=Mmax(mp->nu,kb);
         if (mp->mflop[0] < 0.0)
            mp->mflop[0] = TimeMMKernel(verb, 1, mp, pre, mb, nb, kb, 1, 0, -1);
         printf("  NB=%d, MU=%d, NU=%d, vlen=%d, MFLOP=%.2f\n", 
                nb, mu, mp->nu, mp->vlen, mp->mflop[0]);
      }
      WriteMMFileWithPath(pre, "res", "gAMMRES.sum", gmmb);
      printf("Done.\n\n");
      return(gmmb);
   }
   SetGenVec(verb, pre);
/*
 * Find the best mu/nu for NB=120; we don't care if we overflow cache for
 * this timing, and 120 = LCM(2,3,4,5,6,8,12).  Use ku=1 so that large
 * problems don't have large K-driven advantage.
 */
   KillMMNode(FindDefMUNU(verb, pre, nreg, 0, 120, 1, &MU, &NU));
   gmmb = CreateGenCasesFromNBs(ummb, pre, nbs, nreg, MU, NU, 1);
   if (verb > 1)
   {
      printf("\n");
      PrintMMNodes(stdout, gmmb);
      printf("\n");
   }
   printf("Finding generated cases for all NBs:\n");
   for (mp=gmmb; mp; mp = mp->next)
   {
      int mu;
      mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB, mp->kbB, 
                                  1, 0, -1);
      mu = (mp->vlen) ? mp->mu / mp->vlen : mp->mu;
      printf("   NB=%d, mu=%d, nu=%d, vlen=%d, MFLOPS=%.2f\n", 
             mp->kbB, mu, mp->nu, mp->vlen, mp->mflop[0]);
   }
   printf("Done.\n\n");
   WriteMMFileWithPath(pre, "res", "gAMMRES.sum", gmmb);
   return(gmmb);
}
@endskip


ATL_mmnode_t *GetWorkingUserCases(int verb, char pre)
{
   ATL_mmnode_t *mmb, *mmp;
@ROUT ammsearch00
   mmb = ReadMMFileWithPath(pre, "res", "AMMFRCLST.sum");
   if (mmb)
      return(mmb);
@ROUT ammsearch uammsearch
   mmb = ReadMMFileWithPath(pre, "res", "WORKING.sum");
   if (mmb)
      return(mmb);
   mmb = ReadMMFileWithPath(pre, "AMMCASES", "amcases.idx");
   if (!mmb)
      return(mmb);
/*
 * Eliminate those kernels that can't work for any block size
 */
   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      if (FLAG_IS_SET(mmp->flag, MMF_KUISKB))
         mmp->kbmin = mmp->kbmax = mmp->mbB = mmp->nbB = mmp->kbB = mmp->ku;
      else
      {
         int m = Mylcm(mmp->mu, mmp->nu);
         m = ((60+m-1)/m)*m;
         mmp->mbB = mmp->nbB = mmp->kbB = m;
         if (mmp->kbmin)
            mmp->kbB = Mmax(mmp->kbB, mmp->kbmin);
         if (mmp->kbmax)
            mmp->kbB = Mmin(mmp->kbB, mmp->kbmax);
      }
   }
   mmb = DelBadMMKernels(pre, verb, mmb);
   WriteMMFileWithPath(pre, "res", "WORKING.sum", mmb);
   return(mmb);
}

@ROUT uammsearch
ATL_mmnode_t *FindBestUserCases(int verb, char pre, int *nbs, ATL_mmnode_t *mmb)
/*
 * NOTE: frees mmb after search!!
 * RETURNS: list of the best user case for each supplied NB; if no user case
 *          works, special "generated" node is returned for later filling out.
 */
{
   ATL_mmnode_t *mmp, *mp;
   mp = ReadMMFileWithPath(pre, "res", "uAMMRES.sum");
/*
 * If final output file exists, then we need to rerun timings at worst
 */
   if (mp)
   {
      KillAllMMNodes(mmb);
      for (mmp=mp; mmp; mmp = mmp->next)
      {
         if (mmp->ID > 0 && mmp->mflop[0] < 0.0)
            mmp->mflop[0] = TimeMMKernel(verb, 0, mmp, pre, mmp->mbB, mmp->nbB,
                                         mmp->kbB, 1, 0, -1);
         if (mmp->ID > 0)
            printf("USER KERNEL AT NB=%d gets MFLOP=%.2f\n",
                   mmp->kbB, mmp->mflop[0]);
         else
            printf("NO USER KERNEL FOR NB=%d\n", mmp->kbB);
      }
      printf("\n");
      return(mp);
   }
   mmp = FindBestForEachNB(verb, pre, mmb, nbs);
   KillAllMMNodes(mmb);
   WriteMMFileWithPath(pre, "res", "uAMMRES.sum", mmp);
   return(mmp);
}

@ROUT ammsearch uammsearch gmmsearch
ATL_mmnode_t *MergeCases
(
   int imf,
   ATL_mmnode_t *bs0, /* queue of cases */
   ATL_mmnode_t *bs1  /* queue of cases */
)
/*
 * Merges two queues of matmul kern cases.  Cases are not winnowed, but
 * duplicates are not allowed, so if two entries have the same kbB, then
 * we take the one with best mflop[imf].  If imf < 0, then we do indeed
 * allow duplicates of kbB.
 * NOTE: does not change bs0 or bs1.
 * ASSUMES: both bs0 & bs1 are in kb-increasing order.
 * RETURNS: base ptr to merged queue
 */
{
   ATL_mmnode_t *mb=NULL, *mp;
   while (bs0 || bs1)
   {
      ATL_mmnode_t *p;
      if (bs0 && bs1)
      {
         if (bs0->kbB < bs1->kbB)
         {
            p = CloneMMNode(bs0);
            bs0 = bs0->next;
         }
         else if (bs0->kbB > bs1->kbB)
         {
            p = CloneMMNode(bs1);
            bs1 = bs1->next;
         }
         else /* they are equal, must take best performer, or both */
         {
/*
 *          If we are taking both, special case can't use general completion
 */
            if (imf < 0)
            {
               p = CloneMMNode(bs0);
               bs0 = bs0->next;
               p->next = CloneMMNode(bs1);
               bs1 = bs1->next;
               if (mb)
                  mp->next = p;
               else
                  mb = p;
               mp = p->next;
               continue;
            }
/*
 *          Taking only the best performer, but moving both base ptrs
 */
            else
            {
/*
 *             If they are equal, take the KRUN=1 case if it exists, else
 *             take the most flexible one or one requiring the least cleanup
 */
               if (bs0->mflop[imf] == bs1->mflop[imf])
               {
                  if (FLAG_IS_SET(bs0->flag, MMF_KRUNTIME))
                     p = bs0;
                  else if (FLAG_IS_SET(bs1->flag, MMF_KRUNTIME))
                     p = bs1;
                  else if (bs0->ku < bs1->ku)
                     p = bs0;
                  else if (bs1->ku < bs0->ku)
                     p = bs1;
                  else
                  {
                     const int u0=Mmax(bs0->mu, bs0->nu), 
                               u1=Mmax(bs1->mu, bs1->nu);
                     p = (u0 <= u1) ? bs0 : bs1;
                  }
               }
               else
                  p = (bs0->mflop[imf] > bs1->mflop[imf]) ? bs0 : bs1;
               p = CloneMMNode(p);
               bs0 = bs0->next;
               bs1 = bs1->next;
            }
         }
      }
      else if (bs0)
      {
         p = CloneMMNode(bs0);
         bs0 = bs0->next;
      }
      else /* if (bs1) */
      {
         p = CloneMMNode(bs1);
         bs1 = bs1->next;
      }
      if (mb)
      {
         mp->next = p;
         mp = p;
      }
      else
        mp = mb = p;
   }
   return(mb);
}
@ROUT ammsearch uammsearch

#define HUGE_NB 180
ATL_mmnode_t *WinnowHugeNB
(
   int imf,
   ATL_mmnode_t *mb  /* queue of cases */
)
/*
 * Removes any NB >= HUGE_NB that aren't at least 2% faster than smaller cases
 */
{
   ATL_mmnode_t *mp, *p, *prev=mb;
   double mfB;

   if (!mb || !mb->next)
      return(mb);
   mp = mb->next;
/*
 * Find best-performing kernel below HUGE_NB
 */
   mfB = mp->mflop[imf];
   for (mp=mb->next; mp; mp = mp->next)
   {
      if (mp->mbB < HUGE_NB && mp->nbB < HUGE_NB && mp->kbB < HUGE_NB)
         mfB = Mmax(mfB, mp->mflop[imf]);
      else
         break;
      prev = mp;
   }
/*
 * If no kernels above threshold, return original queue
 */
   if (!mp)
      return(mb);
/* 
 * mp points to first NB above threshold, but there is no point in deleting
 * small NB if we leave large NB, so delete only from the end of queue
 */
  do
  {
     for (p=mp; p->next; p = p->next);
     if (p->mflop[imf] <= 1.02*mfB)
        mp = RemoveMMNodeFromQ(mp, p);
     else  /* stop removing stuff */
        break;
  }
  while (mp);
  prev->next = mp;
  return(mb);
}

@ROUT ammsearch uammsearch gmmsearch
ATL_mmnode_t *WinnowCases
(
   int imf,
   ATL_mmnode_t *mb  /* queue of cases */
)
/*
 * Removes any case that runs slower than a smaller case
 * RETURNS: mb with queue bad kernels deleted
 * NOTE: mb can never change, since by def nothing smaller than 1st case
 */
{
   ATL_mmnode_t *prev = mb, *mp;

   if (!mb)
      return(NULL);
@skip   mb = WinnowHugeNB(imf, mb);
   mp = mb->next;
   while (mp)
   {
      if (mp->mflop[imf] <= prev->mflop[imf])  /* kill slow KB */
         mp = prev->next = KillMMNode(mp);
      else
      {
         prev = mp;
         mp = mp->next;
      }
   }
   return(mb);
}
@ROUT ammsearch uammsearch

ATL_mmnode_t *MergeAndWinnowCases
(
   int verb, 
   char pre, 
   ATL_mmnode_t *umb, /* queue of user cases */
   ATL_mmnode_t *gmb  /* genned cases, always include NBs of umb */
)
/*
 * Merges user and gmp cases, while getting rid of cases that get worse
 * performance than their smaller blocks; FREES umb and gmb
 * RETURNS: new merged and winnowed queue
 */
{
   ATL_mmnode_t *mmb=NULL, *mmp, *gmp, *ump=umb;
   for (gmp=gmb; gmp; gmp = gmp->next)
   {
      ATL_mmnode_t *p;
      if (ump)
      {
         if (ump->kbB == gmp->kbB)
         {
            if (gmp->mflop[0] >= ump->mflop[0])
               p = CloneMMNode(gmp);
            else
               p = CloneMMNode(ump);
            ump = ump->next;
         }
         else
            p = CloneMMNode(gmp);
      }
      else
         p = CloneMMNode(gmp);
      p->next = NULL;
      if (mmb)
      {
/*
 *       If larger NB isn't faster than smaller one, kill it for nb >= 16
 */
         if (p->kbB >= 16 && mmp->mflop[0] > p->mflop[0])
            KillMMNode(p);
         else
         {
            mmp->next = p;
            mmp = p;
         }
      }
      else
         mmp = mmb = p;
   }
   KillAllMMNodes(umb);
   KillAllMMNodes(gmb);
   mmb = WinnowCases(0, mmb);
@skip   mmb = WinnowHugeNB(0, mmb);
   return(mmb);
}


@beginskip
void ApplyMoves2Flags  /* overwrites MV bits according to string */
(
   ATL_mmnode_t *mmb,  /* queue of kernels to set MMF_MV[A,B,C] flag bits */
   char *mvs           /* string passed to timer wt moves */
)
{
   ATL_mmnode_t *mmp;
   const unsigned int NOMV = ~MMF_MVSET;
   unsigned int DOMV;
   if (!mvs)
      DOMV = ((1<<MMF_MVA) | (1<<MMF_MVB));
   else
   {
      DOMV = 0;
      if (strstr(mvs, "MoveA"))
         DOMV |= (1<<MMF_MVA);
      if (strstr(mvs, "MoveB"))
         DOMV |= (1<<MMF_MVB);
      if (strstr(mvs, "MoveC"))
         DOMV |= (1<<MMF_MVC);
   }
   for (mmp=mmb; mmp; mmp = mmp->next)
      mmp->flag = (((mmp->flag) & NOMV) | DOMV);
}
@endskip

int FailKCleanTests(char pre, int nb, ATL_mmnode_t *kp)
/*
 *  This routine tests if a kernel is suitable for use in K-cleanup by
 *  doing testing with ku=1, kb=0, and tries all K values between 1 and nb
 *  RETURNS: 0 if kernel passes all tests, else non-zero
 */
{
   int i, beg, end, inc, kmaj = FLAG_IS_SET(kp->flag, MMF_KVEC) ? kp->vlen:0;;

   if (!FLAG_IS_SET(kp->flag, MMF_KRUNTIME) || 
       (kp->ku != 1 && kp->ku != kmaj))
      return(-1);
   printf("TESTING ID=%d, rout='%s', nb=%d, mu=%d, nu=%d for K-cleanup:\n",
          kp->ID, kp->rout, nb, kp->mu, kp->nu);

   if (kmaj > 1)
   {
      inc = beg = kmaj;
      end = ((nb+inc-1)/inc)*inc;
   }
   else
   {
      beg = inc = 1;
      end = nb;
   }
   for (i=beg; i <= end; i += inc)
   {
      int ierr;
      ierr = MMKernelFailsTest(pre, nb, nb, i, 0, kp);
      if (ierr)
      {
         printf("  K=%d: FAILED!\n", i);
         return(ierr);
      }
      else
         printf("  K=%d: PASSED!\n", i);
   }
   printf("PASSED ALL K-tests!\n\n");
   return(0);
}
@ROUT ammsearch  `@define kpr @AMM@`
@ROUT uammsearch `@define kpr @UMM@`
ATL_mmnode_t *GetUniqueKClean(int verb, char pre, ATL_mmnode_t *mmb)
/*
 * OUTPUT: <pre>@(kpr)KCLEAN.sum: all unique kerns to be compiled
 */
{
   ATL_mmnode_t *mp, *gmmb, *ummb, *ub, *np, **dlmm;
   int nn=0, nd=0, n=0;  /* #needed & done, total, copy of done */
   int *dl, *nl;         /* done and needed lists */
   int i;
@ROUT ammsearch
   gmmb = ReadMMFileWithPath(pre, "res", "@(kpr)KCLEAN.sum");
   if (gmmb)
   {
      printf("READING IN UNIQUE K-CLEANUP:\n");
      MMFillInGenStrings(pre, gmmb);
      for (mp=gmmb; mp; mp = mp->next)
      {
         int mb = (mp->nbB > mp->mu) ? (mp->nbB/mp->mu)*mp->mu : mp->mu;
         int nb = (mp->nbB > mp->nu) ? (mp->nbB/mp->nu)*mp->nu : mp->nu;
         int kb = (nb > 8) ? (nb>>2) : nb, KB = kb;
         int ku = mp->ku, kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;;
         if (kmaj > 1)
            KB = ((kb+ku-1)/ku)*ku;
         if (mp->mflop[0] < 0.0)
         {
            mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mb, nb, KB, 0, 0, -1);
            mp->mflop[0] *= (double)kb / (double)KB;
         }
         printf("   nb=%d,  kb=%d, mu=%d, nu=%d, MFLOP=%.2f\n", 
                nb, kb, mp->mu, mp->nu, mp->mflop[0]);
      }
      printf("Done.\n");
      return(gmmb);
   }
@ROUT ammsearch uammsearch
/*
 * Find out how many total kernels, and how many already have their own
 * cleanup (nd, number done).  This nd may be bigger than it should, because
 * we can't guarantee they are unique
 */
   for (mp=mmb; mp; mp = mp->next, n++)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if ((mp->ku == 1 || (kmaj == mp->ku)) && 
          FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
        nd++;
   }
   dl = malloc(8*n*sizeof(int));
   assert(dl);
   if (nd)
   {
      dlmm = malloc(nd*sizeof(ATL_mmnode_t*));
      assert(dlmm);
   }
   else
      dlmm = NULL;

   nl = dl + (n<<2);
   nd = 0;
/*
 * First, go back through kernels, and add kernels that can serve as K-cleaners
 * to the done list
 */
   for (mp=mmb; mp; mp = mp->next, n++)
   {
      const int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME) && 
          (mp->ku == 1 || kmaj == mp->ku))
      {
         const int nd4 = (nd<<2), mu=mp->mu, nu=mp->nu;
/*
 *       See if trip is already in done list if so, no new entry, just update kb
 *       and cleanup kernel entry
 */
         for (i=0; i < nd4; i += 4)
            if (mu == dl[i] && nu == dl[i+1] && kmaj == dl[i+2])
               break;
         if (i < nd4)
         {                      /* (larger NB always later) */
            dl[i+3] = mp->kbB;  /* take largest kbB that matches mu/nu */
            dlmm[i>>2] = mp;
            continue;           
         }
         else
         {
            dl[nd4] = mu;
            dl[nd4+1] = nu;
            dl[nd4+2] = kmaj;
            dl[nd4+3] = mp->kbB;
            dlmm[nd++] = mp;
         }
      }
   }
/*
 * Delete any kernels from dl that fail to actually work for K cleaning
 */
   for (i=0; i < nd; i++)
   {
      if (FailKCleanTests(pre, dlmm[i]->kbB, dlmm[i]))
      {
         const int i4=(i<<2), nc=nd-i-1;
         if (nc > 0)
         {
            memcpy(dl+i4, dl+i4+4, (nc<<2)*sizeof(int));
            memcpy(dlmm[i], dlmm[i+1], nc*sizeof(ATL_mmnode_t*));
         }
         nd--;
      }
   }

/*
 * Find all unique (mu,nu,kmaj) combos that still need to to be cleaned; 
 * there will be nn (# needed) of these, and we'll save (mu,nu,MAXNB) in
 * needed list (nl).
 * We use MAXNB for testing (large NB tests mosts cases of K).
 * Combos that are handled by the done list (dl) aren't added to needed list.
 */
   for (mp=mmb; mp; mp = mp->next, n++)
   {
      int mu=mp->mu, nu=mp->nu, nn4=(nn<<2), nd4=(nd<<2);
      int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
/*
 *    See if pair is already in done list or needed list, if so, no change
 */
      for (i=0; i < nd4; i += 4)
         if (mu == dl[i] && nu == dl[i+1] && kmaj == dl[i+2])
            break;
      if (i < nd4)    /* if it was found in the done list */
         continue;    /* this combo is already handled */
/*
 *    If we reach here, combo is not handled, must add to needed list 
 */
      for (i=0; i < nn4; i += 4)
         if (mu == nl[i] && nu == nl[i+1] && kmaj == nl[i+2])
            break;
      if (i < nn4)            /* If already in needed list */
      {
         nl[i+3] = mp->kbB;   /* just update kb so we get largest for testing */
         continue;
      }
/*
 *    If we haven't seen this pair before, add to needed list
 */
      else
      {
         nl[nn4] = mu;
         nl[nn4+1] = nu;
         nl[nn4+2] = kmaj;
         nl[nn4+3] = mp->kbB;
         nn++;
      }
   }
/*
 * Now, create a queue of generated kernels for each needed pair, and time
 * it's maxNB performance.
 */
   gmmb = NULL;
   printf("Timing Generated K-cleanup:\n");
   for (i=0; i < nn; i++)
   {
      ATL_mmnode_t *p;
      const int i4 = (i<<2), mu=nl[i4], nu=nl[i4+1], kmaj=nl[i4+2];
      int nb = Mmax(nl[i4+3],nu), mb = (nb > mu) ? (nb/mu)*mu : mu, ku;
      const int kb = (nb > 8) ? (nb>>2) : nb;
      int vl=VLEN, vmu, KK;
      double mf;
/*
 *    HERE HERE: Improve KMAJ when generator is extended!
 */
      if (kmaj > 1)
      {
         while ((mu*nu)%vl)
            vl >>= 1;
         vmu = mu;
         ku = vl;
      }
      else
      {
         while (mu%vl)
            vl >>= 1;
         ku = 1;
      }
/* HERE HERE */
      p = MMGetNodeGEN(pre, 0, 0, mu, nu, ku, vl, kmaj, 0, 0, NULL);
      p->mbB = mb;
      p->nbB = nb;
      p->kbB = kb;
      p->flag |= (1<<MMF_KRUNTIME);
      #if 1  /* by default don't waste time testing generated code */
         assert(!FailKCleanTests(pre, nb, p));
      #endif
      KK = (kmaj < 2) ? kb : ((kb+kmaj-1)/kmaj)*kmaj;
      p->mflop[0] = TimeMMKernel(verb, 0, p, pre, mb, nb, kb, 0, 0, -1);
      if (KK != kb)
         p->mflop[0] *= (double)kb / (double)KK;
      printf("   nb=%d, kb=%d,  mu=%d, nu=%d, MFLOP=%.2f\n", 
             nb, kb, mu, nu, p->mflop[0]);
      if (gmmb)
      {
         mp->next = p;
         mp = p;
      }
      else
         gmmb = mp = p;
   }
   printf("Done.\n");
/*
 * Now, add the done-list items to generated list
 */
   for (i=0; i < nd; i++)
   {
      const int i4=4*i, mu=dl[i4], nu=dl[i4+1], kmaj=dl[i4+2], nb=dl[i4+3];
      ATL_mmnode_t *prev=NULL;
/*
 *    Get a copy of done-list kern that can be added to genlist
 */
      np = CloneMMNode(dlmm[i]);
      np->next = gmmb;
      gmmb = np;
   }
   if (dlmm)
      free(dlmm);
/*
 * Now, search index file for suitable user-submitted kernels to compete
 * with existing solutions
 */
   ub = ReadMMFileWithPath(pre, "AMMCASES", "amcases.idx");
   ummb = NULL;  /* no suitable user cases to begin */
/*
 * Look through user-list for any routine with ku=1 and K-Runtime
 */
   for (mp=ub; mp; mp = mp->next)
   {
      int km = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
      if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME) && 
          (mp->ku == 1 || km == mp->ku))
      {
/*
 *       It matched our gross criteria, see if it is a required mu/nu
 */
         for (i=0; i < nn; i++)
         {
            const int i4=(i<<2), mu=nl[i4], nu=nl[i4+1], kmaj=nl[i4+2], 
                      nb=nl[i4+3];
            if (mp->mu == mu && mp->nu == nu && km == kmaj)
            {
               if (!FailKCleanTests(pre, nb, mp))
               {
                  ATL_mmnode_t *p;
                  p = CloneMMNode(mp);
                  p->next = NULL;
                  p->nbB = ((nb+nu-1)/nu)*nu;
                  p->mbB = ((nb+mu-1)/mu)*mu;
                  p->kbB = nb;
                  if (ummb)
                  {
                     np->next = p;
                     np = p;
                  }
                  else
                     np = ummb = p;
                  break;
               }
            }
         }
      }
   }
   KillAllMMNodes(ub);
/*
 * If we have both user and genned code, must compare timing to select best
 */
   if (ummb)
   {
/*
 *    Now, loop over user cases and time them for comparison with genned
 */
      printf("Timing User K-cleanup:\n");
      for (mp=ummb; mp; mp = mp->next)
      {
         const int nb = mp->nbB, kb = (nb > 8) ? (nb>>2) : nb;
         const int KK = FLAG_IS_SET(mp->flag,MMF_KVEC) ? 
                   kb:((kb+mp->vlen-1)/mp->vlen)*mp->vlen;
         mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mp->mbB, nb, KK, 0,0,-1);
         if (KK != kb)
            mp->mflop[0] *= (double)kb / (double)KK;
         printf("   ID=%d, nb=%d, kb=%d, mu=%d, nu=%d, MFLOP=%.2f\n", 
                mp->ID, nb, kb, mp->mu, mp->nu, mp->mflop[0]);
      }
      printf("Done timing, merging lists:\n");
/*
 *    Merge generated (gmmb) and user (ummb) kerns by selecting best performing.
 *    gmmb is a superset of ummb, so what we will do is look through gmmb
 *    for matching (mu,nu,dup), time them, and if ummb is faster, replace
 *    that entry in gmmb with ummb.
 */
      while (ummb)
      {
         ATL_mmnode_t *prev=NULL;
         int mu=ummb->mu, nu=ummb->nu;
         int kmaj = FLAG_IS_SET(ummb->flag, MMF_KVEC) ? ummb->vlen:0;

         for (mp=gmmb; mp; mp = mp->next)
         {
            int km = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
            if (mp->mu == mu && mp->nu == nu && km == kmaj)
               break;
            prev = mp;
         }
         assert(mp);  /* logic error if we haven't found it */
/*
 *       If user case gets better performance, replace genned case in queue
 */
         if (ummb->mflop[0] > gmmb->mflop[0])
         {
            printf("   Replacing genned case (%.2f) with user ID %d (%.2f)\n",
                   gmmb->mflop[0], ummb->ID, ummb->mflop[0]);
            if (prev)
            {
               prev->next = ummb;
               ummb = ummb->next;
               prev->next->next = KillMMNode(mp);
            }
            else /* replace gmmb, mp pts at gmmb */
            {
               ATL_mmnode_t *up=ummb;
               ummb = ummb->next;
               up->next = KillMMNode(gmmb);
               gmmb = up;
            }
         }
         else /* user case loser, just delete it */
         {
            printf("   Preferring genned case (%.2f) over user ID %d (%.2f)\n",
                   gmmb->mflop[0], ummb->ID, ummb->mflop[0]);
            ummb = KillMMNode(ummb);
         }
      }
      printf("DONE.\n\n");
   }
   else
      printf("NO VALID USER-SUBMITTED K-CLEANUP KERNELS\n\n");
   free(dl);
@skip   ApplyMoves2Flags(gmmb, MOVES);  /* gen must know operand movement pattern */
   WriteRefreshedMMFileWithPath(pre, "res", "@(kpr)KCLEAN.sum", gmmb);
   return(gmmb);
}

@beginskip
int MMKernsSame(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same except for blocking, 0 otherwise
 */
{
/*
 * Two generated kernels are the same if mu,nu,ku,VLEN,flag are the same.
 * NOTE: if we make generator handle muladd, etc, MUST UPDATE HERE!!!
 */
   if (p0->ID == 0 && p1->ID == 0)
      return(p0->mu == p1->mu && p0->nu == p1->nu && p0->ku == p1->ku &&
             p0->vlen == p1->vlen && p0->flag == p1->flag);
/*
 * If both are user kernels, then they may be repeats.  For user kernels,
 * they are the same if both ID and flag match, else they are not.
 */
   else if (p0->ID > 0 && p1->ID > 0)
      return(p0->ID == p1->ID && p0->flag == p1->flag);
   return(0);  /* Can't be the same if above criteria fails */
}

int MMKernCompsSame(ATL_mmnode_t *p0, ATL_mmnode_t *p1)
/*
 * RETURNS: 1 if kernels are the same except for blocking, 0 otherwise
 */
{
/*
 * Kernels are not the same if one has compile-time K and other runtime
 */
   if (FLAG_IS_SET(p0->flag, MMF_KRUNTIME) != 
       FLAG_IS_SET(p1->flag, MMF_KRUNTIME))
      return(0);
/*
 * Kernels not same if both compilet-time K with differing KB
 */
   if (!FLAG_IS_SET(p0->flag, MMF_KRUNTIME) && p0->kbB != p1->kbB)
      return(0);
   return(MMKernsSame(p0, p1));
}
@endskip

@ROUT ammsearch uammsearch gmmsearch
int KernelIsUnique(ATL_mmnode_t *mmb, ATL_mmnode_t *mmp)
/*
 * Determines if mmp is the first mention of a unique kernel in mmb, or not.
 * For user cases (ID > 0), (ID,flag) together make a unique kernel.
 * For user generated cases, if they match on : mu,nu,ku,VLEN,flag
 *
 * RETURNS: 0 if mmp appears in mmb before mmp, else 1
 */
{
   ATL_mmnode_t *mp;
   if (mmp == mmb)
      return(1);
   for (mp=mmb; mp && mp != mmp; mp = mp->next)
      if (MMKernsPerfSame(mmp, mp))
         return(0);
   return(1);  /* didn't find it, must be first time in list */
}
@ROUT ammsearch uammsearch

@beginskip
int MMKernCompIsPresent(ATL_mmnode_t *mmb, ATL_mmnode_t *mmp)
/*
 * RETURNS: 1 if kernel compilation matching mmp is in list mmb, 0 otherwise
 */
{
   ATL_mmnode_t *mp;
   for (mp=mmb; mp; mp = mp->next)
      if (mp != mmp && MMKernCompsSame(mmp, mp))
         return(1);
   return(0);
}
@endskip

/*
 * Returns a non-repetitive list of user kernels (ID>0) found in rb.  Note that
 * differing compilations of the same kernel are reduced to one entry.
 * rb is left unchanged.
 */
ATL_mmnode_t *GetUniqueUserKerns(ATL_mmnode_t *rb)
{
   ATL_mmnode_t *ub=NULL, *p;

   if (!rb)
      return(NULL);
   for (p=rb; p; p = p->next)
      if (p->ID > 0) 
         break;
   if (!p)
      return(NULL);
   ub = CloneMMNode(p);
   for (p=p->next; p; p = p->next)
   {
       if (p->ID > 0)
       {
          ATL_mmnode_t *np;
          int ID = p->ID;

          for (np=ub; np; np = np->next)
             if (np->ID == ID)
                break;
          if (!np)
          {
             np = CloneMMNode(p);
             np->next = ub;
             ub = np;
          }
       }
   }
   return(ub);
}

static int SelfKClean(ATL_mmnode_t *mp)
{
   if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
   {
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
      {
         if (mp->ku == mp->vlen && mp->kbmin == mp->vlen)
            return(1);
      }
      else if (mp->ku == 1 && mp->kbmin < 2)
         return(1);
   }
   return(0);
}

ATL_mmnode_t *CanKClean(ATL_mmnode_t *krn, ATL_mmnode_t *cln)
/*
 * RETURNS: NULL if cln/krn cannot provide K-cleanup for krn, else ptr
 *          to krn if it can do its own K-cleanup, else ptr to cln
 */
{
/*
 * First, determine if kernel can perform its own cleaning
 */
   if (SelfKClean(krn))
      return(krn);
/*
 * Cleaner must share same mu/nu, have runtime K, and handle long enough K
 */
   if (krn->mu == cln->mu && krn->nu == cln->nu && 
       FLAG_IS_SET(cln->flag, MMF_KRUNTIME) &&
      (!cln->kbmax || cln->kbmax >= krn->kbB))
   {
      int kmaj = FLAG_IS_SET(krn->flag, MMF_KVEC) ? krn->vlen:0;
      int km = FLAG_IS_SET(cln->flag, MMF_KVEC) ? cln->vlen:0;
      if (kmaj > 1)
      {
         if (km == kmaj && cln->kbmin <= kmaj)
            return(cln);
      }
      else if (cln->ku == 1 && cln->kbmin < 2 && km < 2)
         return(cln);
   }
   return(NULL);
}

ATL_mmnode_t *FindKCleaner(ATL_mmnode_t *clnb, ATL_mmnode_t *kp)
/*
 * RETURNS: kp if kp provides its own K cleanup, 
 *          else NULL if no K-cleaner for kp is found in clnb, 
 *          else a ptr to the first such valid K-cleaner found in clnb
 */
{
   ATL_mmnode_t *mp, *cln;
   for (mp=clnb; mp; mp = mp->next)
   {
      ATL_mmnode_t *cln;
      cln = CanKClean(kp, mp);
      if (cln)
         return(cln);
   }
   return(NULL);
}

ATL_mmnode_t *FindAllKCleaners(ATL_mmnode_t *clnb, ATL_mmnode_t *kp)
/*
 * RETURNS: if kp provides its own K-cleaning, then kp is returned.
 *          otherwise a queue cloned nodes of all kernels in clnb that 
 *          could be used to clean kp is return.
 * Cloned nodes have their blocking values set to match kp
 */
{
   ATL_mmnode_t *gdb=NULL, *mp;

   gdb = FindKCleaner(clnb, kp);
   if (gdb == kp)
      return(kp);
   else if (gdb)
   {
      mp = gdb;
      gdb = CloneMMNode(gdb);
      gdb->mbB = kp->mbB;
      gdb->nbB = kp->nbB;
      gdb->kbB = kp->kbB;
      while ((mp = FindKCleaner(mp->next, kp)))
      {
         ATL_mmnode_t *p;
         p = CloneMMNode(mp);
         p->mbB = kp->mbB;
         p->nbB = kp->nbB;
         p->kbB = kp->kbB;
         p->next = gdb;
         gdb = p;
      }
      return(gdb);
   }
   return(NULL);
}

ATL_mmnode_t *FindAllUniqueKClean(int verb, char pre, ATL_mmnode_t *mmb)
/*
 * Finds a way to clean up all kernels in mmb
 * RETURNS: list of all unique kernels required to do K-cleanup
 */
{
   ATL_mmnode_t *clnb, *mkb, *kp;
   if (verb)
      printf("FINDING K CLEANERS FOR ALL KERNELS:\n");
   clnb = ReadMMFileWithPath(pre, "res", "k1AMM.sum");
   if (clnb)
   {
      MMFillInGenStrings(pre, clnb);
      TimeNegMMKernels(0, verb, 0, clnb, pre, 1, 0, -1);
      WriteRefreshedMMFileWithPath(pre, "res", "k1AMM.sum", clnb);
      return(clnb);
   }
/*
 * mkb is the list of all candidate cleanup codes
 */
   mkb = GetWorkingUserCases(verb, pre);
   for (kp=mmb; kp; kp = kp->next)
   {
      ATL_mmnode_t *cp;
      if (FindKCleaner(clnb, kp))  /* if we've already got a K-cleaner */
         continue;                 /* for this case, skip! */
      cp = FindAllKCleaners(mkb, kp);
      if (cp)
         printf("   %s --> %s!\n", kp->rout, cp->rout);
      else
         printf("   %s --> no Kclean!\n", kp->rout);
/*
 *    For kernels that serve as their own K-cleanup, just use them wt no need
 *    to time anything else
 */
      if (cp == kp)
      {
         cp = CloneMMNode(kp);
         cp->next = clnb;
         clnb = cp;
      }
/*
 *    For kernels that must be cleaned by other kernels, we must time all
 *    candidate kernels and use the best!
 */
      else
      {
         ATL_mmnode_t *mp;
         const int mb=kp->mbB, nb=kp->nbB, kb=kp->kbB;
         int ntim;
/*
 *       Add generated case to any user cases that work
 */
         mp = GetNewKCleanGenNode(pre, kp, mb, nb, kb);
         if (!CanKClean(kp, mp))
         {
            int kmaj = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen:0;
            int km = FLAG_IS_SET(kp->flag, MMF_KVEC) ? kp->vlen:0;
            fprintf(stderr, "KU=(%d,%d,%d), KV=%d, MU=(%d,%d,%d), MV=%d\n",
                    kp->mu, kp->nu, kp->ku, km,
                    mp->mu, mp->nu, mp->ku, kmaj);
            assert(CanKClean(kp,mp));
         }
         mp->next = cp;
         cp = mp;
         ntim = ATL_CountNumberOfMMNodes(cp);
         if (ntim > 1)
         {
/*
 *          Now time all kernels, and choose the fastest for cleanup.
 *          We'll use kbB as kb, even though this is larger than the code
 *          will ever be used for.  However, it will allow us to directly
 *          compare kernel and cleanup performance.
 *          A better strategy would be to time many different K cases, but
 *          I don't want to spend that amount of install time tuning and timing
 *          low-order cleanup!
 */
            printf("   CHOOSING BETWEEN %d KB=%d K-CLEANERS WITH TIMINGS:\n", 
                   ntim, kb);
            for (mp=cp; mp; mp = mp->next)
            {
               double mf;
               if (mp->mbB != mb || mp->nbB != nb || mp->kbB != kb || 
                   mp->mflop[0] <= 0.0)
               {
                  mp->mbB = mb;
                  mp->nbB = nb;
                  mp->kbB = kb;
                  mf = TimeMMKernel(0, 1, mp, pre, mb, nb, kb, 0, 0, -1);
                  mp->mflop[0] = mf;
               }
               else
                  mf = mp->mflop[0];
               printf("      %d-%s: %.2f\n", mp->ID, mp->rout?mp->rout:"", mf);
            }
            mp = FindMaxMflopMMQ(cp, 0);
            printf("   USING %d-%s\n", mp->ID, mp->rout? mp->rout:"");
            cp = RemoveMMNodeFromQ(cp, mp);
            KillAllMMNodes(cp);
         }
         else
         {
            mp = cp;
            mp->mbB = mb;
            mp->nbB = nb;
            mp->kbB = kb;
         }
         mp->next = clnb;
         clnb = mp;
      }
   }
   KillAllMMNodes(mkb);
   if (verb)
      printf("DONE FINDING FULL LIST OF K-CLEANERS\n");
   WriteRefreshedMMFileWithPath(pre, "res", "k1AMM.sum", clnb);
   return(clnb);
}

ATL_mmnode_t *FindMUNU(ATL_mmnode_t *mb, int mu, int nu)
{
   ATL_mmnode_t *mp;
   for (mp=mb; mp; mp = mp->next)
      if (mp->mu == mu && mp->nu == nu)
         return(mp);
   return(NULL);
}

ATL_mmnode_t *KCleanByNB
(
   int verb, 
   char pre, 
   ATL_mmnode_t *mmb, /* final kernels giving final supported NBs */
   ATL_mmnode_t *mkb  /* All necessary routs ku=1 to clean all kerns in mmb */
)
/*
 * Replicates mkb so that it includes all NBs in mmb, times K-clean,
 * **FREES** mkb, and returns by-NB list
 *
 * OUTPUT:
 *   <pre>@(kpr)KCLEANBYNB.sum: non-unique K-clean for each NB in mmb
 *      mflop[1] contains estimated time for 1 K-it using K=MAX(kb/4,4)
 */
{
   ATL_mmnode_t *nkb=NULL, *mp, *np;
   int kb;
   double mf;

@ROUT ammsearch
   nkb = ReadMMFileWithPath(pre, "res", "@(kpr)KCLEANBYNB.sum");
   if (nkb)
   {
      KillAllMMNodes(mkb);
      printf("READING IN BY-NB K-CLEANUP:\n");
      MMFillInGenStrings(pre, nkb);
      for (mp=nkb; mp; mp = mp->next)
      {
         int mb=mp->mbB, nb=mp->nbB;
         kb = mp->kbB >> 2;
         kb = (kb >= 4) ? kb : 4;
         if (mp->mflop[0] < 0.0)
            mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mb, nb, kb, 0, 0, -1);
         mf = (2.0*nb)*nb;  /* flop count of gemm/kits (kb) */
         mp->mflop[1] = mf / mp->mflop[0]; /* time in microsecs for 1 k-it */
         printf("   nb=%d, kb=%d, mu=%d, nu=%d, mf=%.2f (%e Usec/Kit)\n", 
                nb, kb, mp->mu, mp->nu, mp->mflop[0], mp->mflop[1]);
      }
      printf("Done.\n");
      WriteRefreshedMMFileWithPath(pre, "res", "@(kpr)KCLEANBYNB.sum", nkb);
      return(nkb);
   }
@ROUT ammsearch uammsearch
   printf("TIMING K-CLEAN FOR ALL SUPPORTED NBs:\n");
   for (mp=mmb; mp; mp = mp->next)
   {
      ATL_mmnode_t *p;
      int mb = mp->mbB, nb = mp->nbB, kb;

      kb = mp->kbB >> 2;
      kb = (kb >= 4) ? kb : 4;
      if (FLAG_IS_SET(mp->flag,MMF_KVEC))
         kb = ((kb+mp->vlen-1)/mp->vlen)*mp->vlen;

      p = FindMUNU(mkb, mp->mu, mp->nu);
/*
 *    If no user cleanup exists, generate one
 */
      if (!p)
      {
         if (FLAG_IS_SET(mp->flag, MMF_KVEC))
            p = MMGetNodeGEN(pre, 0, 0, mp->mu, mp->nu, mp->vlen, mp->vlen, 
                             1, 0, 0, NULL);
         else
            p = MMGetNodeGEN(pre, 0, 0, mp->mu, mp->nu, 1, mp->vlen, 
                             0, 0, 0, NULL);
      }
      else
      {
         p = CloneMMNode(p);
         p->next = NULL;
      }
      p->nbB = nb; p->mbB = mb;  p->kbB = kb;
      p->mflop[0] = TimeMMKernel(verb, 0, p, pre, mb, nb, kb, 0, 0, -1);
      mf = mb*nb;
      p->mflop[1] = mf / p->mflop[0];   /* time in microseconds for 1 k it */
      printf("   mb=%d, nb=%d, kb=%d, mu=%d, nu=%d, mf=%.2f (%e Usec/Kit)\n", 
             mb, nb, kb, p->mu, p->nu, p->mflop[0], mf);
      if (nkb)
      {
         np->next = p;
         np = p;
      }
      else
         nkb = np = p;
   }
   printf("DONE.\n\n");
   KillAllMMNodes(mkb);
   WriteRefreshedMMFileWithPath(pre, "res", "@(kpr)KCLEANBYNB.sum", nkb);
   return(nkb);
}

void TimeKClean(int verb, char pre, ATL_mmnode_t *mp)
/*
 *   mp is the ku=1, KRUNTIME K-cleanup kernel for a support NB.
 *   This routine creates an output file for supported the NB, where we
 *   document the performance for all NB different KB values.  These
 *   timings can therefore precisely document how expensive K-cleanup
 *   will be for each NB.  
 *   OUTPUT:
 *   <pre>@(kpr)KCLEAN_<nb>.TIM: timing of K-clean for nb=<nb>; there are
 *   i=nb-1 timings, mflop[0] contains time to do NB-i K its.  Will use
 *   these times to get completely accurate estimate of total time for
 *   large problems (use estimated time in CLBYNB for small probs).
 */
{
   ATL_mmnode_t *mmb, *p, *np;
   char fn[32];
   int mb = mp->mbB, nb = mp->nbB, i;

   sprintf(fn, "@(kpr)KCLEAN_%d.TIM", mp->nbB);
   mmb = ReadMMFileWithPath(pre, "res", fn);
   if (mmb)
   {
      printf("READING IN K-CLEANUP TIMINGS FOR NB=%d:\n", nb);
      MMFillInGenStrings(pre, mmb);
      for (p=mmb; p; p = p->next)
      {
         int kb = p->kbB;
         assert(nb == p->nbB && mb == p->mbB);
         if (p->mflop < 0)
            p->mflop[0] = TimeMMKernel(verb, 0, p, pre, mb, nb, kb, 0, 0, -1);
         printf("   MB=%d, NB=%d, KB=%d, mu=%d, nu=%d, MFLOP=%.2f\n", 
                mb, nb, kb, p->mu, p->nu, p->mflop[0]);
      }
      printf("Done.\n\n");
      WriteRefreshedMMFileWithPath(pre, "res", fn, mmb);
      KillAllMMNodes(mmb);
      return;
   }
   
   printf("TIMING K-CLEANUP FOR MB=%d, NB=%d:\n", mb, nb);
   for (i=1; i <= nb; i++)  /* create queue of ascending KB */
   {
      p = CloneMMNode(mp);
      p->next = NULL;
      p->kbB = i;
      p->mflop[0] = TimeMMKernel(verb, 0, p, pre, mb, nb, i, 0, 0, -1);
      printf("   MB=%d, NB=%d, KB=%d, mu=%d, nu=%d, MFLOP=%.2f\n", mb, nb, i, 
             p->mu, p->nu, p->mflop[0]);
      if (mmb)
      {
         np->next = p;
         np = p;
      }
      else
         mmb = np = p;
   }
   WriteRefreshedMMFileWithPath(pre, "res", fn, mmb);
   KillAllMMNodes(mmb);
   printf("Done.\n");
}

/*
 * Specialize the K cleanup routs in mkb to the kernels in mmb by changing
 * their block factors, and timing them.
 */
ATL_mmnode_t *SpecializeKClean
   (int verb, char pre, ATL_mmnode_t *mmb, ATL_mmnode_t *mkb)
{
   ATL_mmnode_t *mp, *b=NULL;
   for (mp=mmb; mp; mp = mp->next)
   {
      ATL_mmnode_t *kp;
      if (SelfKClean(mp))
      {
         kp = CloneMMNode(mp);
         kp->mflop[2] = 1.0;
      }
      else
      {
         const int mb=mp->mbB, nb=mp->nbB, kb=mp->kbB;
         kp = FindKCleaner(mkb, mp);
         if (!kp)
            fprintf(stderr, "UR(%d,%d,%d), %s: NO KCLEAN", 
                    mp->mu, mp->nu, mp->ku, mp->rout);
         assert(kp);
         kp = CloneMMNode(kp);
         if (kp->mbB != mb || kp->nbB != nb || kp->kbB != kb || 
             kp->mflop[0] <= 0.0)
         {
            kp->mbB = mb;
            kp->nbB = nb;
            kp->kbB = kb;
            kp->mflop[0] = TimeMMKernel(verb, 0, kp, pre, mb, nb, kb, 0, 0, -1);
            kp->mflop[2] = kp->mflop[0] / mp->mflop[0];
         }
      }
      printf("   KB=%d KCLEAN SPEEDUP: %.4f\n", kp->kbB, kp->mflop[2]);
      kp->next = b;
      b = kp;
   }
   return(b);
}
@ROUT uammsearch
void ComputeKClean(int verb, char pre, ATL_mmnode_t *mmb)
{
}
@ROUT ammsearch
void ComputeKClean(int verb, char pre)
/*
 * This kernel finds K-cleanup for all routines present in <pre>geAMMRES.sum
 * and <pre>sqAMMRES.sum.
 *
 * OUTPUT: <pre>@(kpr)KCLEAN.sum: all unique kerns to be compiled
 *         <pre>geAMMKCLEAN.sum:  MFLOP[2] = cleanup slowdown
 *         <pre>sqAMMKCLEAN.sum: MFLOP[2] = cleanup slowdown
@beginskip
 *   i=nb-1 timings, mflop[0] contains time to do NB-i K its.  Will use
 *   these times to get completely accurate estimate of total time for
 *   large problems (use estimated time in CLBYNB for small probs).
@endskip
 * 
 * NOTE: we will time K-cleanup kernels only in BETA=0 case, and peel
 *    the first K-block rather than the last.  This will minimize the C cost,
 *    which is more appreciable for short-K.  We will actually generate all
 *    beta cases, since sometimes you need other betas (in complex, or if
 *    you can't peel first partial for some reason).
 */
{
   ATL_mmnode_t *mkb, *mmGE, *mmSQ, *mp, *mmGEk=NULL, *mmSQk=NULL;
   mmGEk = TimeMMFileWithPath(pre, "res", "geAMMKCLEAN.sum", 
                              0, verb, 0, 0, 0, -1);
   mmSQk = TimeMMFileWithPath(pre, "res", "sqAMMKCLEAN.sum", 
                              0, verb, 0, 0, 0, -1);
   if (mmGEk && mmSQk)
   {
      KillAllMMNodes(mmGEk);
      KillAllMMNodes(mmSQk);
      return;
   }
   if (mmGEk)
      KillAllMMNodes(mmGEk);
   if (mmSQk)
      KillAllMMNodes(mmSQk);
   mmGEk = mmSQk = NULL;
@skip   if (verb)
@skip      printf("FINDING K-CLEANUP FOR EACH KB:");
/*
 * Will use only one K-cleanup for any (mu,nu,kmaj) combo.  Will decide between
 * competing kernels based on timings, with larger KB more important, so we
 * reverse the list order so that the larger block factors choose cleanup for
 * smaller, rather than reverse.
 */
   mmGE = ReverseMMQ(ReadMMFileWithPath(pre, "res", "geAMMRES.sum"));
   mmSQ = ReverseMMQ(ReadMMFileWithPath(pre, "res", "sqAMMRES.sum"));
   assert(mmGE && mmSQ);
/*
 * Now temporarily join rect & square lists into one, and get a list of
 * all cleanup routines that are required.  Routines that provide their
 * own cleanup will always be used regardless of what is in the list,
 * and the first such kernel will appear in mkb
 */
   for (mp=mmGE; mp->next; mp = mp->next);
   mp->next = mmSQ;
   mkb = FindAllUniqueKClean(verb, pre, mmGE);
   mp->next = NULL;  /* go back to separate lists */
/*
 * Use reversed lists to build lists of cleanup, which will be in correct
 * order due to the way we build them
 */
   if (verb)
      printf("SPECIALIZING K-CLEANERS FOR RECTANGULAR BLOCKINGS:\n");
   mmGEk = SpecializeKClean(verb, pre, mmGE, mkb);
   if (verb)
      printf("DONE SPECIALIZING K-CLEANERS FOR RECTANGULAR BLOCKINGS.\n");
   KillAllMMNodes(mmGE);
   WriteRefreshedMMFileWithPath(pre, "res", "geAMMKCLEAN.sum", mmGEk);
   KillAllMMNodes(mmGEk);
/*
 * Now do same for square kernels
 */
   if (verb)
      printf("SPECIALIZING K-CLEANERS FOR SQUARE BLOCKINGS:\n");
   mmSQk = SpecializeKClean(verb, pre, mmSQ, mkb);
   if (verb)
      printf("DONE SPECIALIZING K-CLEANERS FOR SQUARE BLOCKINGS.\n");
   KillAllMMNodes(mmSQ);
   WriteRefreshedMMFileWithPath(pre, "res", "sqAMMKCLEAN.sum", mmSQk);
   KillAllMMNodes(mmSQk);
   if (verb)
      printf("\nDONE FINDING K-CLEANUP FOR EACH KB.\n");
}
@ROUT ammsearch uammsearch

void FindBestKU1
(
   int verb, 
   char pre,   
   int K       /* K dim, should be small, probably like 23 or 17 */
)
/* 
 * Find the best possible kernel for use in low-rank update;  We only consider
 * kernels with runtime-K that handle all possible K (ku=1).  We will try
 * all legal blocking factors between 16 & 480 for this kernel, and choose
 * the one that performs best.  This kernel always used for any K not covered
 * by optimized kernels given in eAMMRES kbBs.  When we match a kbB, we
 * compare the perf of this kernel at its optimal nbB/mbB wt that of the
 * specialized kernel, and choose the best.
 *
 * OUTPUT: This routine outputs two files:
 * (1) AMMRANKK: best ku=1 kern wt best MB/NB, K=K
 * (2) AMMRANKKT: timing of this kern wt M=mbB, N=nbB, all K between 1 & maxNB
 */
{
}

@ROUT ammsearch uammsearch gmmsearch
double CacheRatio_all3pAB(size_t CS, size_t mb, size_t nb, size_t kb, 
                          size_t mu, size_t nu)
{ /* RETURNS: ratio of util cache A,B,C + next A & B */
   double dret = 2.0*kb*(mb+nb)+mb*nb;
   return(dret/CS);
}
double CacheRatio_all3pA(size_t CS, size_t mb, size_t nb, size_t kb, 
                         size_t mu, size_t nu)
{ /* RETURNS: ratio of utilized cache to keep all 3 mm ops + next A in CS */
   double dret = kb*(mb+mb+nb)+mb*nb;
   return(dret/CS);
}
double CacheRatio_all3pB(size_t CS, size_t mb, size_t nb, size_t kb, 
                         size_t mu, size_t nu)
{ /* RETURNS: ratio of utilized cache to keep all 3 mm ops + next A in CS */
   double dret = kb*(mb+nb+nb)+mb*nb;
   return(dret/CS);
}

double CacheRatio_all3(size_t CS, size_t mb, size_t nb, size_t kb, 
                       size_t mu, size_t nu)
{ /* RETURNS: ratio of utilized cache to keep all 3 mm ops in CS */
   double dret = 1.0*kb*(mb+nb)+mb*nb;
   return(dret/CS);
}

double CacheRatio_one(size_t CS, size_t mb, size_t nb, size_t kb, 
                      size_t mu, size_t nu)
{ /* RETURNS: ratio of util cache for B + working set of A/C */
   double dret = kb*nb + 2.0*(mu*kb + mu*nu);
   return(dret/CS);
}

double CacheRatio_ws(size_t CS, size_t mb, size_t nb, size_t kb, 
                     size_t mu, size_t nu)
{ /* RETURNS: ratio of working set of all matmul ops to CS */
   double dret = 2.0*(mu*nu + nu*kb) + mu*kb;
   return(dret/CS);
}

typedef void (*BudgetFunc_t)(double, size_t, size_t, size_t, size_t, 
                             size_t*, size_t*, size_t*);

#define MAXNB 360
void GetBlkFromBudget_allP(char extra, double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   double (*cacheRatio)(size_t,size_t,size_t,size_t,size_t,size_t);
   size_t mb=mu, nb=nu, kb=ku;
   int MGROW, NGROW, KGROW;

   if (extra == 'A')
      cacheRatio = CacheRatio_all3pA;
   else if (extra == 'B')
      cacheRatio = CacheRatio_all3pB;
   else if (extra == '2')
      cacheRatio = CacheRatio_all3pAB;
   else  /* nothing extra */
      cacheRatio = CacheRatio_all3;
   do
   {
      size_t mn=mb+mu, nn=nb+nu, kn=kb+ku;
      MGROW = mn < MAXNB && (cacheRatio(CS, mn, nb, kb, mu, nu) <= thresh);
      NGROW = nn < MAXNB && (cacheRatio(CS, mb, nn, kb, mu, nu) <= thresh);
      KGROW = kn < MAXNB && (cacheRatio(CS, mb, nb, kn, mu, nu) <= thresh);
      if (KGROW && ((!MGROW && !NGROW) || (kn <= nn && kn <= mn)))
         kb = kn;
      else if (MGROW && (!NGROW || mb < nb))
         mb = mn;
      else if (NGROW)
         nb = nn;
   }
   while (MGROW | NGROW | KGROW);
   *MB = mb;
   *NB = nb;
   *KB = kb;
}

void GetBlkFromBudget_all3pA(double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   GetBlkFromBudget_allP('A', thresh, CS, mu, nu, ku, MB, NB, KB);
}
void GetBlkFromBudget_all3pB(double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   GetBlkFromBudget_allP('B', thresh, CS, mu, nu, ku, MB, NB, KB);
}
void GetBlkFromBudget_all3pAB(double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   GetBlkFromBudget_allP('2', thresh, CS, mu, nu, ku, MB, NB, KB);
}
void GetBlkFromBudget_all3(double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   GetBlkFromBudget_allP('N', thresh, CS, mu, nu, ku, MB, NB, KB);
}

void GetBlkFromBudget_one(double thresh, size_t CS, 
                           size_t mu, size_t nu, size_t ku,
                           size_t *MB, size_t *NB, size_t *KB)
{
   size_t mb=mu, nb=nu, kb=ku;
   int NGROW, KGROW;
   do
   {
      size_t nn=nb+nu, mn=(nn/mu)*mu, mn1 = ((nn+mu-1)/mu)*mu, kn=kb+ku;
      if (mn1 - nn <= nn - mn || !mn)
         mn = mn1;
      NGROW = nn < MAXNB && (CacheRatio_one(CS, mn, nn, kb, mu, nu) <= thresh);
      KGROW = kn < MAXNB && (CacheRatio_one(CS, mb, nb, kn, mu, nu) <= thresh);
      if (NGROW && ((nn < kn && mn < kn) || !KGROW))
      {
         nb = nn;
         mb = mn;
      }
      else if (KGROW)
         kb = kn;
   }
   while (NGROW | KGROW);
   *MB = mb;
   *NB = nb;
   *KB = kb;
}

void GetBlkFromBudget_ws(double thresh, size_t CS, 
                          size_t mu, size_t nu, size_t ku,
                          size_t *MB, size_t *NB, size_t *KB)
{
   size_t mb=mu, nb=nu, kb=ku;
   int KGROW;
   do
   {
      size_t kn=kb+ku, mn=(kn > mu)?(kn/mu)*mu:mu, nn=(kn>nu)?(kn/nu)*nu:nu;
      KGROW = kn < MAXNB && (CacheRatio_ws(CS, mn, nn, kn, mu, nu) <= thresh);
      if (KGROW)
      {
         mb = mn;
         nb = mn;
         kb = kn;
      }
   }
   while (KGROW);
   *MB = mb;
   *NB = nb;
   *KB = kb;
}

int Blk2Case(size_t CS, int mb, int nb, int kb, int mu, int nu)
{
   size_t sz3 = mb*nb + kb*(mb+nb);
   if (CacheRatio_all3pAB(CS, mb, nb, kb, mu, nu) < 1.0)
      return(4);
   else if (CacheRatio_all3pA(CS, mb, nb, kb, mu, nu) < 1.0 &&
            CacheRatio_all3pB(CS, mb, nb, kb, mu, nu) < 1.0)
      return(3);
   else if (CacheRatio_all3(CS, mb, nb, kb, mu, nu) < 1.0)
      return(0);
   else if (CacheRatio_one(CS, mb, nb, kb, mu, nu) < 1.0)
      return(1);
   return(2);
}
ATL_mmnode_t *FindBestCacheBudgetCase
(
   int verb,
   char pre, 
   BudgetFunc_t GetBlocking,     /* func ptr to budget function */
   double thresh,                /* max ratio of cache to fill */
   size_t CS,                    /* size of cache we are optimizing for */
   int imf,                      /* entry in mflop[] to use */
   ATL_mmnode_t *mmb             /* list of cases to try */
)
/*
 * RETURNS: clone of best-peforming kernel in mmb for kb=kb, mb & nb 
 *          near-square and within budget
 */
{
   ATL_mmnode_t *mmB=NULL, *mp, *p;
   double mf, mfB=0.0;

   printf("Finding best case for cache budget case=%d, CS=%.0f elts\n",
          imf, CS*thresh);
   for (mp=mmb; mp; mp = mp->next)
   {
      size_t mb, nb, kb, ku=mp->ku;
      if (!mp->ID && FLAG_IS_SET(mp->flag, MMF_KUISKB))
         ku = FLAG_IS_SET(mp->flag, MMF_KVEC) ? mp->vlen : 1;

      GetBlocking(thresh, CS, mp->mu, mp->nu, ku, &mb, &nb, &kb);
      p = CloneMMNode(mp);  /* can't use mp, since may switch KRUNTIME */
      mf = TimeMMKernel_KB(verb, 0, p, pre, mb, nb, kb, 1, 0, -1);
@ROUT gmmsearch
      printf("   RT='%s' B=(%d,%d,%d), MFLOP=%.2f\n", p->rout,
             (int)mb, (int)nb, (int)kb, mf);
@ROUT ammsearch uammsearch
      printf("   ID=%d, mb=%d, nb=%d, kb=%d, RTK=%d, MFLOP=%.2f\n", p->ID,
             (int)mb, (int)nb, (int)kb, FLAG_IS_SET(p->flag, MMF_KRUNTIME), mf);
@ROUT ammsearch uammsearch gmmsearch
      if (mf > mfB)
      {
         if (mmB)
            KillMMNode(mmB);
         p->mbB = mb;
         p->nbB = nb;
         p->kbB = kb;
         mmB = p;
         mfB = mmB->mflop[imf] = mf;
      }
      else
         KillMMNode(p);
   }
   printf("BEST CASE %s: mb=%d, nb=%d, kb=%d, RTK=%d, MFLOP=%.2f\n\n",
          mmB->rout ? mmB->rout : "GENNED",
          mmB->mbB, mmB->nbB, mmB->kbB, FLAG_IS_SET(mmB->flag, MMF_KRUNTIME), 
          mmB->mflop[imf]);
   mmB->next = NULL;
   return(mmB);
}

ATL_mmnode_t *FindBestCacheBudgetCases
(
   int verb,
   char pre, 
   size_t CS,                    /* size of cache we are optimizing for */
   ATL_mmnode_t *mmb             /* list of cases to try */
)
/*
 * This case attempts to find the best kernel for 3-5 cases of interest:
 * (1) All 3 matrices fit in CS -- this case is designed for when we wish
 *     to reuse at least one of the matrices *across* mmkern calls.  It is
 *     particularly good for complex arithmetic, or when CS is large enough
 *     that A&B are reused so much internally to a mmkern call that it makes
 *     sense to retain C in cache for the next mmkern call in K-loop.
 * (2) All of B fits in CS, and so does the working set of A&C.  This one
 *     reuses all internal ops from L1, but won't allow any full op reuse
 *     across multiple GEMM calls.  Usually best for small-to-medium cache
 *     sizes.
 * (3) All of working set of A/B/C fit in cache.  This case provides maximal
 *     NB, where only the mu*KB panel of A is reused from the L1 internally
 *     to the algorthm.  It is essentially an L2-blocked algorithm internally,
 *     but can be useful on those archs where the best sustained bandwidth
 *     comes from one L1 load (A) and 1 L2 load (B).
 * If 3 blocks fit with smallest dim > 16, then also add:
 * (4) All 3 blocks fit in cache, with room for the next A or B.
 * If this fits in cache with smallest dim > 16, then add:
 * (5) All 3 blocks fit in cache, with room for the next A and B.
 */
{
   ATL_mmnode_t *mm3, *mm1, *mmw;
   mm3 = FindBestCacheBudgetCase(verb, pre, GetBlkFromBudget_all3, 1.0, 
                                 CS, 1, mmb);
   mm1 = FindBestCacheBudgetCase(verb, pre, GetBlkFromBudget_one, 1.0, 
                                 CS, 2, mmb);
   mmw = FindBestCacheBudgetCase(verb, pre, GetBlkFromBudget_ws, .90, 
                                 CS, 3, mmb);
   mm3->next = mm1;
   mm1->next = mmw;
   mmw->next = NULL;

/*
 * If cache large enough, try fitting 4 & 5 blocks in it
 */
   if (mm3->mbB > 16 && mm3->nbB > 16 && mm3->kbB > 16)
   {
      ATL_mmnode_t *mp;
      mp = FindBestCacheBudgetCase(verb, pre, (mm3->mbB > mm3->nbB) ?
              GetBlkFromBudget_all3pA:GetBlkFromBudget_all3pB,
              0.95, CS, 4, mmb);
      mmw->next = mp;
      if (mp->mbB > 16 && mp->nbB > 16 && mp->kbB > 16)
      {
         ATL_mmnode_t *mm5;
         mm5 = FindBestCacheBudgetCase(verb, pre, GetBlkFromBudget_all3pAB,
                                       0.95, CS, 5, mmb);
         mp->next = mm5;
      }
   }
   {
      int i;
      ATL_mmnode_t *mp;
      char *exp[5] = {"3BLKS", "1BLKS", "0BLKS", "4BLKS", "5BLKS"};

      for (i=0, mp=mm3; mp; i++, mp=mp->next)
@ROUT gmmsearch
         printf("%s: RT='%s' B=(%d,%d,%d), RK=%d MFLOP=%.2f\n", 
                exp[i], mp->rout, mp->mbB, mp->nbB, mp->kbB, 
                FLAG_IS_SET(mp->flag, MMF_KRUNTIME), mp->mflop[i+1]);
@ROUT ammsearch uammsearch
         printf("%s: ID=%d, RT='%s' B=(%d,%d,%d), RK=%d MFLOP=%.2f\n", 
                exp[i], mp->ID, mp->rout, mp->mbB, mp->nbB, mp->kbB, 
                FLAG_IS_SET(mp->flag, MMF_KRUNTIME), mp->mflop[i+1]);
@ROUT ammsearch uammsearch gmmsearch
      printf("\n");
   }
   return(mm3);
}
@ROUT ammsearch uammsearch
ATL_mmnode_t *TimeKBRegion
(
   int verb,
   char pre, 
   ATL_mmnode_t *mmk,            /* kernel to time throughout region */
   int kbmin,                    /* start of region */
   int kbend,                    /* largest kb in region */
   int kincD                     /* default stride between kernel timings */
)
/*
 * Returns list of timings of kernel mmk using near-square cases with KB
 * varying between kbmin - kbend.  All cases that are legal and incremented
 * by kinc are tried, as are all perfectly square cases
 */
{
   ATL_mmnode_t *mmb=NULL, *mp, *mpB=NULL;
   const int ku = mmk->ku, mu=mmk->mu, nu=mmk->nu;
   int kstart, kinc, kend, k, ksq, ksqinc;
   double mf, mfB=0.0;
/*
 * Get starting and ending point that is legal for this kernel.
 */
   kstart = Mmax(mmk->kbmin, kbmin);
   kstart = ((kstart+ku-1)/ku)*ku;
   kend = ((kbend+ku-1)/ku)*ku;
   if (mmk->kbmax)
      kend = Mmin(kend, mmk->kbmax);
   k = kstart;
/*
 * square inc always lcm(mu,nu,ku).  Normal increment is always at least
 * as big as the default stride, but must be a multiple of the kernel's ku
 */
   ksqinc = Mylcm(mu, nu);
   ksqinc = Mylcm(ksqinc, ku);
   for (kinc=ku; kinc < kincD; kinc += ku);
   if (kstart <= kend)
   {
      int kb = k;
      printf("TIMING %s mu=%d, mu=%d, For KB=[%d,%d]:\n", 
             mmk->rout ? mmk->rout : "Genkern", mu, nu, kstart, kend);
      ksq = ((kstart+ksqinc-1)/ksqinc)*ksqinc;
      do
      {
         ATL_mmnode_t *p;
         const int mb=((kb+mu-1)/mu)*mu, nb=((kb+nu-1)/nu)*nu;

         p = CloneMMNode(mmk);
         mf = TimeMMKernel_KB(verb, 0, p, pre, mb, nb, kb, 1, 0, -1);
         printf("   mb=%d, nb=%d, kb=%d, KRUN=%d, MFLOP=%.2f\n",
                mb, nb, kb, FLAG_IS_SET(p->flag, MMF_KRUNTIME), mf);
         p->mflop[0] = mf;
         if (mf > mfB)
         {
            mfB = mf;
            mpB = p;
         }
         if (mmb)
         {
            mp->next = p;
            mp = p;
         }
         else
            mmb = mp = p;
         if (kb == ksq)
            ksq += ksqinc;
         if (kb == k)
            k += kinc;
         kb = Mmin(k,ksq);
      }
      while(kb <= kend);
      printf("DONE, best case %s mb=%d, nb=%d, kb=%d, MFLOP=%.2f\n\n", 
             mmk->rout ? mmk->rout : "Genkern",
             mpB->mbB, mpB->nbB, mpB->kbB, mfB);
   }
   else
   {
      printf("KERNEL %s mu=%d, mu=%d, has no legal cases in KB=[%d,%d]!\n\n", 
             mmk->rout ? mmk->rout : "Genkern", mu, nu, kstart, kend);
   }
   return(mmb);
}

ATL_mmnode_t *TimeAllKBRegions
(
   int verb,
   char pre, 
   ATL_mmnode_t *mmk,            /* kernel to time throughout regions */
   int kb                        /* maxKB to ever try */
)
/*
 * Times mmk for KBs up to kb
 */
{
   const int ku = mmk->ku;
   ATL_mmnode_t *mmb, *mp;

   mmb = TimeKBRegion(verb, pre, mmk, 24, kb, 4);
   return(mmb);
}

ATL_mmnode_t *FindCacheBudgetCasesByKB
(
   int verb,
   char pre, 
   size_t CS,                    /* size of cache we are optimizing for */
   ATL_mmnode_t *mmb             /* list of cases to try */
)
/* 
 * This routine is responsible for:
 * (1) Find the best performing kernels out of mmb for our 3-5 cache budget
 *     cases
 * (2) Free mmb
 * (3) For each unique kernel, find perf of kernel for all supported KBs 
 *     in the budgetary regions
 * (4) Merge these lists, and winnow underperforming cases
 * (5) RETURN: queue of all supported KBs
 */
{
   ATL_mmnode_t *mm3b, *mp;
   const char upr = (pre == 'z' || pre == 'd') ? 'd' : 's';
/*
 * We want number of real elts, not # of cplx elts!
 */
   if (pre == 'c' || pre == 'z')
      CS += CS;
/*
 * See if we just need to rerun cases
 */
   mm3b = ReadMMFileWithPath(pre, "res", "bAMMRES.sum");
   if (mm3b)
   {
      int i=0, WRT=0;
      printf("READING IN LARGE KERNEL CASES FROM res/<pre>bAMMRES:\n");
      MMFillInGenStrings(pre, mm3b);
      for (mp=mm3b; mp; mp = mp->next)
      {
         if (mp->mflop[0] <= 0.0)
         {
            mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB, 
                                        mp->kbB, 1, 0, -1);
            WRT=1;
         }
         printf("   ID=%d, %s: MB=%d, NB=%d, KB=%d, KRUN=%d, MFLOP=%.2f\n",
                mp->ID, mp->rout ? mp->rout : "Gennedkern",
                mp->mbB, mp->nbB, mp->kbB, FLAG_IS_SET(mp->flag, MMF_KRUNTIME),
                mp->mflop[0]);
         i++;
      }
      if (WRT)
         WriteRefreshedMMFileWithPath(pre, "res", "bAMMRES.sum", mm3b);
      printf("DONE %d CASES.\n\n", i);
      return(mm3b);
   }
/*
 * Find best performing kernels for each of our 3-5 cache budgets
 */
@skip   mm3b = FindBestCacheBudgetCases(verb, pre, CS, mmb);
@skip   KillAllMMNodes(mmb);
   mm3b = mmb;
/*
 * Get list of performance of all-3-5 in-cache kernel in all 3-5 cache regions
 */
   mmb = TimeAllKBRegions(verb, pre, mm3b, mm3b->next->next->kbB);
   for (mp=mm3b->next; mp; mp = mp->next)
   {
      if (KernelIsUnique(mm3b, mp))
      {
         ATL_mmnode_t *p, *p2;
         p = TimeAllKBRegions(verb, pre, mp, mm3b->next->next->kbB);
         p2 = MergeCases(0, mmb, p);
         KillAllMMNodes(p);
         KillAllMMNodes(mmb);
         mmb = p2;
      }
   }
   KillAllMMNodes(mm3b);
/*
 * Now, get rid of any blocking factor that is slower than the preceeding one
 */
   mmb = WinnowCases(0, mmb);
   WriteRefreshedMMFileWithPath(pre, "res", "bAMMRES.sum", mmb);
   return(mmb);
}

@beginskip
ATL_mmnode_t *DecentGenCase(int verb, char pre, int nreg)
{
/*
 * Find out what vectorization, if any, to use in generating kernels
 */
   int mu, nu;
   SetGenVec(verb, pre);
/* 
 * 120 = LCM(2,3,4,5,6,8), and large enough to stress mu/nu
 */
   return(FindDefMUNU(verb, pre, nreg, 0, 120, 1, &mu, &nu));
@skip   return(ReadMMFileWithPath(pre, "res", "gAMMMUNU.sum"));
@skip   return(GetNewGenNode(pre, 0, 0, mu, nu, 1, 0));
}
@endskip

/*
 * This routine finds kernels to use in low-rank-K update. For 3 <= K <= 15,
 * it tries all kernels and chooses the best performing; In this search
 * we consider only compile-time K kernels, since runtime kernels will be
 * selected by general (K>15) search.
 * (K=1 and K=2 are handled by GER and GER2).
 * We consider only user-generated kernels; for any problem sizes that are
 * not supported, we will use the normal K or K-clean routines.  This list
 * is just to allow for hand-tuning small-K special cases.
 * This routine produces output file <pre>AMMLOWK.sum
 */
ATL_mmnode_t *GetLowRankKKernels
(
   int verb,            /* verbosity */
   char pre,            /* s,d */
   int MB,              /* default mb to time with */
   int NB,              /* default nb to time with */
   ATL_mmnode_t *inb    /* all working ukerns */
)
{
   int k, ik;
   ATL_mmnode_t *rkKb=NULL, *mp;
/*
 * Get rid of all K-runtime kernels from consideration
 */
   while (inb && FLAG_IS_SET(inb->flag, MMF_KRUNTIME))
      inb = KillMMNode(inb);
   if (inb)
   {
      ATL_mmnode_t *prev=inb;
      mp = inb->next;
      while (mp)
      {
         if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
         {
            mp = KillMMNode(mp);
            prev->next = mp;
         }
         else
         {
            prev = mp;
            mp = mp->next;
         }
      }
   }
   else
      return(NULL);
   for (ik=0; ik < 2; ik++)
   {
      int kbeg, kend, kinc;
      if (!ik)
      {
         kbeg = 96;
         kend = 16;
         kinc = 16;
      }
      else
      {
         kbeg = 15;
         kend = 3;
         kinc = 1;
      }
      for (k=kbeg; k >= kend; k -= kinc)
      {
         printf("FINDING BEST USER-PROVIDED KERNEL FOR K=%d:\n", k);
         ATL_mmnode_t *best=NULL;
         for (mp=inb; mp; mp = mp->next)
         {
            const int mu = mp->mu, nu = mp->nu, ku = mp->ku;
            const int mb = (MB/mu)*mu, nb = (NB/nu)*nu;
            const int KK = (!FLAG_IS_SET(mp->flag,MMF_KVEC)) ? 
                           k : ((k+ku-1)/ku)*ku;
            double mf;
   
            assert(mb && nb);
            if (FLAG_IS_SET(mp->flag, MMF_KRUNTIME) || KK%ku)
            {
               printf("   skipping %d. %s, KRUN=%d, ku=%d\n", mp->ID, mp->rout,
                      FLAG_IS_SET(mp->flag, MMF_KRUNTIME), ku);
               continue;
            }
            if ((mp->kbmin && k < mp->kbmin) || (mp->kbmax && KK > mp->kbmax))
            {
               printf("   skipping %d. %s, kbmin,max=%d,%d, K=%d\n", 
                      mp->ID, mp->rout, mp->kbmin, mp->kbmax, KK);
               continue;
            }
            mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, KK, 0, 0, -1);
            if (KK != k)
               mf = (mf*k) / (double)KK;
            printf("   %d. %s: mb=%d, nb=%d, MFLOP=%.2f\n", mp->ID, mp->rout,
                   mb, nb, mf);
            if (!best)
            {
               best = mp;
               mp->mflop[0] = mf;
               mp->mbB = mb;
               mp->nbB = nb;
               mp->kbB = k;
            }
            else if (best->mflop[0] < mf)
            {
               best = mp;
               mp->mflop[0] = mf;
               mp->mbB = mb;
               mp->nbB = nb;
               mp->kbB = k;
            }
         }
         if (best)
         {
            best = CloneMMNode(best);
            best->next = rkKb;
            rkKb = best;
            printf("BEST FIXED-%d KERNEL: %d. %s MFLOP=%.2f\n\n", 
                   k, best->ID, best->rout, best->mflop[0]);
         }
         else
            printf("NO SPECIAL CASE for K=%d\n\n", k);
      }
   }
   KillAllMMNodes(inb);
   return(rkKb);
}

/*
 * Finds list of best run-time kernel, ranked by KU.  Higher KUs are not
 * retained unless they beat any lower-KU kernel that divides that KU evenly
 */
ATL_mmnode_t *GetRuntimeKKernels
(
   int verb,            /* verbosity */
   char pre,            /* s,d */
   int MB,              /* default mb to time with */
   int NB,              /* default nb to time with */
   ATL_mmnode_t *inb    /* all working ukerns */
)
{
   ATL_mmnode_t *mp;
   int KU;
/*
 * Get rid of all non-K-runtime kernels from consideration
 */
   while (inb && !FLAG_IS_SET(inb->flag, MMF_KRUNTIME))
      inb = KillMMNode(inb);
/* 
 * Got rid of any at base, now get rid of non-K-runtime from internal nodes
 */
   if (inb)
   {
      ATL_mmnode_t *prev=inb;
      mp = inb->next;
      while (mp)
      {
         if (!FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
         {
            mp = KillMMNode(mp);
            prev->next = mp;
         }
         else
         {
            prev = mp;
            mp = mp->next;
         }
      }
   }
   else
      return(NULL);
   KU = inb->ku;
   for (mp=inb->next; mp; mp = mp->next)
      KU = Mylcm(KU, mp->ku);
   if (KU > 32)
      KU = 32;
   else
      KU = ((16+KU-1)/KU)*KU;
   printf("TRYING ALL RUNTIMEK KERNS WITH MB=%d, NB=%d, KB=%d:\n", MB, NB, KU);
   for (mp=inb; mp; mp = mp->next)
   {
      int mu=mp->mu, nu=mp->nu, ku=mp->ku;
      int mb = (MB/mu)*mu, nb = (NB/nu)*nu, kb = (KU/ku)*ku;
      double mf;
      assert(mb && nb && kb);
      mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, kb, 0, 0, -1);
      printf("   %d. %s: mb=%d, nb=%d, MFLOP=%.2f\n", mp->ID, mp->rout,
             mb, nb, mf);
      mp->mflop[0] = mf;
      mp->mbB = mb;
      mp->nbB = nb;
      mp->kbB = kb;
   }
   printf("\n");
   inb = ATL_SortMMNodesByMflop(0, inb);
   if (inb->ku == 1)
   {
      KillAllMMNodes(inb->next);
      inb->next = NULL;
   }   
   else
   {
      ATL_mmnode_t *p;
/*
 *    Go thru sorted list, and kill all slower nodes that don't add new K
 */
      for (p=inb; p; p = p->next)
      {
         ATL_mmnode_t *prev=p;
         mp = p->next;
         while (mp)
         {
            if (mp->ku % p->ku == 0)
            {
               mp = KillMMNode(mp);
               prev->next = mp;
            }
            else
            {
               prev = mp;
               mp = mp->next;
            }
         }
      }
   }
   if (!inb)
      printf("NO RETAINED RUNTIME KERNELS.\n\n");
   else
   {
      printf("RETAINED RUNTIME KERNELS:\n");
      for (mp=inb; mp; mp = mp->next)
         printf("   %d. %s: ku=%d, MFLOP=%.2f\n", mp->ID, mp->rout, mp->ku,
                mp->mflop[0]);
      printf("DONE.\n");
   }
   return(inb);
}
/*
 * RETURNS: 1 if mmc is slower than any kernel in mmb
 */
int IsSlowerThanList
(
   int verb,            /* verbosity */
   char pre,            /* s,d */
   int MB,
   int NB,              /* default mb/nb to time with */
   ATL_mmnode_t *mmc,  /* candidate mmkern */
   ATL_mmnode_t *mmb   /* kernels to time candidate against */
)
{
   ATL_mmnode_t *mp;
   double mfc, mf;
   int mu, nu, ku;
   int mb, nb, kb, KB;

   if (!mmb)
      return(0);
   kb = mmc->kbB;
   mu = mmc->mu;
   nu = mmc->nu;
   mb = (MB/mu)*mu;
   nb = (NB/nu)*nu;
   assert(mb && nb && kb);
   KB = (!FLAG_IS_SET(mmc->flag,MMF_KVEC))?kb:((kb+mmc->ku-1)/mmc->ku)*mmc->ku;
   mfc = TimeMMKernel(verb, 0, mmc, pre, mb, nb, KB, 0, 0, -1);
   mfc = (kb*mfc)/(double)KB;
   mmc->mflop[1] = mfc;
   kb = mmc->kbB;
   for (mp=mmb; mp; mp = mp->next)
   {
      ku = mp->ku;
      if (mp->kbmin && kb < mp->kbmin)
         continue;
      if (mp->kbmax && kb > mp->kbmax)
         continue;
      if (kb%ku == 0 || FLAG_IS_SET(mp->flag,MMF_KVEC))
      {
         int KK = (FLAG_IS_SET(mp->flag,MMF_KVEC)) ? ((kb+ku-1)/ku)*ku : kb;
         mu = mp->mu;
         nu = mp->nu;
         mb = (MB/mu)*mu;
         nb = (NB/nu)*nu;
         assert(mb && nb);
         mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, KK, 0, 0, -1);
         mp->mflop[1] = (kb*mfc)/(double)KK;
         if (mf > mfc)
         {
@skip            printf("      %d. %s (%.2f) outcompeted by %d. %s (%.2f)\n",
@skip                   mmc->ID, mmc->rout, mfc, mp->ID, mp->rout, mf);
            return(1);
         }
      }
   }
   return(0);
}

/*
 * Finds best-performing square cases in list of pre-existing kernels, mmb.
 * Does not modify original mmb list, and will return only kernels that are
 * faster than smaller square cases.
 * RETURNS: new list of all square cases that got best performance from
 *          original mmb.
 */
@ROUT uammsearch
ATL_mmnode_t *FindBestSquareCases(char pre, int verb, ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mmp, *mmSQ=NULL, *prev=NULL;
   int maxNB=0, maxU=0, i;

   for (mmp=mmb; mmp; mmp = mmp->next)
   {
      if (mmp->mu > maxU)
         maxU = mmp->mu;
      if (mmp->nu > maxU)
         maxU = mmp->nu;
      if (mmp->nbB > maxNB)
         maxNB = mmp->nbB;
      if (mmp->mbB > maxNB)
         maxNB = mmp->mbB;
      if (mmp->kbB > maxNB)
         maxNB = mmp->kbB;
   }
   maxNB = ((maxNB+maxU-1) / maxU)*maxU;

   for (i=4; i <= maxNB; i++)
   {
      mmp = BestForThisNB(verb, pre, mmb, i, i-1, i+1);
      if (mmSQ)
      {
         if (prev->mflop[0] >= mmp->mflop[0])
            KillMMNode(mmp);
         else
         {
            prev->next = mmp;
            prev = mmp;
         }
      }
      else
         mmSQ = prev = mmp;
   }
   return(mmSQ);
}
@ROUT ammsearch
ATL_mmnode_t *FindBestSquareCases(char pre, int verb, int nregs, int maxNB, 
                                  ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mp, *mmSQ=NULL, *mmGN, *prev=NULL, *mmS;
   int maxU=0, i, KM;
   int vlen;
   const char upr = (pre == 's' || pre == 'c') ? 's' : 'd';

   mmGN = GetGenCases(pre);
   assert(mmGN);
   vlen = mmGN->next->next->vlen;
@skip   vlen = GetNativeVLEN(pre);
   if (vlen < 1)
      vlen = 1;
   for (mp=mmb; mp; mp = mp->next)
   {
      if (mp->mu > maxU)
         maxU = mp->mu;
      if (mp->nu > maxU)
         maxU = mp->nu;
@beginskip
      if (mp->nbB > maxNB)
         maxNB = mp->nbB;
      if (mp->mbB > maxNB)
         maxNB = mp->mbB;
      if (mp->kbB > maxNB)
         maxNB = mp->kbB;
@endskip
   }
   maxNB = 1.2 * maxNB;
   maxNB = ((maxNB+maxU-1) / maxU)*maxU;
/*
 * For small problems, try full generated & user kerns, since square kerns
 * are very likely to use some odd kernel that got winnowed in original file
 */
   mmS = ReadMMFileWithPath(upr, "res", "WORKING.sum");
   ATL_LastMMNode(mmS)->next = CloneMMQueue(mmGN);
/*
 * Find best NB=4 case to start queue
 */
   mmSQ = prev = BestForThisNB(verb, pre, mmS, 4, 4-1, 4+1);
/*
 * for nb < vlen, scope every multiple of 2
 */
   KM = Mmax(vlen,16);
   for (i=6; i <= KM; i += 2)
   {
      mp = BestForThisNB(verb, pre, mmS, i, i-1, i+1);
      if (prev->mflop[0] >= mp->mflop[0])
         KillMMNode(mp);
      else
      {
         prev->next = mp;
         prev = mp;
      }
   }
   KillAllMMNodes(mmS);  /* don't need small queue anymore */
/*
 * For larger problems, only use user kernels that won against generated.
 * We add back in all generated kerns in case we need an eliminated one for
 * cleanup.  Could do same for user (use mmS for all), but mmGN is at most
 * length 5, while mmb is of any length, which is why we don't want to time
 * all those kerns.
 */
   mmb = AddUniqueMMKernCompList(mmGN, mmb);
/*
 * For square cases > VLEN, try only multiples of VLEN: since we always 
 * vectorize along at least one dim, only these dims can be fully vectorized
 */
   for (i=((16+vlen)/vlen)*vlen; i <= maxNB; i += vlen)
   {
      mp = BestForThisNB(verb, pre, mmb, i, i-1, i+1);
      if (prev->mflop[0] >= mp->mflop[0])
         KillMMNode(mp);
      else
      {
         prev->next = mp;
         prev = mp;
      }
   }
   return(mmSQ);
}
/*
 * Sets all MV[A,B,C] bits in mmb to those provided in low 3 bits of bits
 */
void ResetMoveBitsInQ(ATL_mmnode_t *mmb, int bits)
{
   while (mmb)
   {
      ATL_MMF_MVPUT(mmb->flag, bits);
      mmb = mmb->next;
   }
}

ATL_mmnode_t *MergeRankKKernels
(
   int verb,            /* verbosity */
   char pre,            /* s,d */
   int MB,              /* default mb to time with */
   int NB,              /* default nb to time with */
   int maxKB,           /* largest KB to produce */
   ATL_mmnode_t *fixb,  /* rank-K fixed-K kerenls */
   ATL_mmnode_t *runb,  /* rank-K, runtime-K kernels */
   ATL_mmnode_t *sqrb   /* optimized near-square kernels */
)
{
   ATL_mmnode_t *rkb, *rkp;
   int k;
   rkp = rkb = GetMMNode();
   printf("CHOOSING BEST KERNEL FOR EACH RANK-K (3 <= K <= %d):\n", maxKB);
   for (k=3; k <= maxKB; k++)
   {
      ATL_mmnode_t *best=NULL, *p;
      double mfB=0.0, mf;
/*
 *    fixb & sqrb are in K-order, so we pop them off stack until we get to
 *    one big enough to solve the problem.  We also ignore all KRUNTIME kernels
 *    in sqrb, since they should appear in runb if they are competitive
 */
      while (fixb)
      {
         if (fixb->kbB < k || (fixb->kbmin && fixb->kbmin > k) ||
             (fixb->kbmax && fixb->kbmax < k))
            fixb = KillMMNode(fixb);
         else
            break;
      }
      while (sqrb)
      {
         if (sqrb->kbB < k || FLAG_IS_SET(sqrb->flag, MMF_KRUNTIME)
             || (sqrb->kbmin && sqrb->kbmin > k) || 
                (sqrb->kbmax && sqrb->kbmax < k))
            sqrb = KillMMNode(sqrb);
         else break;
      }
      if (fixb)
      {
         if (fixb->kbB == k)
         {
            int mu = fixb->mu, nu = fixb->nu, ku = fixb->ku;
            int mb = (NB/mu)*mu, nb = (NB/nu)*nu;
            int kb = (!FLAG_IS_SET(fixb->flag,MMF_KVEC)) ? k : ((k+ku-1)/ku)*ku;
            best = fixb;
            fixb = fixb->next;
            mfB = TimeMMKernel(verb, 0, best, pre, mb, nb, kb, 0,0, -1);
            mfB = (mfB*k)/(double)kb;
         }
      }
      if (sqrb)
      {
         if (sqrb->kbB == k)
         {
            int mu = sqrb->mu, nu = sqrb->nu, ku = sqrb->ku;
            int mb = (MB/mu)*mu, nb = (NB/nu)*nu;
            int kb = (!FLAG_IS_SET(sqrb->flag,MMF_KVEC)) ? k : ((k+ku-1)/ku)*ku;
            mf = TimeMMKernel(verb, 0, sqrb, pre, mb, nb, kb, 0, 0,-1);
            mf = (mf*k)/(double)kb;
            if (mf > mfB)
            {
               mfB = mf;
               if (best)
                  KillMMNode(best);
               best = sqrb;
               sqrb = sqrb->next;
            }
            else
               sqrb = KillMMNode(sqrb);
         }
      }
      for (p=runb; p; p = p->next)
         if ((k % p->ku == 0 || FLAG_IS_SET(p->flag,MMF_KVEC)) && 
             k > p->kbmax && (!p->kbmin || p->kbmin <= k))
            break;
      if (p)
      {
         int mu = p->mu, nu = p->nu, ku = p->ku;
         int mb = (NB/mu)*mu, nb = (NB/nu)*nu;
         int kb = (!FLAG_IS_SET(p->flag,MMF_KVEC)) ? k : ((k+ku-1)/ku)*ku;
         if (p->kbmax && p->kbmax < kb)
            mf = -1.0;
         else
            mf = TimeMMKernel(verb, 0, p, pre, mb, nb, kb, 0, 0, -1);
         mf = (mf*k)/(double)kb;
         if (mf > mfB)
         {
            mfB = mf;
            if (best)
               KillMMNode(best);
            best = CloneMMNode(p);
         }
      }
      assert(best);
      printf("   Best kernel K=%d: %d. %s (%.2f)\n",k,best->ID,best->rout,mfB);
      best->kbB = k;
      rkp->next = best;
      rkp = best;
   }
   if (sqrb)
      KillAllMMNodes(sqrb);
   if (fixb)
      KillAllMMNodes(fixb);
   rkp->next = NULL;
   printf("DONE.\n\n");
   return(KillMMNode(rkb));
}

/*
 * Complex types use the previously selected real kernels in order to
 * reduce library size (means we only have 2 precision GEMMS for 4
 * types/precisions).  The only thing that is different is we may
 * reduce max NB in order to keep complex ops in cache.
 * May want to write this as part of real tuning!
 */
int DoComplex(char pre, int verb)
{
   ATL_mmnode_t *mmb;
   char upr = (pre == 'z') ? 'd' : 's';
   exit(-1);
   mmb = ReadMMFileWithPath(pre, "res", "geAMMRES.sum");
   if (!mmb)
   {
      mmb = ReadMMFileWithPath(upr, "res", "geAMMRES.sum");
      assert(mmb);
      WriteMMFileWithPath(pre, "res", "geAMMRES.sum", mmb);
   }

}

/*
 * Creates two lists from original, which is left unchanged.
 * A list of all unique runtime kernels is RETURNED, 
 * while a list of all unique KB compile kernels is provided by CBAS
 */
ATL_mmnode_t *SplitRunCompKB(ATL_mmnode_t *orig, ATL_mmnode_t **CBAS)
{
   ATL_mmnode_t *comp=NULL, *run, *bp;
   for (bp=orig; bp; bp = bp->next)
   {
      if (FLAG_IS_SET(bp->flag, MMF_KRUNTIME))
      {
         if (!MMKernCompIsPresent(run, bp))
         {
            ATL_mmnode_t *tp;
            tp = CloneMMQueue(bp);
            tp->next = run;
            run = tp;
         }
      }
      else  /* candidate for compile-time K list */
      {
         if (!MMKernCompIsPresent(comp, bp))
         {
            ATL_mmnode_t *tp;
            tp = CloneMMQueue(bp);
            tp->next = comp;
            comp = tp;
         }
      }
   }
/*
 * Put them back in original order, they were produced backwards from orig
 */
   if (comp)
      comp = ReverseMMQ(comp);
   if (run)
      run = ReverseMMQ(run);

   *CBAS = comp;
   return(run);
}
/*
 * Deletes all kernels in mmb with kbB that are not a multiple of mu
 */
ATL_mmnode_t *KillIncompatible_MK(ATL_mmnode_t *mmb)
{
   while (mmb && (mmb->kbB/mmb->mu)*mmb->mu != mmb->kbB)
      mmb = KillMMNode(mmb);
   if (mmb)
   {
      ATL_mmnode_t *mp=mmb->next, *prev=mmb;

      while (mp)
      {
         if ((mp->kbB/mp->mu)*mp->mu != mp->kbB)
             mp = prev->next = KillMMNode(mp);
         else
         {
            prev = mp;
            mp = mp->next;
         }
      }
   }
   return(mmb);
}
/*
 * Given a list of kernels being already being used by GEMM, find best
 * performing cases with MB=KB, and NB allowed to vary.  These blockings
 * of already-existing kernels will be used to build triangular & symmetric
 * amm-based routines 
 */
ATL_mmnode_t *DoMKB_findNB(char pre, int verb, ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mmSQ, *run, *comp, *mp;
   mmSQ = ReadMMFileWithPath(pre, "res", "mkbAMMRES.sum");
   if (mmSQ)
   {
      MMFillInGenStrings(pre, mmSQ);
      if (mmSQ->mflop[0] < 0.0)
      {
         for (mp=mmSQ; mp; mp = mp->next)
         {
            int nb=mp->kbB;
            if (mp->mflop[0] < 0.0)
               mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, nb, nb, nb, 
                                           1, 0, -1);
         }
         WriteMMFileWithPath(pre, "res", "mkbAMMRES.sum", mmSQ);
      }
      return(mmSQ);
   }
   run = SplitRunCompKB(mmb, &comp);
   comp = KillIncompatible_MK(comp);
/*
 * Add all K-cleanup kernels to list of candidates
 */
   mp = ReadMMFileWithPath(pre, "res", "AMMKCLEAN.sum");
   if (mp)
   {
      ATL_mmnode_t *r, *c;
      r = SplitRunCompKB(mp, &c);
      KillAllMMNodes(mp);
      c = KillIncompatible_MK(c);
      mp = MergeCases(-1, run, r);
      KillAllMMNodes(run);
      KillAllMMNodes(r);
      run = mp;
      mp = MergeCases(-1, comp, c);
      KillAllMMNodes(comp);
      KillAllMMNodes(c);
      comp = mp;
   }
/*
 * HERE HERE HERE
 */
}
ATL_mmnode_t *DoSquare(char pre, int verb, int nregs, ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mmSQ;
   const char upr = (pre == 'z' || pre == 'd') ? 'd' : 's';

   mmSQ = TimeMMFileWithPath(pre, "res", "sqAMMRES.sum", 0, verb, 0, 1, 0, -1);
   if (mmSQ)
      return(mmSQ);
   else
   {
      int maxNB=0;
      ATL_mmnode_t *mp;
      for (mp=mmb; mp; mp = mp->next)
      {
          if (mp->kbB > maxNB)
             maxNB = mp->kbB;
          if (mp->mbB > maxNB)
             maxNB = mp->mbB;
          if (mp->nbB > maxNB)
             maxNB = mp->nbB;
      }
@skip      mmb = GetWorkingUserCases(verb, upr);
@skip      mmb = GetUniqueUserKerns(mmb);
      mmSQ = FindBestSquareCases(pre, verb, nregs, maxNB, mmb);
@skip      KillAllMMNodes(mmb);
      WriteRefreshedMMFileWithPath(pre, "res", "sqAMMRES.sum", mmSQ);
   }
   return(mmSQ);
}

void DoTRSM(char pre, int verb)
/*
 * Later, may need to put trsm 'Right' timings in mflop[1]
 */
{
   ATL_mmnode_t *tb, *tp, *sb;
   if (pre == 'z' || pre == 'c')
      return;
   tb = ReadMMFileWithPath(pre, "res", "tsAMMRES.sum");
   if (tb)  /* already ran! */
   {
      for (tp=tb; tp; tp = tp->next)
      {
         if (tp->mflop[0] <= 0.0)
         {
            tp->mflop[0] = TimeTSKernel(verb, 0, pre, tp->mbB, tp->nbB, 0);
            if (verb)
               printf("   trsmKL %dx%d: %.2f\n", tp->mbB,tp->nbB, tp->mflop[0]);
         }
      }
      WriteRefreshedMMFileWithPath(pre, "res", "tsAMMRES.sum", tb);
      KillAllMMNodes(tb);
      return;
   }

   tb = ReadMMFileWithPath(pre, "res", "sqAMMRES.sum");
   printf("\nFINDING PERFORMANCE OF TRSM KERNELS FOR SQUARE AMM:\n");
   for (tp=tb; tp; tp = tp->next)
   {
      tp->mflop[0] = TimeTSKernel(verb, 0, pre, tp->mbB, tp->nbB, 0);
      if (verb)
         printf("   trsmKL %dx%d: %.2f\n", tp->mbB, tp->nbB, tp->mflop[0]);
   }
   WriteRefreshedMMFileWithPath(pre, "res", "tsAMMRES.sum", tb);
   printf("DONE TRSM TIMING.\n");
   KillAllMMNodes(tb);
}

ATL_mmnode_t *FindBestNK_M
   (char pre, int verb, ATL_mmnode_t *mmb, unsigned int mb)
/*
 * RETURNS: Clone of node that provides best perf for a problem with MB=mb.
 *          We try finding best nb&kb by using ones near any that are near
 *          those in list of mmb.  NULL if no kern can do MB=mb.
 */
{
   ATL_mmnode_t *mp, *mpMax=NULL;
   unsigned int kbB=0, nbB=0;
   double mf, mfMax=0.0;
/*
 * Try all candidate kernels for this mb
 */
   for (mp=mmb; mp; mp = mp->next)
   {
      int kb=mp->kbB, nb=mp->nbB;
      if (mb % mp->mu)
         continue;
      mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, kb, 1, 0, -1);
/*
 *    Try NB (and if allowed KB) from larger kerns to see if they improve
 *    small mb perf
 */
      if (mp->next)  /* larger KB/NB kerns exist */
      {
         ATL_mmnode_t *mpG; /* kerns of greater size */
         int KB, lastK=kb, lastN=nb;
         const int ku=mp->ku, nu=mp->nu; 
         const int CHGK=FLAG_IS_SET(mp->flag, MMF_KRUNTIME);

         for (mpG=mp->next; mpG; mpG = mpG->next)
         {
            int k = mpG->kbB, n=mpG->nbB;
            double mfG;

            if (nu <= 8)
               n = ((n+nu-1)/nu)*nu;
            else
               n = (n/nu)*nu;
            if (CHGK)
            {
               if (ku <= 8)
                  k = ((k+ku-1)/ku)*ku;
               else
                  k = (k/ku)*ku;
            }
            else 
               k = kb;
            if (n <= lastN || k <= lastK)
               continue;
            mfG = TimeMMKernel(verb, 0, mp, pre, mb, n, k, 1, 0, -1);
            if (mfG > mf)
            {
               mf = mfG;
               nb = n;
               kb = k;
            }
            lastN = n;
            lastK = k;
         }
      }
      if (mf > mfMax)
      {
         nbB = nb;
         kbB = kb;
         mfMax = mf;
         mpMax = mp;
      }
   }
   if (mpMax)
   {
      int i;
      for (i=0, mp=mmb; mp != mpMax; i++, mp = mp->next);
      mp = mpMax;
      mpMax = CloneMMNode(mpMax);
      mpMax->ivar = i + 1;
      mpMax->mflop[0] = mfMax;
      mpMax->mbB = mb;
      mpMax->nbB = nbB;
      mpMax->kbB = kbB;
   }
   return(mpMax);
}

ATL_mmnode_t *FindBestMK_N
   (char pre, int verb, ATL_mmnode_t *mmb, unsigned int nb)
/*
 * RETURNS: Clone of node that provides best perf for a problem with NB=nb.
 *          We try finding best mb&kb by using ones near any that are near
 *          those in list of mmb.  NULL if no kern can do NB=nb.
 */
{
   ATL_mmnode_t *mp, *mpMax=NULL;
   unsigned int kbB=0, mbB=0;
   double mf, mfMax=0.0;
/*
 * Try all candidate kernels for this nb
 */
   for (mp=mmb; mp; mp = mp->next)
   {
      int kb=mp->kbB, mb=mp->mbB;
      if (nb % mp->nu)
         continue;
      mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, kb, 1, 0, -1);
/*
 *    Try MB (and if allowed KB) from larger kerns to see if they improve
 *    small nb perf
 */
      if (mp->next)  /* larger KB/MB kerns exist */
      {
         ATL_mmnode_t *mpG; /* kerns of greater size */
         int KB, lastK=kb, lastM=mb;
         const int ku=mp->ku, mu=mp->mu; 
         const int CHGK=FLAG_IS_SET(mp->flag, MMF_KRUNTIME);

         for (mpG=mp->next; mpG; mpG = mpG->next)
         {
            int k = mpG->kbB, m=mpG->mbB;
            double mfG;

            if (mu <= 8)
               m = ((m+mu-1)/mu)*mu;
            else
               m = (m/mu)*mu;
            if (CHGK)
            {
               if (ku <= 8)
                  k = ((k+ku-1)/ku)*ku;
               else
                  k = (k/ku)*ku;
            }
            else 
               k = kb;
            if (m <= lastM || k <= lastK)
               continue;
            mfG = TimeMMKernel(verb, 0, mp, pre, m, nb, k, 1, 0, -1);
            if (mfG > mf)
            {
               mf = mfG;
               mb = m;
               kb = k;
            }
            lastM = m;
            lastK = k;
         }
      }
      if (mf > mfMax)
      {
         mbB = mb;
         kbB = kb;
         mfMax = mf;
         mpMax = mp;
      }
   }
   if (mpMax)
   {
      int i;
      for (i=0, mp=mmb; mp != mpMax; i++, mp = mp->next);
      mp = mpMax;
      mpMax = CloneMMNode(mpMax);
      mpMax->ivar = i + 1;
      mpMax->mflop[0] = mfMax;
      mpMax->nbB = nb;
      mpMax->mbB = mbB;
      mpMax->kbB = kbB;
   }
   return(mpMax);
}

ATL_mmnode_t *FindBestK_MN
   (char pre, int verb, ATL_mmnode_t *mmb, unsigned int nb)
/*
 * RETURNS: Clone of node that provides best perf for a problem with MB=NB=nb,
 *          and any KB in the list of mmb.  NULL if no kern can do MB=NB=nb.
 */
{
   ATL_mmnode_t *mp, *mpMax=NULL;
   unsigned int kbB=0;
   double mf, mfMax=0.0;
   for (mp=mmb; mp; mp = mp->next)
   {
      int kb=mp->kbB;
      if (nb % mp->mu || nb % mp->nu)
         continue;
      mf = TimeMMKernel(verb, 0, mp, pre, nb, nb, kb, 1, 0, -1);
/*
 *    If we can change KB, try larger ones before giving up on this kern
 */
      if (mp->next && FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
      {
         ATL_mmnode_t *mpK;
         int KB, lastK=kb;
         const int ku=mp->ku;

         for (mpK=mp->next; mpK; mpK = mpK->next)
         {
            int k = mpK->kbB;
            double mfK;

            if (ku <= 8)
               k = (k+ku-1)/ku;
            else
            {
               k = (k/ku)*ku;
               if (k <= lastK)
                  continue;
            }
            mfK = TimeMMKernel(verb, 0, mp, pre, nb, nb, k, 1, 0, -1);
            if (mfK > mf)
            {
               mf = mfK;
               kb = k;
            }
            lastK = k;
         }
      }
      if (mf > mfMax)
      {
         kbB = kb;
         mfMax = mf;
         mpMax = mp;
      }
   }
   if (mpMax)
   {
      int i;
      for (i=0, mp=mmb; mp != mpMax; i++, mp = mp->next);
      mpMax = CloneMMNode(mpMax);
      mpMax->ivar = i + 1;
      mpMax->mflop[0] = mfMax;
      mpMax->mbB = mpMax->nbB = nb;
      mpMax->kbB = kbB;
   }
   return(mpMax);
}

void GenAllViews(char pre, int verb)
/*
 * Generates performance views of [ge,rk]AMMRES.sum
 */
{
   ATL_mmnode_t *mmb, *mp, *mpL;
   mmb = ReadMMFileWithPath(pre, "res", "geAMMRES.sum");
   assert(mmb);
   mp = TimeMMFileWithPath(pre, "res", "ipmnPERF.sum", 0, verb, 0, 1, 0, -1);
   if (mp)
      KillAllMMNodes(mp);
   else /* generate inner-product MB=NB, KB free view */
   {
      int i, nb, NBMAX, k;
      ATL_mmnode_t *mb=NULL;
      double mfL=0.0;

      printf("   FINDING BEST CASE FOR DEGENERATE MB=NB\n");
      i = GetOffset(mmb, &(mmb->next));
      GetIntMaxMinAtOff(mmb, i, GetOffset(mmb, &(mmb->nbB)), &NBMAX, &nb);
      GetIntMaxMinAtOff(mmb, i, GetOffset(mmb, &(mmb->mbB)), &k, &i);
      NBMAX = Mmax(NBMAX,k);
      nb = Mmin(nb, i);
      for (mpL=mmb; mpL->next; mpL=mpL->next);
      while (nb <= NBMAX)
      {
         mp = FindBestK_MN(pre, verb, mmb, nb);
         if (mp && mp->mflop[0] >= mfL)
         {
            mfL = mp->mflop[0];
            printf("      BEST CASE NB=%d: %d-%s, KB=%d  mf=%.2f.\n", mp->nbB,
                   mp->ID, mp->rout ? mp->rout:"gen", mp->kbB, mfL);
            mp->next = mb;
            mb = mp;
         }
         nb++;
@skip         while (mb->kbB < nb && mb->next)
@skip            mb = mb->next;
      }
      mb = ReverseMMQ(mb);
@skip      MMPruneMflopTol(mb, 0, 1.0);
      WriteMMFileWithPath(pre, "res", "ipmnPERF.sum", mb);
      KillAllMMNodes(mb);
      printf("   DONE DEGENERATE MB/NB SEARCH.\n\n");
   }
   mp = TimeMMFileWithPath(pre, "res", "ipmnPERFcp.sum", 0, verb, 0, 1, 0, -1);
   if (!mp)
   {
      ATL_mmnode_t *mb;
      printf("TIMING COPY ROUTINES FOR DEG MB/NB:\n");
      mb = ReadMMFileWithPath(pre, "res", "ipmnPERF.sum");
      for (mp=mb; mp; mp = mp->next)
      {
         double mf;
         mp->blask = ATL_KGECPFA;
         mp->TB = mp->TA = AtlasTrans; /* generally, worst case perf-wise */
         if (mp->rout)
           free(mp->rout);
         mp->rout = DupString("ATL_tmp.c");
         if (mp->comp)
            free(mp->comp);
         if (mp->cflags)
            free(mp->cflags);
         if (mp->auth)
            free(mp->auth);
         mp->auth = mp->comp = mp->cflags = NULL;
         if (mp->genstr)
           free(mp->genstr);
         mp->genstr = MMGetGenString(pre, mp);
         mf = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB, mp->kbB, 1,0,-1);
         mp->mflop[0] = mf;
         printf("      cpA, NB=%d: %d-%s, KB=%d  mf=%.2f.\n", mp->nbB,
                mp->ID, mp->rout ? mp->rout:"gen", mp->kbB, mf);
         mp->blask = ATL_KGECP2C;
         if (mp->genstr)
           free(mp->genstr);
         mp->genstr = MMGetGenString(pre, mp);
         mf = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB, mp->kbB, 1,0,-1);
         mp->mflop[1] = mf;
         printf("      cpC, NB=%d: %d-%s, KB=%d  mf=%.2f.\n", mp->nbB,
                mp->ID, mp->rout ? mp->rout:"gen", mp->kbB, mf);
      }
      WriteMMFileWithPath(pre, "res", "ipmnPERFcp.sum", mb);
      printf("DONE TIMING COPY ROUTINES FOR DEG MB/NB.\n\n");
      mp = mb;
   }
   KillAllMMNodes(mp);

   mp = TimeMMFileWithPath(pre, "res", "ipnPERF.sum", 0, verb, 0, 1, 0, -1);
   if (mp)
      KillAllMMNodes(mp);
   else /* generate inner-product NB < MAXNB, MB,KB free view */
   {
      int i, nb, NBMAX, k;
      ATL_mmnode_t *mb=NULL;
      double mfL=0.0;

      printf("   FINDING BEST CASE FOR DEGENERATE NB\n");
      i = GetOffset(mmb, &(mmb->next));
      GetIntMaxMinAtOff(mmb, i, GetOffset(mmb, &(mmb->nbB)), &NBMAX, &nb);
      while (nb <= NBMAX)
      {
         mp = FindBestMK_N(pre, verb, mmb, nb);
         if (mp && mp->mflop[0] >= mfL)
         {
            mfL = mp->mflop[0];
            printf("      BEST CASE NB=%d: %d-%s, MB=%d, KB=%d  mf=%.2f.\n", 
                   mp->nbB, mp->ID, mp->rout ? mp->rout:"gen", 
                   mp->mbB, mp->kbB, mfL);
            mp->next = mb;
            mb = mp;
         }
         nb++;
      }
      mb = ReverseMMQ(mb);
@skip      MMPruneMflopTol(mb, 0, 1.0);
      WriteMMFileWithPath(pre, "res", "ipnPERF.sum", mb);
      KillAllMMNodes(mb);
      printf("   DONE DEGENERATE NB SEARCH.\n\n");
   }

   mp = TimeMMFileWithPath(pre, "res", "ipmPERF.sum", 0, verb, 0, 1, 0, -1);
   if (mp)
      KillAllMMNodes(mp);
   else /* generate inner-product NB < MAXNB, MB,KB free view */
   {
      int i, nb, NBMAX, k;
      ATL_mmnode_t *mb=NULL;
      double mfL=0.0;

      printf("   FINDING BEST CASE FOR DEGENERATE MB\n");
      i = GetOffset(mmb, &(mmb->next));
      GetIntMaxMinAtOff(mmb, i, GetOffset(mmb, &(mmb->mbB)), &NBMAX, &nb);
      while (nb <= NBMAX)
      {
         mp = FindBestNK_M(pre, verb, mmb, nb);
         if (mp && mp->mflop[0] >= mfL)
         {
            mfL = mp->mflop[0];
            printf("      BEST CASE MB=%d: %d-%s, NB=%d, KB=%d  mf=%.2f.\n", 
                   mp->mbB, mp->ID, mp->rout ? mp->rout:"gen", 
                   mp->nbB, mp->kbB, mfL);
            mp->next = mb;
            mb = mp;
         }
         nb++;
      }
      mb = ReverseMMQ(mb);
@skip      MMPruneMflopTol(mb, 0, 1.0);
      WriteMMFileWithPath(pre, "res", "ipmPERF.sum", mb);
      KillAllMMNodes(mb);
      printf("   DONE DEGENERATE MB SEARCH.\n\n");
   }

   KillAllMMNodes(mmb);
}
/*
 * Finds main amm kernels
 */
ATL_mmnode_t *DoMainMM(char pre, int verb, int nregs, int CS)
{
   ATL_mmnode_t *mmb, *sqmmb, *mp, *mmGN;
   const char upr = (pre == 'z' || pre == 'd') ? 'd' : 's';
/* 
 * If we are quick returning, still must possibly retime subsearches
 */
   mmb = TimeMMFileWithPath(pre, "res", "geAMMRES.sum", 0, verb, 0, 1, 0, -1);
   if (mmb)
   {
      KillAllMMNodes(DoSquare(pre, verb, nregs, mmb));
      return(mmb);
   }
/*
 * Find the generated cases for each cache context
 */
   mmGN = GetGenCases(pre);
   assert(mmGN);
/*
 * Find which user-supplied kernels can compile on this platform
 */
   mmb = GetWorkingUserCases(verb, upr);
/*
 * Add gmmsearch-suggested kernels to those being considered.
 */
   mp = ATL_LastMMNode(mmGN);
   mp->next = mmb;
   mmb = mmGN;
/*
 * Find the best user-supplied cases for the three common cache blking cases
 */
   mmb = FindCacheBudgetCasesByKB(verb, pre, CS, mmb);
/*
 * Now find best square cases
 */
   sqmmb = DoSquare(pre, verb, nregs, mmb);
/*
 * Now merge square & rect lists for best performing kernels, and write it out
 */
   mp = MergeCases(0, mmb, sqmmb);
   KillAllMMNodes(sqmmb);
   KillAllMMNodes(mmb);
   mmb = WinnowCases(0, mp);
   WriteRefreshedMMFileWithPath(pre, "res", "geAMMRES.sum", mmb);
   return(mmb);
}
@beginskip
/*
 * Finds main amm kernels
 */
ATL_mmnode_t *DoMainMM(char pre, int verb, int nregs, int CS, int *nbs)
{
   ATL_mmnode_t *mmb, *smmb;
   mmb = ReadMMFileWithPath(pre, "res", "geAMMRES.sum");
   if (mmb)
   {
      MMFillInGenStrings(pre, mmb);
      if (mmb->mflop[0] < 0.0)
      {
         ATL_mmnode_t *mp;
         for (mp=mmb; mp; mp = mp->next)
            mp->mflop[0] = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB,
                                        mp->kbB, 1, 0, -1);
         WriteMMFileWithPath(pre, "res", "geAMMRES.sum", mmb);
      }
      return(mmb);
   }
   if (verb)
   {
      int i;
      const int n = (nbs[0] >= 0) ? nbs[0]+1 : 1-nbs[0];
      printf("NBs = %3d", nbs[1]);
      for (i=2; i < n; i++)
         printf(", %3d", nbs[i]);
      printf("\n");
   }
/*
 * Find which kernels can compile on this platform
 */
   mmb = GetWorkingUserCases(verb, pre);
/*
 * For small cases (or user specified), try all kernels with all KB for
 * user generated.  Smmb now points to these KB values that are always
 * retained, and will simply be added to eventual list of large KB kernels
 * that we generate in the next step.
 */
   if (mmb)
   {
      ATL_mmnode_t *mmp;
      mmp = CloneMMQueue(mmb);
      smmb = FindBestUserCases(verb, pre, nbs, mmp);
      mmp = FindBestGenCases(verb, pre, nregs, nbs, smmb);
      if (nbs[0] >= 0)
         smmb = MergeAndWinnowCases(verb, pre, smmb, mmp);
      else  /* forced nbs are all kept, so just merge */
         smmb = MergeCases(0, smmb, mmp);
@skip         WriteMMFileWithPath(pre, "./", "win0.sum", smmb);
   }
   else
     smmb = FindBestGenCases(verb, pre, nregs, nbs, NULL);
/*
 * If nbs aren't being forced, then try larger ranges using cache budgets
 */
   if (nbs[0] >= 0)
   {
      ATL_mmnode_t *mp;
/*
 *    Find decent generator case and find correct vectorization settings, add
 *    this case to default list to be searched.
 */
      mp = DecentGenCase(verb, pre, nregs);
      mp->next = mmb;
      mmb = mp;
/*
 *    Find the best user-supplied cases for the three common cache blking cases
 */
      mmb = FindCacheBudgetCasesByKB(verb, pre, CS, mmb);
/*
 *    Now add small-case kernels back in, and write it out
 */
      mp = MergeCases(0, mmb, smmb);
      KillAllMMNodes(smmb);
      KillAllMMNodes(mmb);
      mmb = WinnowCases(0, mp);
   }
   else /* when we force nbs, we just blindly use the provided list */
      mmb = smmb;
   WriteMMFileWithPath(pre, "res", "geAMMRES.sum", mmb);
   return(mmb);
}
@endskip

int KernHandlesThisKB(ATL_mmnode_t *mp, int kb)
{
   int ku;
   if (!mp->ID)  /* genned kernel handles all K (kvec needs padding) */
      return(1);
   if (mp->kbmax && kb > mp->kbmax)
      return(0);
/*
 * KVEC kerns can always handle problems within vlen-1 less than their kb
 * due to padding in copy routines.
 */
   if (FLAG_IS_SET(mp->flag, MMF_KVEC))
   {
      int KB;
      if (mp->kbmin)
      {
         KB = (mp->kbmin / mp->vlen)*mp->vlen;
         if (KB < mp->kbmin)
            return(0);
      }
      KB = ((kb+mp->vlen-1)/mp->vlen)*mp->vlen;
      if ((KB/ku)*ku != kb)
         return(0);
   }
   else
   {
      if (kb < mp->kbmin)
         return(0);
      ku = mp->ku;
      if ((kb/ku)*ku != kb)
      {
         if (mp->ID)
            return(0);
         else if (!FLAG_IS_SET(mp->flag, MMF_KUISKB))
            return(0);  /* genned codes can adjust fully-unrolled loop */
      }
   }
   return(1);
}

/*
 * This routine tries all kernels in mmb, with K=KB, M=CEIL(KB/MU)*MU,
 * N=CEIL(KB/NU)*NU.  Kernels that can't handle KB are rejected
 * RETURNS: new mmnode ptr for best case for this KB; cannot be NULL, because
 *          1st param of mmb must be a generated kernel that works for any KB
 */
ATL_mmnode_t *BestKernForKB(int verb, char pre, ATL_mmnode_t *mmb, int KB)
{
   ATL_mmnode_t *mp, *mpB=NULL;
   double mfB=0.0;
   assert(mmb);
   printf("   FINDING BEST NEAR-SQUARE KERNEL WT KB=%d:\n", KB);
   for (mp=mmb; mp; mp = mp->next)
   {
      const int mu=mp->mu, nu=mp->nu, ku=mp->ku, ID=mp->ID;
      const int mb=((KB+mu-1)/mu)*mu, nb=((KB+nu-1)/nu)*nu;
      int kb=KB;
      const char *rt=mp->rout;
      double mf;

      if (!KernHandlesThisKB(mp, KB))
      {
         if (ID)
            printf("      %d-%s: skipped, cannot handle KB=%d\n", ID, rt, KB);
         else
         {
            printf("      0-");
            PrintGen0(stdout, mp, 0, 0, 0);
            printf(": skipped, cannot handle KB=%d\n", KB);
         }
         continue;
      }
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         kb = ((KB+mp->vlen-1)/mp->vlen)*mp->vlen;
      if (!mp->ID && FLAG_IS_SET(mp->flag, MMF_KUISKB))
      {
         mp->kbmin = kb-mp->vlen+1;
         mp->kbmax = mp->ku = kb;
         mp->kbB = KB;
         if (mp->genstr);
            free(mp->genstr);
         mp->genstr = MMGetGenString(pre, mp);
      }
      mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, KB, 0,  0, -1);
      if (mf > mfB)
      {
         mfB = mf;
         mpB = mp;
      }
      if (ID)
         printf("      %d-%s, M=%d, N=%d, K=%d: %.0f\n", ID, rt, mb,nb,KB, mf);
      else
      {
         printf("      0-");
         PrintGen0(stdout, mp, mb, nb, KB);
         printf(": %.0f\n", mf);

      }
   }
   assert(mpB);
   printf("   BEST FOR KB=%d: %d-%s (%.1f MFLOPS)\n", 
          KB, mpB->ID, mpB->rout, mfB);
   mpB = CloneMMNode(mpB);
   mpB->mflop[0] = mfB;
   mpB->kbB = KB;
   mpB->mbB = ((KB+mpB->mu-1)/mpB->mu)*mpB->mu;
   mpB->nbB = ((KB+mpB->nu-1)/mpB->nu)*mpB->nu;
   return(mpB);
}

ATL_mmnode_t *DoRankK(char pre, int verb, int nregs, const ATL_mmnode_t *mainb)
{
   ATL_mmnode_t *rkb=NULL, *mp, *mmb;
   const ATL_mmnode_t *cmp;
   int maxB=0, b;
   const char upr = (pre == 'z' || pre == 'd') ? 'd' : 's';
   rkb = TimeMMFileWithPath(pre, "res", "rkAMMRES.sum", 0, verb, 0, 1, 0, -1);
   if (rkb)
      return(rkb);
/*
 * Find largest KB used by main kernels; we will time all near-square kernels
 * of this size and below
 */
   for (cmp=mainb; cmp; cmp = cmp->next)
      if (cmp->kbB > maxB)
         maxB = cmp->kbB;
   if (!maxB)
      maxB = 256;
/*
 * All we need main kerns for is to find maxB, so now reuse the ptr to hold
 * all user cases that work on this platform
 */
   mmb = GetGenCases(pre);
   mp = ATL_LastMMNode(mmb);
   mp->next = GetWorkingUserCases(verb, upr);
@beginskip
   mmb = GetWorkingUserCases(verb, upr);
   mp = DecentGenCase(verb, pre, nregs);
   assert(mp);
   mp->next = mmb;
   mmb = mp;
@endskip
   ResetMoveBitsInQ(rkb, 5);
   printf("TUNING RANK-K, 3 <= K <= %d:\n", maxB);
   for (b = maxB; b > 2; b--)
   {
      mp = BestKernForKB(verb, pre, mmb, b);
      mp->next = rkb;
      rkb = mp;
   }
   WriteRefreshedMMFileWithPath(pre, "res", "rkAMMRES.sum", rkb);
   return(rkb);
}

int main(int nargs, char **args)
{
   char pre='d';
   int verb, nregs, nb, CS, gmu, gnu;
   char *fnout;
   ATL_mmnode_t *mmb, *rnkK, *grnkK, *emb, *mp, *mmSQ;

   GetFlags(nargs, args, &pre, &verb, &nregs, &nb, &CS);
   mmb = DoMainMM(pre, verb, nregs, CS);
   emb = TimeExtraBlockings(pre, verb);
   if (emb)
   {
      emb = SortMMQByIntVal(emb, &(emb->kbB));
      mp = MergeCases(0, mmb, emb);
      KillAllMMNodes(mmb);
      KillAllMMNodes(emb);
      mmb = WinnowCases(0, mp);
      WriteMMFileWithPath(pre, "res", "geAMMRES.sum", mmb);
   }
   rnkK = DoRankK(pre, verb, nregs, mmb);
/*
 * Handle K-cleanup
 */
   ComputeKClean(verb, pre);
/*
 * Time TRSM kernels with matching block factors as square cases
 */
   DoTRSM(pre, verb);
/*
 * Join mmb & rnkK to make master list of all kernels required in this search
 */
   if (rnkK)
   {
      for (mp=mmb; mp->next; mp = mp->next);
      mp->next = rnkK;
   }
   mp = GetUniqueUserKerns(mmb);
   KillAllMMNodes(mmb);
   WriteRefreshedMMFileWithPath(pre, "res", "AMMFRCLST.sum", mp);
   KillAllMMNodes(mp);
   GetGenKernForNB(pre, 0);  /* dealloc static mmnodes */
   GenAllViews(pre, verb);
   exit(0);
}
@ROUT uammsearch
/*
 * ASSUMES: mmb comes in ordered from smallest blocking to largest.  
 * Kills any kernel that is not faster than a smaller-NB kernel.
 */
ATL_mmnode_t *HarshPrune(ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mmp=mmb;
   while (mmp)
   {
      if (!mmp->next)
         return(mmb);
      do
      {
         if (!mmp->next)
            return(mmb);
         if (mmp->mflop[0] > mmp->next->mflop[0])
            mmp->next = KillMMNode(mmp->next);
         else
            mmp = mmp->next;
      }
      while (mmp);
   }
}
/*
 * ASSUMES: mmb comes in ordered from smallest blocking to largest.  
 * Kills any kernel that is not faster than a smaller-NB kernel.
 */
ATL_mmnode_t *TolerantPrune
(
   ATL_mmnode_t *mmb,   /* list of kernels to prune */
   double tol           /* set > 1 to allow slow kernels to stay */
)                       /* < 1 to make pruning harsher */
{
   ATL_mmnode_t *mmp=mmb;
   double mfB = 0.0;
   while (mmp)
   {
      if (!mmp->next)
         return(mmb);
      do
      {
         if (!mmp->next)
            return(mmb);
         if (mmp->mflop[0] > mfB)
            mfB = mmp->mflop[0];
         if (mfB > tol*mmp->next->mflop[0])
            mmp->next = KillMMNode(mmp->next);
         else
            mmp = mmp->next;
      }
      while (mmp);
   }
}
#define CON_NOKVEC 0
#define CON_NOMVEC 1
#define CON_NOCOMPK 2
/*
 * RETURNS: N-length queue wt best-performing kernel for specified dims
 */
ATL_mmnode_t *FindBestKerns
(
   char pre, 
   int verb, 
   ATL_mmnode_t *mmb,            /* candidate user-supplied kerns */
   int N,                        /* number of forced block factors */
   int *mbs, int *nbs, int *kbs, /* forced block factors */
   int C,                        /* constraints */
   float tol                     /* tolerance in getting rid of slow kerns */
)
{
   ATL_mmnode_t *nmmb=NULL, *mp, *mpB, *mpG, *mpg;
   const int TRYKVEC=!(C & (1<<CON_NOKVEC));
   const int TRYMVEC=!(C & (1<<CON_NOMVEC));
   int i, mbB=0;
   double mfB, mf;
/*
 * Find basic register blocking for generated case
 */
   mpG = DecentGenCase(verb, pre, 32);
   if (mpG->vlen != VLEN[VECi])
      VECi = VTSC;
   assert (mpG->kmaj < 2);
/*
 * Loop over all required blocking factors
 */
   printf("SEARCHING %d USER BLOCKINGS:\n", N);
   for (i=N-1; i >= 0; i--)
   {
      int mb=mbs[i], nb=nbs[i], kb=kbs[i], MB=mbs[i];
      int kuG, KK=kb, veci0=VECi;
      double mfK=0.0, mfM=0.0;
      int iveci = VECi, VL=VLEN[VECi];
/*
 *    If mb not specified, choose one near specified KB
 */
      printf("\n   FINDING KERNEL FOR MB=%d, NB=%d, KB=%d:\n", mb, nb, kb);
/*
 *    Find best of M- or K-vectorized generated code for this problem size
 */
      mpg = mpB = NULL;
      if (TRYMVEC)
      {
         int muG=mpG->mu, nuG=mpG->nu, ut=muG*nuG; 
/*
 *       If mb is not specified, make it a multiple of mu & vlen
 */
         if (!MB)
         {
            int mb0;
            mb = Mylcm(muG, VL);
            mb0 = (kb/mb)*mb;
            mb = ((kb+mb-1)/mb)*mb;
            if (mb0 && mb-kb > kb-mb0)
               mb = mb0;
         }
/*
 *       If specified mb not a multiple of vlen, reduce vlen until it is
 */
         else if (mb%VL)
         {
            if (VECi == VTAVX && !(mb%VLEN[VTSSE]))
               VECi = VTSSE;
            else
               VECi = VTSC;
         }
/*
 *       Make register block a multiple of mandated block
 */
         muG = (muG / VL)*VLEN[VECi];
         ut = muG * nuG;
         while (muG > 1 && mb%muG)
            muG -= VLEN[VECi];
         if (muG < 1)
            muG = 1;
         while(muG*(nuG+1) <= ut)
            nuG++;
         while (nb%nuG)
            nuG--;
         kuG = 1;
         mpg = GetNewGenNode(pre, kb, 0, muG/VLEN[VECi], nuG, 1, 0);
         mpg->mbB = mb;
         mfM = TimeMMKernel(verb, 0, mpg, pre, mb, nb, KK, KK, KK, mb, 1, 0,-1);
         printf("      Gen mu=%d, nu=%d, kmaj=%d, mf=%.2f\n", muG, nuG, 0, mfM);
      }
      VECi = iveci;
/*
 *    Generator currently does not support k-vectorized kernels
 */
      if (0 && TRYKVEC)
      {
         int muG, nuG=mpG->nu, ut;

         if (VLEN[VECi] > 1)
            muG = mpG->mu / VLEN[VECi];
         else
            muG = mpG->mu;
         ut = muG * nuG;
/*
 *       If kb not a multiple of vlen, reduce it until it is
 */
         if (kb%VLEN[VECi])
         {
            if (VECi == VTAVX && !(kb%VLEN[VTSSE]))
               VECi = VTSSE;
            else
               VECi = VTSC;
         }
         kuG = VLEN[VECi];
/*
 *       Make register block a multiple of mandated block
 */
         while (mb%muG)
            muG--;
         while(muG*(nuG+1) <= ut)
            nuG++;
         while (nb%nuG)
            nuG--;
         if (kuG > 1)
         {
            mpB =  GetNewGenNode(pre, kb, 0, muG, nuG, kuG, kuG);
            mpg->mbB = mb;
            mfK = TimeMMKernel(verb, 0, mpB, pre, mb, nb, KK, KK, KK, mb,
                               1, 0,-1);
            printf("      Gen mu=%d, nu=%d, kmaj=%d, mf=%.2f\n", muG, nuG, kuG,
                   mfK);
         }
      }
      if (mfM >= mfK)  /* use M-vectorized gen kernel */
      {
         if (mpB)
            KillMMNode(mpB);
         mpB = mpg;
         mfB = mfM;
      }
      else
      {
         if (mpg)
            KillMMNode(mpg);
         mpg = mpB;
         mfB = mfK;
      }
      VECi = iveci;
      if (KK != kb)
         mfB *= (double)kb / (double)KK;
      mpg->mflop[0] = mfB;
/*
 *    Search through all user kernels, and take best performing
 */
      mpB = mpg;
      mbB = mpg->mbB;
      for (mp=mmb; mp; mp = mp->next)
      {
         const int mu=mp->mu, nu=mp->nu, ku=mp->ku, kmaj=mp->kmaj;
         const int KB = (kmaj < 2) ? kb : ((kb+ku-1)/ku)*ku;
         int SKIP=0;
         if (!MB)
         {
            if (nb%nu || KB%ku)
               SKIP=1;
            else
            {
               int mb0;
               mb0 = (kb/mu)*mu;
               mb = ((kb+mu-1)/mu)*mu;
               if (mb0 && (mb-kb > kb-mb0))
                  mb = mb0;
            }
         }
         else if (mb%mu || nb%nu || KB%ku)
            SKIP=1;
         if (mp->kbmin && mp->kbmin > kb)
            SKIP=1;
         else if (mp->kbmax && mp->kbmax < kb)
            SKIP=1;
         if (SKIP)
         {
            printf("      %d-%s: SKIPPED\n", mp->ID, mp->rout);
            continue;
         }
         mf = TimeMMKernel(verb, 0, mp, pre, mb, nb, KB, KB, KB, mb, 1, 0, -1);
         if (KB != kb)
            mf *= (double)kb / (double)KB;
         printf("      %d-%s: %.2f\n", mp->ID, mp->rout, mf);
         if (mf > mfB)
         {
            mfB = mf;
            mpB = mp;
            mbB = mb;
         }
      }
      printf("    [M,N,K]B=%d,%d,%d BEST: %d-%s %.2f\n", mbB, nb, kb,
             mpB->ID, mpB->rout, mfB);
      if (mpB == mpg)
      {
         mpg->next = nmmb;
         nmmb = mpg;
      }
      else
      {
         KillMMNode(mpg);
         mp = CloneMMNode(mpB);
         mp->next = nmmb;
         nmmb = mp;
      }
      nmmb->mflop[0] = mfB;
      nmmb->mbB = mbB;
      nmmb->nbB = nb;
      nmmb->kbB = kb;
      VECi = veci0;
   }
   KillAllMMNodes(mmb);
   KillMMNode(mpG);
@skip   PrintMMNodes(stderr, nmmb);
   if (tol > 0.0)
      nmmb = TolerantPrune(nmmb, tol);
@skip   ApplyMoves2Flags(nmmb, MOVES);  /* gen must know operand movement pattern */
   WriteMMFileWithPath(pre, "res", "uAMMFRC.sum", nmmb);
   printf("DONE.\n");
   return(nmmb);
}

/*
 * This routine applies the contraints C to mmb, and returns winnowed queue
 * RETURNS: Q wt all kernels failing constraints stropped out
 */
ATL_mmnode_t *ApplyConstraints(ATL_mmnode_t *mmb, int C)
{
    if (C)
    {
       ATL_mmnode_t *mp = mmb, *next;
       while (mp)
       {
          next = mp->next;
          if ((C & (1<<CON_NOKVEC)) && mp->kmaj > 1)
             mmb = KillMMNodeFromQ(mmb, mp);
          else if ((C & (1<<CON_NOMVEC)) && mp->kmaj < 2)
             mmb = KillMMNodeFromQ(mmb, mp);
          else if ((C & (1<<CON_NOCOMPK)) && 
                   !FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
             mmb = KillMMNodeFromQ(mmb, mp);
          mp = next;
       }
    }
    return(mmb);
}
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr, 
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, 
   "   -S <file> : take kerns from sum file, force square sizes\n");
   fprintf(stderr, "   -T #  : set pruning tolerance for slower kernels:\n");
   fprintf(stderr, 
   "      # <= 0.0 : keep all legal kernel sizes regardless of performance\n");
   fprintf(stderr, 
   "      # >=0.0 : delete all kerns wt perf*# < maxSmallerPerf\n");
   fprintf(stderr, 
   "                maxSmallerPerf= max perf found in smaller-sized kern\n");
   fprintf(stderr, "   -p [s,d]: set precision prefix (d) \n");
   fprintf(stderr, "   -b # nb1 ... nb# : square NBs to force\n");
   fprintf(stderr, "   -B # mb1 nb1 kb1 ... mb# nb# kb#: dims to force\n");
   fprintf(stderr, 
           "   -M # abc1 ... abc#: which matblks should be cache flushed\n");
   fprintf(stderr, "   -v <verb> : set verbosity (1)\n");
   fprintf(stderr, "   -C [kmc] : Constrain kernel choice:\n");
   fprintf(stderr, "      k : don't allow K-vectorized storage\n");
   fprintf(stderr, "      m : don't allow M-vectorized storage\n");
   fprintf(stderr, "      c : don't allow compile-time K kernels\n");
   fprintf(stderr, "   -K <1/0> : do/don't generate K cleanup\n");

   fprintf(stderr,
      "   -F <b0> <bN> <KI> <idx> <rfn>: brute-force blocking search:\n");
   fprintf(stderr, "       b0: smallest value to try for all dims\n");
   fprintf(stderr, "       b1: largest value to try for all dims\n");
   fprintf(stderr, "       KI: min K increment\n");
   fprintf(stderr, "      idx: index in rfn to use; -1 means last\n");
   fprintf(stderr, "      rfn: search result file name to read kern from\n");
   exit(ierr ? ierr : -1);
}

ATL_mmnode_t *GetFlags(int nargs, char **args, char *PRE, int *VERB, int *NN,
                       int *C, int **MBS, int **NBS, int **KBS, float *TOL,
                       int *KCLEAN)
{
   ATL_mmnode_t *mmb=NULL;
   int B0=0, BN, KI;
   int *mbs=NULL, *nbs=NULL, *kbs=NULL;
   int i, k, j, N=0, ALL=0, MV;
   char *cs;

@skip   MOVES = NULL;
   *TOL = 0.0;
   *VERB = 1;
   *PRE = 'd';
   *C = 0;
   *KCLEAN = 1;
   for (i=1; i < nargs; i++)
   {
      int n;
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'T':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *TOL = atof(args[i]);
         if (*TOL < 0.0)
            *TOL = 0.0;
         break;
      case 'F':  /* <b0> <bN> <KI> <idx> <rfn> */
         if (i+5 >= nargs)
            PrintUsage(args[0], i-1, NULL);
         else
         {
            int I, k;
            ATL_mmnode_t *mp;

            B0 = atoi(args[i+1]);
            BN = atoi(args[i+2]);
            KI = atoi(args[i+3]);
            I = atoi(args[i+4]);
            mmb = ReadMMFile(args[i+5]);
            assert(mmb);
            if (I < 0)
               for (mp=mmb; mp->next; mp = mp->next);
            else
               for (k=0, mp=mmb; k < I && mp; k++, mp = mp->next);
            assert(mp);
            mp = CloneMMNode(mp);
            KillAllMMNodes(mmb);
            mmb = mp;
         }
         i += 5;
         break;
      case 'M':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         n = atoi(args[i]);
         for (MV=k=0; k < n; k++)
         {
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            if (args[i][0] == 'a' || args[i][0] == 'A')
               MV |= 1;
            else if (args[i][0] == 'b' || args[i][0] == 'B')
               MV |= 2;
            else if (args[i][0] == 'c' || args[i][0] == 'C')
               MV |= 4;
            else
               PrintUsage(args[0], -i, "UNKNOWN MATRIX FOR -M");
         }
         IMVS = MV;
@beginskip
         n=0;
         if (MV&1) n++;
         if (MV&2) n++;
         if (MV&4) n++;
         if (n == 1)
         {
            MOVES = DupString("-DMoveA");
            if (MV == 2)
               (MOVES)[6] = 'B';
            else if (MV == 4)
               (MOVES)[6] = 'C';
         }
         else if (n == 2)
         {
            MOVES = DupString("-DMoveA -DMoveB");
            if ((MV&1) == 0)
               MOVES[6] = 'C';
            else if ((MV&2) == 0)
               MOVES[14] = 'C';
         }
         else
            MOVES = DupString("-DMoveA -DMoveB -DMoveC");
@endskip
         break;
      case 'S':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         mmb = ReadMMFile(args[i]);
         break;
      case 'K':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *KCLEAN = atoi(args[i]);
         break;
      case 'v':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *VERB = atoi(args[i]);
         break;
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        *PRE = tolower(args[i][0]);
        assert(*PRE == 's' || *PRE == 'd' || *PRE == 'z' || *PRE == 'c');
        break;
      case 'C':  /* -C <constraint string */
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         cs = args[i];
         n = strlen(cs);
         for (k=0; k < n; k++)
         {
            switch(cs[k])
            {
            case 'm':
               *C |= 1<<CON_NOMVEC;
               break;
            case 'k':
               *C |= 1<<CON_NOKVEC;
               break;
            case 'c':
               *C |= 1<<CON_NOCOMPK;
               break;
            default:
               PrintUsage(args[0], -i, "UNKNOWN CONSTRAINT");
            }
         }
      case 'B':
         if (nbs)
         {
            free(mbs);
            free(nbs);
            free(kbs);
         }
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         N = atoi(args[i]);
         assert(N > 0);
         nbs = malloc(N*sizeof(int));
         assert(nbs);
         mbs = malloc(N*sizeof(int));
         assert(mbs);
         kbs = malloc(N*sizeof(int));
         assert(kbs);
         for (k=0; k < N; k++)
         {
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           mbs[k] = atoi(args[i]);
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           nbs[k] = atoi(args[i]);
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           kbs[k] = atoi(args[i]);
         }
         break;
      case 'b':
         if (nbs)
         {
            free(mbs);
            free(nbs);
            free(kbs);
         }
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         N = atoi(args[i]);
         if (N < 0)
         {
            ALL = (N == -2) ? 32 : -1;  /* -2: don't force MB */
            N = 36;
         }
         assert(N > 0);
         nbs = malloc(N*sizeof(int));
         assert(nbs);
         mbs = malloc(N*sizeof(int));
         assert(nbs);
         kbs = malloc(N*sizeof(int));
         assert(nbs);
         if (ALL)  /* special case to just try most possible NBs */
         {
            mbs[ 0]=nbs[ 0]=kbs[ 0]=4;
            mbs[ 1]=nbs[ 1]=kbs[ 1]=6;
            mbs[ 2]=nbs[ 2]=kbs[ 2]=8;
            mbs[ 3]=nbs[ 3]=kbs[ 3]=12;
            mbs[ 4]=nbs[ 4]=kbs[ 4]=14;
            mbs[ 5]=nbs[ 5]=kbs[ 5]=16;
            mbs[ 6]=nbs[ 6]=kbs[ 6]=20;
            mbs[ 7]=nbs[ 7]=kbs[ 7]=22;
            mbs[ 8]=nbs[ 8]=kbs[ 8]=24;
            mbs[ 9]=nbs[ 9]=kbs[ 9]=26;
            mbs[10]=nbs[10]=kbs[10]=28;
            mbs[11]=nbs[11]=kbs[11]=32;
            mbs[12]=nbs[12]=kbs[12]=36;
            mbs[13]=nbs[13]=kbs[13]=40;
            mbs[14]=nbs[14]=kbs[14]=44;
            mbs[15]=nbs[15]=kbs[15]=48;
            mbs[16]=nbs[16]=kbs[16]=52;
            mbs[17]=nbs[17]=kbs[17]=56;
            mbs[18]=nbs[18]=kbs[18]=60;
            mbs[19]=nbs[19]=kbs[19]=64;
            mbs[20]=nbs[20]=kbs[20]=72;
            mbs[21]=nbs[21]=kbs[21]=80;
            mbs[22]=nbs[22]=kbs[22]=84;
            mbs[23]=nbs[23]=kbs[23]=88;
            mbs[24]=nbs[24]=kbs[24]=96;
            mbs[25]=nbs[25]=kbs[25]=104;
            mbs[26]=nbs[26]=kbs[26]=112;
            mbs[27]=nbs[27]=kbs[27]=120;
            mbs[28]=nbs[28]=kbs[28]=128;
            mbs[29]=nbs[29]=kbs[29]=132;
            mbs[30]=nbs[30]=kbs[30]=144;
            mbs[31]=nbs[31]=kbs[31]=156;
            mbs[32]=nbs[32]=kbs[32]=168;
            mbs[33]=nbs[33]=kbs[33]=192;
            mbs[34]=nbs[34]=kbs[34]=216;
            mbs[35]=nbs[35]=kbs[35]=240;
            for (k=0; k < ALL; k++)     /* don't force any particular */
               mbs[k] = 0;              /* MB during search */
         }
         else
         {
            for (k=0; k < N; k++)
            {
              if (++i >= nargs)
                  PrintUsage(args[0], i-1, NULL);
               mbs[k] = kbs[k] = nbs[k] = atoi(args[i]);
            }
         }
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (B0 && mmb)
   {
      ATL_mmnode_t *mp;
      mp = BestBlocking_BFI(1, *PRE, mmb, B0, BN, KI, 0);
      KillMMNode(mmb);
      KillMMNode(mp);
      exit(0);
   }
   if (!nbs && !mmb)
      PrintUsage(args[0], -1, "Dimensional flag (-b or -B) or -S required!");
   *MBS = mbs;
   *NBS = nbs;
   *KBS = kbs;
   if (*PRE == 's' || *PRE == 'c')
   {
      VLEN[VTAVXZ] = 16;
      VLEN[VTAVX] = 8;
      VLEN[VTSSE] = 4;
      VLEN[VTGV] = 4;
      TSIZE = 4;
   }
   #ifdef ATL_AVXZ
      VECi = VTAVXZ;
   #elif defined(ATL_AVX)
      VECi = VTAVX;
   #elif defined(ATL_SSE1)
      if (*PRE == 's')
         VECi = VTSSE;
      #ifdef ATL_SSE2
      else
         VECi = VTSSE;
      #endif
   #elif (defined(ATL_AltiVec) && !defined(ATL_VSX)) || \
         (defined(ATL_NEON) && defined(ATL_NONIEEE) && ATL_NONIEEE != 0) || \
         (defined(ATL_3DNow) && defined(ATL_NONIEEE) && ATL_NONIEEE != 0)
      if (pre == 's')
         VECi = VTGV;
   #elif defined(ATL_VSX)
      VECi = VTGV;
   #endif
   *NN = N;
   return(mmb);
}

/*
 * Finds best-performing square cases from input list of good kernels, which
 * are first pruned of any losers (any kernel that is not faster than a
 * kernel with a smaller NB).
 */
ATL_mmnode_t *FindBestSquareKern(char pre, int verb, ATL_mmnode_t *mmb)
{
   ATL_mmnode_t *mmp, *mmSQ=NULL, *prev=NULL;
   int maxNB=0;

   mmb = HarshPrune(mmb);  /* kill uncompetitive kernels */
   assert(mmb);

   mmSQ = FindBestSquareCases(pre, verb, mmb);
   assert(mmSQ);
   KillAllMMNodes(mmb);
@skip   ApplyMoves2Flags(mmSQ, MOVES);  /* gen must know operand movement pattern */
   WriteMMFileWithPath(pre, "res", "uAMMFRC.sum", mmSQ);
   printf("DONE.\n");
   return(mmSQ);
}

int main(int nargs, char **args)
{
   int *nbs, *mbs, *kbs, verb, N, C=0, KCLEAN;
   float tol;
   char pre;
   ATL_mmnode_t *mmb, *mp, *mmB;
   double mfB;

   mmb = GetFlags(nargs, args, &pre, &verb, &N, &C, &mbs, &nbs, &kbs, &tol,
                  &KCLEAN);
/*
 * If -S is thrown, we take kernels from prior search, and just retune with
 * requirement that the kernels be square
 */
   if (mmb)
   {
      mmb = ApplyConstraints(mmb, C);
      assert(mmb);
      ApplyMoves2Flags(mmb, IMVS);
@beginskip
      if (MOVES)
      {
         for (mp=mmb; mp; mp = mp->next)
            mp->moves = DupString(MOVES);
      }
@endskip
      mmb = FindBestSquareKern(pre, verb, mmb);
   }
   else
   {
      char upr=pre;
      if (pre == 'z')
         upr = 'd';
      else if (pre == 'c')
         upr = 's';
      mmb = GetWorkingUserCases(verb, upr);  /* get all working kernels */
      mmb = ApplyConstraints(mmb, C);        /* reject disallowed kerns */
      ApplyMoves2Flags(mmb, IMVS);           /* indicate A/B/C movememnt */
      mmb = FindBestKerns(pre, verb, mmb, N, mbs, nbs, kbs, C, tol);
   }
   if (KCLEAN)
      ComputeKClean(verb, pre, mmb);
   mmb = ATL_SortMMNodesByMflop(0, mmb);
   mmB = ReadMMFileWithPath(pre, "res", "geAMMRES.sum");
   mmB = ATL_SortMMNodesByMflop(0, mmB);
   printf("\n");
   if (mmb)
      printf("YOUR BEST CASE: %d-%s, BLK=%d,%d,%d  %.2f\n", 
             mmb->ID, mmb->rout, mmb->mbB, mmb->nbB, mmb->kbB, mmb->mflop[0]);
   if (mmB)
   {
      printf("ATLAS BEST CASE: %d-%s, BLK=%d,%d,%d  %.2f\n", mmB->ID, 
             mmB->rout, mmB->mbB, mmB->nbB, mmB->kbB, mmB->mflop[0]);
      if (mmb)
         printf("   RATIO=%0.4f\n", mmb->mflop[0] / mmB->mflop[0]);
   }

   KillAllMMNodes(mmb);
   KillAllMMNodes(mmB);
   free(mbs);
   free(nbs);
   free(kbs);
@skip   if (MOVES)
@skip      free(MOVES);
   return(0);
}
@ROUT gmmsearch

int NumberBetaFails(FILE *fperr, char pre, int nb, ATL_mmnode_t *p)
{
   const int mu = p->mu, nu = p->nu, ku = p->ku;
   int mb = ((nb+mu-1)/mu)*mu, kb = ((nb+ku-1)/ku)*ku;
   int i, nfail = 0;

   if (kb < p->kbmin)
      kb = p->kbmin;
   if (p->kbmax && kb > p->kbmax)
      kb = p->kbmax;
   nb = ((nb+nu-1)/nu)*nu;
   for (i=(-1); i < 2; i++)
   {
      if (pre == 'z' || pre == 'c')  /* beta=0 case tests all 3 real betas */
         i = 0;
      if (MMKernelFailsTest(pre, mb, nb, kb, i, p))
      {
         if (fperr)
         {
            char *sp;
            fprintf(fperr, "FAIL: B=(%d,%d,%d), rout='%s', genstr='%s'\n", 
                    mb, nb, kb, p->rout?p->rout:"NULL", 
                    p->genstr?p->genstr:"NULL");
            sp = MMGetTestString(pre, mb, nb, kb, i, p);
            fprintf(fperr,"   '%s'\n", sp);
            free(sp);
         }
         nfail++;
      }
      if (pre == 'z' || pre == 'c')
         break;
   }
   return(nfail);
}
@beginskip
ATL_mmnode_t *FindVecVL(int verb, char pre, int NB)
/*
 * This search attempts to find both the best VLEN for this platform, and
 * if vectorizing K or M dimension provides the best performance for a problem
 * of roughly nb square.
 */
{
   int vl, vlB, kvecB=0, mb, nb, kb, mu, nu;
   double mf, mfB;
   char *vtyp;
   ATL_mmnode_t *mmB, *mmN;
   printf("\nSEARCHING FOR VEC TYPE AND LEN FOR PRE='%c':\n", pre);
   printf("    MB  NB  KB  VTYP  VLEN            MFLOP\n");
   printf("   === === ===  ====  ====  ===============\n");
/*
 * If we know the VLEN based on CPP defined, take that as our minimal VLEN.
 * We don't assume VLEN can't be larger, due to backwards compatability
 * (eg., an AVX machine would be detected as SSE): ATLAS could lack support
 * for newest standard, but gcc have it in gnuvec!
 * If VLEN unknown, start search at 2 (minimum len vector).
 */
   vl = GetNativeVLEN(pre);
   vl = Mmax(vl, 2);
   mu = vl >> 1;
   nu = 2;
   mb = (NB/mu)*mu;
   nb = (NB/nu)*nu;
   kb = NB;
   mmB = MMGetNodeGEN(pre, 0, kb, mu, nu, 1, 1, 0, 0, NULL);
   mfB = TimeMMKernel(2, 3, mmB, pre, mb, nb, kb, 1, 0, 0);
   printf("  %4d %3d %3d  %4s %5d  %15.0f\n", mb, nb, kb, "SCLR", 1, mfB);
   do
   {
   }
   while(0);
   if (mmB->vlen < 2)
      vtyp = "SCALAR";
   else if (FLAG_IS_SET(mmB->flag, MMF_KVEC))
      vtyp = "VEC-K";
   else 
      vtyp = "VEC-M";
   mmB->mflop[3] = mfB;
   printf("BEST VEC IS '%s', VLEN=%d, MFLOP=%e\n", vtyp, mmB->vlen, mfB);
   return(mmB);
}
@endskip

/*
 * RETURNS: 0 if bcast slower than ld/splat combo
 */
int UseBcast(int flg, int verb, char pre, int kb, int nreg, int VL)
{
   int nu=VL, mu, mb, nb, TEST=flg&1;
   ATL_mmnode_t *mpBC, *mpNO;
   double mfBC, mfNO;

   if (VL < 2)
      return(1);
   mu = (nreg-nu-1) / (nu+1);
   if (mu < 2)
      mu = (nreg - 2) / (nu+1);
   mu = (mu) ? mu : 1;
   mb = ((kb+mu-1)/mu)*mu;
   nb = ((kb+nu-1)/nu)*nu;
   mpBC = MMGetNodeGEN(pre, 0, nb, mu*VL, nu, 1, VL, 0, 0, 0, NULL);
   mpNO = MMGetNodeGEN(pre, 1, nb, mu*VL, nu, 1, VL, 0, 0, 0, NULL);
   printf("TIMING BCAST VS SPLAT MVEC WITH: B=(%d,%d,%d) U=(%d,%d,1)\n",
          mb, nb, kb, mu, nu);
   mfBC = TimeMMKernel(verb, 1, mpBC, pre, mb, nb, kb, 1, 0, -1);
   printf("   BCAST = %.0f MFLOP\n", mfBC);
   mfNO = TimeMMKernel(verb, 1, mpNO, pre, mb, nb, kb, 1, 0, -1);
   printf("   SPLAT = %.0f MFLOP\n", mfNO);
   if (TEST)
   {
      printf("   TESTING . . .");
      assert(!NumberBetaFails(stderr, pre, nb, mpBC));
      printf("  . . . ");
      assert(!NumberBetaFails(stderr, pre, nb, mpNO));
      printf("   PASS!\n");
   }
   KillMMNode(mpBC);
   KillMMNode(mpNO);
   if (mfNO > mfBC)
   {
      printf("VLD/VSPLAT PROVIDES %.4f SPEEDUP\n", mfNO/mfBC);
      return(0);
   }
   printf("VBCAST PROVIDES %.4f SPEEDUP\n", mfBC/mfNO);
   return(1);
}

ATL_mmnode_t *DoSyrkMUNU
   (int flg, int vrb, char pre, int nreg, int nb, int kb, int VL)
{
   ATL_mmnode_t *pM, *pB, *pK, *mp;
   double mfB = 0.0;
   int i, j, uB=VL, bcB=1, kvecB=0, kbB=0;
   const char *frm="   %c%c %4d %4d %3d %9.0f\n";

   pM = MMGetNodeGEN(pre, 0, 0, VL, 1, 1, VL, 0, 0, 0, DupString("ATL_tmp.c"));
   pB = MMGetNodeGEN(pre, 1, 0, VL, 1, 1, VL, 0, 0, 0, DupString("ATL_tmp.c"));
   pK = MMGetNodeGEN(pre, 0, 0, 1, 1, VL, VL, 1, 0, 0, DupString("ATL_tmp.c"));
   pM->blask = pB->blask = pK->blask = 1;
   pK->next = pM;
   pM->next = pB;

   pM->ku = pB->ku = 1;
   pM->kbB = pB->kbB = kb;
   pK->ku = VL;
   pK->kbB = ((kb+VL-1)/VL)*VL;
   free(pM->genstr); free(pB->genstr); free(pK->genstr);

   printf("Full search for SYRK kernel for nb=%d, NREG=%d, VLEN=%d\n",
          nb, nreg, VL);
   printf("   VD   NB   KB  NU      MFLOP\n");
   printf("   ==  ===  ===  ==  =========\n");
   for (i=1; i <= nreg; i++)
   {
      for (j=1; j <= nreg; j++)
      {
         if (i*j+1 > nreg || j > nb)
            continue;
         if (i*VL == j) /* legal M-vectorized SYRK kernel */
         {
            const int b = (nb > j) ? (nb/j)*j : j;
            double mf;

            pB->mu = pB->nu = pM->mu = pM->nu = j;
            pB->mbB = pB->nbB = pM->mbB = pM->nbB = b;
            pM->genstr = MMGetGenString(pre, pM);
            pB->genstr = MMGetGenString(pre, pB);
            mf = TimeMMKernel(vrb, 0, pM, pre, b, b, kb, 1, 0, -1);
            assert(!MMKernelFailsTest(pre, b, b, kb, 1, pM));
            printf(frm, 'M', 'b', b, kb, j, mf);
            if (mf > mfB)
            {
               mfB = mf;
               uB = j;
               kvecB = 0;
               bcB = 0;
               kbB = kb;
            }
            mf = TimeMMKernel(vrb, 0, pB, pre, b, b, kb, 1, 0, -1);
            assert(!MMKernelFailsTest(pre, b, b, kb, 1, pB));
            printf(frm, 'M', 's', b, nb, j, mf);
            if (mf > mfB)
            {
               mfB = mf;
               uB = j;
               kvecB = 0;
               bcB = 1;
               kbB = kb;
            }
            free(pM->genstr);
            free(pB->genstr);
         }
         if (i == j)    /* legal k-vectorized SYRK kernel */
         {
            const int b = (nb > j) ? (nb/j)*j : j;
            double mf;

            pK->mbB = pK->nbB = b;
            pK->mu = pK->nu = j;
            pK->genstr = MMGetGenString(pre, pK);
            mf = TimeMMKernel(vrb, 0, pK, pre, b, b, pK->kbB, 1, 0, -1);
            assert(!MMKernelFailsTest(pre, b, b, pK->kbB, 1, pK));
            printf(frm, 'K', ' ', b, nb, j, mf);
            if (mf > mfB)
            {
               mfB = mf;
               uB = j;
               kvecB = VL;
               bcB = 1;
               kbB = pK->kbB;
            }
            free(pK->genstr);
         }
      }
   }
   pM->genstr = pK->genstr = pB->genstr = NULL;
   KillAllMMNodes(pK);
   printf("Done.\n");
   pK = MMGetNodeGEN(pre, bcB, 0, uB, uB, kvecB ? kvecB:1, VL, kvecB, 
                      0, 0, NULL);
   pK->blask = 1;
   pK->mflop[0] = mfB;
   pK->mbB = pK->nbB = nb;
   pK->kbB = kbB;
   pK->blask = 1;
   return(pK);
}
@beginskip
ATL_mmnode_t *GetSyrkCases(int flg, int vrb, char pre, int nreg, int nb, int VL)
{
   ATL_mmnode_t *mb, *mp, *mp4;

   mb = TimeMMFileWithPath(pre, "res", "gAMSYRKU.sum", 0, vrb, 0, 1, 0, -1);
   if (mb)
      return(mb);
/*
 * Find candidate kernels for large and small problems
 */
   mb = DoSyrkMUNU(flg, vrb, pre, nreg, nb, VL);
   mp = mb->next = DoSyrkMUNU(flg, vrb, pre, nreg, 16, Mmin(VL,16));
   mp->next = DoSyrkMUNU(flg, vrb, pre, nreg, 8, Mmin(VL,8));
   mp = mp->next;
   mp->next = DoSyrkMUNU(flg, vrb, pre, nreg, 4, Mmin(VL,4));
   WriteRefreshedMMFileWithPath(pre, "res", "gAMSYRKU.sum", mb);
   return(mb);
}
@endskip

ATL_mmnode_t *FullSrchMUNU(int flg, int verb, char pre, int nreg, int nb, 
                           int VL, int KVEC)
{
   char fn[32];
   ATL_mmnode_t *mmp;
   double mf, mfB=0.0;
   const int CHK=(flg&1), ku = (KVEC) ? VL : 1;
   int n, i, j, mbB, nbB, kbB, muB=1, nuB=1;
   char ch;

   assert(VL < 1000 && nreg < 1000);  /* don't overflow fn len */
   if (VL < 2)
      ch = 'U';
   else
      ch = (KVEC) ? 'K':'M';
   sprintf(fn, "gAMMUR_%c%d_%d.sum", ch, VL, nreg);
   mmp = ReadMMFileWithPath(pre, "res", fn);
   if (mmp)
   {
      MMFillInGenStrings(pre, mmp);
      TimeNegMMKernels(0, verb, 0, mmp, pre, 1, 0, -1);
      WriteMMFileWithPath(pre, "res", fn, mmp);
      return(mmp);
   }
   assert(nb%VL == 0);
   mmp = MMGetNodeGEN(pre, 0, nb, 1, 1, ku, 1, KVEC, 0, 0,
                      DupString("ATL_Xamm_munu.c"));
   mmp->rout[4] = pre;
   mmp->mbB = mmp->nbB = mmp->kbB = nb;
   mmp->vlen = VL;
   if (KVEC)
      mmp->flag |= (1<<MMF_KVEC);
   else if (!UseBcast(flg, verb, pre, nb, nreg, VL))
      mmp->flag |= (1<<MMF_NOBCAST);
/*
 * Try all MU/NU unrollings
 */
   printf("Full search on MUxNU for nb=%d, NREG=%d, VLEN=%d, KVEC=%d\n",
          nb, nreg, VL, KVEC);
   for (i=1; i <= nreg; i++)
   {
      for (j=1; j <= nreg; j++)
      {
@skip         int ONETIME=0;
         int mbu, nbu, mu, nu;
         if (i*j+Mmin(i,j)+1 > nreg)
            continue;
@beginskip
         if (KVEC)  /* vec on K needs mu*nu mult of VLEN */
         {
            if (VL >= nreg)
            {
               ONETIME=1;
               i = VL;
               j = 1;
            }
            else if ((i*j)%VL)
               continue;
            mu = i;
         }
         else /* vect on M dim need mu multiple of VLEN */
@endskip
         mu = (KVEC) ? i : i*VL;
         nu = j;
         mmp->mu = mu;
         mmp->nu = nu;
         if (mmp->genstr)
           free(mmp->genstr);
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         mmp->genstr = MMGetGenString(pre, mmp);
         mf = TimeMMKernel(verb, 0, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (CHK)
         {
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
         }
         if (mf > mfB)
         {
            mbB = mbu;
            nbB = nbu;
            kbB = nb;
            muB = mu;
            nuB = nu;
            mfB = mf;
         }
@skip         if (ONETIME)
@skip            goto DONE;
      }
   }
DONE:
   assert(mfB > 0.0);
   i = FLAG_IS_SET(mmp->flag, MMF_NOBCAST);
   KillMMNode(mmp);
   mmp = MMGetNodeGEN(pre, i, nb, muB, nuB, ku, VL, KVEC, 0, 0, NULL);
   mmp->mbB = mbB;
   mmp->nbB = nbB;
   mmp->kbB = kbB;
   mmp->mflop[0] = mfB;
   printf("BEST FULL-SEARCH CASE IS B=(%d,%d,%d), U=(%d,%d) MFLOP=%.2f\n\n", 
          mbB, nbB, kbB, muB, nuB, mfB);
   WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
   return(mmp);
}

ATL_mmnode_t *SrchNU(int flg, int verb, char pre, int nreg, int nb, int VL, 
                     int I)
/*
 * M-vectorized search for with mu=I*VLEN.  It allows us to find a case
 * that can handle smaller blocks with VLEN is long.
 */
{
   char fn[32];
   ATL_mmnode_t *mmp;
   double mf, mfB=0.0;
   const int CHK=(flg&1), mu = I*VL;
   int n, i, j, mbB, nbB, kbB, nuB=1, mbu;

   sprintf(fn, "gAMMUR_MU%d_M%d_%d.sum", I, VL, nreg);
   mmp = ReadMMFileWithPath(pre, "res", fn);
   if (mmp)
   {
      MMFillInGenStrings(pre, mmp);
      TimeNegMMKernels(0, verb, 0, mmp, pre, 1, 0, -1);
      WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
      return(mmp);
   }
   mmp = MMGetNodeGEN(pre, 0, nb, 1, 1, 1, 1, 0, 0, 0, 
                      DupString("ATL_Xamm_munu.c"));
   mmp->rout[4] = pre;
   mmp->mbB = mmp->nbB = mmp->kbB = nb;
   mmp->vlen = VL;
   mmp->mu = mu;
   mbu = (nb >= mu) ? (nb/mu)*mu : mu;
   if (!UseBcast(flg, verb, pre, nb, nreg, VL))
      mmp->flag |= (1<<MMF_NOBCAST);
/*
 * Try all powers of 2 MU/NU unrollings
 */
   printf("Searching M-VEC MU=%d xNU case for mb=%d, kb=%d, NREG=%d, VLEN=%d\n",
          I, mbu, nb, nreg, VL);
   for (j=1; j <= nreg; j++)
   {
      int nbu, nu;
      if (I*j+Mmin(I,j)+1 > nreg)
         continue;
      nu = j;
      mmp->nu = nu;
      if (mmp->genstr)
        free(mmp->genstr);
      nbu = (nb >= nu) ? (nb/nu)*nu : nu;
      mmp->genstr = MMGetGenString(pre, mmp);
      mf = TimeMMKernel(verb, 0, mmp, pre, mbu, nbu, nb, 1, 0, -1);
      printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", I, j, mf);
      if (CHK)
      {
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
      }
      if (mf > mfB)
      {
         mbB = mbu;
         nbB = nbu;
         kbB = nb;
         nuB = nu;
         mfB = mf;
      }
   }
   i = FLAG_IS_SET(mmp->flag, MMF_NOBCAST);
   KillMMNode(mmp);
   if (mfB == 0.0)  /* no legal kern found! */
   {
      printf("NO LEGAL KERNS FOR MU=%d!\n", I);
      return(NULL);
   }
   mmp = MMGetNodeGEN(pre, i, nb, mu, nuB, 1, VL, 0, 0, 0, NULL);
   mmp->mbB = mbB;
   mmp->nbB = nbB;
   mmp->kbB = kbB;
   mmp->mflop[0] = mfB;
   assert(mfB > 0.0);
   printf("BEST MU=%d CASE IS B=(%d,%d,%d) U=(%d,%d), MFLOP=%.2f\n\n", 
          I, mbB, nbB, kbB, mu, nuB, mfB);
   WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
   return(mmp);
}

ATL_mmnode_t *SrchMUNUp2(int flg, int verb, char pre, int nreg, int nb,
                         int VL, int KVEC)
{
   char fn[32];
   ATL_mmnode_t *mmp;
   double mf, mfB=0.0;
   const int CHK=(flg&1), ku = (KVEC) ? VL : 1;
   int n, i, j, mbB, nbB, kbB, muB=1, nuB=1;
   char ch;

   if (VL < 2)
      ch = 'U';
   else
      ch = (KVEC) ? 'K':'M';
   sprintf(fn, "gAMMURP2_%c%d_%d.sum", ch, VL, nreg);
   mmp = ReadMMFileWithPath(pre, "res", fn);
   if (mmp)
   {
      MMFillInGenStrings(pre, mmp);
      TimeNegMMKernels(0, verb, 0, mmp, pre, 1, 0, -1);
      WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
      return(mmp);
   }
   mmp = MMGetNodeGEN(pre, 0, nb, 1, 1, ku, 1, KVEC, 0, 0,
                      DupString("ATL_Xamm_munu.c"));
   mmp->rout[4] = pre;
   mmp->mbB = mmp->nbB = mmp->kbB = nb;
   mmp->vlen = VL;
   if (KVEC)
      mmp->flag |= (1<<MMF_KVEC);
   else if (!UseBcast(flg, verb, pre, nb, nreg, VL))
      mmp->flag |= (1<<MMF_NOBCAST);
/*
 * Try all powers of 2 MU/NU unrollings
 */
   printf("Searching PWR-2 MUxNU cases for nb=%d, NREG=%d, VLEN=%d, KVEC=%d\n",
          nb, nreg, VL, KVEC);
@beginskip
/*
 * Long VLEN with small NREG can be impossible to do with mu*nu%VLEN==0,
 * so force at least one case even if it overruns registers
 */
@endskip
   for (i=1; i <= nreg; i += i)
   {
      for (j=1; j <= nreg; j += j)
      {
@skip         int ONETIME=0;
         int mbu, nbu, mu, nu;
         if (i*j+Mmin(i,j)+1 > nreg)
            continue;
@beginskip
         if (KVEC)  /* vec on K needs mu*nu mult of VLEN */
         {
            if (VL >= nreg)
            {
               ONETIME = 1;
               i=VL;
               j=1;
            }
            else if ((i*j)%VL)
               continue;
            mu = i;
         }
         else /* vect on M dim need mu multiple of VLEN */
@endskip
         mu = (KVEC) ? i : i*VL;
         nu = j;
         mmp->mu = mu;
         mmp->nu = nu;
         if (mmp->genstr)
           free(mmp->genstr);
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         mmp->genstr = MMGetGenString(pre, mmp);
         mf = TimeMMKernel(verb, 0, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (CHK)
         {
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
         }
         if (mf > mfB)
         {
            mbB = mbu;
            nbB = nbu;
            kbB = nb;
            muB = mu;
            nuB = nu;
            mfB = mf;
         }
@skip         if (ONETIME)
@skip            goto DONE;
      }
   }
DONE:
   assert(mfB != 0.0);
   i = FLAG_IS_SET(mmp->flag, MMF_NOBCAST);
   KillMMNode(mmp);
   mmp = MMGetNodeGEN(pre, i, nb, muB, nuB, ku, VL, KVEC, 0, 0, NULL);
   mmp->mbB = mbB;
   mmp->nbB = nbB;
   mmp->kbB = kbB;
   mmp->mflop[0] = mfB;
   printf("BEST POW2 CASE IS B=(%d,%d,%d) U=(%d,%d), MFLOP=%.2f\n\n", 
          mbB, nbB, kbB, muB, nuB, mfB);
   WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
   return(mmp);
}

ATL_mmnode_t *SrchMUNU(int flg, int verb, char pre, int nreg, int nb, 
                       int VL, int KVEC)
{
   ATL_mmnode_t *mmp, *mmp2;
   char fn[32];
   double mf, mfB=0.0;
   const int CHK=(flg&1), ku = (KVEC) ? VL : 1;
   #if (defined(ATL_GAS_x8664) || defined(ATL_GAS_x8632)) && !defined(ATL_AVX)
      int DO1D=1;
   #else
      int DO1D=(nreg < 9 || nreg < VL);
   #endif
   int n, i, j, kb, mbB, nbB, kbB, muB=1, nuB=1;
   char ch;

   if (flg&2)
      return(FullSrchMUNU(flg, verb, pre, nreg, nb, VL, KVEC));
   mmp2 = SrchMUNUp2(flg, verb, pre, nreg, nb, VL, KVEC);
   assert(VL < 1000 && nreg < 1000);  /* don't overflow fn len */
   if (VL < 2)
      ch = 'U';
   else
      ch = (KVEC) ? 'K':'M';
   sprintf(fn, "gAMMUR_%c%d_%d.sum", ch, VL, nreg);
   mmp = ReadMMFileWithPath(pre, "res", fn);
   if (mmp)
   {
      KillAllMMNodes(mmp2);
      MMFillInGenStrings(pre, mmp);
      TimeNegMMKernels(0, verb, 0, mmp, pre, 1, 0, -1);
      WriteMMFileWithPath(pre, "res", fn, mmp);
      return(mmp);
   }
   mmp = MMGetNodeGEN(pre, 0, nb, 1, 1, ku, 1, KVEC, 0, 0,
                      DupString("ATL_Xamm_munu.c"));
   mmp->rout[4] = pre;
   mmp->mbB = mmp->nbB = mmp->kbB = nb;
   mmp->vlen = VL;
   if (KVEC)
      mmp->flag |= (1<<MMF_KVEC);
   else if (!UseBcast(flg, verb, pre, nb, nreg, VL))
      mmp->flag |= (1<<MMF_NOBCAST);
/*
 * Try all near-square register blocking cases
 */
   printf("Finding best MUxNU case for nb=%d, NREG=%d, VLEN=%d, KVEC=%d\n",
          nb, nreg, VL, KVEC);
   for (n=4; n <= nreg; n++)
   {
@skip      int ONETIME=0;
      int mbu, nbu, mu, nu;
      for (j=1; j*j < n; j++);
      i = n / j;
      if (nb%i || nb%j)
         continue;
@beginskip
      if (KVEC)
      {
         if (VL >= nreg)
         {
            ONETIME = 1;
            i = VL;
            j = 1;
         }
         else if ((i*j)%VL)
            continue;
      }
@endskip
      mu = (KVEC) ? i : i*VL;
      nu = j;
      mmp->mu = mu;
      mmp->nu = nu;
      if (mmp->genstr)
        free(mmp->genstr);
      mbu = (nb >= mu) ? (nb/mu)*mu : mu;
      nbu = (nb >= nu) ? (nb/nu)*nu : nu;
      mmp->genstr = MMGetGenString(pre, mmp);
      mf = TimeMMKernel(verb, 0, mmp, pre, mbu, nbu, nb, 1, 0, -1);
      printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
      if (CHK)
      {
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
         assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
      }
      if (mf > mfB)
      {
         mbB = mbu;
         nbB = nbu;
         kbB = nb;
         muB = mu;
         nuB = nu;
         mfB = mf;
      }
@skip      if (ONETIME)
@skip         break;
   }
/*
 * For non-AVX x86, try 1-D cases since they are 2-operand assemblies; always
 * try 1-D for low registers
 */
   if (DO1D)
   {
      printf("BEST NEAR-SQUARE CASE IS MU=%d, NU=%d, MFLOP=%.2f\n\n", 
             muB, nuB, mfB);
      printf("Finding best 1-D outer loop unrolling for nb=%d\n", nb);
      for (n=2; n <= nreg; n++)
      {
         int mbu, nbu, mu, nu;
         i = 1; j = n;
         if (nb % n)
            continue;
         mu = (KVEC) ? i : i*VL;
         nu = mmp->nu = j;
         if (mmp->genstr)
           free(mmp->genstr);
         mmp->genstr = MMGetGenString(pre, mmp);
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         mf = TimeMMKernel(verb, 0, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (CHK)
         {
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
         }
         if (mf > mfB)
         {
            muB = i;
            nuB = j;
            mfB = mf;
         }
         i = n; j = 1;
         mu = mmp->mu = (KVEC) ? i : i * VL;
         nu = mmp->nu = j;
         mbu = (nb >= mu) ? (nb/mu)*mu : mu;
         nbu = (nb >= nu) ? (nb/nu)*nu : nu;
         if (mmp->genstr)
           free(mmp->genstr);
         mmp->genstr = MMGetGenString(pre, mmp);
         mf = TimeMMKernel(verb, 1, mmp, pre, mbu, nbu, nb, 1, 0, -1);
         printf("   MU=%2d, NU=%2d, MFLOP=%.2f\n", i, j, mf);
         if (CHK)
         {
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 1, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, 0, mmp));
            assert(!MMKernelFailsTest(pre, mbu, nbu, nb, -1, mmp));
         }
         if (mf > mfB)
         {
            muB = i;
            nuB = j;
            mfB = mf;
         }
      }
   }

   assert(mfB > 0.0);
   i = FLAG_IS_SET(mmp->flag, MMF_NOBCAST);
   KillMMNode(mmp);
   mmp = MMGetNodeGEN(pre, i, nb, muB, nuB, ku, VL, KVEC, 0, 0, NULL);
   mmp->mbB = mbB;
   mmp->nbB = nbB;
   mmp->kbB = kbB;
   mmp->mflop[0] = mfB;
   if (mmp->mflop[0] < mmp2->mflop[0])
   {
      printf("Taking pow2 srch (%d,%d:%.0f) over square (%d,%d:%.0f)\n",
             mmp2->mu, mmp2->nu, mmp2->mflop[0],
             mmp->mu, mmp->nu, mmp->mflop[0]);
      KillMMNode(mmp);
      mmp = mmp2;
   }
   else
      KillAllMMNodes(mmp2);
   WriteRefreshedMMFileWithPath(pre, "res", fn, mmp);
   printf("BEST CASE IS B=(%d,%d,%d), U=(%d,%d), MFLOP=%.2f\n\n", 
          mmp->mbB, mmp->nbB, mmp->kbB, mmp->mu, mmp->nu, mmp->mflop[0]);
   return(mmp);
}

#if 0
/* this idea doesn't really work */
int FindKvecXover(int flg, int verb, char pre, int nreg, int VL, int nb)
/*
 * On some machines, vectorizing the M dim will win for small problems,
 * due to not needing to the summation at the end of the K-loop.  However,
 * once this cost is dominated by the K-loop, K dim vectorization can
 * start to win, possibly by reducing the C write traffic, as well as
 * avoiding vec bcast inside the K-loop.
 *
 * For finding this crossover, we use best pw2 M/K, since we can be sure
 * they can always use a pwr2 block factor for direct comparison.  If pwr2
 * cases are much different than normal, this may cause problems!
 * IDEA: Read in normal MUNU results, and don't use this test if gap is wide.
 */
{
   ATL_mmnode_t *mmM, *mmK; 
   double mfM, mfK;
   int b, b0;

   mmM = SrchMUNUp2(flg, verb, pre, nreg, nb, VL, 0);
   mmK = SrchMUNUp2(flg, verb, pre, nreg, nb, VL, 1);
   printf("FINDING NB CROSSOVER FOR M- AND K-VECTORIZATION:");
   b = Mmax(mmM->mu, mmK->mu);
   b = Mmax(b, mmM->nu);
   b = Mmax(b, mmK->nu);
   b = Mmax(b,16);
   b0 = b;
   while (b < 512)
   {
      mfM = TimeMMKernel(verb, 0, mmM, pre, b, b, b, 1, 0, -1);
      mfK = TimeMMKernel(verb, 0, mmK, pre, b, b, b, 1, 0, -1);
      printf("   B=%d, mflopM=%.0f, mflopK=%.0f\n", b, mfM, mfK);
      if (mfK > mfM*1.02)
         break;
      b += b;
   }
   if (b == b0)
   {
      printf("K-VECTORIZATION BETTER FROM FIRST BLOCK!\n");
      b = 1;            /* Kvec always better */
   }
   else if (b == 512)
   {
      printf("M-VECTORIZATION ALWAYS BETTER\n");
      b = 0;            /* Kvec never better */
   }
   else
      printf("K-VEC BEGINS WINNING AROUND %d\n", b);
   return(b);
}
#endif

void FindDefMUNU(int flg, int verb, char pre, int nb, int *NREG, int *VLEN)
{
   ATL_mmnode_t *mp, *mmM, *mmK;
   int nreg=(*NREG), VL=(*VLEN), chkNR=0, chkVL=0;

   if (nreg < 1)
      nreg = GetNumVecRegs(pre);
   if (nreg < 1)
   {
      #ifdef ATL_GAS_x8632
         nreg = 8;
      #else
         nreg = 16;
      #endif
      chkNR = 1;
   }
   if (VL < 1)
      VL = GetNativeVLEN(pre);
   if (!VL)
   {
      VL = (pre == 'c' || pre == 's') ? 4:2;
      chkVL = 1;
   }
/* 
 * Always do full search for low number of registers, where this is only search
 */
   if (!chkNR && nreg > 0 && nreg < 20)
      flg |= 2;
   mmM = SrchMUNU(flg, verb, pre, nreg, nb, VL, 0);
   mmK = SrchMUNU(flg, verb, pre, nreg, nb, VL, 1);
   printf("MVEC: B=(%d,%d,%d) mu=%d, nu=%d, MFLOP=%.0f\n",
          mmM->mbB,  mmM->nbB,  mmM->kbB, mmM->mu, mmM->nu, mmM->mflop[0]);
   printf("KVEC: B=(%d,%d,%d) mu=%d, nu=%d, MFLOP=%.0f\n",
          mmK->mbB,  mmK->nbB,  mmK->kbB, mmK->mu, mmK->nu, mmK->mflop[0]);
/*
 * After this, fastest code in mmM, slowest mmK
 */
   if (mmK->mflop[0] > mmM->mflop[0])
   {
      mp = mmK;
      mmK = mmM;
      mmM = mp;
   }
   KillAllMMNodes(mmK);
/*
 * If we only guessed a lower bound on # regs, try some searches with
 * increasing regs
 */
   if (chkNR)
   {
      const int KVEC = FLAG_IS_SET(mmM->flag, MMF_KVEC);
      int i, nr = nreg+nreg;
      printf("NREG=%d, U=(%d,%d): MFLOP=%.0f\n", 
             nreg, mmM->mu, mmM->nu, mmM->mflop[0]);
      for (i=0; i < 4; i++)  /* sanity check for stopping */
      {
         mp = SrchMUNU(flg, verb, pre, nr, nb, VL, KVEC);
         printf("NREG=%d, U=(%d,%d): MFLOP=%.0f\n", 
                nr, mp->mu, mp->nu, mp->mflop[0]);
         if (mp->mu*mp->nu + mp->mu + 1 <= (nr>>1)) /* did not use more regs */
            break;
         if (mp->mflop[0] < 1.03*mmM->mflop[0])     /* perf not better */
            break;
         KillMMNode(mmM);
         mmM = mp;
         nreg = nr;
         nr += nr;
      }
   }
/*
 * Now that we are confident in our NREG, see if we need to confirm VLEN
 */
   if (chkVL)
   {
   }
   *NREG = nreg;
   *VLEN = VL;
#if 0
/*
 * Now see if K-vec has a crossover with M-vec
 */
   FindKvecXover(flg, verb, pre, nreg, VL, nb);
#endif
   KillAllMMNodes(mmM);
}

void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
   fprintf(stderr, "   -r <nreg> : set max # of registers to try\n");
   fprintf(stderr, "   -V <vlen> : force vector length\n");
   fprintf(stderr, "   -b <nb>   : set initial block factor to try\n");
   fprintf(stderr, "   -v <verb> : set verbosity (1)\n");
   fprintf(stderr, "   -T 1      : test all legal kerns, and exit\n");
   fprintf(stderr, 
           "   -f <flg>  : bitvec for srch control, add vals you want set:\n");
   fprintf(stderr, "        1: test all generated kernels\n");
   fprintf(stderr, "        2: do full MUxNU search\n");
   fprintf(stderr, "        4: print # of regs to res/<pre>nreg\n");
   fprintf(stderr, "        8: pref tune & time kerns in time.sum & exit\n");
   fprintf(stderr, "       16: create [d,s]flops.frc and return\n");
   fprintf(stderr, "      DEFAULT: all bits unset\n");
   exit(ierr ? ierr : -1);
}

void GetFlags(int nargs, char **args, int *FLG, int *VERB, char *PRE, int *NREG,
              int *VLEN, int *NB, int *TEST)
{
   int i, flg=0, nreg=0;
   char pre = 'd';

   *VERB = 0;
   *NB = 120;
   *VLEN = 0;
   *TEST = 0;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        assert(pre == 's' || pre == 'd' || pre == 'z' || pre == 'c');
        break;
      case 'T':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *TEST = atoi(args[i]);
         break;
      case 'V':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *VLEN = atoi(args[i]);
         break;
      case 'f':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         flg = atoi(args[i]);
         break;
      case 'r':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         nreg = atoi(args[i]);
         break;
      case 'v':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *VERB = atoi(args[i]);
         break;
      case 'b':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *NB = atoi(args[i]);
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (!nreg)
      nreg = GetNumVecRegs(pre);
   *PRE = pre;
   *FLG = flg;
   *NREG = nreg;
}

/*
 * Using best discovered kernel, figure out the largest NB < 512 that
 * gets good performance
 */
int GetMaxNB(int flag, int verb, char pre, ATL_mmnode_t *mp)
{
   int inc, i, bB=0, badrow=0;
   double mf, mfB=0.0;

   printf("FINDING RANGE OF NB FOR GENKERN MU=%d, NU=%d, %cVEC=%d:\n",
          mp->mu, mp->nu, FLAG_IS_SET(mp->flag, MMF_KVEC)?'K':'M', mp->vlen);
   inc = Mylcm(mp->mu, mp->nu);
   inc = Mylcm(inc,mp->ku);
   while (inc < 12)
      inc += inc;

   for (i=inc; i < 512; i += inc)
   {
       mf = TimeMMKernel(verb, 0, mp, pre, i, i, i, 1, 0, -1);
       printf("   NB=%d, mf=%.0f\n", i, mf);
       if (mf > mfB)
       {
          bB=i;
          mfB = mf;
       }
       else badrow++;
       if (badrow > 4)
          break;
   }
   mp->mbB = mp->kbB = mp->nbB = bB;
   mp->mflop[0] = mfB;
   printf("BEST SQUARE NB=%d (%.0f)\n", bB, mfB);
   return(bB+inc-1);
}

void FindInfo(int flag, int verb, char pre, int NB, int *NREG, int *VLEN)
{
   const int WNR=(flag&4);
   int nreg=(*NREG), vlen=(*VLEN);
   ATL_mmnode_t *mp, *mpN;

   if (pre == 'z')
      pre = 'd';
   else if (pre == 'c')
      pre = 's';

   mp = ReadMMFileWithPath(pre, "res", "gmvAMMUR.sum");
   mpN = ReadMMFileWithPath(pre, "res", "gkvAMMUR.sum");
   if (mp && mpN)
   {
      *VLEN = mp->vlen;
      *NREG = mp->ivar;
      MMFillInGenStrings(pre, mp);
      MMFillInGenStrings(pre, mpN);
      TimeNegMMKernels(0, verb, 0, mp, pre, 1, 0, -1);
      TimeNegMMKernels(0, verb, 0, mpN, pre, 1, 0, -1);
      WriteRefreshedMMFileWithPath(pre, "res", "gmvAMMUR.sum", mp);
      WriteRefreshedMMFileWithPath(pre, "res", "gkvAMMUR.sum", mpN);
      KillAllMMNodes(mp);
      KillAllMMNodes(mpN);
      if (WNR)
      {
         FILE *fp;
         char fn[12];
         sprintf(fn, "res/%cnreg", pre);
         fp = fopen(fn, "w");
         fprintf(fp, "%d\n", *NREG);
         fclose(fp);
      }
      return;
   }
   else if (mp)
      KillAllMMNodes(mp);
   else if (mpN)
      KillAllMMNodes(mpN);
   FindDefMUNU(flag, verb, pre, NB, &nreg, &vlen);
   printf("\nNREG=%d, VLEN=%d\n", nreg, vlen);
/*
 * With nreg & vlen set, create output with best K- & M- vectorized code
 * in standard names with nreg in mp->ivar
 */
   mp = SrchMUNU(flag, verb, pre, nreg, NB, vlen, 0);
   mpN = SrchMUNUp2(flag, verb, pre, nreg, NB, vlen, 0);
   mpN->next = SrchNU(flag, verb, pre, nreg, NB, vlen, 1);
   if (mpN->next)
   {
      mpN->next->next = SrchNU(flag, verb, pre, nreg, NB, vlen, 2);
      if (mpN->next->next)
          mpN->next->next->next = SrchNU(flag, verb, pre, nreg, NB, vlen, 3);
   }
   mp = AddUniqueMMKernCompList(mp, mpN);
   KillAllMMNodes(mpN);
   mp = ReverseMMQ(mp);
   mp->ivar = nreg;
   WriteRefreshedMMFileWithPath(pre, "res", "gmvAMMUR.sum", mp);
   KillAllMMNodes(mp);

   mp = SrchMUNU(flag, verb, pre, nreg, NB, vlen, 1);
   mp->ivar = nreg;
   mpN = SrchMUNUp2(flag, verb, pre, nreg, NB, vlen, 1);
   mp = AddUniqueMMKernCompList(mp, mpN);
   KillAllMMNodes(mpN);
   mp = ReverseMMQ(mp);
   WriteRefreshedMMFileWithPath(pre, "res", "gkvAMMUR.sum", mp);
   KillAllMMNodes(mp);
   if (WNR)
   {
      FILE *fp;
      char fn[12];
      sprintf(fn, "res/%cnreg", pre);
      fp = fopen(fn, "w");
      fprintf(fp, "%d\n", nreg);
      fclose(fp);
   }
   *VLEN = vlen;
   *NREG = nreg;
}
ATL_mmnode_t *GetBestKernVT(char pre, char vt)
{
   ATL_mmnode_t *mp;
   if (vt == 'K')
      mp = ReadMMFileWithPath(pre, "res", "gkvAMMUR.sum");
   else
      mp = ReadMMFileWithPath(pre, "res", "gmvAMMUR.sum");
   assert(mp);
   if (mp->next)
   {
      KillAllMMNodes(mp->next);
      mp->next = NULL;
   }
   return(mp);
}

ATL_mmnode_t *GetBestKern(char pre)
{
   ATL_mmnode_t *mp, *mpB;
   mpB = GetBestKernVT(pre, 'M');
   mp =  GetBestKernVT(pre, 'K');
   if (mp->mflop[0] > mpB->mflop[0])
   {
      KillAllMMNodes(mpB);
      mpB = mp;
   }
   else
      KillAllMMNodes(mp);
   return(mpB);
}


void DoSquare(int flag, int verb, char pre, int nreg, int VL)
{
   ATL_mmnode_t *mp;
   int maxNB;

   mp = GetBestKern(pre);
   maxNB = GetMaxNB(flag, verb, pre, mp);
}

int TestWithKU(int verb, char pre, int NB, ATL_mmnode_t *mp, FILE *fperr)
{
   int nf;
   mp->flag |= (1<<MMF_KUISKB);
   mp->kbB = mp->ku = NB;
   free(mp->rout);
   free(mp->genstr);
   mp->rout = MMGetGenName(pre, NB, mp);
   mp->genstr = MMGetGenString(pre, mp);
   nf = NumberBetaFails(fperr, pre, NB, mp);
   return(nf);
}

int CountFails(int TEST, int flg, int verb, char pre, int NB, int nreg, int VL)
{
   int i, j, ntest=0, nfail=0;
   char *frm="%8d %4d %3d %3d %3d  %2d   %c %2d  %5d\n";
   FILE *fperr;

   fperr = fopen("res/FAIL.OUT", "w");
   assert(fperr);

   assert(VL);
   assert(nreg);
   assert(NB > 0);
   printf("     NUM    B  MU  NU  KU  VL VEC BC  NPASS\n");
   printf("======== ==== === === ===  == === ==  =====\n");
   for (i=1; i <= nreg; i++)
   {
      for (j=1; j <= nreg; j++)
      {
         ATL_mmnode_t *mp;
         int nf;
         if (i == 1 || j == 1)
         {
            if (i*j+1 > nreg)
               continue;
         }
         else if (i*j+Mmin(i,j)+1 > nreg)
               continue;

         mp = MMGetNodeGEN(pre, 0, NB, i*VL, j, 1, VL, 0, 0, 0, NULL);
         nf = NumberBetaFails(fperr, pre, NB, mp);
         printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 0, 3-nf);
         nfail += nf;
         ntest += 3;
         if (!nf)  /* try fully unrolled case if rolled worked*/
         {
            nf = TestWithKU(verb, pre, NB, mp, fperr);
            printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 0, 3-nf);
            nfail += nf;
            ntest += 3;
         }
         mp = KillMMNode(mp);
         if (j%VL == 0)  /* try m-vec w/o bcast */
         {
            mp = MMGetNodeGEN(pre, 1, NB, i*VL, j, 1, VL, 0, 0, 0, NULL);
            nf = NumberBetaFails(fperr, pre, NB, mp);
            printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 
                   FLAG_IS_SET(mp->flag, MMF_NOBCAST), 3-nf);
            nfail += nf;
            ntest += 3;
            if (!nf)  /* try fully unrolled case if rolled worked*/
            {
               nf = TestWithKU(verb, pre, NB, mp, fperr);
               printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 
                      FLAG_IS_SET(mp->flag, MMF_NOBCAST), 3-nf);
               nfail += nf;
               ntest += 3;
            }
            mp = KillMMNode(mp);
         }
         if (1 /*(i*j)%VL == 0*/) /* try k-vec */
         {
            mp = MMGetNodeGEN(pre, 0, NB, i, j, VL, VL, 1, 0, 0, NULL);
            nf = NumberBetaFails(fperr, pre, NB, mp);
            printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'K', 0, 3-nf);
            nfail += nf;
            ntest += 3;
            if (!nf)  /* try fully unrolled case if rolled worked*/
            {
               nf = TestWithKU(verb, pre, NB, mp, fperr);
               printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'K', 0, 3-nf);
               nfail += nf;
               ntest += 3;
            }
            mp = KillMMNode(mp);
         }
      }
   }
   if (TEST > 1)
   {
      printf("\n   .... start of prefetch tests ....\n");
/*
 *    Now test some pref on both 1- & 2-D kernels.  Prefetch of next block of
 *    A & B affect peeling, and so can cause errors (K-loop prefetch no).
 *    Fully unrolled cases don't need to be tested again, since they are
 *    totally peeled with or without prefetch.
 */
      assert(nreg > 2);
      for (i=0; i < 7; i++)  /* 1-D in both directions, and some 2-D */
      {
         const int NOBCAST = (i == 5 || i == 6); /* spec cases for no-bcast */
         int MU;
         int mu, nu, pfLS;
         if (i == 0)
         {
            mu = nreg - 2;
            nu = 1;
         }
         else if (i == 1)
         {
            mu = 1;
            nu = nreg - 2;
            if (nu > VL)
               nu = (nu / VL) * VL;
         }
         else if (i == 2)
         {
            mu = 3;
            for (nu=3; nu*mu+mu+1 < nreg; nu++);
         }
         else if (i == 4)
            mu = nu = 2;
         else if (i == 5)
         {
            nu = VL;
            mu = 3;
         }
         else if (i == 6)
         {
            nu = VL*2;
            mu = 2;
         }
   
         if (i <= 2)  /* 1-D case */
         {
            if (mu*nu+1 > nreg)
               continue;
         }
         else if (mu*nu+Mmin(mu,nu)+1 > nreg)
            continue;
   
         MU = mu*VL;
   
         for (pfLS=16; pfLS < 128; pfLS += pfLS)
         {
            int k, pfs[6]={1, 2, 4, 1|2, 2|4, 1|2|4};
            for (k=0; k < 5; k++)
            {
               ATL_mmnode_t *mp;
               int nf;
/*
 *             Test M-vec using broadcast
 */
               if (!NOBCAST)
               {
                  mp = MMGetNodeGEN(pre, 0, NB, MU, nu, 1, VL, 0, 
                                    pfs[k], pfLS, NULL);
                  nf = NumberBetaFails(fperr, pre, NB, mp);
                  printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 
                         FLAG_IS_SET(mp->flag, MMF_NOBCAST), 3-nf);
                  nfail += nf;
                  ntest += 3;
                  KillMMNode(mp);
               }
               if (nu%VL == 0)  /* try m-vec using splat & w/o bcast */
               {
                  mp = MMGetNodeGEN(pre, 1, NB, MU, nu, 1, VL, 0, 
                                    pfs[k], pfLS, NULL);
                  nf = NumberBetaFails(fperr, pre, NB, mp);
                  printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'M', 
                         FLAG_IS_SET(mp->flag, MMF_NOBCAST), 3-nf);
                  nfail += nf;
                  nfail += nf;
                  ntest += 3;
                  KillMMNode(mp);
               }
               if (!NOBCAST && (mu*nu)%VL == 0)  /* try k-vec */
               {
                  mp = MMGetNodeGEN(pre, 0, NB, mu, nu, VL, VL, 1, 
                                    pfs[k], pfLS, NULL);
                  nf = NumberBetaFails(fperr, pre, NB, mp);
                  printf(frm, ntest, NB, mp->mu, mp->nu, mp->ku, VL, 'K', 
                         0, 3-nf);
                  nfail += nf;
                  ntest += 3;
                  KillMMNode(mp);
               }
            }
         }
      }
   }
   if (!nfail)
   {
      printf("ALL %d TESTS PASS!\n", ntest);
      fprintf(fperr, "ALL %d TESTS PASS!\n", ntest);
   }
   else
   {
      printf("FAILED %d OF %d TESTS!!\n\n", nfail, ntest);
      fprintf(fperr, "FAILED %d OF %d TESTS!!\n\n", nfail, ntest);
   }
   fclose(fperr);
   return(nfail);
}

int FindBlockingRegions(int flag, int verb, char pre)
/*
 * This routine attempts to find the best prefetch kernel for all problem sizes
 * using timings of the fastest unprefetched kernel found in MU/NU search.
 * We can prefetch or not each of the three operands, and for each we an
 * also use ATL_pfl1 (pref to L1) or ATL_pfl2.  L2 may really be last-lvl cache.
 * We assume there are five operand size ranges of interest:
 * 1. nb <= sqrt(L1sz/5) : can fit 5 blks of A/B in L1.  May be worthwhile
 *    to prefetch next block of A & B to L1 cache
 * 2. nb <= sqrt(L1sz/4) : fit 4 blks, try fetching A or B to L1, other to L2
 * 3. nb <= sqrt(L2sz/6) : pref next A&B blocks to L2
 * 4. nb <= sqrt(L2sz/5) : pref only one of A/B to L2
 * 5. else only do inter-block prefetch
 * RETURNS: maximum NB providing speedup 
 */
{
   int maxNB=0;

   return(maxNB);
}

int TryKU(char pre, int verb, ATL_mmnode_t *mp, int imf, int ku)
/*
 * Assumes mp->mflop[imf] presently holds perf of present ku unrolling.
 * Times (& tests) unrolling of ku, and retains best setting.
 * Penalizes larger unroll very slightly due to potential code size problems.
 * RETURNS: 1 if new ku is faster, else 0.
 */
{
   const double newmul = (mp->ku < ku) ? 0.99 : 1.01; /* bias big unroll */
   double mf0=mp->mflop[0], mfN;
   char *gs0=mp->genstr;
   int ku0 = mp->ku, fail;

   mp->ku = ku;
   if (mp->rout)
      free(mp->rout);
   mp->rout = MMGetGenName(pre, mp->kbB, mp);
   mp->genstr = MMGetGenString(pre, mp);
   fail = MMKernelFailsAnyBeta(pre, mp->mbB, mp->nbB, mp->kbB, mp);
   if (fail)
      printf("   ku=%d FAILS TESTS!\n", ku);
   else
   {
      mfN = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB, mp->kbB, 1, 0, -1);
      printf("      ku=%d, MFLOP=%.2f, SPEEDUP=%.3f\n", ku, mfN, mfN/mf0);
   }
   if (!fail && mfN*newmul > mf0)  /* is new timing better? */
   {
      if (gs0)
         free(gs0);
      mp->mflop[0] = mfN;
      if (ku == mp->kbB)
         mp->flag |= (1<<MMF_KUISKB);
      return(1);
   }
   else  /* original ku best */
   {
      free(mp->genstr);
      free(mp->rout);
      mp->ku = ku0;
      mp->genstr = gs0;
      mp->rout = MMGetGenName(pre, mp->kbB, mp);
   }
}

int TryPref(char pre, int verb, int vrb, ATL_mmnode_t *mp, int ibet, int imf, 
            int ipf, int pfLS)
/*
 * Times mmb with present prefetch setting, and (ipf,pfLS), and returns
 * in mmb the best.  mp->mflop[imf] must contain the timing for the present
 * prefetch settings.
 * RETURNS: 1 if new settings taken, 0 if old are kept
 */
{
   char *gs0=mp->genstr, *rt0=mp->rout;
   int ipf0=mp->pref, pfLS0=mp->pfLS;
   double mf0=mp->mflop[imf], mfN;

   if (mp->pref == ipf && mp->pfLS == pfLS)
   {
      if (vrb)
         printf("      pref settings unchanged!\n");
      return(0);
   }
   mp->pref = ipf;
   mp->pfLS = pfLS;
   mp->rout = DupString("ATL_tmp.c");
   mp->genstr = MMGetGenString(pre, mp);
   mfN = TimeMMKernel(verb, 0, mp, pre, mp->mbB, mp->nbB, mp->kbB, ibet, 0, -1);
   if (vrb)
      printf("      old=(%d,%d,%.0f), new=(%d,%d,%.0f), spdup=%.3f\n", 
             ipf0, pfLS0, mf0, mp->pref, mp->pfLS, mfN, mfN/mf0);
   if (mfN > mf0)  /* new settings win */
   {
      if (gs0)
         free(gs0);
      if (rt0)
         free(rt0);
      mp->mflop[imf] = mfN;
      return(1);
   }
   else  /* old settings best */
   {
      free(mp->genstr);
      mp->genstr = gs0;
      free(mp->rout);
      mp->rout = rt0;
      mp->pref = ipf0;
      mp->pfLS = pfLS0;
   }
   return(0);
}

void DoKUs(char pre, int flg, int verb, ATL_mmnode_t *mmb)
/*
 * Given routs times with KU=1 (mflop stored at imf), try various KU settings
 * and return the best
 */
{
   ATL_mmnode_t *mp;
   printf("TUNING KU FOR ALL KERNELS:\n");
   for (mp=mmb; mp; mp = mp->next)
   {
      int kumax, kumul, ku;
      const double mf0 = mp->mflop[0];

      printf("   TRYING KUs, RT='%s' B=(%d,%d,%d)\n", mp->rout,
             mp->mbB, mp->nbB, mp->kbB);
      printf("      ku=%d, MFLOP=%.2f, SPEEDUP=1.0\n", mp->ku, mf0);
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         assert(mp->ku == mp->vlen);
      else
         assert(mp->ku == 1);
      #if 0  /* present generator handles only ku=1,full */
      kumax = (mp->kbB)>>1;
      kumax = Mmin(kumax, 128);
      kumul = Mmin(mp->mu, mp->nu); /* square-friendly K unrollings */
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         kumul = Mylcm(kumul, mp->vlen);
      else
         kumul = (kumul != 1) ? kumul : 2;

      for (ku=kumul; ku <= kumax; ku += kumul)
         TryKU(pre, verb, mp, 0, ku);
      #endif
      TryKU(pre, verb, mp, 0, mp->kbB);

      printf("   DONE: KU=%d gives MFLOP=%.0f, SPEEDUP=%.3f\n", 
             mp->ku, mp->mflop[0], mp->mflop[0]/mf0);
   }
   printf("DONE TUNING KU FOR ALL KERNELS.\n\n");
}

@ROUT prefparse
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
@ROUT prefparse gmmsearch
void PrintPref(FILE *fp, int ipf)
{
   if (ipf & 2)
   {
      if (ipf & 64)
         fprintf(fp, " Ab to L1");
      else if (ipf & 512)
         fprintf(fp, " Ab to LLC");
      else
         fprintf(fp, " Ab to L2");
   }
   else
      fprintf(fp, " NO Ab PREF");
   if (ipf & 4)
   {
      if (ipf & 128)
         fprintf(fp, ", Bb to L1");
      else if (ipf & 1024)
         fprintf(fp, ", Bb to LLC");
      else
         fprintf(fp, ", Bb to L2");
   }
   else
      fprintf(fp, ", NO Bb PREF");
   if (ipf & 8)
   {
      if (ipf & 2048)
         fprintf(fp, ", Ak to L1");
      else if (ipf & 8192)
         fprintf(fp, ", Ak to LLC");
      else
         fprintf(fp, ", Ak to L2");
   }
   else
      fprintf(fp, ", NO Ak PREF");
   if (ipf & 16)
   {
      if (ipf & 4096)
         fprintf(fp, ", Bk to L1");
      else if (ipf & 16384)
         fprintf(fp, ", Bk to LLC");
      else
         fprintf(fp, ", Bk to L2");
   }
   else
      fprintf(fp, ", NO Bk PREF");
   if (ipf & 1)
   {
      if (ipf & 32)
         fprintf(fp, ", C to L1");
      else if (ipf &256)
         fprintf(fp, ", C to LLC");
      else
         fprintf(fp, ", C to L2");
   }
   else
      fprintf(fp, ", NO C PREF");
}
@ROUT gmmsearch

void DoPref1(char pre, int flg, int verb, int vrb0, ATL_mmnode_t *mmb)
/*
 * Given routs times with no prefetch (mflop stored at imf), try various
 * prefetch strategies, and return the best
 */
{
   ATL_mmnode_t *mp;
                    /* Lx(A)  ; Lx(B),   Lx(A&B)       2(A),x(B),  x(A),2(B) */
   const int ipfs[11]={2|512, 4|1024, 2|4|512|1024, 2|4|1024, 2|512|4,
                  /*L2(A); L2(B);L2(A&B);1(A),2(B);2(A)1(B),    L1(A&B) */
                        2,     4, 2|4,   2|64|4,   2|4|128, 2|64|4|128};
   int k, n, vrb=(vrb0 > 1);

/*
 * First, try A/B prefetch, since they are N^3
 */
   for (n=0,mp=mmb; mp; n++,mp = mp->next);
   if (vrb0)
      printf("PREFETCH TUNING FOR ALL %d KERNELS\n", n);
   for (k=0,mp=mmb; mp; k++,mp = mp->next)
   {
      const int ipf=mp->pref;
      int npf, i;
      double mf0=mp->mflop[0];
      mp->mflop[1] = mf0;
      npf = 11;     /* try all cases */
      if (vrb)
         printf("TUNING A/B PREFETCH FOR KERN %d of %d\n", k+1, n);
/*
 *    First, try only next-block prefetch
 */
      for (i=0; i < npf; i++)
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|ipfs[i], 64);
/*
 *    Now let's try K-loop prefetch, both in addition to prior setting and
 *    w/o other prefetch
 */
      for (i=0; i < npf; i++)
      {
         const int kpf = mp->pref;
         const double kmf = mp->mflop[0];
         int pf;

         mp->mflop[0] = mf0;
         mp->pref = ipf;
/*
 *       Try fetching next B working set to L1, L2, & L3
 */
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|16|4096, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|16, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|16|16384, 64);
         pf = mp->pref;
/*
 *       Using B setting, try A working set prefetch.  Not as likely to help,
 *       since we prefetch same set MB/mu times for 1 use.
 */
         TryPref(pre, verb, vrb, mp, 1, 0, pf|16|4096, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, pf|16, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, pf|16|16384, 64);
/*
 *       Now try combining best-found with above
 */
         pf = mp->pref;
         if (pf != kpf && kpf)
            TryPref(pre, verb, vrb, mp, 1, 0, pf|kpf, 64);
         if (mp->mflop[0] < kmf*1.005) /* if new settings (pen expen k-pref) */
         {                              /* slower M/N fetch alone, revert */
            mp->pref = kpf;
            mp->mflop[0] = kmf;
         }
         if (vrb)
            printf("   A/B PREFETCH FOR %d SPEEDUP=%.3f\n", 
                   k+1,mp->mflop[0]/mf0);
      }
      {
         const int ipf=mp->pref;
         double mf0=mp->mflop[0];
         if (vrb)
            printf("   TUNING C PREFETCH FOR %d\n", k+1);
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|1, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|1|32, 64);
         TryPref(pre, verb, vrb, mp, 1, 0, ipf|1|256, 64);
         if (vrb)
            printf("   C PREFETCH FOR %d SPEEDUP=%.3f\n", k+1, 
                   mp->mflop[0]/mf0);
      }
      if (vrb0)
      {
         printf("   PREF:");
         PrintPref(stdout, mp->pref);
         printf("; SPD=%.2f\n", mp->mflop[0] / mp->mflop[1]);
      }
      mp->mflop[1] = 0.0;
   }
   if (vrb0)
      printf("DONE  PREFETCH TUNING FOR ALL %d KERNELS\n\n", n);
}

void DoPref(char pre, int flg, int verb, ATL_mmnode_t *mmb)
/*
 * Given routs times with no prefetch (mflop stored at imf), try various
 * prefetch strategies, and return the best
 */
{
   ATL_mmnode_t *mp;
   char *ctxt[5]={"3BLKS IN L1", "1BLKS IN L1", "0BLKS IN L1", 
                  "4BLKS IN L1", "5BLKS IN L1"};
                    /* Lx(A)  ; Lx(B),   Lx(A&B)       2(A),x(B),  x(A),2(B) */
   const int ipfs[11]={2|512, 4|1024, 2|4|512|1024, 2|4|1024, 2|512|4,
                  /*L2(A); L2(B);L2(A&B);1(A),2(B);2(A)1(B),    L1(A&B) */
                        2,     4, 2|4,   2|64|4,   2|4|128, 2|64|4|128};
   int k;

   printf("START PREFETCH TUNING FOR ALL CACHE CONTEXTS\n");
/*
 * First, try A/B prefetch, since they are N^3
 */
   for (k=0,mp=mmb; mp; k++,mp = mp->next)
   {
      const int ipf=mp->pref;
      int npf, i;
      double mf0=mp->mflop[0];
      mp->mflop[1] = mf0;
      if (k <= 2) /* for cases where L1 is full */
         npf = 8; /* only try prefetches to L2 (really last level cache) */
      else if (k == 3) /* room for one block */
         npf = 9;      /* try fetching one block to L1 */
      else             /* room for 5 blocks */
         npf = 11;     /* try all cases */
      printf("   TUNING A/B PREFETCH FOR %s\n", ctxt[k]);
/*
 *    First, try only next-block prefetch
 */
      for (i=0; i < npf; i++)
         TryPref(pre, verb, 1, mp, 1, 0, ipf|ipfs[i], 64);
/*
 *    Now let's try K-loop prefetch, both in addition to prior setting and
 *    w/o other prefetch
 */
      for (i=0; i < npf; i++)
      {
         const int kpf = mp->pref;
         const double kmf = mp->mflop[0];
         int pf;

         mp->mflop[0] = mf0;
         mp->pref = ipf;
/*
 *       Try fetching next B working set to L1, L2, & L3
 */
         TryPref(pre, verb, 1, mp, 1, 0, ipf|16|4096, 64);
         TryPref(pre, verb, 1, mp, 1, 0, ipf|16, 64);
         TryPref(pre, verb, 1, mp, 1, 0, ipf|16|16384, 64);
         pf = mp->pref;
/*
 *       Using B setting, try A working set prefetch.  Not as likely to help,
 *       since we prefetch same set MB/mu times for 1 use.
 */
         TryPref(pre, verb, 1, mp, 1, 0, pf|16|4096, 64);
         TryPref(pre, verb, 1, mp, 1, 0, pf|16, 64);
         TryPref(pre, verb, 1, mp, 1, 0, pf|16|16384, 64);
/*
 *       Now try combining best-found with above
 */
         pf = mp->pref;
         if (pf != kpf && kpf)
            TryPref(pre, verb, 1, mp, 1, 0, pf|kpf, 64);
         if (mp->mflop[0] < kmf*1.005) /* if new settings (pen expen k-pref) */
         {                              /* slower M/N fetch alone, revert */
            mp->pref = kpf;
            mp->mflop[0] = kmf;
         }
      }
      printf("   A/B PREFETCH FOR %s SPEEDUP=%.3f\n", ctxt[k],mp->mflop[0]/mf0);
   }
   printf("\n");
/*
 * First, try prefC for each kernel
 */
   for (k=0,mp=mmb; mp; k++,mp = mp->next)
   {
      const int ipf=mp->pref;
      double mf0=mp->mflop[0];
      printf("   TUNING C PREFETCH FOR %s\n", ctxt[k]);
      TryPref(pre, verb, 1, mp, 1, 0, ipf|1, 64);
      TryPref(pre, verb, 1, mp, 1, 0, ipf|1|32, 64);
      TryPref(pre, verb, 1, mp, 1, 0, ipf|1|256, 64);
      printf("   C PREFETCH FOR %s SPEEDUP=%.3f\n", ctxt[k], mp->mflop[0]/mf0);
      printf("   PREF:");
      PrintPref(stdout, mp->pref);
      printf("; SPD=%.2f\n", mp->mflop[0] / mp->mflop[1]);
      mp->mflop[1] = 0.0;
   }
   printf("DONE  PREFETCH TUNING FOR ALL CACHE CONTEXTS\n\n");
}

void FixContextMflop(ATL_mmnode_t *mm3)
/*
 * Put all context mflop back to ->mflop[0]
 */
{
   ATL_mmnode_t *mp;

   mm3->mflop[0] = mm3->mflop[1]; mm3->mflop[1] = 0.0;
   mp = mm3->next;
   mp->mflop[0] = mp->mflop[2]; mp->mflop[2] = 0.0;
   mp = mp->next;
   mp->mflop[0] = mp->mflop[3]; mp->mflop[3] = 0.0;
   mp = mp->next;
   if (mp)
   {
      mp->mflop[0] = mp->mflop[4]; mp->mflop[4] = 0.0;
      mp = mp->next;
      if (mp)
      {
         mp->mflop[0] = mp->mflop[5]; mp->mflop[5] = 0.0;
      }
   }
}
void DoBlock(char pre, int flg, int verb)
{
   int L1ELTS;
   ATL_mmnode_t *mmb, *mm3, *mp;
   int b;
   char upr;

   mmb = TimeMMFileWithPath(pre, "res", "gAMMRES.sum", 0, verb, 0, 1, 0, -1);
   if (mmb)
   {
      KillAllMMNodes(mmb);
      return;
   }
   if (pre == 'c')
      upr = 's';
   else 
      upr = (pre == 'z') ? 'd' : pre;
/*
 * Compute # of L1 cache elements, and join M- & K-vec kernels found so far
 */
   L1ELTS = GetL1CacheElts(upr);
   mmb = ReadMMFileWithPath(upr, "res", "gmvAMMUR.sum");
   assert(mmb);
   mp = ReadMMFileWithPath(upr, "res", "gkvAMMUR.sum");
   ATL_LastMMNode(mmb)->next = mp;
   MMFillInGenStrings(pre, mmb);
/*
 * mm3: A,B,C in L1, mm3->next: B fits in L1, 
 * mm3->next->next: mu*KB panel of A fits in L1 (L2 blocked)
 */
   mm3 = FindBestCacheBudgetCases(verb, pre, L1ELTS, mmb);
   KillAllMMNodes(mmb);
   FixContextMflop(mm3);
   mmb = mm3;
   DoKUs(pre, flg, verb, mmb);   /* find best ku */
   DoPref(pre, flg, verb, mmb);  /* find best prefetch patterns */
   WriteRefreshedMMFileWithPath(pre, "res", "gAMMRES.sum", mmb);
   KillAllMMNodes(mmb);
}

int getSzC(ATL_mmnode_t *mp, int nb)
{
   const int nu = mp->nu, nnu = (nb+nu-1)/nu;
   const int vlen=mp->vlen, nvec=(nu*nu+vlen-1)/vlen, blksz=nvec*vlen;
   return(nnu*nnu*blksz);
}
int getSzA(ATL_mmnode_t *mp, int nb, int kb)
{
   const int nu = mp->nu, nnu = (nb+nu-1)/nu, ku=mp->ku, nku=(kb+ku-1)/ku;
   return(nnu*nku*nu*ku);
}

void TryAllSyrkPref(int flag, int vrb, char pre, ATL_mmnode_t *mp, 
                    int nb, int kb)
/* 
 * This kernel is designed to do an inner-product syrk.  This means we actually
 * reuse workspace for both A & C all the time, so it doesn't make sense to
 * prefetch anything from outside the block.
 */
{
   double mf0, mfB;
   int i, ipf, ils;
   const int thsA[3] = {8|8192, 8, 8|2048};
   const int thsC[3] = {1|256, 1, 1|32};
@skip   const int nxtA[3] = {2|512, 2, 2|64};
   printf("PREFETCH TUNING NB=%d, KB=%d, U=%d, KVEC=%d, SPLAT=%d:\n", nb, kb, 
          mp->nu, FLAG_IS_SET(mp->flag, MMF_KVEC)?mp->vlen:0, 
          FLAG_IS_SET(mp->flag, MMF_NOBCAST));
   mp->pref = 0; mp->pfLS=64;
   mf0 = mfB = TimeMMKernel(vrb, 0, mp, pre, nb, nb, kb, 1, 0, -1);
   mp->mflop[0] = mf0;
   printf("   No prefetch, MFLOP=%.0f\n", mf0);
   printf("   TRY PREFETCH A:\n");
/*
 * Try K-loop A/At pref for LS=64 & 128, since it's N^3 cost
 */
   for (i=0; i < 3; i++)
   {
      TryPref(pre, vrb, 1, mp, 1, 0, thsA[i], 64);
      TryPref(pre, vrb, 1, mp, 1, 0, thsA[i], 128);
   }
/*
 * Now try C prefetch (N^2 cost)
 */
  printf("   TRY PREFETCH C:\n");
  ipf = mp->pref;
  ils = mp->pfLS;
  for (i=0; i < 3; i++)
     TryPref(pre, vrb, 1, mp, 1, 0, ipf|thsC[i], ils);
  printf("DONE PREFETCH=(%d,%d), FINAL MFLOP=%.0f, SPEEDUP=%.3f\n",
         mp->pref, mp->pfLS, mp->mflop[0], mp->mflop[0] / mf0);
}
double TimeSyrkKBs(int flg, int vrb, char pre, ATL_mmnode_t *mp, int nb)
{
   const unsigned int ku=mp->ku, kb=(nb+ku-1)/ku;
   unsigned int KB, sz;
   static int l1elts=0;
   double mf0, mf=0.0;

   if (l1elts == 0)
      l1elts = GetL1CacheElts((pre=='c' || pre=='s') ? 's':'d');

   mf0 = TimeMMKernel(vrb, 0, mp, pre, nb, nb, kb, 1, 0, -1);
/*
 * For problems that fit entirely in L1 (including A you're copying from),
 * find a large KB that fills L1.  This will reduce the N^2 costs, which
 * are important for these small problems.  We can do this, since this
 * kernel is intended for inner product (large K, small N).
 */
   KB = kb;
   do
   {
      KB += ku;
      sz = (getSzA(mp, nb, KB)<<1)+getSzC(mp, nb);
   }
   while (l1elts > sz);
   KB -= ku;
   if (KB > kb)
      mf = TimeMMKernel(vrb, 0, mp, pre, nb, nb, KB, 1, 0, -1);

   if (mf0 > mf)
   {
      mp->mflop[0] = mf0;
      mp->kbB = kb;
   }
   else
   {
      mp->mflop[0] = mf;
      mp->kbB = KB;
      mf0 = mf;
   }
   return(mf0);
}

int SyrkXoverUp(int flg, int vrb, char pre, ATL_mmnode_t *ms,/* syrk kerns */
                ATL_mmnode_t *mg)  /* gemm largest kb */
{
   const double mfG = mg->mflop[0];
   double mfS=ms->mflop[0], mfR; /* MFLOP for SYRK & recursion */
   const unsigned int nuS = ms->nu, kuS=ms->ku, NB=ms->nbB;
   int nb, incb;

   incb = Mylcm(nuS,kuS);
   nb = NB;
   printf("ESTIMATING SYRK RECURSIVE STOPPING POINT BY INCREASING N:\n");
   while (1)
   {
      int nbn = nb+incb, nbS, nbG;
      double mfR, mfn;            /* mflop for recursion & syrk(N/2) */
      if (nbn > 512)
         break;
      mfn = TimeSyrkKBs(flg, vrb, pre, ms, nbn);
      mfR = 0.5*(mfS + mg->mflop[0]);
      printf("   SYRK-%d = %.0f, GEMM/SYRK-%d = %.0f (S:%.0f,G:%.0f)\n",
             nbn, mfn, nb, mfR, mfS, mfG);
      if (mfR > mfn)
         break;
      mfS = mfn;
      nb = nbn;
   }
   printf("STOPPING POINT N = %d\n", nb);
   return(nb);
}
int SyrkXover(int flg, int vrb, char pre, ATL_mmnode_t *ms,/* syrk kerns */
              ATL_mmnode_t *mG)  /* gemm kernels */
{
   ATL_mmnode_t *mg=mG, *mp;
   const double mf0 = ms->mflop[0];
   double mfS=mf0, mfR; /* MFLOP for SYRK & recursion */
   const unsigned int nuS = ms->nu, kuS=ms->ku, NB=ms->nbB;
   int nb;
/*
 * We are using the SYRK kernel when we stop recurring on SYRK.  In each
 * recursion, we divide C into hi&low triangles (SYRK) and a square GEMM.  
 * During recursion, each SYRK is again divided to continue to use GEMM.
 * When we stop the recursion, we call the SYRK kernel we are tuning here
 * for the high & low triangles, and then unwind all the GEMM calls.
 * We note that SYRK has roughly half the flops as GEMM, but during the
 * recursion we make two SYRK calls, so at the stopping point, we can
 * simply average the MFLOP rate of SYRK & GEMM to estimate the MFLOP rate
 * the non-recursive call would get.
 *
 * We want to estimate where we should stop our recursion based on kernel
 * timings.  At each candidate N, we can make one SYRK call, or recur.
 * If we assume this is the stopping point, then its MFLOP rate is
 * that of a single syrk call.  If we assume the N/2 (next candidate N)
 * is the stopping point, its mflop rate is (syrkMF(N/2)+gemmMF(N/2)).
 * So, we have reached the estimated crossover point when 
 * syrkMF(N) >= syrkMF(N/2)+gemmMF(N/2).
 *
 * This code attempts to find this point.  Note that this is a very rough
 * estimation, since the kernel timer doesn't include cpy of A, which is
 * an important part of inner product.  SYRK has to copy only A, whereas
 * GEMM needs both A & B, so we should give SYRK the benefit of the doubt,
 * and err on the side of stopping the recursion.
 */
 
   nb = NB;
   mg = mG;
   printf("ESTIMATING SYRK RECURSIVE STOPPING POINT:\n");
   while (1)
   {
      int nb2 = nb>>1, nbS, nbG;
      double mfR, mfs;            /* mflop for recursion & syrk(N/2) */
      if (nb2 < nuS)
         break;
      for (; mg; mg=mg->next)     /* find gemm used by nb/2 */
         if (mg->nbB <= nb2)
            break;
      if (!mg)
         break;
      nbS = (nb2/nuS)*nuS;       /* basic syrk perf estimate */
      mfs = TimeSyrkKBs(flg, vrb, pre, ms, nbS);
      mfR = 0.5*(mfs + mg->mflop[0]);
      printf("   N=%3d (S:%d,G:%d), SYRK=%.0f, RECUR=%.0f (S:%.0f,G:%.0f)\n", 
             nb, nbS, mg->nbB, mfS, mfR, mfs, mg->mflop[0]);
      if (mfR < mfS)
         break;
      mfS = mfs;
      nb = nb2;
   }
   ms->mbB = ms->nbB = ((nb+nuS-1)/nuS)*nuS;
   ms->kbB = ((nb+kuS-1)/kuS)*kuS;
   if (nb == NB)
   {
      ms->mflop[0] = mf0;
      nb = SyrkXoverUp(flg, vrb, pre, ms, mG);
   }
   else
      printf("STOPPING POINT N = %d\n", nb);
   return(nb);
}

void DoAllSyrkNB(char pre, int vrb, ATL_mmnode_t *mSQ, ATL_mmnode_t *sy)
{
   ATL_mmnode_t *mSY, *mp;
   const unsigned int nu=sy->nu, ku=sy->ku;
/*
 * Make a syrk node for all nodes in mSQ
 */
   printf("TIMING SYRK KERN FOR ALL NBs:\n");
   for (mSY=NULL,mp=mSQ; mp; mp = mp->next)
   {
      ATL_mmnode_t *syp;
      double mf, mul=1.0, mfG;

      syp = CloneMMNode(sy);
      syp->mbB = syp->nbB = ((mp->nbB+nu-1) / nu)*nu;
      syp->kbB = ((mp->kbB+ku-1)/ku)*ku;
      mf = TimeMMKernel(vrb, 0, syp, pre, syp->mbB, syp->nbB, syp->kbB, 1,0,-1);
      if (syp->nbB != mp->nbB)
      {
         mul = mp->nbB;
         mul /= syp->nbB;
         mul *= mul;
      }
      if (syp->kbB != mp->kbB)
         mul *= ((double)mp->kbB)/((double)syp->kbB);
      syp->mflop[0] = mul*mf;
      printf("   NB=%4d, KB=%4d: GEMM=%.0f,(%.0f), SYRK=%.0f,(%.0f)\n", 
             mp->nbB, mp->kbB, mp->mflop[0]/2.0,mp->mflop[0],syp->mflop[0],mf);
      syp->next = mSY;
      mSY = syp;
   }
   printf("DONE TIMING SYRK KERN FOR ALL NBs.\n");
   if (mSY->next && mSY->nbB > mSY->next->nbB)
      mSY = ReverseMMQ(mSY);
   WriteMMFileWithPath(pre, "res", "gAMSYRK.tim", mSY);
   KillAllMMNodes(mSY);
}

void DoSyrkTim(char pre, int verb)
{
   ATL_mmnode_t *tb, *tp, *sb, *syp, *syb=NULL;
   int mu, nu;
   tb = ReadMMFileWithPath(pre, "res", "syrkK.sum");
   if (tb)  /* already ran! */
   {
      for (tp=tb; tp; tp = tp->next)
      {
         if (tp->mflop[0] <= 0.0)
         {
            tp->mflop[0] = TimeMMKernel(verb, 0, tp, pre, tp->mbB, tp->nbB, 0,
                                        1, 0, -1);
            if (verb)
               printf("   syrkK %dx%d: %.2f\n", tp->mbB, tp->nbB, tp->mflop[0]);
         }
      }
      WriteRefreshedMMFileWithPath(pre, "res", "syrkK.sum", tb);
      KillAllMMNodes(tb);
      return;
   }

   tb = ReadMMFileWithPath(pre, "res", "sqAMMRES.sum");
   syp = ReadMMFileWithPath(pre, "res", "gAMSYRK.sum");
   assert(syp);
   mu=syp->mu; 
   nu=syp->nu;
   printf("\nFINDING PERFORMANCE OF SYRK KERNELS FOR SQUARE AMM:\n");
   for (tp=tb; tp; tp = tp->next)
   {
      ATL_mmnode_t *new;
      double ratio, mf;
      int mb=tp->mbB, nb=tp->nbB;
      
      new = CloneMMNode(syp);
      mb = ((mb+mu-1)/mu)*mu;
      nb = ((nb+nu-1)/nu)*nu;
      new->mbB = mb;
      new->nbB = nb;
      new->kbB = tp->kbB;
      if (mb == tp->mbB && nb == tp->nbB)
         ratio = 1.0;
      else
         ratio = (((double)tp->mbB)*tp->nbB) / (((double)mb)*nb);
      mf = TimeMMKernel(verb, 0, new, pre, mb, nb, tp->kbB, 1, 0, -1);
      mf *= ratio;  /* don't count useless flops */
      new->mflop[0] = mf;
      printf("   syrkK %dx%d: %.2f (%.2f)\n", tp->mbB, tp->nbB, mf, ratio);
      new->next = syb;
      syb = new;
   }
   KillAllMMNodes(tb);
   KillAllMMNodes(syp);
   syb = ReverseMMQ(syb);
   WriteRefreshedMMFileWithPath(pre, "res", "syrkK.sum", syb);
   printf("DONE SYRK TIMING.\n");
   KillAllMMNodes(syb);
}

void DoSyrk(int flg, int vrb, char pre, int nreg, int nb, int VL)
{
   ATL_mmnode_t *mb, *mSQ, *mp, *mSY;
   int L1ELTS, i, maxNB, nu, ku, kb;
   char upr = (pre == 'c' || pre == 's') ? 's' : 'd';
   double mf0, mfB;

   
   mSQ = TimeMMFileWithPath(pre, "res", "ipmnPERF.sum", 0, vrb, 0, 1, 0, -1);
   if (!mSQ)
      return;
   mb = TimeMMFileWithPath(pre, "res", "gAMSYRK.sum", 0, vrb, 0, 1, 0, -1);
   if (mb)
   {
      mSY = TimeMMFileWithPath(pre, "res", "gAMSYRK.tim", 0, vrb, 0, 1, 0, -1);
      if (!mSY)
         DoAllSyrkNB(pre, vrb, mSQ, mb);
      else
         KillAllMMNodes(mSY);
      KillAllMMNodes(mb);
      KillAllMMNodes(mSQ);
      DoSyrkTim(pre, vrb);
      return;
   }
   mSQ = ReverseMMQ(mSQ);  /* sorted from large to small NB */
   mb = DoSyrkMUNU(flg, vrb, pre, nreg, mSQ->nbB, mSQ->kbB, VL); 
   mp = mb;
   nu = mp->nu;
   ku = mp->ku;
   mp->nbB = mp->mbB = nb = (mSQ->nbB / nu)*nu;
   mp->kbB = kb = (mSQ->kbB / ku)*ku;
   assert(nb && kb);
   TryAllSyrkPref(flg, vrb, pre, mp, nb, kb);
   maxNB = SyrkXover(flg, vrb, pre, mp, mSQ);
   mb->mbB = mb->nbB = mb->kbB = maxNB;
   WriteMMFileWithPath(pre, "res", "gAMSYRK.sum", mp);
/*
 * Make a syrk node for all nodes in mSQ
 */
   DoAllSyrkNB(pre, vrb, mSQ, mb);
@beginskip
   printf("TIMING SYRK KERN FOR ALL NBs:\n");
   for (mSY=NULL,mp=mSQ; mp; mp = mp->next)
   {
      ATL_mmnode_t *syp;
      double mf, mul=1.0, mfG;

      syp = CloneMMNode(mb);
      syp->mbB = syp->nbB = ((mp->nbB+nu-1) / nu)*nu;
      syp->kbB = ((mp->kbB+ku-1)/ku)*ku;
      mf = TimeMMKernel(vrb, 0, syp, pre, syp->mbB, syp->nbB, syp->kbB, 1,0,-1);
      if (syp->nbB != mp->nbB)
      {
         mul = mp->nbB;
         mul /= syp->nbB;
         mul *= mul;
      }
      if (syp->kbB != mp->kbB)
         mul *= ((double)mp->kbB)/((double)syp->kbB);
      syp->mflop[0] = mul*mf;
      printf("   NB=%4d, KB=%4d: GEMM=%.0f,(%.0f), SYRK=%.0f,(%.0f)\n", 
             mp->nbB, mp->kbB, mp->mflop[0]/2.0,mp->mflop[0],syp->mflop[0],mf);
      syp->next = mSY;
      mSY = syp;
   }
   printf("DONE TIMING SYRK KERN FOR ALL NBs.\n");
   WriteMMFileWithPath(pre, "res", "gAMSYRK.tim", mSY);
   KillAllMMNodes(mSY);
@endskip
   KillAllMMNodes(mSQ);
   KillMMNode(mb);
   DoSyrkTim(pre, vrb);
}

void DoPrefOnList(int flg, int vrb, char pre, int maxB)
{
   ATL_mmnode_t *mb, *mp, *pb;
   int b, binc;
   FILE *fp;

   mb = ReadMMFile("time.sum");
   if (!mb)
   {
      fprintf(stderr, "No files in time.sum, exiting!\n");
      remove("NB-pref.txt");
      return;
   }
   binc = Mylcm(mb->mu, mb->nu);
   for (mp=mb->next; mp; mp = mp->next)
   {
      binc = Mylcm(binc, mp->mu);
      binc = Mylcm(binc, mp->nu);
   }
   fp = fopen("NB-pref.txt", "w");
   assert(fp);
   fprintf(fp, "      ");
   for (mp=mb; mp->next; mp = mp->next)
      fprintf(fp, "-----------");
   fprintf(fp, "---------  ");
   for (mp=mb; mp->next; mp = mp->next)
      fprintf(fp, "-----------");
   fprintf(fp, "---------\n");
   fprintf(fp, "  NB");
   for (mp=mb; mp; mp = mp->next)
      fprintf(fp, "   %c%c:%2dx%2d", FLAG_IS_SET(mp->flag, MMF_KVEC) ? 'K':'M', 
              FLAG_IS_SET(mp->flag,MMF_NOBCAST)?'s':'b', mp->mu, mp->nu);
   for (mp=mb; mp; mp = mp->next)
      fprintf(fp, "  PREF %c%2dx%2d", 
              FLAG_IS_SET(mp->flag, MMF_KVEC) ? 'K':'M', mp->mu, mp->nu);
   fprintf(fp, "\n====");
   for (mp=mb; mp; mp = mp->next)
      fprintf(fp, "  =========");
   for (mp=mb; mp; mp = mp->next)
      fprintf(fp, "  ==== ======");
   fprintf(fp, "\n");
   fflush(fp);
   for (b=binc; b <= maxB; b += binc)
   {
      fprintf(fp, "%4d", b);
      for (mp=mb; mp; mp = mp->next)
      {
         double mf;
         mp->pref = 0;
         mp->nbB = mp->mbB = mp->kbB = b;
         if (mp->genstr)
            free(mp->genstr);
         mp->genstr = NULL;
         mf = TimeMMKernel(vrb, 0, mp, pre, b, b, b, 1, 0, -1);
         mp->mflop[0] = mf;
         fprintf(fp, "     %6.0f", mf);
      }
      DoPref1(pre, flg, vrb, 1, mb);
      for (mp=mb; mp; mp = mp->next)
         fprintf(fp, "  %4.4x %6.0f", mp->pref, mp->mflop[0]);
      fprintf(fp, "\n");
      fflush(fp);
   }
   fclose(fp);
   KillAllMMNodes(mb);  /* done with these! */
}

void SetFlops(int flg, int verb, char pre, int VL)
/* 
 * This search finds a decent generated kernel, and uses it to find the
 * number of flops that must be forced to get 
 * 1:  each problem above .25 sec?
 * 2:  10 timings withing 2% of each other?
 * which should be enough to avoid huge timing error bars
 */
{
   ATL_mmnode_t *mp;
   FILE *fp;
   char *rt;
   char fn[16];
   int b, i;
   int muB, nuB, kvecB, bB, bcB;
   #define TOL .015
   const double mbig=(1.0+TOL), msml=(1.0-TOL);
   double mfB, mf, mul, nmf, tim;

/*
 * Get square blocking factor that fills cache with one block
 */
   i = GetL1CacheElts(pre);
   for (b=4; b*b <= i; b += 4);
   b -= 4;
/*
 * If we have no vector length set, see if we know the platform, else
 * attempt to determine it empirically (can use gnuvec to vectorize
 * archs where ATLAS has no explicit support).
 */
   if (VL < 1)
      VL = GetNativeVLEN(pre);
   if (VL < 1)  /* no good guess, will have to probe for it */
   {
      int vl, vlB=1;
      int B = (b>>1)<<1;
      mp = MMGetNodeGEN(pre, 0, 0, 2, 2, 1, 1, 1, 0, 0, DupString("ATL_tmp.c"));
      mp->mbB = mp->nbB = 2;
      mp->kbB = 480;
      mp->flag &= ~( (1<<MMF_MVA)|(1<<MMF_MVB)|(1<<MMF_MVC) );
      mfB = 0.0;
      printf("ATTEMPTING TO DETECT VECTOR LENGTH:\n");
      for (vl=1; vl < 16; vl += vl)
      {
         mp->ku = mp->vlen = vl;
         if (vl == 2)
            mp->flag |= (1<<MMF_KVEC);
         if (mp->genstr)
            free(mp->genstr);
         mp->genstr = NULL;
         mf = TimeMMKernel(verb, 1, mp, pre, 2, 2, 480, 1, mul, 0);
         printf("   VL=%d, KVEC=1, B=(2,2,480) U=2: %.0f\n", vl, mf);
         if (mf > mfB)
         {
            mfB = mf;
            vlB=vl;
         }
      }
      printf("VLEN SET TO %d\n\n", vlB);
      VL = vlB;
      KillMMNode(mp);
   }
   
   mp = MMGetNodeGEN(pre, 0, 0, 1, 1, VL, VL, 1, 0, 0, DupString("ATL_tmp.c"));
   mp->ku = 1;
   mp->flag &= ~( (1<<MMF_MVA)|(1<<MMF_MVB)|(1<<MMF_MVC) ); /* no cache flush */
   printf("SCOPING FOR A DECENT SQUARE REGISTER BLOCKING, VLEN=%d\n", VL);
   printf("     B   U  Mb MFLOP  Ms MFLOP  K  MFLOP\n");
   printf("   ===  ==  ========  ========  ========\n");
   bB = Mylcm(VL, 6);
   bB = ((b+bB-1)/bB)*bB;
   i = MMTimeAllVecGen(verb, 1, mp, pre, bB, bB, bB, 0, 0, 0);
   printf("%6d %3d %9.0f %9.0f %9.0f\n", i, 1, 
          mp->mflop[0],mp->mflop[1],mp->mflop[2]);
   fflush(stdout);
   mfB = mp->mflop[i];
   muB = nuB = 1;
   kvecB = (i == 2) ? 1 : 0;
   bcB = (i != 1);
   for (i=2; i*i <= 64; i++)
   {
      int B = (b > i) ? (b/i)*i : i, iB; 
      mp->mu = mp->nu = i;
      iB = MMTimeAllVecGen(verb, 1, mp, pre, B, B, B, 0, 0, 0);
      printf("%6d %3d %9.0f %9.0f %9.0f\n", B, i, 
             mp->mflop[0],mp->mflop[1],mp->mflop[2]);
      if (mp->mflop[iB] > mfB)
      {
         mfB = mp->mflop[iB];
         muB = nuB = i;
         bB = B;
         bcB = (iB != 1);
         kvecB = (iB == 2) ? 1 : 0;
      }
      fflush(stdout);
   }
   if (mp->genstr)
      free(mp->genstr);
   mp->genstr = NULL;
/*
 * Now, pump up mflop until the run takes 3 seconds or we can get 8 timings
 * in a row that are within 1.5% of each other
 */
   mp->mflop[0] = mfB;
   mp->mflop[1] = mp->mflop[2] = 0.0;
   mp->nu = nuB;
   mp->mbB = mp->nbB = mp->kbB = bB;
   if (kvecB)
   {
      mp->ku = VL;
      mp->mu = muB;
      mp->flag |= (1<<MMF_KVEC);
      mp->flag &= ~(1<<MMF_NOBCAST);
   }
   else
   {
      mp->ku = 1;
      mp->mu = muB * VL;
      mp->flag &= ~(1<<MMF_KVEC);
      if (bcB) 
         mp->flag &= ~(1<<MMF_NOBCAST);
      else
         mp->flag |= (1<<MMF_NOBCAST);
   }
/*
 * aim for a run that should take .08 sec if above timing was good
 *    (seconds / mflop) * nmfl = .08 -> nmflop = .08*mfB;
 */
   nmf = .08*mfB;
   if (nmf < 1.0)
      nmf = 1.0;
   while(1)
   {
      double mf0;
      int inmf = (int) nmf;
      tim = nmf/mfB;
      fprintf(stderr, "nmf=%d, pred time = %e seconds\n", inmf, 
              1.0/(nmf*mfB));
      if (tim >= 2.0)
         break;
      mf0 = TimeMMKernel(verb, 1, mp, pre, bB, bB, bB, 1, nmf, 0);
      printf("mf=%.0f:", mf0);
      for (i=0; i < 7; i++)
      {
         double spdup;
         mf = TimeMMKernel(verb, 1, mp, pre, bB, bB, bB, 1, mul, 0);
         spdup = mf*mf0;
         printf(" %.4f%c", mf/mf0, i==6?'.':',');
         if (mf > mf0*mbig || mf < mf0*msml)
            break;
      }
      printf("\n");
      fflush(stdout);
      if (i == 7)
         break;
      nmf *= 2.0;
   }
   printf("Final timing interval: %e seconds, nmflops=%.0f\n", tim, nmf);

   sprintf(fn, "%cmflops.frc", pre);
   fp = fopen(fn, "w");
   fprintf(fp, "%e", nmf);
   fclose(fp);
   KillMMNode(mp);
}
int main(int nargs, char **args)
{
   int flg, verb, nreg, VLEN, NB, TEST;
   char pre, upr;
   GetFlags(nargs, args, &flg, &verb, &pre, &nreg, &VLEN, &NB, &TEST);
   upr = pre;
   if (pre == 'z')
      upr = 'd';
   else if (pre == 'c')
      upr = 's';
   if (TEST)
      return(CountFails(TEST, flg, verb, pre, NB, nreg, VLEN));
   if (flg&8)
   {
      DoPrefOnList(flg, verb, pre, NB);
      return(0);
   }
   if (flg&16)
   {
      SetFlops(flg, verb, upr, VLEN);
      return(0);
   }
   FindInfo(flg, verb, upr, NB, &nreg, &VLEN);
   if (flg&4)     /* If I just wanted nreg calc */
      return(0);  /* then I'm done */
   DoBlock(pre, flg, verb);
   DoSyrk(flg, verb, pre, nreg, NB, VLEN);
   return(0);
}
@ROUT ATL_ammmABC
#include "atlas_misc.h"
/*
 * This routine loops over calls to the access-major matmul kernel given
 * in the arguments, using the NMK loop pattern, using the given blocking
 * parameters.  
 * alpha & beta are both applied by ablk2cmat.
 * It allocates an K*NB workspace for B, and an Mc*K workspace for A,
 * and a NB*NB workspace for C.
 */

typedef void (*mat2am_t)
   (ATL_CINT, ATL_CINT, const SCALAR, const TYPE*, ATL_CINT, TYPE*);
typedef void (*ablk2cmat_t)
   (ATL_CINT M, ATL_CINT N, const SCALAR al, const TYPE*A, 
    const SCALAR beta, TYPE*C, ATL_CINT ldc);
typedef void (*ammm_t)
   (ATL_CINT M, ATL_CINT N, ATL_CINT K, TYPE *A, TYPE *B, TYPE *C);
int Mjoin(PATL,ammmABC)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CINT M,
   ATL_CINT N,
   ATL_CINT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CINT lda,
   const TYPE *B,
   ATL_CINT ldb,
   const SCALAR beta,
   const TYPE *C,
   ATL_CINT ldc,
   ATL_CINT MB,                 /* chosen M blocking for this problem */
   ATL_CINT NB,                 /* chosen N blocking for this problem */
   ATL_CINT KB,                 /* chosen K blocking for this problem */
   ATL_CINT mu,                 /* M unrolling used by kernels */
   ATL_CINT nu,                 /* N unrolling used by kernels */
   ATL_CINT ku,                 /* K unrolling used by non-cleanup kernels */
   ammm_t ammmk_b0,             /* amm beta=0 kernel to use */
   ammm_t ammmk_b1,             /* amm beta=1 kernel to use */
   ammm_t ammmk_ku1,            /* amm beta=1 for K-cleanup */
   mat2am_t A2am,               /* routine to translate A into access-major */
   mat2am_t B2am,               /* routine to translate B into access-major */
   ablk2cmat_t ablk2cmat,       /* put ammmk's C back to user's C */
)
{
   ATL_CINT Mf = (M/mu)*mu, mr = M-Mf, Nf = (N/nu)*nu, nr = N-Nf;
   ATL_CINT Kf = (K/ku)*ku, kr = K-Kf;
   ATL_CINT Mc = (mr) ? Mf + mr : Mf;  /* compute CEIL from FLOOR */
   ATL_CINT Nc = (nr) ? Nf + nr : Nf;
   ATL_CINT Kc = (kr) ? Kf + kr : Kf;
   ATL_CINT incBn = (TB == AtlasNoTrans) ldb*NB-Kf : NB-Kf*ldb;
   ATL_CINT incAm = (TA == AtlasNoTrans) ? MB - Kf*ldb : MB*ldb - Kf;
   ATL_INT i, j, k;
   void *vp;
   TYPE *pA, *pB, *c;
   int COPYA=1;

   if (K <= KB) 
      return(1);   /* don't handle rank-K update with this routine */
   vp = malloc(3*ATL_Cacchelen + sizeof(TYPE)*(Mc*K+K*NB+NB*NB));
   if (!vp)
      return(2);
   pB = ATL_AlignPtr(vp);
   pA = pB + K*NB;
   pA = ATL_AlignPtr(pA);
   c = pA + Mc*K;
   c = ATL_AlignPtr(c);

   for (j=0; j != Nc; j += NB)
   {
      ATL_CINT n = Mmin(NB, Nc-j), incb = n*nu*KB, n0 = Mmin(NB, N-j);
      int COPYB=1;
      TYPE *b = pB, *a = pA;

      for (i=0; i != Mc; i += MB)
      {
         ATL_CINT m = Mmin(MB, Mc-i), inca = m*mu*KB, m0 = Mmin(NB,M-j);

/* 
 *       Handle first block, known to always have a full KB, using _b0
 *       case to initialize workspace c
 */
         if (COPYA)
            A2am(m, KB, ATL_rone, A, lda, a);
         if (COPYB)
            B2am(KB, n, ATL_rone, B, ldb, b);
         ammmk_b0(m, n, KB, a, b, c);
         a += inca; b += incb;
/*
 *       Loop over all remaining blocks that can use ammmk_b1
 */
         for (k=KB; k < Kf; k += KB, a += inca, b += incb)
         {
            ATL_CINT kk = Mmin(KB, Kf-i);
/*
 *          If necessary, copy both A & B blocks to access-major format
 */
            if (COPYA)
            {
               A2am(m, kk, ATL_rone, A, lda, a);
               A += (TA == AtlasNoTrans) ? kk*lda : kk;
            }
            if (COPYB)
            {
               B2am(kk, n, ATL_rone, B, ldb, b);
               B += (TB == AtlasNoTrans) ? kk : kk*ldb;
            }
            ammmk_b1(m, n, kk, a, b, c);
         }
/*
 *       Handle K cleanup using the provided kernel
 */
         if (kr)
         {
            if (COPYA)
               A2am(m, kr, ATL_rone, A, lda, a);
            if (COPYB)
               B2am(kr, n, ATL_rone, B, ldb, b);
            ammmk_ku1(m, n, kr, a, b, c);
            a += kr*m;
         }
         A += incAm;
/*
 *       Write answer back out to user's C 
 */
         ablk2cmat(m0, n0, alpha, c, beta, C, ldc);
         C += m0;
         COPYB = 0;
         b = pB;
      }
      B += incBn;
      COPYA = 0;
   }
   free(vp);
   return(0);
}
@ROUT ATL_ammm_IP ATL_cammm_IP ATL_ammm_tN_old ATL_cammm_tN ATL_ammmMNK ATL_cammmMNK
   @define rt @Mjoin(PATL,ammm_IP)@
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
@ROUT ATL_ammm_IP ATL_cammm_IP
/*
 * This routine handles M <= MAXM && N <= MAXN && very long K, or
 * the inner-product GEMM form.  It appears in the GEMM-based SYRK, which
 * is important for Cholesky.  It is typically the worst-case for ATLAS,
 * since the copy of A and B are of the same order as the computation.
 * It is a minimal workspace routine.
 */
@ROUT ATL_cammm_1b
#include "atlas_misc.h"
#include "atlas_amm.h"
#include "atlas_level1.h"
#include "atlas_lvl2.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
@ROUT ATL_ammm_1b ATL_ammmKNM
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
@ROUT ATL_ammm ATL_cammm
#include "atlas_misc.h"
#include "atlas_lvl2.h"
#include "atlas_level1.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
   @define rt @Mjoin(PATL,ammm)@
@ROUT ATL_cammm_tN ATL_cammmMNK
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
#define MY_MAXMB ATL_rkAMM_LASTMB
#define MY_MAXNB ATL_rkAMM_LASTNB
@ROUT ATL_ammm_tN_old ATL_cammm_tN ATL_ammmMNK @\
      ATL_ammmKNM ATL_cammmMNK

#ifdef __GNUC__
static inline int ATL_ComputeB   /* RETURNS: selected blocking */
#else
static int ATL_ComputeB           /* RETURNS: selected blocking */
#endif
(
   size_t N,   /* problem dimension */
   int nu,     /* unrolling by kernel on this dim */
   int nb,     /* IN: large-case blocking */
   size_t *NS, /* OUT: # of blks of size NB-nu to perform */
   size_t *NT  /* OUT: # of blks to perform */
)
{
   size_t ns, nt, nblks, NN;
/*
 * If the entire problem is less than or equal to the unrolling, choose a block
 * of the ceiling of the unrolling and only do one
 */
   NN=((N+nu-1)/nu)*nu;  /* ceiling of number of unrollings in N */
   if (NN <= nu)
   {
      *NS = 0;
      *NT = 1;
      return(NN);
   }
/*
 * If suggested block size is smaller or same as unrolling, then the blocking
 * size is the unrolling, and we don't have an NB-nu sized-blocks, since that
 * would be zero sized
 */
   if (nb <= nu)
   {
      *NS = 0;
      *NT = NN/nu;
      return(nu);
   }

   nb = (nb/nu)*nu;      /* floor of number of unrollings in a block*/
/*
 * If 1 block is within NU of covering the entire dim, just make the
 * block size the entire dim
 */
   if (nb+nu >= NN)
   {
      *NS = 0;
      *NT = 1;
      return(NN);
   }
/*
 * Otherwise, compute how many blocks we need  of each type
 */
   while(1)
   {
      nblks = (N+nb-1)/nb;
      ns = (nblks*nb - NN)/nu;
      if (ns < nblks)
         break;
      nb -= nu;
   }

   *NS = ns;
   *NT = nblks;
   return(nb);
}
@ROUT ATL_ammmKNM

static int ATL_ammm_rkK
(
   const size_t M,
   const size_t nmblks,
   const size_t nsmblks,
   const int MB,
   const int NMU,
   const int mu,
   const size_t N,
   const size_t nnblks,
   const size_t nsnblks,
   const int NB,
   const int NNU,
   const int nu,
   const int K,
   const int KK,
   const int ku,
   const TYPE *A,      /* pts to beginning of matrix */
   const size_t lda,
   const size_t incAm0,
   const size_t incAm,
   const TYPE *B,      /* pts to 1 past END of matrix */
   const size_t ldb,
   const size_t incBn0,
   const size_t incBn,
   TYPE *C,            /* pts to 1 past END of matrix */
   const size_t ldc,
   const SCALAR alpA, 
   const SCALAR alpB,
   const SCALAR beta,
   TYPE *pA,
   const size_t incAw0,
   const size_t incAw,
   TYPE *pB,
   TYPE *pC,
   const ammkern_t amm,
   const cm2am_t a2blk,
   const cm2am_t b2blk,
   const ablk2cmat_t blk2c
)
{
   size_t n, j;
   int mb, nb;
   TYPE *pA0=pA;

   n = N;
   for (n=N, j=0; j < nnblks; j++)
   {
      int nmu, mb, nnu, nb, nn;
      size_t i, m;
      TYPE *c;
      if (j < nsnblks)
      {
         nb = NB-nu;
         nnu = NNU-1;
         B -= incBn0;
      }
      else
      {
         nb = NB;
         nnu = NNU;
         B -= incBn;
      }
      nn = Mmin(n, nb);
      C -= nn*ldc;
      c=C;

      b2blk(K, nn, alpB, B, ldb, pB);

      mb = MB-mu;
      nmu = NMU-1;
      pA = pA0;
      for (m=M,i=0; i < nsmblks; i++, m -= mb, c += mb)
      {
         const int mm = Mmin(m, mb);
         TYPE *pAn = pA + incAw0;
         if (!j)
         {
            a2blk(K, mm, alpA, A, lda, pA);
            A += incAm0;
         }
         amm(nmu, nnu, KK, pA, pB, pC, pAn, pB, pC);
         blk2c(mm, nn, ATL_rone, pC, beta, c, ldc);
         pA = pAn;
      }

      for (mb=MB, nmu=NMU; i < nmblks; i++, m -= mb, c += mb)
      {
         const int mm = Mmin(m, mb);
         TYPE *pAn = pA + incAw;
         if (!j)
         {
            a2blk(K, mm, alpA, A, lda, pA);
            A += incAm;
         }
         amm(nmu, nnu, KK, pA, pB, pC, pAn, pB, pC);
         blk2c(mm, nn, ATL_rone, pC, beta, c, ldc);
         pA = pAn;
      }
      n -= nb;
   }
   return(0);
}

@ROUT ATL_ammmKNM
   @define rt @Mjoin(PATL,ammmKNM)@
/*
 * This routine called for very large matrices; requires workspace of
 * one panel and 2 blocks at most
 */
@ROUT ATL_ammmMNK ATL_cammmMNK
   @define rt @Mjoin(PATL,ammmMNK)@
/*
 * This routine called when N < M and K is large
 */
@ROUT ATL_ammm_1b ATL_cammm_1b
   @define rt @Mjoin(PATL,ammm_1b)@
/* 
 * This routine called in degenerate case where all dims less than max block,
 * so we can do entire operation with one kernel call
 */
@ROUT ATL_ammm ATL_cammm
static int ATL_ammm
@ROUT ATL_ammm_tN_old ATL_cammm_tN
/* 
 * This routine handles N <= MAXN, K & M large (left-looking shape)
 */
int Mjoin(PATL,ammm_tN)
@ROUT ATL_ammm_1b ATL_cammm_1b ATL_ammmMNK ATL_cammmMNK ATL_cammm_IP ATL_ammmKNM
int @(rt)
@ROUT ATL_ammm ATL_ammm_1b  ATL_cammm ATL_cammm_1b ATL_ammmMNK @\
      ATL_cammm_IP ATL_ammm_tN_old ATL_cammm_tN ATL_ammmKNM ATL_cammmMNK
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
@ROUT ATL_ammmMNK ATL_cammmMNK
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   size_t m, nsmblks, nmblks, nsnblks, nnblks, i, incAm0, incAm, incAw0;
   size_t nkb, incAk, incAk0, mulAm, incBk, incBk0, mulBn;
   int mu, nu, ku, MB, NB, KB, KB0, kb0, NMU, NNU, A_1TRIP;
   void *vp;
@ROUT ATL_ammmMNK
   TYPE *pC, *pB, *pB0, *pA, *pA0;
   ammkern_t ammK0, amm;
   const int B_BYCOLS = (TB == AtlasNoTrans);
   const int A_BYROWS = (TA == AtlasNoTrans);
   TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
@ROUT ATL_cammmMNK
   TYPE *rC, *iC, *iB, *pB0, *iA, *pA0;
   ammkern_t ammK0, ammK0_bn, ammK0_b1, amm_b1, amm_bn;
   const int B_BYCOLS = (TB == AtlasNoTrans || TB == AtlasConj);
   const int A_BYROWS = (TA == AtlasNoTrans || TA == AtlasConj);
   const TYPE ONE[2] = {ATL_rone, ATL_rzero};
   const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
@ROUT ATL_ammmMNK ATL_cammmMNK
   amminfo_t mminfo;

   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else 
      alpC = alpha;
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
@ROUT ATL_cammmMNK
   MB = ATL_ComputeB(M, mu, MY_MAXMB, &nsmblks, &nmblks);
   NMU = MB / mu;
   NB = ATL_ComputeB(N, nu, MY_MAXNB, &nsnblks, &nnblks);
@ROUT ATL_ammmMNK
   MB = ATL_ComputeB(M, mu, ATL_geAMM_LASTMB, &nsmblks, &nmblks);
   NMU = MB / mu;
   NB = ATL_ComputeB(N, nu, ATL_geAMM_LASTNB, &nsnblks, &nnblks);
@ROUT ATL_ammmMNK ATL_cammmMNK
   NNU = NB / nu;
   KB = mminfo.kb;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0 = mminfo.amm_b0;
         else
            ammK0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && kb0 == (kb0/ku)*ku &&
          kb0 > mminfo.kbmin)
         ammK0 = mminfo.amm_b0;
   }
@ROUT ATL_ammmMNK
   amm = mminfo.amm_b1;
@ROUT ATL_cammmMNK
   if (ammK0 == mminfo.amm_b0)
   {
      amm_b1 = ammK0_b1 = mminfo.amm_b1;
      amm_bn = ammK0_bn = mminfo.amm_bn;
   }
   else
   {
      ammK0_b1 = mminfo.amm_k1_b1;
      ammK0_bn = mminfo.amm_k1_bn;
      amm_b1 = mminfo.amm_b1;
      amm_bn = mminfo.amm_bn;
   }
@ROUT ATL_ammmMNK ATL_cammmMNK
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;
   i = nkb*KB+KB0;
/*
 * Determine worspace requirements and allocate
 */
   {
      size_t tsz;
      const size_t szA=MB*i;
      const size_t szB=i*(nsnblks*(NB-nu)+(nnblks-nsnblks)*NB);
      const int szC = MB*NB;

      tsz = ATL_MulBySize(szA + szB + szC + mu*nu*ku) + 3*ATL_Cachelen;
      if (tsz > ATL_MaxMalloc)
         return(2);
      vp = malloc(tsz);
      if (!vp)
         return(1);
@ROUT ATL_ammmMNK
      pC = ATL_AlignPtr(vp);
      pA = pC + szC;
      pA0 = pA = ATL_AlignPtr(pA);
      pB = pA + szA;
      pB0 = pB = ATL_AlignPtr(pB);
@ROUT ATL_cammmMNK
      iC = ATL_AlignPtr(vp);
      rC = iC + szC;
      iA = rC + szC;
      pA0 = iA = ATL_AlignPtr(iA);
      iB = iA + szA + szA;
      pB0 = iB = ATL_AlignPtr(iB);
@ROUT ATL_ammmMNK ATL_cammmMNK
   }
   if (A_BYROWS)
   {
      incAk = KB*(lda SHIFT);
      incAk0 = kb0*(lda SHIFT);
      mulAm = 1 SHIFT;
   }
   else
   {
      incAk = KB SHIFT;
      incAk0 = kb0 SHIFT;
      mulAm = lda SHIFT;
   }
   if (B_BYCOLS)
   {
      incBk = KB SHIFT;
      incBk0 = kb0 SHIFT;
      mulBn = ldb SHIFT;
   }
   else
   {
      incBk = (KB SHIFT)*ldb;
      incBk0 = kb0*(ldb SHIFT);
      mulBn = 1 SHIFT;
   }

   for (m=M, i=0; i < nmblks; i++)
   {
      size_t j, n;
      int mb, mm, nmu, incAw, incAw0;
      TYPE *c=C;
      if (i < nsmblks)
      {
         mb = MB-mu;
         nmu = NMU-1;
      }
      else
      {
         mb = MB;
         nmu = NMU;
      }
      mm = Mmin(m, mb);  /* number of A/C rows left */
      m -= mm;
      incAw = mb*KB;
      incAw0 = mb*KB0;
      for (n=N, j=0; j < nnblks; j++)
      {
         size_t k;
@ROUT ATL_ammmMNK
         int nb, nn, nnu, incBw;
         const TYPE *b=B, *a=A; 
         TYPE *pAn, *pBn;
@ROUT ATL_cammmMNK
         int nb, nn, nnu, incBw, incBw0;
         const TYPE *b=B, *a=A; 
         TYPE *pAn, *pBn, *rA, *rB;
@ROUT ATL_ammmMNK ATL_cammmMNK

         if (j < nsnblks)
         {
            nb = NB-nu;
            nnu = NNU-1;
         }
         else
         {
            nb = NB;
            nnu = NNU;
         }
         incBw = KB*nb;
         nn = Mmin(n, nb);  /* number of B/C cols left */
         n -= nn;
@ROUT ATL_ammmMNK
         if (!j)
         {
            a2blk(kb0, mm, alpA, a, lda, pA);
            a += incAk0;
         }
         if (!i)
         {
             b2blk(kb0, nn, alpB, b, ldb, pB);
             b += incBk0;
         }
         pAn = pA + incAw0;
         pAn = (nkb) ? pAn : pA0;
         pBn = pB + KB0*nb;
         ammK0(nmu, nnu, KB0, pA, pB, pC, pAn, pBn, pC);
         pA = pAn;
         pB = pBn;
         for (k=0; k < nkb; k++)
         {
            if (!j)
            {
               a2blk(KB, mm, alpA, a, lda, pA);
               a += incAk;
            }
            if (!i)
            {
                b2blk(KB, nn, alpB, b, ldb, pB);
                b += incBk;
            }
            pAn = pA + incAw;
            pAn = (k != nkb-1) ? pAn : pA0;
            pBn = pB + incBw;
            pBn = (k != nkb-1 || j != nnblks-1) ? pBn : pB0;
            amm(nmu, nnu, KB, pA, pB, pC, pAn, pBn, pC);
            pA = pAn;
            pB = pBn;
         }
         blk2c(mm, nn, alpC, pC, beta, c, ldc);
         c += nn*(ldc SHIFT);
         B += nn*mulBn;
      }
      pB = pB0;
      A += mm*mulAm;
      C += mm;
   }
@ROUT ATL_cammmMNK
         incBw0 = KB0*nb;

         rA = iA + incAw0;
         pAn = rA + incAw0;
         pAn = (nkb) ? pAn : pA0;
         rB = iB + incBw0;
         pBn = rB + incBw0;
         if (!j)
         {
            a2blk(kb0, mm, alpA, a, lda, rA, iA);
            a += incAk0;
         }
         if (!i)
         {
             b2blk(kb0, nn, alpB, b, ldb, rB, iB);
             b += incBk0;
         }
         ammK0(nmu, nnu, KB0, iA, iB, rC, rA, iB, iC);
         ammK0(nmu, nnu, KB0, rA, iB, iC, rA, rB, rC);
         ammK0_bn(nmu, nnu, KB0, rA, rB, rC, iA, rB, iC);
         ammK0_b1(nmu, nnu, KB0, iA, rB, iC, pAn, pBn, rC);
         iA = pAn;
         iB = pBn;
         for (k=0; k < nkb; k++)
         {
            rA = iA + incAw;
            rB = iB + incBw;
            if (!j)
            {
               a2blk(KB, mm, alpA, a, lda, rA, iA);
               a += incAk;
            }
            if (!i)
            {
                b2blk(KB, nn, alpB, b, ldb, rB, iB);
                b += incBk;
            }
            pAn = rA + incAw;
            pAn = (k != nkb-1) ? pAn : pA0;
            pBn = rB + incBw;
            pBn = (k != nkb-1 || j != nnblks-1) ? pBn : pB0;
            amm_bn(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
            amm_b1(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
            amm_bn(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
            amm_b1(nmu, nnu, KB, iA, rB, iC, pAn, pBn, rC);
            iA = pAn;
            iB = pBn;
         }
         blk2c(mm, nn, alpC, rC, iC, beta, c, ldc);
         c += nn*(ldc SHIFT);
         B += nn*mulBn;
      }
      iB = pB0;
      A += mm*mulAm;
      C += mm SHIFT;
   }
@ROUT ATL_ammmMNK ATL_cammmMNK

   free(vp);
   return(0);
}
@ROUT ATL_ammmKNM
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   size_t n, nsmblks, nmblks, nsnblks, nnblks, j, incAm0, incAm, incAw0, incAw;
   size_t KK, incAk, incBk, incBn0, incBn, k;
   int mu, nu, ku, MB, NB, KB, mb, nb, NMU, NNU, A_1TRIP, nkb, kb0, KB0;
   void *vp;
   TYPE *pC, *pB, *pA, *pA0;
   ammkern_t ammK0, amm;
   const int B_BYCOLS = (TB == AtlasNoTrans);
   const int A_BYROWS = (TA == AtlasNoTrans);
   TYPE alpA=ATL_rone, alpB=ATL_rone;
   amminfo_t mminfo;

@skip   ATL_assert(N > ATL_AMM_MAXNB & M > ATL_AMM_MAXMB & K > ATL_AMM_MAXKB);
   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else
      alpB = alpha;
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   MB = ATL_ComputeB(M, mu, ATL_geAMM_LASTMB, &nsmblks, &nmblks);
   NMU = MB / mu;
   NB = ATL_ComputeB(N, nu, ATL_geAMM_LASTMB, &nsnblks, &nnblks);
   NNU = NB / nu;
   A_1TRIP = (nnblks < 2);
   KB = mminfo.kb;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0 = mminfo.amm_b0;
         else
            ammK0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && kb0 == (kb0/ku)*ku &&
          kb0 > mminfo.kbmin)
         ammK0 = mminfo.amm_b0;
   }
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;
   KK = nkb*KB + KB0;
/*
 * Do memory allocation, setup pointers
 */
   {
      size_t tsz, szA;
      const int szB = NB*KB, szC = MB*NB;

      if (A_1TRIP)
         szA = KB*MB;
      else
         szA = (nsmblks*(MB-mu)+(nmblks-nsmblks)*MB)*KB;
      tsz = ATL_MulBySize(szA + szB + szC + mu*nu*ku) + 3*ATL_Cachelen;
      if (tsz > ATL_MaxMalloc)
         return(2);
      vp = malloc(tsz);
      if (!vp)
         return(1);
      pC = ATL_AlignPtr(vp);
      pB = pC + szC;
      pB = ATL_AlignPtr(pB);
      pA = pB + szB;
      pA = ATL_AlignPtr(pA);
   }

   if (A_BYROWS)
   {
      incAm0 = (MB-mu);
      incAm = MB;
      incAk = KB*lda;
   }
   else
   {
      incAm0 = (MB-mu)*lda;
      incAm = MB*lda;
      incAk = KB;
   }
   if (B_BYCOLS)
   {
      incBn0 = (NB-nu)*ldb;
      incBn = NB*ldb;
   }
   else
   {
      incBn0 = (NB-nu);
      incBn = NB;
   }
   if (A_1TRIP)
      incAw0 = incAw = 0;
   else
   {
      incAw0 = (MB-mu)*KB0;
      incAw = MB*KB0;
   }

   C += N*ldc;
   j = (nnblks-nsnblks)*NB + nsnblks*(NB-nu);
   if (B_BYCOLS)
   {
      B += j*ldb;
      incBk = KB;
   }
   else
   {
      B += j;
      incBk = KB*ldb;
   }
/*
 * Handle remainder/full block using the actual beta; all remaining K blks
 * will be of size KB after this
 */
   ATL_ammm_rkK(M, nmblks, nsmblks, MB, NMU, mu, N, nnblks, nsnblks, NB,
                NNU, nu, kb0, KB0, ku, A, lda, incAm0, incAm, B, ldb, 
                incBn0, incBn, C, ldc, alpA, alpB, beta, pA, incAw0, incAw, 
                pB, pC, ammK0, a2blk, b2blk, blk2c);
   B += (B_BYCOLS) ? kb0 : kb0*ldb;
   A += (A_BYROWS) ? kb0*lda : kb0;
/* 
 * If A workspace is entire panel, must now base increment on full KB
 */
   if (!A_1TRIP && KB0 != KB)
   {
      incAw0 = (MB-mu)*KB;
      incAw = MB*KB;
   }
/*
 * Loop over all remaining blocks using beta=1 and full KB
 * ALSO: need to change blk2c if it is bn!
 */
   amm = mminfo.amm_b0;
   for (k=0; k < nkb; k++, B += incBk, A += incAk)
      ATL_ammm_rkK(M, nmblks, nsmblks, MB, NMU, mu, N, nnblks, nsnblks, NB,
                   NNU, nu, KB, KB, ku, A, lda, incAm0, incAm, B, ldb, 
                   incBn0, incBn, C, ldc, alpA, alpB, ATL_rone, 
                   pA, incAw0, incAw, pB, pC, amm, a2blk, b2blk, blk2c);
   free(vp);
   return(0);
}
@ROUT ATL_aliased_rkK
#include "atlas_misc.h"
#include "atlas_amm.h"
#include "atlas_level1.h"
#include "atlas_lvl2.h"

static void *FixVector(enum ATLAS_TRANS TX, ATL_CSZT N, const SCALAR alpha,
                       const TYPE *X, ATL_CSZT incX)
{
   void *vx;
   TYPE *x;
   vx = malloc(ATL_MulBySize(N)+ATL_Cachelen);
   ATL_assert(vx);
   x = ATL_AlignPtr(vx);
   #ifndef TCPLX
      if (SCALAR_IS_ONE(alpha))
         Mjoin(PATL,copy)(N, X, incX, x, 1);
      else
         Mjoin(PATL,cpsc)(N, alpha, X, incX, x, 1);
   #else
      if (SCALAR_IS_ONE(alpha))
      {
         if (TX == AtlasTrans || TX == AtlasNoTrans)
            Mjoin(PATL,copy)(N, X, incX, x, 1);
         else
            Mjoin(PATL,copyConj)(N, X, incX, x, 1);
      }
      else
      {
         if (TX == AtlasTrans || TX == AtlasNoTrans)
            Mjoin(PATL,cpsc)(N, alpha, X, incX, x, 1);
         else
            Mjoin(PATL,moveConj)(N, alpha, X, incX, x, 1);
      }
   #endif
   return(vx);
}

/*
 * This entry makes rkK safe for L3kernel aliased calls.  It handles
 * only the aliasing required by the L3kernels, namely square blocks
 * less than ATLAS's largest blocking factor for the square dimensions,
 * with one of A/B aliased with C, and aliased by having
 * either A == C or B == C (i.e., not a partial overlap).  When A==C, 
 * M=K < ATL_rkAMM_LASTKB; when B==C, N=K < ATL_rkAMM_LASTKB.
 */
int Mjoin(PATL,ammm_aliased_rkK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alp,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef TCPLX
      const TYPE ONE[2] = {ATL_rone, ATL_rzero};
   #else
      #define ONE ATL_rone
   #endif
   void *vp=NULL;

   if (K == 0 || SCALAR_IS_ZERO(alp))
   {
      if (SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gezero)(M, N, C, ldc);
      else if (!SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gescal)(M, N, beta, C, ldc);
      return(0);
   }
   if (K == 1)
   {
      #ifdef TCPLX
         const SCALAR alpha = alp;
      #else
         TYPE alpha = alp;
      #endif
      void *xp=NULL, *yp=NULL;
      TYPE *a = (TYPE*)A, *b = (TYPE*)B;
      size_t ldA=lda, ldB=ldb;

      if (A == C)
      {
         xp = FixVector(TA, M, alpha, A, 
                        (TA == AtlasTrans || TA == AtlasConjTrans) ? lda:1);
         a = ATL_AlignPtr(xp);
         alpha = ONE;
         if (TA == AtlasConjTrans || TA == AtlasTrans)
         {
            TA = AtlasTrans;
            ldA = 1;
         }
         else if (TA == AtlasConj)
            TA = AtlasNoTrans;
      }
      if (B == C)
      {
         yp = FixVector(TB, N, alpha, B, 
                        (TB == AtlasTrans || TB == AtlasConjTrans) ? 1:ldb);
         b = ATL_AlignPtr(yp);
         alpha = ONE;
         if (TB == AtlasConjTrans)
            TB = AtlasTrans;
         else if (TB == AtlasConj || TB == AtlasNoTrans)
         {
            TA = AtlasNoTrans;
            ldB = 1;
         }
      }
      Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, a, ldA, b, ldB, beta, C, ldc);
      if (xp)
         free(xp);
      if (yp)
         free(yp);
      return(0);
   }

   if (K == 2)
   {
      #ifdef TCPLX
         const SCALAR alpha = alp;
      #else
         TYPE alpha = alp;
      #endif
/*
 *    If BETA != 1, ammm_rk2 will copy all inputs and thus aliasing safe
 */
      if (!SCALAR_IS_ONE(beta))
         Mjoin(PATL,ammm_rk2)(TA, TB, M, N, alpha, A, lda, B, ldb, beta, 
                              C, ldc);
/*
 *    For beta = 1, copy aliased input array(s) and then call GER2
 */
      else
      {
         void *wp=NULL, *xp=NULL, *yp=NULL, *zp=NULL;
         TYPE *w, *x, *y, *z;
         ATL_SZT incX, incY;
      #ifndef TCPLX
         if (A == C)
         {
            ATL_CSZT incx = (TA == AtlasTrans) ? lda:1;
      #else
         if (A == C || TA == AtlasConjTrans || TA == AtlasConj)
         {
            ATL_CSZT incx = (TA == AtlasTrans || TA == AtlasConjTrans) ? lda:1;
      #endif
            wp = FixVector(TA, M, alpha, A, incx);
            xp = FixVector(TA, M, alpha, A+((incx==1 ? lda:1)SHIFT), incx);
            alpha = ONE;
            w = ATL_AlignPtr(wp);
            incX = 1;
         }
         else  /* don't need to copy A */
         {
            w = (TYPE*)A;
            if (TA == AtlasNoTrans)
            {
               x = (TYPE*)(A + (lda SHIFT));
               incX = 1;
            }
            else /* if (TA == AtlasTrans) */
            {
               x = (TYPE*)(A + (1 SHIFT));
               incX = lda;
            }
         }
         if (B == C)
         {
            ATL_CSZT incy = (TB == AtlasTrans || TB == AtlasConjTrans) ? 1:ldb;
            yp = FixVector(TB, N, alpha, A, incy);
            zp = FixVector(TB, N, alpha, A+(((incy==1)?ldb:1)SHIFT), incy);
            y = ATL_AlignPtr(yp);
            z = ATL_AlignPtr(zp);
         #ifdef TCPLX
            if (TB == AtlasConj)
               TB = AtlasNoTrans;
            else if (TB == AtlasConjTrans)
               TB = AtlasTrans;
         #endif
            incY = 1;
            alpha = ONE;
         
         }
         else  /* no need to copy B */
         {
            y = (TYPE*)B;
         #ifdef TCPLX
            if (TB == AtlasNoTrans || TB == AtlasConj)
         #else
            if (TB == AtlasNoTrans)
         #endif
            {
               incY = ldb;
               z = (TYPE*)(B + (1 SHIFT));
            }
            else
            {
               incY = 1;
               z = (TYPE*)(B + (ldb SHIFT));
            }
         }
         #ifndef TCPLX
            Mjoin(PATL,ger2)(M, N, alpha, w, incX, y, incY, ONE, 
                             x, incX, z, incY, C, ldc);
         #else
            if (TB == AtlasNoTrans || TB == AtlasTrans)
               Mjoin(PATL,ger2u)(M, N, alpha, w, incX, y, incY, ONE, 
                                 x, incX, z, incY, C, ldc);
            else
               Mjoin(PATL,ger2c)(M, N, alpha, w, incX, y, incY, ONE, 
                                 x, incX, z, incY, C, ldc);
         #endif
         if (wp)
            free(wp);
         if (xp)
            free(xp);
         if (yp)
            free(yp);
         if (zp)
            free(zp);
         return(0);
      }
      return(0);
   }
/*
 * For K > 3, ATL_ammm_rkK is safe for these precise aliasing conditions
 */
   ATL_assert(!Mjoin(PATL,ammm_rkK)(TA, TB, M, N, K, alp, A, lda, B, ldb, 
                                    beta, C, ldc));
   return(0);
@beginskip
   if (K < 3)
   {
      lda = (TA == AtlasNoTrans || TA == AtlasConj) ? M:K;
      ldb = (TB == AtlasNoTrans || TB == AtlasConj) ? K:N;
      a = malloc(ATL_MulBySize((M+N)*K));
      ATL_assert(a);
      b = a + ((M*K)SHIFT);
      if (lda == M)
         Mjoin(PATL,gecopy)(M, K, A, ldA, a, lda);
      else
         Mjoin(PATL,gecopy)(K, M, A, ldA, a, lda);
      if (ldb == K)
         Mjoin(PATL,gecopy)(K, N, B, ldB, b, ldb);
      else
         Mjoin(PATL,gecopy)(N, K, B, ldB, b, ldb);
   }
   ATL_assert(!Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, a, lda, b, ldb, 
              beta, C, ldc));
   if (a != A)
      free(a);
@endskip
}
@ROUT ATL_ammm_tN
#include "atlas_amm.h"
/* 
 * This routine handles N <= MAXN, K & M large (left-looking shape)
 */
int Mjoin(PATL,ammm_tN)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   size_t szB, szC;
   TYPE *a, *b, *c;
   void *vp;
   int idx;
   ipinfo_t ip;


   idx = Mjoin(PATL,geGetAmmmIndx)(M, N, K);
   Mjoin(PATL,geComputeIPInfo)(&ip, idx, TA, TB, M, N, K, lda, 
                               ldb, ldc, alpha, beta);
   szC = ip.szC;
   szB = ip.pszB*ip.npnblks + ip.szB*ip.nfnblks;
   szB = ip.szB*(ip.nfkblks+1);
   vp = malloc(ATL_MulBySize(szC+ip.szA+szB+(ip.mu<<1)*ip.nu)
               + 3*ATL_Cachelen);
   if (!vp)
      return(1);
   a = ATL_AlignPtr(vp);
   b = a + (ip.szA SHIFT);
   b = ATL_AlignPtr(b);
   c = b + (szB SHIFT);
   c = ATL_AlignPtr(c);
   Mjoin(PATL,iploopsMK)(&ip, 0, 0, A, B, C, 2, a, b,
   #ifdef TCPLX
                         c+szC, c, beta, ip.blk2c);
   #else
                         c, c, beta, ip.blk2c);
   #endif

   free(vp);
   return(0);
}
@ROUT ATL_ammm_tN_old
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   ammkern_t ammK0, amm;
   amminfo_t mminfo;
   TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   TYPE *pA, *pB0, *pB, *pC;
   int mu, nu, ku, nnu, NN, MB, NMU, KB, KB0, kb0, incBw, incBw0;
   size_t incAk0, incAk, mulAm, incBk0, incBk, nkb, k, nmblks, nsmblks, i, m;
   void *vp;

   ATL_assert(N <= ATL_geAMM_LASTNB);
   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   MB = ATL_ComputeB(M, mu, ATL_geAMM_LASTMB, &nsmblks, &nmblks);
   NMU = MB / mu;
   nnu = (N+nu-1)/nu;
   KB = mminfo.kb;
   NN = nnu * nu;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0 = mminfo.amm_b0;
         else
            ammK0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && kb0 == (kb0/ku)*ku &&
          kb0 > mminfo.kbmin)
         ammK0 = mminfo.amm_b0;
   }
   amm = mminfo.amm_b1;
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;

/*
 * Do memory allocation, setup pointers
 */
   {
      const int szA = MB*KB, szC=MB*NN; 
      size_t szB = (nkb*KB+KB0)*NN;
      const size_t tsz = ATL_MulBySize(szA+szB+szC+mu*nu*ku) + 3*ATL_Cachelen;
      if (tsz > ATL_MaxMalloc)
         return(2);
      vp = malloc(tsz);
      if (!vp)
         return(1);
      pA = ATL_AlignPtr(vp);
      pB = pA + szA;
      pB0 = pB = ATL_AlignPtr(pB);
      pC = pB + szB;
      pC = ATL_AlignPtr(pC);
   }
   if (TA == AtlasNoTrans)
   {
      incAk = lda*KB;
      incAk0 = lda*kb0;
      mulAm = 1;
   }
   else
   {
      incAk = KB;
      incAk0 = kb0;
      mulAm = lda;
   }
   if (TB == AtlasNoTrans)
   {
      incBk = KB;
      incBk0 = kb0;
   }
   else
   {
      incBk = KB*ldb;
      incBk0 = kb0*ldb;
   }
   if (nkb)
   {
      incBw0 = KB0*NN;
      if (nkb > 1)
         incBw = KB*NN;
      else incBw = 0;
   }
   else 
      incBw = incBw0 = 0;
   for (m=M,i=0; i < nmblks; i++)
   {
      const TYPE *An;
      TYPE *pBn;
      int mb, nmu, mm;

      if (i < nsmblks)
      {
         mb = MB-mu;
         nmu = NMU-1;
      }
      else
      {
         mb = MB;
         nmu = NMU;
      }
      mm = Mmin(m, mb);
      m -= mm;
      An = A + mm*mulAm;
/*
 *    Do first (possibly partial) K-block
 */
      a2blk(kb0, mm, alpA, A, lda, pA);
      A += incAk0;
      if (!i)
      {
         b2blk(kb0, N, alpB, B, ldb, pB);
         B += incBk0;
      }
      pBn = pB + incBw0;
      ammK0(nmu, nnu, KB0, pA, pB, pC, pA, pBn, pC);
      pB = pBn;
/*
 *    Loop over all full-sized blocks
 */
      for (k=0; k < nkb; k++)
      {
         a2blk(KB, mm, alpA, A, lda, pA);
         A += incAk;
         if (!i)
         {
            b2blk(KB, N, alpB, B, ldb, pB);
            B += incBk;
         }
         pBn = (k < nkb-1) ? pB+incBw : pB0;
         amm(nmu, nnu, KB, pA, pB, pC, pA, pBn, pC);
         pB = pBn;
      }
      blk2c(mm, N, alpC, pC, beta, C, ldc);
      C += mm;
      A = An;
   }

   free(vp);
   return(0);
}
@ROUT ATL_cammm_tN
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   ammkern_t ammK0_b0, ammK0_b1, ammK0_bn, amm_b1, amm_bn;
   amminfo_t mminfo;
   const TYPE ONE[2] = {ATL_rone, ATL_rzero};
   const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
   TYPE *rA, *iA, *pB0, *rC, *iC;
   int mu, nu, ku, nnu, NN, MB, NMU, KB, KB0, kb0, incBw, incBw0;
   size_t incAk0, incAk, mulAm, incBk0, incBk, nkb, k, nmblks, nsmblks, i, m;
   void *vp;

   ATL_assert(N <= ATL_geAMM_LASTNB);
   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   MB = ATL_ComputeB(M, mu, MY_MAXMB, &nsmblks, &nmblks);
   NMU = MB / mu;
   nnu = (N+nu-1)/nu;
   KB = mminfo.kb;
   NN = nnu * nu;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0_b0 = mminfo.amm_b0;
         else
            ammK0_b0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0_b0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && (kb0/ku)*ku == kb0 &&
          kb0 > mminfo.kbmin)
         ammK0_b0 = mminfo.amm_b0;
   }
   amm_b1 = mminfo.amm_b1;
   amm_bn = mminfo.amm_bn;
   if (ammK0_b0 == mminfo.amm_b0)
   {
      ammK0_b1 = mminfo.amm_b1;
      ammK0_bn = mminfo.amm_bn;
   }
   else
   {
      ammK0_b1 = mminfo.amm_k1_b1;
      ammK0_bn = mminfo.amm_k1_bn;
   }
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;

/*
 * Do memory allocation, setup pointers
 */
   {
      const int szA = MB*KB, szC=MB*NN; 
      size_t szB = (nkb*KB+KB0)*NN;
      const size_t tsz = ATL_MulBySize(szA+szB+szC+mu*nu*ku) + 3*ATL_Cachelen;
      if (tsz > ATL_MaxMalloc)
         return(2);
      vp = malloc(tsz);
      if (!vp)
         return(1);
      iA = ATL_AlignPtr(vp);
      rA = iA + szA;
      iC = rA + szA;
      iC = ATL_AlignPtr(iC);
      rC = iC + szC;
      pB0 = rC + szC;
      pB0 = ATL_AlignPtr(pB0);
   }
   if (TA == AtlasNoTrans)
   {
      incAk = (lda*KB)SHIFT;
      incAk0 = (lda*kb0)SHIFT;
      mulAm = 2;
   }
   else
   {
      incAk = KB SHIFT;
      incAk0 = kb0 SHIFT;
      mulAm = lda SHIFT;
   }
   if (TB == AtlasNoTrans)
   {
      incBk = KB SHIFT;
      incBk0 = kb0 SHIFT;
   }
   else
   {
      incBk = (KB*ldb)SHIFT;
      incBk0 = (kb0*ldb)SHIFT;
   }
   incBw0 = KB0*NN;
   incBw = KB*NN;
   for (m=M,i=0; i < nmblks; i++)
   {
      const TYPE *An;
      TYPE *iB=pB0, *rB=pB0+incBw0, *pBn=rB+incBw0;
      int mb, nmu, mm;

      if (i < nsmblks)
      {
         mb = MB-mu;
         nmu = NMU-1;
      }
      else
      {
         mb = MB;
         nmu = NMU;
      }
      mm = Mmin(m, mb);
      m -= mm;
      An = A + mm*mulAm;
/*
 *    Do first (possibly partial) K-block
 */
      a2blk(kb0, mm, alpA, A, lda, rA, iA);
      A += incAk0;
      if (!i)
      {
         b2blk(kb0, N, alpB, B, ldb, rB, iB);
         B += incBk0;
      }
      rB = iB + incBw0;
      pBn = rB + incBw0;
      ammK0_b0(nmu, nnu, KB0, iA, iB, rC, rA, iB, iC);
      ammK0_b0(nmu, nnu, KB0, rA, iB, iC, rA, rB, rC);
      ammK0_bn(nmu, nnu, KB0, rA, rB, rC, iA, rB, iC);
      ammK0_b1(nmu, nnu, KB0, iA, rB, iC, rA, pBn, iC);
      iB = pBn;
/*
 *    Loop over all full-sized blocks
 */
      for (k=0; k < nkb; k++)
      {
         a2blk(KB, mm, alpA, A, lda, rA, iA);
         A += incAk;
         rB = iB + incBw;
         if (!i)
         {
            b2blk(KB, N, alpB, B, ldb, rB, iB);
            B += incBk;
         }
         pBn = (k < nkb-1) ? rB+incBw : pB0;
         amm_bn(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
         amm_b1(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
         amm_bn(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
         amm_b1(nmu, nnu, KB, iA, rB, iC, rA, pBn, iC);
         iB = pBn;
      }
      blk2c(mm, N, alpC, rC, iC, beta, C, ldc);
      C += mm+mm;
      A = An;
   }

   free(vp);
   return(0);
}
@ROUT ATL_cammm_IP
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   ammkern_t ammK0_b0, ammK0_b1, ammK0_bn, amm_b1, amm_bn;
   amminfo_t mminfo;
   const TYPE ONE[2] = {ATL_rone, ATL_rzero};
   const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
   TYPE *rA, *iA, *rB, *iB, *rC, *iC;
   int mu, nu, ku, nmu, nnu, MM, NN, KB, KB0, kb0;
   size_t incA, incB, nkb, k;
   void *vp;

   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   nmu = (M+mu-1)/mu;
   nnu = (N+nu-1)/nu;
   KB = mminfo.kb;
   MM = nmu * mu;
   NN = nnu * nu;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0_b0 = mminfo.amm_b0;
         else
            ammK0_b0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0_b0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && (kb0/ku)*ku == kb0 && 
          kb0 > mminfo.kbmin)
         ammK0_b0 = mminfo.amm_b0;
   }
   amm_b1 = mminfo.amm_b1;
   amm_bn = mminfo.amm_bn;
   if (ammK0_b0 == mminfo.amm_b0)
   {
      ammK0_b1 = amm_b1;
      ammK0_bn = amm_bn;
   }
   else
   {
      ammK0_b1 = mminfo.amm_k1_b1;
      ammK0_bn = mminfo.amm_k1_bn;
   }
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;

/*
 * Do memory allocation, setup pointers
 */
   {
      const int szA=MM*KB, szB=KB*NN, szC=MM*NN;
      vp = malloc(ATL_MulBySize(szA + szB + szC + mu*nu*ku) + 3*ATL_Cachelen);
      ATL_assert(vp);
      iA = ATL_AlignPtr(vp);
      rA = iA + szA;
      iB = rA + szA;
      iB = ATL_AlignPtr(iB);
      rB = iB + szB;
      iC = rB + szB;
      iC = ATL_AlignPtr(iC);
      rC = iC + szC;
   }
   incA = ((TA == AtlasNoTrans) ? lda*KB : KB)SHIFT;
   incB = ((TB == AtlasNoTrans) ? KB : KB*ldb)SHIFT;
/*
 * Do first (possibly partial) K-block
 */
   a2blk(kb0, M, alpA, A, lda, rA, iA);
   b2blk(kb0, N, alpB, B, ldb, rB, iB);
   ammK0_b0(nmu, nnu, KB0, iA, iB, rC, rA, iB, iC);
   ammK0_b0(nmu, nnu, KB0, rA, iB, iC, rA, rB, rC);
   ammK0_bn(nmu, nnu, KB0, rA, rB, rC, iA, rB, iC);
   ammK0_b1(nmu, nnu, KB0, iA, rB, iC, iA, iB, rC);
   A += ((TA == AtlasNoTrans) ? lda*kb0 : kb0)SHIFT;
   B += ((TB == AtlasNoTrans) ? kb0 : kb0*ldb)SHIFT;
/*
 * Loop over all full-sized blocks
 */
   for (k=0; k < nkb; k++)
   {
      a2blk(KB, M, alpA, A, lda, rA, iA);
      b2blk(KB, N, alpB, B, ldb, rB, iB);
      ammK0_bn(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
      ammK0_b1(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
      ammK0_bn(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
      ammK0_b1(nmu, nnu, KB, iA, rB, iC, iA, iB, rC);
      A += incA;
      B += incB;
   }
   blk2c(M, N, alpC, rC, iC, beta, C, ldc);

   free(vp);
   return(0);
}
@ROUT ATL_ammm_IP_0
{
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   ammkern_t ammK0, amm;
   amminfo_t mminfo;
   TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   TYPE *pA, *pB, *pC;
   int mu, nu, ku, nmu, nnu, MM, NN, KB, KB0, kb0;
   size_t incA, incB, nkb, k;
   void *vp;

   mu = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   nmu = (M+mu-1)/mu;
   nnu = (N+nu-1)/nu;
   KB = mminfo.kb;
   MM = nmu * mu;
   NN = nnu * nu;
   nkb = K/KB;
/*
 * kb0: K remainder, KB0 is CEIL(kb0/ku)*ku for k-vector kerns, and
 * same as kb0 for M-vector kerns
 */
   KB0 = kb0 = K - nkb*KB;
   if (!kb0)
   {
      KB0 = kb0 = KB;
      nkb--;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            ammK0 = mminfo.amm_b0;
         else
            ammK0 = (mminfo.kb==KB0) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
   {
      ammK0 = (kb0 == KB) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && kb0 == (kb0/ku)*ku && 
          kb0 > mminfo.kbmin)
         ammK0 = mminfo.amm_b0;
   }
   amm = mminfo.amm_b1;
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;

/*
 * Do memory allocation, setup pointers
 */
   {
      const int szA=MM*KB, szB=KB*NN, szC=MM*NN;
      vp = malloc(ATL_MulBySize(szA + szB + szC + mu*nu*ku) + 3*ATL_Cachelen);
      ATL_assert(vp);
      pA = ATL_AlignPtr(vp);
      pB = pA + szA;
      pB = ATL_AlignPtr(pB);
      pC = pB + szB;
      pC = ATL_AlignPtr(pC);
   }
   incA = (TA == AtlasNoTrans) ? lda*KB : KB;
   incB = (TB == AtlasNoTrans) ? KB : KB*ldb;
/*
 * Do first (possibly partial) K-block
 */
   a2blk(kb0, M, alpA, A, lda, pA);
   b2blk(kb0, N, alpB, B, ldb, pB);
   ammK0(nmu, nnu, KB0, pA, pB, pC, pA, pB, pC);
   A += (TA == AtlasNoTrans) ? lda*kb0 : kb0;
   B += (TB == AtlasNoTrans) ? kb0 : kb0*ldb;
/*
 * Loop over all full-sized blocks
 */
   for (k=0; k < nkb; k++)
   {
      a2blk(KB, M, alpA, A, lda, pA);
      b2blk(KB, N, alpB, B, ldb, pB);
      amm(nmu, nnu, KB, pA, pB, pC, pA, pB, pC);
      A += incA;
      B += incB;
   }
   blk2c(M, N, alpC, pC, beta, C, ldc);

   free(vp);
   return(0);
}
@ROUT ATL_ammm_IP
int Mjoin(PATL,ammm_IP)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   ipinfo_t ip;
   TYPE *a, *b, *c;
   void *vp;
   int i;

   i = Mjoin(PATL,geGetAmmmIndx)(M, N, K);
   Mjoin(PATL,geComputeIPInfo)(&ip, i, TA, TB, M, N, K, lda, ldb, ldc, 
                               alpha, beta);
   vp = malloc(ATL_MulBySize(ip.szC+ip.szA+ip.szB+(ip.mu<<1)*ip.nu)
               + 3*ATL_Cachelen);
   if (!vp)
      return(1);

   a = ATL_AlignPtr(vp);
   b = a + (ip.szA SHIFT);
   b = ATL_AlignPtr(b);
   c = b + (ip.szB SHIFT);
   c = ATL_AlignPtr(c);
   Mjoin(PATL,iploopsK)(&ip, 0, 0, A, B, C, 0, a, b, 
   #ifdef TCPLX
                        c+ip.szC, c, beta, ip.blk2c);
   #else
                        c, c, beta, ip.blk2c);
   #endif
   free(vp);
   return(0);
}
@beginskip
int Mjoin(PATL,ammm_IP)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef TCPLX
      const TYPE ONE[2]={ATL_rone,ATL_rzero}, ZERO[2]={ATL_rzero,ATL_rzero};
      const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
   #else
      #define ONE ATL_rone
      TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   #endif
   TYPE *a, *b, *rC, *iC;
   void *vp;
   size_t sz, incAk, incBk;
   ATL_INT lenA, lenB, lenC;
   int mu, nu, ku, nmu, nnu, kb, MB, NB, KB, kb0, KB0;
   ATL_INT nfkblks;
   amminfo_t mminf;


   mu = Mjoin(PATL,GetAmmmInfo)(&mminf, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminf.mu;
   nu = mminf.nu;
   ku = mminf.ku;
   nmu = (M+mu-1)/mu;
   nnu = (N+nu-1)/nu;
   KB = kb = mminf.kb;
   nfkblks = K / kb;
   MB = nmu * mu;
   NB = nnu * nu;
   kb0 = K - nfkblks*kb;
   if (!kb0)
   {
      kb0 = KB0 = kb;
      nfkblks--;
   }
   else
   {
      #if ATL_geAMM_MAXKVEC > 1
         if (ATL_AMMFLG_KMAJOR(mminf.flag))
         {
            KB0 = ((kb0+ku-1)/ku)*ku;
            KB = Mmax(KB, KB0);
         }
         else
      #endif
      KB0 = kb0;
   }
   lenA = MB*KB;
   lenB = KB*NB;
   lenC = MB*NB;
   sz = lenA + lenB + lenC + 2*mu*nu;
   sz = ATL_MulBySize(sz) + 4*ATL_Cachelen;
   vp = malloc(sz);
   ATL_assert(vp);
   a = ATL_AlignPtr(vp);
   b = a + (lenA SHIFT);
   b = ATL_AlignPtr(b);
   iC = b + (lenB SHIFT);
   iC = ATL_AlignPtr(iC);
   #ifdef TCPLX
      rC = iC + lenC;
      rC = ATL_AlignPtr(rC);
   #else
      rC = iC;
   #endif
   incAk = (IS_COLMAJ(TA)) ? lda*kb : kb;
   incBk = (IS_COLMAJ(TB)) ? kb : kb*ldb;
   #ifdef TCPLX
      incAk += incAk;
      incBk += incBk;
   #endif
   Mjoin(PATL,ammmK)(&mminf, M, nmu, N, nnu, nfkblks, kb, kb0, KB0, A, lda,
                     incAk, B, ldb, incBk, mminf.Cblk2cm, C, ldc, a, 0, b, 0,
                     rC, iC, alpA, alpB, alpC, beta);
   free(vp);
   return(0);
}
@endskip
@ROUT ATL_ammm_1b
{
   size_t szA, szB, szC;
   int i;
   int nmu, nnu, nku, bM, bN, bK;
   #if ATL_geAMM_MAXKVEC > 1
      int KK;
   #else
      #define KK K
   #endif
   int mu, nu, ku, appAl;
   void *vp;
   TYPE *pA, *pB, *pC, *p;
   TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   ammkern_t amm;
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   amminfo_t mminfo;
   appAl = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!appAl)
      alpA = alpha;
   else if (appAl == 1)
      alpB = alpha;
   else
      alpC = alpha;
/*
 * These kernels all take runtime M/N, and do well with near-square, so
 * blindly use this kernel with nM = CEIL(M/mu)*mu, nN = CEIL(N/nu)*nu
 */
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   nmu = (M+mu-1)/mu;
   nnu = (N+nu-1)/nu;
   nku = (K+ku-1)/ku;
   bM = nmu * mu;
   bN = nnu * nu;
   bK = nku * ku;
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;
   #if ATL_geAMM_MAXKVEC > 1
      KK = K;
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KK = bK;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            amm = mminfo.amm_b0;
         else 
            amm = (mminfo.kb==KK) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
         amm = (bK == K) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      else
         amm = (K == mminfo.kb) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
/*
 * Force rank-K code to handle this case if we would have to use K-cleanup
 * code with unknown performance
 */
   if (amm != mminfo.amm_b0 && K > 2 && K <= ATL_rkAMM_LASTKB)
      return(-1);
   szA = bM*KK;
   szB = KK*bN;
   #if ATL_geAMM_MAXKVEC > 1
      szC = ((mu*nu+mminfo.vlen-1)/mminfo.vlen)*mminfo.vlen * nmu * nnu;
   #else
      szC = bM*bN;
   #endif
   vp = malloc(ATL_MulBySize(szC+szA+szB + (mu+mu)*nu*ku) + 3*ATL_Cachelen);
   if (!vp)
      return(1);
   pB = ATL_AlignPtr(vp);
   pA = pB + szB;
   pA = ATL_AlignPtr(pA);
   pC = pA + szA;
   pC = ATL_AlignPtr(pC);
/*
 * Copy A & B into workspace, and pad K its if necessary
 */
   a2blk(K, M, alpA, A, lda, pA);
   b2blk(K, N, alpB, B, ldb, pB);
   amm(nmu, nnu, KK, pA, pB, pC, pA, pB, pC);
   blk2c(M, N, alpC, pC, beta, C, ldc);

   free(vp);
   return(0);
}
@ROUT ATL_cammm_1b
{
   int i;
   int nmu, nnu, nku, bM, bN, bK;
   int szA, szB, szC;
   #if ATL_geAMM_MAXKVEC > 1
      int KK;
   #else
      #define KK K
   #endif
   int mu, nu, ku, appAl;
   void *vp;
   TYPE *rA, *iA, *rB, *iB, *rC, *iC, *p, *w;
   const TYPE one[2] = {ATL_rone, ATL_rzero};
   const TYPE *alpA=one, *alpB=one, *alpC=one;
   ammkern_t amm;
   ablk2cmat_t blk2c;
   cm2am_t a2blk, b2blk;
   amminfo_t mminfo;
   appAl = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (K < mminfo.kbmin || (mminfo.kbmax && mminfo.kbmax < K))
      return(1);
   if (!appAl)
      alpA = alpha;
   else if (appAl == 1)
      alpB = alpha;
   else
      alpC = alpha;
/*
 * These kernels all take runtime M/N, and do well with near-square, so
 * blindly use this kernel with nM = CEIL(M/mu)*mu, nN = CEIL(N/nu)*nu
 */
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   nmu = (M+mu-1)/mu;
   nnu = (N+nu-1)/nu;
   nku = (K+ku-1)/ku;
   bM = nmu * mu;
   bN = nnu * nu;
   bK = nku * ku;
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
   blk2c = mminfo.Cblk2cm;
   #if ATL_geAMM_MAXKVEC > 1
      KK = K;
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KK = bK;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            amm = mminfo.amm_b0;
         else 
            amm = (mminfo.kb==KK) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
   #endif
      if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
         amm = (bK == K) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
      else
         amm = (K == mminfo.kb) ? mminfo.amm_b0 : mminfo.amm_k1_b0;
/*
 * Force rank-K code to handle this case if we would have to use K-cleanup
 * code with unknown performance
 */
   if (amm != mminfo.amm_b0 && K > 2 && K <= ATL_rkAMM_LASTKB)
      return(-1);
   szB = KK*bN;
   szA = bM*KK;
   #if ATL_geAMM_MAXKVEC > 1
      szC = ((mu*nu+mminfo.vlen-1)/mminfo.vlen)*mminfo.vlen * nmu * nnu;
   #else
      szC = bM*bN;
   #endif
   vp = malloc((szC+mu*nu*ku + szA + szB)*2*ATL_sizeof + 3*ATL_Cachelen);
   ATL_assert(vp);
   iB = ATL_AlignPtr(vp);
   rB = iB + szB;
   rB = ATL_AlignPtr(rB);
   iA = rB + szB;
   iA = ATL_AlignPtr(iA);
   rA = iA + szA;
   iC = rA + szA;
   rC = iC + szC;
   w = rC + szC;
/*
 * Copy A & B into workspace, and pad K its if necessary
 */
   a2blk(K, M, alpA, A, lda, rA, iA);
   b2blk(K, N, alpB, B, ldb, rB, iB);
   amm(nmu, nnu, KK, iA, iB, rC, rA, iB, iC);
   amm(nmu, nnu, KK, rA, iB, iC, rA, rB, rC);
   if (amm == mminfo.amm_b0)
   {
      mminfo.amm_bn(nmu, nnu, KK, rA, rB, rC, iA, rB, iC);
      mminfo.amm_b1(nmu, nnu, KK, iA, rB, iC, iA, rB, iC);
   }
   else
   {
      mminfo.amm_k1_bn(nmu, nnu, KK, rA, rB, rC, iA, rB, iC);
      mminfo.amm_k1_b1(nmu, nnu, KK, iA, rB, iC, iA, rB, iC);
   }
   blk2c(M, N, alpC, rC, iC, beta, C, ldc);

   free(vp);
   return(0);
}
@ROUT ATL_ammm
{
@beginskip
   #ifdef TREAL
      if (TA == AtlasConj)
         TA = AtlasNoTrans;
      else if (TA == AtlasConjTrans)
         TA = AtlasTrans;
      if (TB == AtlasConj)
         TB = AtlasNoTrans;
      else if (TB == AtlasConjTrans)
         TB = AtlasTrans;
   #endif
@endskip
/*
 * Just do a scale and return
 */
   if (SCALAR_IS_ZERO(alpha) || !K)
   {
      if (SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gezero)(M, N, C, ldc);
      else if (!SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gescal)(M, N, beta, C, ldc);
      return(0);
   }
/*
 * Scope for degenerate cases that should call Level-2 BLAS; these
 * routines assert they work, since their workspace is O(N) and so are
 * not allowed to fail.
 */
   if (K == 1)  /* really a GER */
   {
   #ifdef TCPLX
      if (!SCALAR_IS_ONE(beta))  /* can't use GER for beta != 1 */
      {
         int i;
         const register TYPE ral=alpha[0], ial=alpha[1];
         const size_t ldc2 = ldc+ldc;
         ATL_CSZT incB = ((TB == AtlasNoTrans) ? ldb : 1)SHIFT;
         const register TYPE
            cjm = (TB==AtlasConj || TB==AtlasConjTrans) ? ATL_rnone:ATL_rone;
         TYPE *X=(TYPE*)A;
         void *vp=NULL;
/*
 *       Copy A if it's a row or if it must be conjugated
 */
         if (TA == AtlasTrans || TA == AtlasConjTrans || TA == AtlasConj)
         {
            vp = malloc(ATL_MulBySize(M)+ATL_Cachelen);
            ATL_assert(vp);
            X = ATL_AlignPtr(vp);
            if (TA == AtlasTrans)
               Mjoin(PATL,copy)(M, A, lda, X, 1);
            else if (TA == AtlasConjTrans)
               Mjoin(PATL,copyConj)(M, A, lda, X, 1);
            else
               Mjoin(PATL,copyConj)(M, A, 1, X, 1);
         }
         for (i=0; i < N; i++, B += incB, C += ldc2)
         {
            TYPE scal[2];
            register TYPE rb=(*B), ib=cjm*B[1];
            scal[0] = rb*ral - ib*ial;
            scal[1] = rb*ial + ib*ral;
            Mjoin(PATL,axpby)(M, scal,  X, 1, beta, C, 1);
         }
         if (vp)
            free(vp);
      }
      else  /* BETA=1, can use GERU/GERC */
      {
         if (TA == AtlasConjTrans || TA == AtlasConj)  /* must copyConj A */
         {
            void *vp;
            TYPE *X;
            const TYPE ONE[2] = {ATL_rone, ATL_rzero};
            vp = malloc(ATL_MulBySize(M)+ATL_Cachelen);
            ATL_assert(vp);
            X = ATL_AlignPtr(vp);
            Mjoin(PATL,moveConj)(M, alpha, A, (TA == AtlasConj) ? 1:lda, X, 1);
            if (TB == AtlasConjTrans || TB == AtlasConj)  /* use gerc */
               Mjoin(PATL,gerc)(M, N, ONE, X, 1, B,
                                (TB == AtlasConj) ? ldb : 1, C, ldc);
            else
               Mjoin(PATL,geru)(M, N, ONE, X, 1, B,
                                (TB == AtlasNoTrans) ? ldb : 1, C, ldc);
            free(vp);
         }
         else if (TB == AtlasConjTrans || TB == AtlasConj)  /* use gerc */
            Mjoin(PATL,gerc)(M, N, alpha, A, (TA == AtlasNoTrans) ? 1 : lda,
                             B, (TB == AtlasConj) ? ldb : 1, C, ldc);
         else /* use geru */
            Mjoin(PATL,geru)(M, N, alpha, A, (TA == AtlasNoTrans) ? 1 : lda,
                            B, (TB == AtlasNoTrans) ? ldb : 1, C, ldc);
      }
   #else
      if (!SCALAR_IS_ONE(beta)) /* can't use GER for beta != 1 */
      {
         int i;
         ATL_CSZT incA = ((TA == AtlasNoTrans) ? 1 : lda);
         ATL_CSZT incB = ((TB == AtlasNoTrans) ? ldb : 1);
         for (i=0; i < N; i++, B += incB, C += ldc)
            Mjoin(PATL,axpby)(M, alpha * *B,  A, incA, beta, C, 1);
      }
      else
         Mjoin(PATL,ger)(M, N, alpha, A, (TA == AtlasNoTrans) ? 1 : lda,
                         B, (TB == AtlasNoTrans) ? ldb : 1, C, ldc);
   #endif
      return(0);
   }
   if (K == 2)
      return(Mjoin(PATL,ammm_rk2)(TA, TB, M, N, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
   if (N == 1)  /* Really GEMV with A as matrix, A & C as vectors */
   {
   #ifdef TCPLX
      TYPE *X = (TYPE*)B;
      void *vp = NULL;
      int incX = 1;
/*
 *    Copy B if it we need to conjugate it
 */
      if (TB == AtlasConj || TB == AtlasConjTrans)
      {
         vp = malloc(ATL_MulBySize(K)+ATL_Cachelen);
         ATL_assert(vp);
         X = ATL_AlignPtr(vp);
         Mjoin(PATL,copyConj)(K, B, (TB == AtlasConj) ? 1:ldb, X, 1);
      }
      else
         incX = (TB == AtlasNoTrans) ? 1:ldb;
      if (TA == AtlasNoTrans || TA == AtlasConj)
         Mjoin(PATL,gemv)(TA, M, K, alpha, A, lda, X, incX, beta, C, 1);
      else /* if (TA == AtlasTrans || TA == AtlasConjTrans) */
         Mjoin(PATL,gemv)(TA, K, M, alpha, A, lda, X, incX, beta, C, 1);
      if (vp)
         free(vp);
   #else
      if (TA == AtlasNoTrans)
         Mjoin(PATL,gemv)(AtlasNoTrans, M, K, alpha, A, lda, B,
                          (TB == AtlasNoTrans) ? 1:ldb, beta, C, 1);
      else
         Mjoin(PATL,gemv)(AtlasTrans, K, M, alpha, A, lda, B,
                          (TB == AtlasNoTrans) ? 1:ldb, beta, C, 1);
   #endif
      return(0);
   }
   if (M == 1)  /* Really GEMV with B as matrix, A & C as vectors */
   {
   #ifdef TCPLX
      TYPE *X = (TYPE*)A;
      void *vp = NULL;
      int incX = 1;
/*
 *    Copy A if it we need to conjugate it
 */
      if (TA == AtlasConj || TA == AtlasConjTrans)
      {
         vp = malloc(ATL_MulBySize(K)+ATL_Cachelen);
         ATL_assert(vp);
         X = ATL_AlignPtr(vp);
         Mjoin(PATL,copyConj)(K, A, (TA == AtlasConj) ? lda:1, X, 1);
      }
      else
         incX = (TA == AtlasNoTrans) ? lda:1;
      if (TB == AtlasNoTrans)
         Mjoin(PATL,gemv)(AtlasTrans, K, N, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasConj)
         Mjoin(PATL,gemv)(AtlasConjTrans, K, N, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasTrans)
         Mjoin(PATL,gemv)(AtlasNoTrans, N, K, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasConjTrans)
         Mjoin(PATL,gemv)(AtlasConj, N, K, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      if (vp)
         free(vp);
   #else
      if (TB == AtlasNoTrans)
         Mjoin(PATL,gemv)(AtlasTrans, K, N, alpha, B, ldb, A,
                          (TA == AtlasNoTrans) ? lda:1, beta, C, ldc);
      else
         Mjoin(PATL,gemv)(AtlasNoTrans, N, K, alpha, B, ldb, A,
                          (TA == AtlasNoTrans) ? lda:1, beta, C, ldc);
   #endif
      return(0);
   }
/*
 * Special case mainly for real LU, where K==4, N==4 beta=1.0, TA==AtlasNoTrans;
 * Can do a no-copy update with only one loop.
 */
   #ifndef TCPLX
   if (K == 4 && N == 4 && TA==AtlasNoTrans && SCALAR_IS_ONE(beta))
   {
      int Mjoin(PATL,rk4n4)(enum ATLAS_TRANS,ATL_CSZT,const SCALAR,
          const TYPE*,ATL_CSZT,const TYPE*,ATL_CSZT,TYPE*,ATL_CSZT);
      if (!Mjoin(PATL,rk4n4)(TB, M, alpha, A, lda, B, ldb, C, ldc))
         return(0);
   }
   #endif
/*
 * 1-block special case code can return w/o doing op if it thinks
 * rank-K would be faster
 */
   if (M <= ATL_geAMM_LASTMB && N <= ATL_geAMM_LASTNB && K <= ATL_geAMM_LASTKB)
      if (!Mjoin(PATL,ammm_1b)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                               beta, C, ldc))
         return(0);
/*
 * Rank-K can fail to allocate space, so return success/failure
 */
   if (K > 2 && K <= ATL_rkAMM_LASTKB)
      return(Mjoin(PATL,ammm_rkK)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
/*
 * Handle case that is really an inner product shape (M<=MB, N<=NB, large K)
 * This case not allowed to fail since it requires only 3*NB^2 workspace.
 */
   if (M <= ATL_geAMM_LASTMB && N <= ATL_geAMM_LASTNB)
      return(Mjoin(PATL,ammm_IP)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                 beta, C, ldc));
/*
 * If B/C have only one column panel, call special low-workspace (3NB^3)
 * code for additional performance.  This shape occurs in left-looking LU.
 */
   if (N <= ATL_geAMM_LASTNB)
      return(Mjoin(PATL,ammm_tN)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                 beta, C, ldc));
/*
 * Next two loop orderings are general case, so use whichever uses least
 * workspace
 */
   if (M > N)
      return(Mjoin(PATL,ammmKMNK)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
   return(Mjoin(PATL,ammmKNMK)(TA, TB, M, N, K, alpha, A, lda, B, ldb, 
                               beta, C, ldc));
}
@ROUT ATL_cammm
{
/*
 * Just do a scale and return
 */
   if (SCALAR_IS_ZERO(alpha) || !K)
   {
      if (SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gezero)(M, N, C, ldc);
      else if (!SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gescal)(M, N, beta, C, ldc);
      return(0);
   }
/*
 * Scope for degenerate cases that should call Level-2 BLAS; these
 * routines assert they work, since their workspace is O(N) and so they
 * are not allowed to fail.
 */
   if (K == 1)  /* really a GER */
   {
      if (!SCALAR_IS_ONE(beta))  /* can't use GER for beta != 1 */
      {
         int i;
         const register TYPE ral=alpha[0], ial=alpha[1];
         const size_t ldc2 = ldc+ldc;
         ATL_CSZT incB = ((TB == AtlasNoTrans) ? ldb : 1)SHIFT;
         const register TYPE 
            cjm = (TB==AtlasConj || TB==AtlasConjTrans) ? ATL_rnone:ATL_rone;
         TYPE *X=(TYPE*)A;
         void *vp=NULL;
/*
 *       Copy A if it's a row or if it must be conjugated
 */
         if (TA == AtlasTrans || TA == AtlasConjTrans || TA == AtlasConj)
         {
            vp = malloc(ATL_MulBySize(M)+ATL_Cachelen);
            ATL_assert(vp);
            X = ATL_AlignPtr(vp);
            if (TA == AtlasTrans)
               Mjoin(PATL,copy)(M, A, lda, X, 1);
            else if (TA == AtlasConjTrans)
               Mjoin(PATL,copyConj)(M, A, lda, X, 1);
            else
               Mjoin(PATL,copyConj)(M, A, 1, X, 1);
         }
         for (i=0; i < N; i++, B += incB, C += ldc2)
         {
            TYPE scal[2];
            register TYPE rb=(*B), ib=cjm*B[1];
            scal[0] = rb*ral - ib*ial;
            scal[1] = rb*ial + ib*ral;
            Mjoin(PATL,axpby)(M, scal,  X, 1, beta, C, 1);
         }
         if (vp) 
            free(vp);
      }
      else  /* BETA=1, can use GERU/GERC */
      {
         if (TA == AtlasConjTrans || TA == AtlasConj)  /* must copyConj A */
         {
            void *vp;
            TYPE *X;
            const TYPE ONE[2] = {ATL_rone, ATL_rzero};
            vp = malloc(ATL_MulBySize(M)+ATL_Cachelen);
            ATL_assert(vp);
            X = ATL_AlignPtr(vp);
            Mjoin(PATL,moveConj)(M, alpha, A, (TA == AtlasConj) ? 1:lda, X, 1);
            if (TB == AtlasConjTrans || TB == AtlasConj)  /* use gerc */
               Mjoin(PATL,gerc)(M, N, ONE, X, 1, B, 
                                (TB == AtlasConj) ? ldb : 1, C, ldc);
            else
               Mjoin(PATL,geru)(M, N, ONE, X, 1, B, 
                                (TB == AtlasNoTrans) ? ldb : 1, C, ldc);
            free(vp);
         }
         else if (TB == AtlasConjTrans || TB == AtlasConj)  /* use gerc */
            Mjoin(PATL,gerc)(M, N, alpha, A, (TA == AtlasNoTrans) ? 1 : lda, 
                             B, (TB == AtlasConj) ? ldb : 1, C, ldc);
         else /* use geru */
            Mjoin(PATL,geru)(M, N, alpha, A, (TA == AtlasNoTrans) ? 1 : lda, 
                            B, (TB == AtlasNoTrans) ? ldb : 1, C, ldc);
      }
      return(0);
   }
   if (K == 2)
      return(Mjoin(PATL,ammm_rk2)(TA, TB, M, N, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
   if (N == 1)  /* GEMV wt A as matrix, B&C vecs */
   {                     
      TYPE *X = (TYPE*)B;
      void *vp = NULL;
      int incX = 1;
/*
 *    Copy B if it we need to conjugate it
 */
      if (TB == AtlasConj || TB == AtlasConjTrans)
      {
         vp = malloc(ATL_MulBySize(K)+ATL_Cachelen);
         ATL_assert(vp);
         X = ATL_AlignPtr(vp);
         Mjoin(PATL,copyConj)(K, B, (TB == AtlasConj) ? 1:ldb, X, 1);
      }
      else
         incX = (TB == AtlasNoTrans) ? 1:ldb;
      if (TA == AtlasNoTrans || TA == AtlasConj)
         Mjoin(PATL,gemv)(TA, M, K, alpha, A, lda, X, incX, beta, C, 1);
      else /* if (TA == AtlasTrans || TA == AtlasConjTrans) */
         Mjoin(PATL,gemv)(TA, K, M, alpha, A, lda, X, incX, beta, C, 1);
      if (vp)
         free(vp);
      return(0);
   }
   if (M == 1)  /* Really GEMV with B as matrix, A & C as vectors */
   {
      TYPE *X = (TYPE*)A;
      void *vp = NULL;
      int incX = 1;
/*
 *    Copy A if it we need to conjugate it
 */
      if (TA == AtlasConj || TA == AtlasConjTrans)
      {
         vp = malloc(ATL_MulBySize(K)+ATL_Cachelen);
         ATL_assert(vp);
         X = ATL_AlignPtr(vp);
         Mjoin(PATL,copyConj)(K, A, (TA == AtlasConj) ? lda:1, X, 1);
      }
      else
         incX = (TA == AtlasNoTrans) ? lda:1;
      if (TB == AtlasNoTrans)
         Mjoin(PATL,gemv)(AtlasTrans, K, N, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasConj)
         Mjoin(PATL,gemv)(AtlasConjTrans, K, N, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasTrans)
         Mjoin(PATL,gemv)(AtlasNoTrans, N, K, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      else if (TB == AtlasConjTrans)
         Mjoin(PATL,gemv)(AtlasConj, N, K, alpha, B, ldb, X, incX,
                          beta, C, ldc);
      if (vp)
         free(vp);
      return(0);
   }
/*
 * 1-block special case code can return w/o doing op if it thinks
 * rank-K would be faster
 */
   if (M <= ATL_geAMM_LASTMB && N <= ATL_geAMM_LASTNB && K <= ATL_geAMM_LASTKB)
   {
      if (!Mjoin(PATL,ammm_1b)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                               beta, C, ldc))
         return(0);
   }
/*
 * Rank-K could fail to allocate M*KB+KB*N+MB*KB workspace
 */
   if (K > 2 && K <= ATL_rkAMM_LASTKB)
      return(Mjoin(PATL,ammm_rkK)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
/*
 * If B/C have only one column panel, call special low-workspace (3NB^3)
 * code for additional performance.  This shape occurs in left-looking algs.
 */
   if (N <= ATL_geAMM_LASTNB)
      return(Mjoin(PATL,ammm_tN)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                 beta, C, ldc));
/*
 * Handle case that is really an inner product shape (M<=MB, N<=NB, large K)
 */
   if (M <= ATL_geAMM_LASTMB && N <= ATL_geAMM_LASTNB)
      return(Mjoin(PATL,ammm_IP)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                 beta, C, ldc));
/*
 * Next two loop orderings are general case, so use whichever uses least
 * workspace
 */
#if 0
   if (M > N)
      return(Mjoin(PATL,ammmMNK)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                 beta, C, ldc));
/*
 * This guy tries to allocate (M+NB)*K + NB^2 worskpace, so recursion
 * may be needed to keep it within allotted memory.
 */
   return(Mjoin(PATL,ammmNMK)(TA, TB, M, N, K, alpha, A, lda, B, ldb, 
                              beta, C, ldc));
#else
   if (M > N)
      return(Mjoin(PATL,ammmKMNK)(TA, TB, M, N, K, alpha, A, lda, B, ldb,
                                  beta, C, ldc));
   return(Mjoin(PATL,ammmKNMK)(TA, TB, M, N, K, alpha, A, lda, B, ldb, 
                               beta, C, ldc));
#endif
}
@ROUT ATL_ammm ATL_cammm
/*
 * Recur to get K below this value; this puts a ceiling on workspace and
 * usually improves performance (in huge problems, reduces TLB pressure)
 */
#define ATL_MAX_RK 3000


/*
 * This routine uses recursion to cut the dimensions of the matrices until
 * workspace requirements are low enough that a call to ATL_ammm succeeds
 */
void Mjoin(PATL,ammm)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   if (!M || !N)
      return;
/*
 * Cases where all we must do is possibly scale and return
 */
   if (SCALAR_IS_ZERO(alpha) || !K)
   {
      if (SCALAR_IS_ZERO(beta))
         Mjoin(PATL,gezero)(M, N, C, ldc);
      else if (!SCALAR_IS_ONE(beta))
         Mjoin(PATL,gescal)(M, N, beta, C, ldc);
      return;
   }
/*
 * Our stopping criteria is if ATL_ammm signals success in mallocing mem
 */
   if (K <= ATL_MAX_RK)
   {
      if(!ATL_ammm(TA, TB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc))
         return;
   }
/*
 * =========================================================================
 * Otherwise, problem too large, so we'll recursively divide its largest dim
 * =========================================================================
 */
/*
 * if K is tied for largest, cut it, since it reduces size of A & B
 * NOTE: C always uses only NB^2 workspace, so only A/B matters.
 */
   if (K > ATL_MAX_RK || (K >= N && K >= M))
   {
      const size_t kL=(K>>4)<<3, kR=K-kL;
      #ifdef TCPLX
         const TYPE ONE[2] = {ATL_rone, ATL_rzero};
      #else
         #define ONE ATL_rone
      #endif

      Mjoin(PATL,ammm)(TA, TB, M, N, kL, alpha, A, lda, B, ldb, beta, C, ldc);
      if (TA == AtlasNoTrans || TA == AtlasConj)
         A += (lda*kL)SHIFT;
      else
         A += kL SHIFT;
      if (TB == AtlasNoTrans)
         B += kL SHIFT;
      else
         B += (ldb*kL) SHIFT;
      Mjoin(PATL,ammm)(TA, TB, M, N, kR, alpha, A, lda, B, ldb, 
                       ONE, C, ldc);
      #ifdef ONE
         #undef ONE
      #endif
   }
   else if (N >= M)  /* cutting N */
   {
      const size_t nL = (N>>1), nR = N-nL;
      Mjoin(PATL,ammm)(TA, TB, M, nL, K, alpha, A, lda, B, ldb, beta, C, ldc);
      if (TB == AtlasNoTrans || TB == AtlasConj)
         B += (ldb*nL)SHIFT;
      else 
         B += nL SHIFT;
      C += (ldc*nL)SHIFT;
      Mjoin(PATL,ammm)(TA, TB, M, nR, K, alpha, A, lda, B, ldb, beta, C, ldc);
   }
   else  /* cutting M */
   {
      const size_t mL = (M>>1), mR = M-mL;
      Mjoin(PATL,ammm)(TA, TB, mL, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
      if (TA == AtlasNoTrans || TA == AtlasConj)
         A += mL SHIFT;
      else
         A += (mL*lda)SHIFT;
      C += mL SHIFT;
      Mjoin(PATL,ammm)(TA, TB, mR, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
   }
}

void Mjoin(PATL,gemm)(const enum ATLAS_TRANS TA, const enum ATLAS_TRANS TB,
                      ATL_CINT M, ATL_CINT N, ATL_CINT K, const SCALAR alpha,
                      const TYPE *A, ATL_CINT lda, const TYPE *B, 
                      ATL_CINT ldb, const SCALAR beta, TYPE *C, ATL_CINT ldc)
{
   Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
}
@ROUT atlas_simd.h
#ifndef ATLAS_SIMD_H
   #define  ATLAS_SIMD_H 1
#ifdef ATL_GAS_ARM64
   #define ATL_VECARM1 1
/*
 * On 32-bit ARM, disable SIMD unless NONIEEE flag is thrown
 */
#elif defined(ATL_GAS_ARM)
   #if !defined(ATL_NONIEEE) || !(defined(SREAL) || defined(SCPLX))
      #ifdef ATL_VLEN
         #undef ATL_VLEN
      #endif
      #define ATL_VLEN 1
   #else
      #define ATL_NEON 1
   #endif
#endif
//#undef ATL_AVX
//#undef ATL_SSE3
//#undef ATL_SSE2
//#undef ATL_SSE1
//#define ATL_FRCGNUVEC 1
//#define ATL_VLEN 32
/*
 * This header files contains wrappers to allow you to use SIMD vector
 * extensions in a very simplified way in a type-independent manner.
 * ATL_VLEN is treated differently, depending on whether we are using
 * system-dependent vectorization (eg., AVX, VSX, etc.) or gnu vectorization:
 * - For gnu vectorization, ATL_VLEN must be defined as a power of 2.
 * - For non-gnu vec ATL_VLEN should match the system, or be undefined.
* All macro funcs first arg is the destination.  vr stands for vector register.
 * We support the following miscellaneous instructions:
 *    ATL_vzero(vr)       : zero all vr entries
 *    ATL_vcopy(vrd, vrs) : vrd = vrs
 *
 * We support 5 load/store operations (where p is a pointer):
 *    ATL_vbcast(vr, p) : broadcast pointed-to scalar to all vr entries
 *    ATL_vuld(vr, p)   : unaligned load from ptr to vr
 *    ATL_vld(vr, p)    : aligned load from ptr to vr
 *    ATL_vust(p, vr)   : unaligned store to ptr from vr
 *    ATL_vst(p, vr)    : aligned store to ptr from vr
 * NOTE: if VLEN < native length, all  usually assume unaligned data,
 *       and (except bcast) become a series of instructions rather than one.
 *
 * We support 3 computational macros:
 * ATL_vadd(vrd, vrs1, vrs2) : vrd = vrs1 + vrs2
 * ATL_vsub(vrd, vrs1, vrs2) : vrd = vrs1 - vrs2
 * ATL_vmul(vrd, vrs1, vrs2) : vrd = vrs1 * vrs2
 * ATL_vmac(vrd, vrs1, vrs2) : vrd += vrs1 * vrs2
 *
 * For L1BLAS, we support a vector being summed to a scalar.
 * NOTE: srd must be a scalar reg
 *    ATL_vrsum1(srd, vrs)        : srd = sum(vrs[:])
 * For k-vec amm, we need to support summing up VLEN different accumulators,
 * and placing the result in one destination.  This requires the using code
 * to know VLEN (perhaps with a cpp if/else chain), but allows us to get
 * high performance on C stores.  We show the answer for vvrsum2 & 4, but
 * remember that only vvrsumVLEN will actually exist:
 *    ATL_vvrsum2(d, s0, s1) : d[0] = sum(s0[:]), d[1] = sum(s1[:])
 *    ATL_vvrsum4(d, s1, s2, s3, s4) : d[0:3] = sum(s0:4)
 */
/*
 * If ATL_VLEN is set, force gnuvec if it isn't set to the native length
 */
#ifdef ATL_VLEN
   #ifdef ATL_VSX
      #if ((defined(SREAL) || defined(SCPLX)) && ATL_VLEN != 4) || \
          ((defined(DREAL) || defined(DCPLX)) && ATL_VLEN != 2)
         #define ATL_FRCGNUVEC
      #endif
   #elif defined(ATL_VXZ)
      #if ATL_VLEN != 2;
         #define ATL_FRCGNUVEC
      #endif
   #elif defined(ATL_NEON)
      #if ((defined(SREAL) || defined(SCPLX)) && ATL_VLEN != 4) || \
          ((defined(DREAL) || defined(DCPLX)) && ATL_VLEN != 1)
         #define ATL_FRCGNUVEC
      #endif
@multidef vl    2   2    4      4       2
@whiledef sv SSE1 SSE2 AVX AVXMAC VECARM1
   @iexp vl2 @(vl) @(vl) +
   #elif defined(ATL_@(sv))
      #if ((defined(SREAL) || defined(SCPLX)) && ATL_VLEN != @(vl2)) || \
          ((defined(DREAL) || defined(DCPLX)) && ATL_VLEN != @(vl))
         #define ATL_FRCGNUVEC
      #endif
   @undef vl
@endwhile
   #endif
/*
 * Compute ATL_VLEN based on SIMD extension & TYPE, if not already set
 */
#else
   #ifdef ATL_VSX
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLEN 4
      #else
         #define ATL_VLEN 2
      #endif
   #elif defined(ATL_VXZ)
      #define ATL_VLEN 2
   #elif defined(ATL_NEON)
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLEN 4
      #else
         #define ATL_VLEN 1
      #endif
@multidef vl    2   2    4      4       2
@whiledef sv SSE1 SSE2 AVX AVXMAC VECARM1
   @iexp vl2 @(vl) @(vl) +
   #elif defined(ATL_@(sv))
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLEN @(vl2)
      #else
         #define ATL_VLEN @(vl)
      #endif
   @undef vl
@endwhile
   #endif
#endif
/*
 * Derive ATL_VLENb (veclen in bytes) from ATL_VLEN
 */
#ifndef ATL_VLEN
   #error "ATL_VLEN not defined!"
#else
   #if ATL_VLEN == 1
      #define ATL_VLSH 0
      #define ATL_DivByVLEN(i_) (i_)
      #define ATL_MulByVLEN(i_) (i_)
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLENb 4
      #else
         #define ATL_VLENb 8
      #endif
   @define i @1@
   @define p @2@
   @iwhile i < 6
   #elif ATL_VLEN == @(p)
      #define ATL_VLSH @(i)
      #define ATL_DivByVLEN(i_) ((i_)>>@(i))
      #define ATL_MulByVLEN(i_) ((i_)<<@(i))
      @iexp vl @(p) 4 *
      @iexp vl2 @(p) 8 *
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLENb @(vl)
      #else
         #define ATL_VLENb @(vl2)
      #endif
      @iexp p @(p) 2 *
      @iexp i @(i) 1 +
   @endiwhile
   #else
      #define ATL_DivByVLEN(i_) ((i_)/ATL_VLEN)
      #define ATL_MulByVLEN(i_) ((i_)*ATL_VLEN)
      #if defined(SREAL) || defined(SCPLX)
         #define ATL_VLENb (ATL_VLEN*4)
      #else
         #define ATL_VLENb (ATL_VLEN*8)
      #endif
   #endif
#endif
/*
 * We may want to force use of GNU vectorization on any platform.  If so,
 * undefine any defined system-specific vectorization.  
 * Undefine all vectorization if VLEN=1 (scalar code)!
 */
#if defined(ATL_FRCGNUVEC) || ATL_VLEN < 2
@whiledef sv VXZ VSX AVXMAC AVX SSE3 SSE2 SSE1 VECARM1 NEON
   #ifdef ATL_@(sv)
      #undef ATL_@(sv)
   #endif
@endwhile
   #if ATL_VLEN < 2 && defined(ATL_FRCGNUVEC)
       #undef ATL_FRCGNUVEC
   #endif
#endif
/*
 * Now set computational macros based on ATL_VLEN & SIMD defines
 */
#if defined(ATL_VSX)
   #include <altivec.h>
/*
 * Older gcc don't support don't support xxpermdi, merge[o,e], xxsel
 */
   #if (__GNUC__ > 4) || (__GNUC__ == 4 && __GNUC_MINOR__ > 9) || \
        (__GNUC__ == 4 && __GNUC_MINOR__ == 9 && __GNU_PATHLEVEL__ > 1) || \
        !defined(__GNUC__)
      #define ATL_FULLGCCVSX 1
   #else
      #define ATL_FULLGCCVSX 0
   #endif
   #if defined(SREAL) || defined(SCPLX)
      #define ATL_VTYPE vector float
      #if ATL_VLEN != 4
         #error "VSX supports only VLEN = 4 for floats!"
      #endif
   #else        /* double precision */
      #define ATL_VTYPE vector double
      #if ATL_VLEN != 2
         #error "VSX supports only VLEN = 2 for doubles!"
      #endif
   #endif
   #define ATL_vzero(v_) v_ = vec_splats((TYPE)0.0)
   #define ATL_vcopy(d_, s_) d_ = s_
   #define ATL_vbcast(v_, p_) v_ =  vec_splats(*((TYPE*)(p_)))
   #define ATL_vuld(v_, p_) v_ = vec_vsx_ld(0, (ATL_VTYPE*)(p_))
   #define ATL_vld(v_, p_) v_ = vec_ld(0, (ATL_VTYPE*)(p_))
   #define ATL_vust(p_, v_) vec_vsx_st(v_, 0, (ATL_VTYPE*)(p_))
   #define ATL_vst(p_, v_)  vec_st(v_, 0, (ATL_VTYPE*)(p_))
   #define ATL_vadd(d_, s1_, s2_) d_ =  vec_add(s1_, s2_)
   #define ATL_vsub(d_, s1_, s2_) d_ =  vec_sub(s1_, s2_)
   #define ATL_vmul(d_, s1_, s2_) d_ =  vec_mul(s1_, s2_)
   #define ATL_vmac(d_, s1_, s2_) d_ = vec_madd(s1_, s2_, d_)
   #if defined(SREAL) || defined(SCPLX)
      #define ATL_vrsum1(d_, s_) \
      { \
         VTYPE t_; \
         d_ = vec_splat(s_, 1); \
         d_ = vec_add(d_, s_) ; \
         t_ = vec_splat(s_, 2); \
         d_ = vec_add(d_, t_) ; \
         t_ = vec_splat(s_, 3); \
         d_ = vec_add(d_, t_) ; \
      }
      #if ATL_FULLGCCVSX
         #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
         {  ATL_VTYPE t_, h_;                    /*{s0d,s0c,s0b,s0a}*/\
            t_ = vec_vmrghw(s0_, s1_);           /*{s1b,s0b,s1a,s0a}*/\
            s0_ = vec_vmrglw(s0_, s1_);          /* s1d,s0d,s1c,s0c}*/ \
            s0_ = ATL_vadd(s0_, s0_, t_);        /*{s1bd,s0bd,s1ac,s0ac}*/\
            h_ = vec_vmrghw(s2_, s3_);           /*{s3b,s2b,s3a,s2a}*/\
            s2_ = vec_vmrglw(s2_, s3_);          /*{s3d,s2d,s3c,s2c}*/ \
            s2_ = ATL_vadd(s2_, s2_, h_);        /*{s3bd,s2bd,s3ac,s2ac}*/\
            t_ =  vec_xxpermdi(s0_, s2_, 0);     /*{s3ac,s2ac,s1ac,s0ac}*/\
            s0_ = vec_xxpermdi(s0_, s2_, 3);     /*{s3bd,s2bd,s1bd,s0bd}*/ \
            ATL_vadd(s0_, s0_, t_); \
            s0_ = vec_xxpermdi(s0_, s0_, 2);     /* pwr8 endian-insanity */ \
         }
         #define ATL_vvrsum2(s0_, s1_) \
         {  ATL_VTYPE t_, h_;                    /*{s0d,s0c,s0b,s0a}*/\
            t_ = vec_vmrghw(s0_, s1_);           /*{s1b,s0b,s1a,s0a}*/\
            s0_ = vec_vmrglw(s0_, s1_);          /*{s1d,s0d,s1c,s0c}*/ \
            s0_ = ATL_vadd(s0_, s0_, t_);        /*{s1bd,s0bd,s1ac,s0ac}*/\
            t_ =  vec_xxpermdi(s0_, s0_, 0);     /*{s1ac,s0ac,s1ac,s0ac}*/\
            s0_ = vec_xxpermdi(s0_, s0_, 3);     /*{s1bd,s0bd,s1bd,s0bd}*/ \
            ATL_vadd(s0_, s0_, t_); \
            s0_ = vec_xxpermdi(s0_, s0_, 2);     /* pwr8 endian-insanity */ \
         }
         #define ATL_vvrsum1(s0_) \
         {  ATL_VTYPE t_, h_;                    /*{s0d,s0c,s0b,s0a}*/\
            t_ = vec_vmrghw(s0_, s0_);           /*{s0b,s0b,s0a,s0a}*/\
            s0_ = vec_vmrglw(s0_, s0_);          /*{s0d,s0d,s0c,s0c}*/ \
            s0_ = ATL_vadd(s0_, s0_, t_);        /*{s0bd,s0bd,s0ac,s0ac}*/\
            t_ =  vec_xxpermdi(s0_, s0_, 0);     /*{s0ac,s0ac,s0ac,s0ac}*/\
            s0_ = vec_xxpermdi(s0_, s0_, 3);     /*{s0bd,s0bd,s0bd,s0bd}*/ \
            ATL_vadd(s0_, s0_, t_); \
            s0_ = vec_xxpermdi(s0_, s0_, 2);     /* pwr8 endian-insanity */ \
         }
      #endif
   @iexp i 0 0 +
   @iwhile i < 4
      #define ATL_vsplat@(i)(d_, s_) d_ = vec_splat(s_, @(i))
      @iexp i @(i) 1 +
   @endiwhile
   #else
      #define ATL_vrsum1(d_, s_) \
      { \
         d_ = vec_splat(s_, 1); \
         d_ = vec_add(d_, s_) ; \
      }
      #if ATL_FULLGCCVSX 
         #define ATL_vvrsum2(s0_, s1_) \
         {  ATL_VTYPE t_;\
            t_ =  vec_xxpermdi(s0_, s1_, 0); \
            s0_ = vec_xxpermdi(s0_, s1_, 3); \
            ATL_vadd(s0_, s0_, t_); \
            s0_ = vec_xxpermdi(s0_, s0_, 2); /* pwr8 endian-insanity */ \
         }
         #define ATL_vvrsum1(s0_) \
         {  ATL_VTYPE t_;\
            t_ =  vec_xxpermdi(s0_, s0_, 0); \
            ATL_vadd(s0_, s0_, t_); \
         }
      #else
         #define ATL_vvrsum1(s0_) \
         {  ATL_VTYPE t_;\
            t_ = vec_splat(s0_, 1); \
            ATL_vadd(s0_, s0_, t_); \
         }
      #endif
   @iexp i 0 0 +
   @iwhile i < 2
      #define ATL_vsplat@(i)(d_, s_) d_ = vec_splat(s_, @(i))
      @iexp i @(i) 1 +
   @endiwhile
   #endif
#elif defined(ATL_VXZ)
   #include <vecintrin.h>

   #if ATL_VLEN != 2
      #error "VSXZ supports only VLEN = 2!"
   #endif
   #define ATL_VTYPE vector double
   #if (defined(DREAL) || defined(DCPLX))
      #define ATL_vld(v_, p_) {v_[0] = *(p_); v_[1] = (p_)[1]; }
      #define ATL_vst(p_, v_)  {*(p_) = v_[0]; (p_)[1] = v_[1];}
   #else
      #define ATL_vld(v_, p_) v_ = vec_ld2f(p_);
      #define ATL_vst(p_, v_) vec_st2f(v_, p_);
   #endif
   #define ATL_vzero(v_) v_ = vec_splats((TYPE)0.0)
   #define ATL_vcopy(d_, s_) d_ = s_
   #define ATL_vbcast(v_, p_) v_ =  vec_splats(*((TYPE*)(p_)))
   #define ATL_vuld(v_, p_) ATL_vld(v_, p_)
   #define ATL_vust(p_, v_) ATL_vst(p_, v_)
   #define ATL_vadd(d_, s1_, s2_) d_ =  s1_ + s2_
   #define ATL_vsub(d_, s1_, s2_) d_ =  s1_ - s2_
   #define ATL_vmul(d_, s1_, s2_) d_ =  s1_ * s2_
   #define ATL_vmac(d_, s1_, s2_) d_ = vec_madd(s1_, s2_, d_)
   #define ATL_vvrsum1(s0_) \
   {  ATL_VTYPE t_;\
      t_ = vec_splat(s0_, 1); \
      s0 += t_; \
   }
   #define ATL_vsplat0(d_, s_) d_ = vec_splat(s_, 0)
   #define ATL_vsplat1(d_, s_) d_ = vec_splat(s_, 1)
#elif defined(ATL_NEON) && (defined(SREAL) || defined(SCPLX))
   #include "arm_neon.h"
   #define ATL_VTYPE float32x4_t
  #define ATL_vzero(v_) v_ = vdupq_n_f32(0.0f)
   #define ATL_vbcast(v_, p_) v_ =  vdupq_n_f32(*(p_));
   #define ATL_vld(v_, p_) v_ = vld1q_f32(p_)
   #define ATL_vst(p_, v_) vst1q_f32(p_, v_)
   #define ATL_vadd(d_, s1_, s2_) d_ = vaddq_f32(s1_, s2_)
   #define ATL_vsub(d_, s1_, s2_) d_ = vsubq_f32(s1_, s2_)
   #define ATL_vmul(d_, s1_, s2_) d_ = vmulq_f32(s1_, s2_)
   #define ATL_vmac(d_, s1_, s2_) d_ = vmlaq_f32(d_, s1_, s2_)
   #define ATL_vrsum1(d_, s_) \
   {  ATL_VTYPE t4_; float32x2_t t2_, t1_; \
      t1_ = vget_high_f32(s_); \
      t2_ = vget_low_f32(s_); \
      t2_ = vpadd_f32(t1_, t2_); \
      d_ = vget_lane_f32(t2_, 0); \
      d_ += vget_lane_f32(t2_, 1); \
   }
   #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
   { ATL_VTYPE t0_, t1_; \
      t0_[0] = s0_[0]; \
      t0_[1] = s1_[0]; \
      t0_[2] = s2_[0]; \
      t0_[3] = s3_[0]; \
      t1_[0] = s0_[1]; \
      t1_[1] = s1_[1]; \
      t1_[2] = s2_[1]; \
      t1_[3] = s3_[1]; \
      t0_ = vaddq_f32(t0_, t1_); \
      t1_[0] = s0_[2]; \
      t1_[1] = s1_[2]; \
      t1_[2] = s2_[2]; \
      t1_[3] = s3_[2]; \
      t0_ = vaddq_f32(t0_, t1_); \
      t1_[0] = s0_[3]; \
      t1_[1] = s1_[3]; \
      t1_[2] = s2_[3]; \
      t1_[3] = s3_[3]; \
      s0_ = vaddq_f32(t0_, t1_); \
   }
   @beginskip
   #define ATL_vsplat0(d_, s_) d_[0] = d_[1] = d_[2] = d_[3] = s_[0]
   #define ATL_vsplat1(d_, s_) d_[0] = d_[1] = d_[2] = d_[3] = s_[1]
   #define ATL_vsplat2(d_, s_) d_[0] = d_[1] = d_[2] = d_[3] = s_[2]
   #define ATL_vsplat3(d_, s_) d_[0] = d_[1] = d_[2] = d_[3] = s_[3]
   @endskip
   #define ATL_vsplat0(d_, s_) d_ = vmovq_n_f32(vgetq_lane_f32(s_, 0))
   #define ATL_vsplat1(d_, s_) d_ = vmovq_n_f32(vgetq_lane_f32(s_, 1))
   #define ATL_vsplat2(d_, s_) d_ = vmovq_n_f32(vgetq_lane_f32(s_, 2))
   #define ATL_vsplat3(d_, s_) d_ = vmovq_n_f32(vgetq_lane_f32(s_, 3))
   #define ATL_vuld(v_, p_) ATL_vld(v_, p_)
   #define ATL_vust(p_, v_) ATL_vst(p_, v_)
#elif defined(ATL_VECARM1)
   #include "arm_neon.h"
   #if defined(SREAL) || defined(SCPLX)
      #define ATL_VTYPE float32x4_t
   #else
      #define ATL_VTYPE float64x2_t
   #endif
   #if defined(SREAL) || defined(SCPLX)
      #define ATL_vzero(v_) v_ = vdupq_n_f32(0.0f)
      #define ATL_vbcast(v_, p_) v_ =  vld1q_dup_f32(p_)
      #define ATL_vld(v_, p_) v_ = vld1q_f32(p_)
      #define ATL_vst(p_, v_) vst1q_f32(p_, v_)
      #define ATL_vadd(d_, s1_, s2_) d_ = vaddq_f32(s1_, s2_)
      #define ATL_vsub(d_, s1_, s2_) d_ = vsubq_f32(s1_, s2_)
      #define ATL_vmul(d_, s1_, s2_) d_ = vmulq_f32(s1_, s2_)
      #define ATL_vmac(d_, s1_, s2_) d_ = vfmaq_f32(d_, s1_, s2_)
      #define ATL_vrsum1(d_, s_) \
      {  ATL_VTYPE t4_; float32x2_t t2_, t1_; \
         t1_ = vget_high_f32(s_); \
         t2_ = vget_low_f32(s_); \
         t2_ = vpadd_f32(t1_, t2_); \
         d_ = vget_lane_f32(t2_, 0); \
         d_ += vget_lane_f32(t2_, 1); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      { ATL_VTYPE t0_, t1_; \
         t0_[0] = s0_[0]; \
         t0_[1] = s1_[0]; \
         t0_[2] = s2_[0]; \
         t0_[3] = s3_[0]; \
         t1_[0] = s0_[1]; \
         t1_[1] = s1_[1]; \
         t1_[2] = s2_[1]; \
         t1_[3] = s3_[1]; \
         t0_ = vaddq_f32(t0_, t1_); \
         t1_[0] = s0_[2]; \
         t1_[1] = s1_[2]; \
         t1_[2] = s2_[2]; \
         t1_[3] = s3_[2]; \
         t0_ = vaddq_f32(t0_, t1_); \
         t1_[0] = s0_[3]; \
         t1_[1] = s1_[3]; \
         t1_[2] = s2_[3]; \
         t1_[3] = s3_[3]; \
         s0_ = vaddq_f32(t0_, t1_); \
      }
   @iexp i 0 0 +
   @iwhile i < 4
      #define ATL_vsplat@(i)(d_, s_) d_ = vdupq_laneq_f32(s_, @(i))
      @iexp i @(i) 1 +
   @endiwhile
   #else  /* double */
      #define ATL_vzero(v_) v_ = vdupq_n_f64(0.0)
@skip      #define ATL_vbcast(v_, p_) v_ =  vdupq_n_f64((*p_))
      #define ATL_vbcast(v_, p_) v_ =  vld1q_dup_f64(p_)
      #define ATL_vld(v_, p_) v_ = vld1q_f64(p_)
      #define ATL_vst(p_, v_) vst1q_f64(p_, v_)
      #define ATL_vadd(d_, s1_, s2_) d_ = vaddq_f64(s1_, s2_)
      #define ATL_vsub(d_, s1_, s2_) d_ = vsubq_f64(s1_, s2_)
      #define ATL_vmul(d_, s1_, s2_) d_ = vmulq_f64(s1_, s2_)
      #define ATL_vmac(d_, s1_, s2_) d_ = vfmaq_f64(d_, s1_, s2_)
      #define ATL_vrsum1(d_, s_) d_ = vget_low_f64(vpaddq_f64(s_, s_))
      #define ATL_vvrsum2(s0_, s1_) s0_ = vpaddq_f64(s0_, s1_)
   @iexp i 0 0 +
   @iwhile i < 2
      #define ATL_vsplat@(i)(d_, s_) d_ = vdupq_laneq_f64(s_, @(i))
      @iexp i @(i) 1 +
   @endiwhile
   #endif
   #define ATL_vuld(v_, p_) ATL_vld(v_, p_)
   #define ATL_vust(p_, v_) ATL_vst(p_, v_)
#elif defined(ATL_AVXMAC) || defined(ATL_AVX)
   #include <immintrin.h>
   #if defined(SREAL) || defined(SCPLX)
      #if ATL_VLEN != 8
         #error "VLEN != 8 not supported for AVX or AVX2!"
      #endif
      #define ATL_VTYPE __m256
      #define ATL_vzero(v_) v_ = _mm256_setzero_ps()
      #define ATL_vbcast(v_, p_) v_ =  _mm256_broadcast_ss(p_)
      #define ATL_vuld(v_, p_) v_ = _mm256_loadu_ps(p_)
      #define ATL_vld(v_, p_) v_ = _mm256_load_ps(p_)
      #define ATL_vust(p_, v_) _mm256_storeu_ps(p_, v_)
      #define ATL_vst(p_, v_) _mm256_store_ps(p_, v_)
      #define ATL_vadd(d_, s1_, s2_) d_ =  _mm256_add_ps(s1_, s2_)
      #define ATL_vsub(d_, s1_, s2_) d_ =  _mm256_sub_ps(s1_, s2_)
      #define ATL_vmul(d_, s1_, s2_) d_ =  _mm256_mul_ps(s1_, s2_)
      #ifdef ATL_AVXMAC
         #define ATL_vmac(d_, s1_, s2_) \
            d_ = _mm256_fmadd_ps(s1_, s2_, d_)
      #else
         #define ATL_vmac(d_, s1_, s2_) \
         { ATL_VTYPE t_; \
            t_ = _mm256_mul_ps(s1_, s2_); \
            d_ = _mm256_add_ps(t_, d_); \
         }
      #endif
      #define ATL_vvrsum8(s0_, s1_, s2_, s3_, s4_, s5_, s6_, s7_) \
      { \
         s0_ = _mm256_hadd_ps(s0_, s1_); \
            /*{s1gh,s1ef,s0gh,s0ef,s1cd,s1ab,s0cd,s0ab}*/\
         s2_ = _mm256_hadd_ps(s2_, s3_); \
            /*{s3gh,s3ef,s2gh,s2ef,s3cd,s3ab,s2cd,s2ab}*/\
         s4_ = _mm256_hadd_ps(s4_, s5_); \
            /*{s5gh,s5ef,s4gh,s4ef,s5cd,s5ab,s4cd,s4ab}*/\
         s6_ = _mm256_hadd_ps(s6_, s7_); \
            /*{s7gh,s7ef,s6gh,s6ef,s7cd,s7ab,s6cd,s6ab}*/\
         s0_ = _mm256_hadd_ps(s0_, s2_); \
            /*{s3e-h,s2e-h,s1e-h,s0e-g,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         s4_ = _mm256_hadd_ps(s4_, s6_); \
            /*{s7e-h,s6e-h,s5e-h,s4e-g,s7a-d,s6a-d,s5a-d,s4a-d}*/\
         s1_ = _mm256_permute2f128_ps(s0_, s4_, 0x31); \
            /*{s7e-h,s6e-h,s5e-h,s4e-g,s3e-h,s2e-h,s1e-h,s0e-g}*/\
         s0_ = _mm256_permute2f128_ps(s0_, s4_, 0x20); \
            /*{s7a-d,s6a-d,s5a-d,s4a-d,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      { \
         s0_ = _mm256_hadd_ps(s0_, s1_); \
            /*{s1gh,s1ef,s0gh,s0ef,s1cd,s1ab,s0cd,s0ab}*/\
         s2_ = _mm256_hadd_ps(s2_, s3_); \
            /*{s3gh,s3ef,s2gh,s2ef,s3cd,s3ab,s2cd,s2ab}*/\
         s0_ = _mm256_hadd_ps(s0_, s2_); \
            /*{s3e-h,s2e-h,s1e-h,s0e-g,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         s1_ = _mm256_permute2f128_ps(s0_, s0_, 0x31); \
            /*{s3e-h,s2e-h,s1e-h,s0e-g,s3e-h,s2e-h,s1e-h,s0e-g}*/\
         s0_ = _mm256_permute2f128_ps(s0_, s0_, 0x20); \
            /*{s3a-d,s2a-d,s1a-d,s0a-d,s3a-d,s2a-d,s1a-d,s0a-d}*/\
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vvrsum2(s0_, s1_) \
      { \
         s0_ = _mm256_hadd_ps(s0_, s1_); \
            /*{s1gh,s1ef,s0gh,s0ef,s1cd,s1ab,s0cd,s0ab}*/\
         s0_ = _mm256_hadd_ps(s0_, s0_); \
            /*{s1e-h,s0e-h,s1e-h,s0e-g,s1a-d,s0a-d,s1a-d,s0a-d}*/\
         s1_ = _mm256_permute2f128_ps(s0_, s0_, 0x31); \
            /*{s1e-h,s0e-h,s1e-h,s0e-g,s1e-h,s0e-h,s1e-h,s0e-g}*/\
         s0_ = _mm256_permute2f128_ps(s0_, s0_, 0x20); \
            /*{s1a-d,s0a-d,s1a-d,s0a-d,s1a-d,s0a-d,s1a-d,s0a-d}*/\
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vvrsum1(s0_) \
      {  ATL_VTYPE t1_; \
         s0_ = _mm256_hadd_ps(s0_, s0_); \
            /*{s0gh,s0ef,s0gh,s0ef,s0cd,s0ab,s0cd,s0ab}*/\
         s0_ = _mm256_hadd_ps(s0_, s0_); \
            /*{s0e-h,s0e-h,s0e-h,s0e-g,s0a-d,s0a-d,s0a-d,s0a-d}*/\
         t1_ = _mm256_permute2f128_ps(s0_, s0_, 0x31); \
            /*{s0e-h,s0e-h,s0e-h,s0e-g,s0e-h,s0e-h,s0e-h,s0e-g}*/\
         s0_ = _mm256_permute2f128_ps(s0_, s0_, 0x20); \
            /*{s0a-d,s0a-d,s0a-d,s0a-d,s0a-d,s0a-d,s0a-d,s0a-d}*/\
         ATL_vadd(s0_, s0_, t1_); \
      }
      #define ATL_vsplat0(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,0), 1); \
      }
      #define ATL_vsplat1(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0x55); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,0), 1); \
      }
      #define ATL_vsplat2(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0xAA); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,0), 1); \
      }
      #define ATL_vsplat3(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0xFF); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,0), 1); \
      }
      #define ATL_vsplat4(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,1), 0); \
      }
      #define ATL_vsplat5(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0x55); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,1), 0); \
      }
      #define ATL_vsplat6(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0xAA); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,1), 0); \
      }
      #define ATL_vsplat7(d_, s_) \
      { \
         d_ = _mm256_shuffle_ps(s_, s_, 0xFF); \
         d_ = _mm256_insertf128_ps(d_, _mm256_extractf128_ps(d_,1), 0); \
      }
   #else        /* double precision */
      #if ATL_VLEN != 4
         #error "AVX SUPPORTS ONLY VLEN=4 FOR DOUBLE!"
      #endif
      #define ATL_VTYPE __m256d
      #define ATL_vzero(v_) v_ = _mm256_setzero_pd()
      #define ATL_vbcast(v_, p_) v_ =  _mm256_broadcast_sd(p_)
      #define ATL_vuld(v_, p_) v_ = _mm256_loadu_pd(p_)
      #define ATL_vld(v_, p_) v_ = _mm256_load_pd(p_)
      #define ATL_vust(p_, v_) _mm256_storeu_pd(p_, v_)
      #define ATL_vst(p_, v_) _mm256_store_pd(p_, v_)
      #define ATL_vadd(d_, s1_, s2_) d_ =  _mm256_add_pd(s1_, s2_)
      #define ATL_vsub(d_, s1_, s2_) d_ =  _mm256_sub_pd(s1_, s2_)
      #define ATL_vmul(d_, s1_, s2_) d_ =  _mm256_mul_pd(s1_, s2_)
      #ifdef ATL_AVXMAC
         #define ATL_vmac(d_, s1_, s2_) \
            d_ = _mm256_fmadd_pd(s1_, s2_, d_)
      #else
         #define ATL_vmac(d_, s1_, s2_) \
         { ATL_VTYPE t_; \
            t_ = _mm256_mul_pd(s1_, s2_); \
            d_ = _mm256_add_pd(t_, d_); \
         }
      #endif
      #define ATL_vrsum1(d_, s_) \
      {  __m128d t_; \
         t_ = _mm_add_pd(_mm256_extractf128_pd(s_, 0), \
                         _mm256_extractf128_pd(s_, 1)); \
         t_ = _mm_hadd_pd(t_, t_); \
         d_ = _mm_cvtsd_f64(t_); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      { \
         s0_ = _mm256_hadd_pd(s0_, s1_); /*{s1cd,s0cd,s1ab,s0ab}*/ \
         s2_ = _mm256_hadd_pd(s2_, s3_); /*{s3cd,s2cd,s3ab,s2ab}*/ \
         s1_ = _mm256_permute2f128_pd(s0_, s2_,0x31);/*{s3cd,s2cd,s1cd,s0cd}*/ \
         s0_ = _mm256_permute2f128_pd(s0_, s2_,0x20);/*{s3ab,s2ab,s1ab,s0ab}*/ \
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vvrsum2(s0_, s1_) \
      { \
         s0_ = _mm256_hadd_pd(s0_, s1_); /*{s1cd,s0cd,s1ab,s0ab}*/ \
         s1_ = _mm256_permute2f128_pd(s0_, s1_,0x31);/*{s3cd,s2cd,s1cd,s0cd}*/ \
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vvrsum1(s0_) \
      { ATL_VTYPE s1_; \
         s0_ = _mm256_hadd_pd(s0_, s0_); /*{s0cd,s0cd,s0ab,s0ab}*/ \
         s1_ = _mm256_permute2f128_pd(s0_, s1_,0x31);/*{s0cd,s0cd,s0cd,s0cd}*/ \
         ATL_vadd(s0_, s0_, s1_); \
      }
      #define ATL_vsplat0(d_, s_) \
      { \
         d_ = _mm256_unpacklo_pd(s_, s_); \
         d_ = _mm256_insertf128_pd(d_, _mm256_extractf128_pd(d_,0), 1); \
      }
      #define ATL_vsplat2(d_, s_) \
      { \
         d_ = _mm256_unpacklo_pd(s_, s_); \
         d_ = _mm256_insertf128_pd(d_, _mm256_extractf128_pd(d_,1), 0); \
      }
      #define ATL_vsplat1(d_, s_) \
      { \
         d_ = _mm256_unpackhi_pd(s_, s_); \
         d_ = _mm256_insertf128_pd(d_, _mm256_extractf128_pd(d_,0), 1); \
      }
      #define ATL_vsplat3(d_, s_) \
      { \
         d_ = _mm256_unpackhi_pd(s_, s_); \
         d_ = _mm256_insertf128_pd(d_, _mm256_extractf128_pd(d_,1), 0); \
      }
   #endif
#elif defined(ATL_SSE2) && (defined(DREAL) || defined(DCPLX))
   #include <xmmintrin.h>
   #if defined(ATL_SSE3)
      #include <pmmintrin.h>
      #include <tmmintrin.h>
   #endif
   #define ATL_VTYPE __m128d
   #if ATL_VLEN != 2
      #error "VLEN == 2 only supported size for double precision SSE!"
   #endif
   #define ATL_vzero(v_) v_ = _mm_setzero_pd()
   #define ATL_vbcast(v_, p_) v_ =  _mm_load1_pd(p_)
   #define ATL_vuld(v_, p_) v_ = _mm_loadu_pd(p_)
   #define ATL_vld(v_, p_) v_ = _mm_load_pd(p_)
   #define ATL_vust(p_, v_) _mm_storeu_pd(p_, v_)
   #define ATL_vst(p_, v_) _mm_store_pd(p_, v_)
   #define ATL_vadd(d_, s1_, s2_) d_ =  _mm_add_pd(s1_, s2_)
   #define ATL_vsub(d_, s1_, s2_) d_ =  _mm_sub_pd(s1_, s2_)
   #define ATL_vmul(d_, s1_, s2_) d_ =  _mm_mul_pd(s1_, s2_)
   #define ATL_vmac(d_, s1_, s2_) \
   { ATL_VTYPE t_; \
      t_ = _mm_mul_pd(s1_, s2_); \
      d_ = _mm_add_pd(t_, d_); \
   }
   #ifdef ATL_SSE3
      #define ATL_vrsum1(d_, s_) d_ = _mm_cvtsd_f64(_mm_hadd_pd(s_, s_))
      #define ATL_vvrsum2(s0_, s1_) s0_ = _mm_hadd_pd(s0_, s1_)
      #define ATL_vvrsum1(s0_) s0_ = _mm_hadd_pd(s0_, s0_)
      #define ATL_vsplat0(d_, s_) d_ = _mm_movedup_pd(s_)
      #define ATL_vsplat1(d_, s_) d_ = (ATL_VTYPE) \
         _mm_shuffle_epi32((__m128i)(s_), 0xEE)
   #else
      #define ATL_vrsum1(d_, s_) \
         d_ = _mm_cvtsd_f64(_mm_add_sd(_mm_unpackhi_pd(s_, s_), s_))
      #define ATL_vvrsum2(s0_, s1_) \
      { \
         __m128d t0_; \
         t0_ = _mm_unpackhi_pd(s0_, s1_); \
         s0_ = _mm_unpacklo_pd(s0_, s1_); \
         ATL_vadd(s0_, s0_, t0_); \
      }
      #define ATL_vvrsum1(s0_) \
      { \
         __m128d t0_; \
         t0_ = _mm_unpackhi_pd(s0_, s0_); \
         s0_ = _mm_unpacklo_pd(s0_, s0_); \
         ATL_vadd(s0_, s0_, t0_); \
      }
      #define ATL_vsplat0(d_, s_) d_ = (ATL_VTYPE) \
         _mm_shuffle_epi32((__m128i)(s_), 0x0)
      #define ATL_vsplat1(d_, s_) d_ = (ATL_VTYPE) \
         _mm_shuffle_epi32((__m128i)(s_), 0x55)
      #define ATL_vsplat2(d_, s_) d_ = (ATL_VTYPE) \
         _mm_shuffle_epi32((__m128i)(s_), 0xAA)
      #define ATL_vsplat3(d_, s_) d_ = (ATL_VTYPE) \
         _mm_shuffle_epi32((__m128i)(s_), 0xFF)
   #endif
#elif defined(ATL_SSE1)
   #include <xmmintrin.h>
   #if defined(ATL_SSE3)
      #include <tmmintrin.h>
   #endif
   #define ATL_VTYPE __m128
   #if defined(ATL_VLEN) && ATL_VLEN != 4
      #error "VLEN == 4 only supported size for single precision SSE!"
   #elif !defined(ATL_VLEN)
      #define ATL_VLEN 4
   #endif
   #define ATL_vzero(v_) v_ = _mm_setzero_ps()
   #define ATL_vbcast(v_, p_) v_ =  _mm_load1_ps(p_)
   #define ATL_vuld(v_, p_) v_ = _mm_loadu_ps(p_)
   #define ATL_vld(v_, p_) v_ = _mm_load_ps(p_)
   #define ATL_vust(p_, v_) _mm_storeu_ps(p_, v_)
   #define ATL_vst(p_, v_) _mm_store_ps(p_, v_)
   #define ATL_vadd(d_, s1_, s2_) d_ =  _mm_add_ps(s1_, s2_)
   #define ATL_vsub(d_, s1_, s2_) d_ =  _mm_sub_ps(s1_, s2_)
   #define ATL_vmul(d_, s1_, s2_) d_ =  _mm_mul_ps(s1_, s2_)
   #define ATL_vmac(d_, s1_, s2_) \
   { ATL_VTYPE t_; \
      t_ = _mm_mul_ps(s1_, s2_); \
      d_ = _mm_add_ps(t_, d_); \
   }
   #ifdef ATL_SSE3
      #define ATL_vrsum1(d_, s_) \
      {  ATL_VTYPE t_; \
         t_ = _mm_hadd_ps(s_, s_); \
         d_ = _mm_cvtss_f32(_mm_hadd_ps(t_, t_)); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      { \
         s0_ = _mm_hadd_ps(s0_, s1_); /*{s1cd,s1ab,s0cd,s0ab}*/ \
         s2_ = _mm_hadd_ps(s2_, s3_); /*{s3cd,s3ab,s2cd,s2ab}*/ \
         s0_ = _mm_hadd_ps(s0_, s2_); /*{s3a-d,s2a-d,s1a-d,s0a-d}*/ \
      }
      #define ATL_vvrsum2(s0_, s1_) \
      { \
         s0_ = _mm_hadd_ps(s0_, s1_); /*{s1cd,s1ab,s0cd,s0ab}*/ \
         s0_ = _mm_hadd_ps(s0_, s0_); /*{s1a-d,s0a-d,s1a-d,s0a-d}*/ \
      }
      #define ATL_vvrsum1(s0_) \
      { \
         s0_ = _mm_hadd_ps(s0_, s0_); /*{s0cd,s0ab,s0cd,s0ab}*/ \
         s0_ = _mm_hadd_ps(s0_, s0_); /*{s0a-d,s0a-d,s0a-d,s0a-d}*/ \
      }
   #else
      #define ATL_vrsum1(d_, s_) \
      { \
         ATL_VTYPE t_; \
         t_ = _mm_movehl_ps(s_, s_); \
         t_ = _mm_add_ps(t_, s_); \
         t_ = _mm_add_ps(t_, _mm_shuffle_ps(t_, t_, 1)); \
         d_ = _mm_cvtss_f32(t_); \
      }
      #define ATL_vvrsum4(s0_, s1_, s2_, s3_) \
      {                                      /*{sXd,  sXc,  sXb,  sXa}*/ \
         ATL_VTYPE t0_; \
         t0_ = _mm_unpackhi_ps(s0_,s1_);     /*{s1d,  s0d,  s1c,  s0c}*/\
         s0_ = _mm_unpacklo_ps(s0_,s1_);     /*{s1b,  s0b,  s1a,  s0a}*/\
         s1_ = _mm_unpackhi_ps(s2_,s3_);     /*{s3d,  s2d,  s3c,  s2c}*/\
         ATL_vadd(s0_, s0_, t0_);            /*{s1bd, s0bd, s1ac, s0ac}*/\
         s2_ = _mm_unpacklo_ps(s2_,s3_);     /*{s3b,  s2b,  s3a,  s2a}*/\
         ATL_vadd(s2_, s2_, s1_);            /*{s3bd, s2bd, s3ac, s2ac}*/\
         t0_ = _mm_shuffle_ps(s0_,s2_,0xEE); /*{s3bd, s2bd, s1bd, s0bd}*/\
         s0_ = _mm_shuffle_ps(s0_,s2_,0x44); /*{s3ac, s2ac, s1ac, s0ac}*/\
         ATL_vadd(s0_,s0_,t0_);              /*{s3a-d,s2a-d,s1a-d,s0a-d}*/\
      }
      #define ATL_vvrsum2(s0_, s1_) \
      {                                      /*{sXd,  sXc,  sXb,  sXa}*/ \
         ATL_VTYPE t0_; \
         t0_ = _mm_unpackhi_ps(s0_,s1_);     /*{s1d,  s0d,  s1c,  s0c}*/\
         s0_ = _mm_unpacklo_ps(s0_,s1_);     /*{s1b,  s0b,  s1a,  s0a}*/\
         ATL_vadd(s0_, s0_, t0_);            /*{s1bd, s0bd, s1ac, s0ac}*/\
         t0_ = _mm_shuffle_ps(s0_,s0_,0xEE); /*{s1bd, s0bd, s1bd, s0bd}*/\
         s0_ = _mm_shuffle_ps(s0_,s0_,0x44); /*{s1ac, s0ac, s1ac, s0ac}*/\
         ATL_vadd(s0_,s0_,t0_);              /*{s1a-d,s0a-d,s1a-d,s0a-d}*/\
      }
      #define ATL_vvrsum1(s0_) \
      {                                      /*{sXd,  sXc,  sXb,  sXa}*/ \
         ATL_VTYPE t0_; \
         t0_ = _mm_unpackhi_ps(s0_,s0_);     /*{s0d,  s0d,  s0c,  s0c}*/\
         s0_ = _mm_unpacklo_ps(s0_,s0_);     /*{s0b,  s0b,  s0a,  s0a}*/\
         ATL_vadd(s0_, s0_, t0_);            /*{s0bd, s0bd, s0ac, s0ac}*/\
         t0_ = _mm_shuffle_ps(s0_,s0_,0xEE); /*{s0bd, s0bd, s0bd, s0bd}*/\
         s0_ = _mm_shuffle_ps(s0_,s0_,0x44); /*{s0ac, s0ac, s0ac, s0ac}*/\
         ATL_vadd(s0_,s0_,t0_);              /*{s0a-d,s0a-d,s0a-d,s0a-d}*/\
      }
   #endif
#elif ATL_VLEN > 1  /* use gnuvec when atlas knows no VEC ISA */
@skip   typedef TYPE ATL_gnuvec_t  __attribute__ ((vector_size (ATL_VLENb)))
@skip   #define ATL_VTYPE ATL_gnuvec_t
   #define ATL_VTYPE TYPE __attribute__ ((vector_size (ATL_VLENb)))
@skip   #define ATL_UPVTYPE TYPE __attribute__ ((vector_size (ATL_VLENb))) \
@skip                           __attribute__ ((aligned(8)))
   #if defined(SREAL) || defined(SCPLX)
      #define ATL_VITYPE int  __attribute__ ((vector_size (ATL_VLENb)))
   #else
      #define ATL_VITYPE long long  __attribute__ ((vector_size (ATL_VLENb)))
   #endif
   #define ATL_vzero(d_) d_ = (ATL_VTYPE)(((ATL_VITYPE)(d_))^((ATL_VITYPE)(d_)))
   #define ATL_vcopy(d_, s_) d_ = s_
   #ifndef ATL_vbcast
      #if 0
         #define ATL_vbcast(v_, p_) v_ = *((TYPE*)(p_));
      #elif 0
         #define ATL_vbcast(v_, p_) \
         { \
            (v_)[0] = p_; \
            v_ =  __builtin_shuffle(v_, (ATL_VITYPE){0}); \
         }
      #endif
   #endif
@skip   #define ATL_vuld(v_, p_) \
@skip      v_ = *((ATL_UPVTYPE*)(p_))
   #define ATL_vld(v_, p_) \
      v_ = *((ATL_VTYPE*)__builtin_assume_aligned(p_,ATL_VLENb))
   #define ATL_vust(p_, v_) *((ATL_VTYPE*)(p_)) = v_
   #define ATL_vst(p_, v_) \
      *((ATL_VTYPE*)__builtin_assume_aligned(p_,ATL_VLENb)) = v_
   #define ATL_vadd(d_, s1_, s2_) d_ =  s1_ + s2_
   #define ATL_vsub(d_, s1_, s2_) d_ =  s1_ - s2_
   #define ATL_vmul(d_, s1_, s2_) d_ =  s1_ * s2_
   #define ATL_vmac(d_, s1_, s2_) d_ += s1_ * s2_
   #if ATL_VLEN == 1
      #define ATL_vbcast(v_, p_) v_ = *(p_)
      #ifndef ATL_vuld
         #define ATL_vuld(v_, p_) v_ = {*(p_)}
      #endif
      #ifndef ATL_vrsum1
         #define ATL_vrsum1(d_, s_) d_ = (s_)
      #endif
   #elif ATL_VLEN == 2
      #define ATL_vbcast(v_, p_) v_ = (ATL_VTYPE){*(p_), *(p_)}
      #ifndef ATL_vuld
         #define ATL_vuld(v_, p_) v_ = (ATL_VTYPE){*(p_), (p_)[1]}
      #endif
      #ifndef ATL_vrsum1
         #define ATL_vrsum1(d_, s_) d_ = ((s_)[0] + (s_)[1])
      #endif
   #elif ATL_VLEN == 4
      #define ATL_vbcast(v_, p_) v_ = (ATL_VTYPE){*(p_), *(p_), *(p_), *(p_)}
      #ifndef ATL_vuld
      #define ATL_vuld(v_, p_) v_ = (ATL_VTYPE){*(p_),(p_)[1],(p_)[2],(p_)[3]}
      #endif
      #ifndef ATL_vrsum1
         #define ATL_vrsum1(d_, s_) d_ = ((s_)[0] + (s_)[1] + (s_)[2] + (s_)[3])
      #endif
   #elif ATL_VLEN == 8
      #ifndef ATL_vuld
      #define ATL_vuld(v_, p_) v_ = (ATL_VTYPE) \
         {*(p_), (p_)[1], (p_)[2], (p_)[3], (p_)[4], (p_)[5], (p_)[6], (p_)[7]}
      #endif
      #define ATL_vbcast(v_, p_) v_ = (ATL_VTYPE){*(p_), *(p_), *(p_), *(p_), \
               *(p_), *(p_), *(p_), *(p_)}
      #ifndef ATL_vrsum1
      #define ATL_vrsum1(d_, s_) d_ = ((s_)[0] + (s_)[1] + (s_)[2] + (s_)[3] + \
                                       (s_)[4] + (s_)[5] + (s_)[6] + (s_)[7])
      #endif
   #elif ATL_VLEN == 16
      #ifndef ATL_vuld
      #define ATL_vuld(v_, p_) v_ = (ATL_VTYPE) \
         {*(p_),(p_)[1],(p_)[2],(p_)[3],(p_)[4],(p_)[5],(p_)[6],(p_)[7], \
          (p_)[8],(p_)[9],(p_)[10],(p_)[11],(p_)[12],(p_)[13],(p_)[14],(p_)[15]}
      #endif
      #ifndef ATL_vrsum1
      #define ATL_vrsum1(d_, s_) d_ = \
      ((s_)[0]+(s_)[1]+(s_)[2]+(s_)[3]+(s_)[4]+(s_)[5]+(s_)[6]+(s_)[7] +\
       (s_)[ 8]+(s_)[ 9]+(s_)[10]+(s_)[11]+(s_)[12]+(s_)[13]+(s_)[14]+(s_)[15])
      #endif
   #elif ATL_VLEN == 32
      #ifndef ATL_vuld
      #define ATL_vuld(v_, p_) v_ = (ATL_VTYPE) \
      {*(p_),(p_)[1],(p_)[2],(p_)[3],(p_)[4],(p_)[5],(p_)[6],(p_)[7], \
       (p_)[8],(p_)[9],(p_)[10],(p_)[11],(p_)[12],(p_)[13],(p_)[14],(p_)[15],\
       (p_)[16],(p_)[17],(p_)[18],(p_)[19],(p_)[20],(p_)[21],(p_)[22],(p_)[23],\
       (p_)[24],(p_)[25],(p_)[26],(p_)[27],(p_)[28],(p_)[29],(p_)[30],(p_)[31]}
      #endif
      #define ATL_vrsum1(d_, s_) d_ = \
      ((s_)[0]+(s_)[1]+(s_)[2]+(s_)[3]+(s_)[4]+(s_)[5]+(s_)[6]+(s_)[7] \
      +(s_)[ 8]+(s_)[ 9]+(s_)[10]+(s_)[11]+(s_)[12]+(s_)[13]+(s_)[14]+(s_)[15] \
      +(s_)[16]+(s_)[17]+(s_)[18]+(s_)[19]+(s_)[20]+(s_)[21]+(s_)[22]+(s_)[23] \
      +(s_)[24]+(s_)[25]+(s_)[26]+(s_)[27]+(s_)[28]+(s_)[29]+(s_)[30]+(s_)[31])
   #else
      #error "Unsupported ATL_VLEN"
   #endif
#else
   #if defined(ATL_VLEN) && ATL_VLEN != 1
      #error "For systems without vector support, only ATL_VLEN=1 supported!"
   #elif !defined(ATL_VLEN)
      #define ATL_VLEN 1
   #endif
   #define ATL_VTYPE TYPE

   #define ATL_vzero(d_) d_ = 0.0
   #define ATL_vcopy(d_, s_) d_ = s_
   #define ATL_vbcast(d_, p_) d_ = *(p_)
   #define ATL_vuld(v_, p_) v_ = *(p_)
   #define ATL_vld(v_, p_) v_ = *(p_)
   #define ATL_vust(p_, s_) *(p_) = s_
   #define ATL_vst(p_, s_) *(p_) = s_
   #define ATL_vadd(d_, s1_, s2_) d_ =  (s1_) + (s2_)
   #define ATL_vsub(d_, s1_, s2_) d_ =  (s1_) - (s2_)
   #define ATL_vmul(d_, s1_, s2_) d_ =  (s1_) * (s2_)
   #define ATL_vmac(d_, s1_, s2_) d_ += (s1_) * (s2_)
   #define ATL_vrsum1(d_, s_) d_ = s_
#endif
@beginskip
@iexp p 1 0 +
@iexp j 0 0 +
@iwhile p < 64
   #if ATL_VLEN == @(p)
      #define ATL_VLSH @(j)
      #if defined(SREAL) || defined(SCPLX)
         @iexp i @(p) 4 *
         #define ATL_VLENb @(i)
      #else
         @iexp i @(p) 8 *
         #define ATL_VLENb @(i)
      #endif
   #endif
   @iexp j @(j) 1 +
   @iexp p @(p) 2 *
@endiwhile
@endskip
@SKIP produce a list of numbered args on 1 line, like: <nm>#<sf>
@BEGINPROC arglst n nm sf
   @define i @1@
   @define at @@(nm)0@(sf)@
   @iwhile i < @(n)
      @define nat @@(at)@
      @undef at
      @define at @@(nat), @(nm)@(i)@(sf)@
      @undef nat
      @iexp i @(i) 1 +
   @endiwhile
   @define arglst @@(at)@
   @undef at
   @undef i
@ENDPROC
@BEGINPROC addarr n nm
   @define i @1@
   @define at @@(nm)[0]@
   @iwhile i < @(n)
      @define nat @@(at)@
      @undef at
      @define at @@(nat)+@(nm)[@(i)]@
      @undef nat
      @iexp i @(i) 1 +
   @endiwhile
   @define addarr @@(at)@
   @undef at
   @undef i
@ENDPROC
@BEGINPROC asgarr n nm
   @define i @1@
   @define at @@(nm)[0]@
   @iwhile i < @(n)
      @define nat @@(at)@
      @undef at
      @define at @@(nat)=@(nm)[@(i)]@
      @undef nat
      @iexp i @(i) 1 +
   @endiwhile
   @define asgarr @@(at)@
   @undef at
   @undef i
@ENDPROC
/* 
 * If it isn't already defined (fast system-specific version), define vvrsumX
 * This may be horribly slow or great, depending on how smart the compiler is.
 */
#if ATL_VLEN == 2
   #ifndef ATL_vvrsum1
      #define ATL_vvrsum1(s0_) s0_[0] += s0_[1]
   #endif
   #ifndef ATL_vvrsum2
      #define ATL_vvrsum2(s0_, s1_) \
      { \
         s0_[0] += s0_[1]; \
         s0_[1] = s1_[0] + s1_[1]; \
      }
   #endif
#endif
@iexp vl 2 2 +
@iwhile vl < 64
#if ATL_VLEN == @(vl)
   @iexp n 1
   @iexp kk @(vl) 1 +
   @iwhile n < kk
   @CALLPROC arglst @(n) s _
   #ifndef ATL_vvrsum@(n)
      #define ATL_vvrsum@(n)(@(arglst))\
   @undef arglst
      { \
      @iexp i 0 0 +
      @iwhile i < @(n)
         @CALLPROC addarr @(vl) s@(i)_
         s0_[@(i)] = @(addarr); \
         @undef addarr
         @iexp i @(i) 1 +
      @endiwhile
      }
   #endif
      @iexp n @(n) @(n) +
   @endiwhile
#endif
   @iexp vl @(vl) @(vl) +
@endiwhile
/*
 * If it isn't defined already (fast sys-spec vers), define 
 *    vsplatI (0 <= I < VL) using vector indexing.  
 * This may be horribly slow or great, depending on how smart the compiler is.
 */
#if ATL_VLEN == 2
   #ifndef ATL_vsplat0
   #define ATL_vsplat0(d_, s_) d_[0] = d_[1] = s_[0]
   #endif
   #ifndef ATL_vsplat1
   #define ATL_vsplat1(d_, s_) d_[0] = d_[1] = s_[1]
   #endif
@iexp vl 2 2 +
@iwhile vl < 64
#elif ATL_VLEN == @(vl)
   @iexp k 0 0 +
   @iwhile k < @(vl)
      @CALLPROC asgarr @(vl) d_ s_[@(k)]
   #ifndef ATL_vsplat@(k)
   #define ATL_vsplat@(k)(d_, s_) \
      @(asgarr) = s_[@(k)]
      @iexp k @(k) 1 +
   #endif
   @endiwhile
@beginskip
   @CALLPROC arglst @(vl) s _
   #ifndef ATL_vvrsum@(vl)
   #define ATL_vvrsum@(vl)(@(arglst))\
   @undef arglst
   { \
   @iexp i 0 0 +
   @iwhile i < @(vl)
      @CALLPROC addarr @(vl) s@(i)_
      s0_[@(i)] = @(addarr); \
      @undef addarr
      @iexp i @(i) 1 +
   @endiwhile
   }
   #endif
@endskip
   @iexp vl @(vl) @(vl) +
@endiwhile
#endif
/*
 * If we don't have one defined, write slow version that should work with
 * any gcc-compatible compiler
 */
#ifndef ATL_vrsum1
   #define ATL_vrsum1(d_, s_) \
   {  TYPE mem_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
      int i_; \
      ATL_vst(mem_, s_); \
      d_ = *mem_; \
      for (i_=1; i_ < ATL_VLEN; i_++) \
         d_ += mem_[i_]; \
   }
#endif
@beginskip
/*
 * If no special case, do vrsum2/4 slow way by calling vrsum1
 * THESE ARE WRONG: vrsum2 should put 1st ans in d[0], 2nd in d[1], so on,
 *                  not add them all up!  Leave until needed (kvec).
 */
#ifndef ATL_vrsum2
   #define ATL_vrsum2(d_, s1_, s2_) \
   { \
      ATL_VTYPE t0_; \
      ATL_vrsum1(d_, s1_); \
      ATL_vrsum1(s1_, s2_); \
      ATL_vadd(d_, d_, s1_); \
   }
#endif
#ifndef ATL_vrsum4
   #define ATL_vrsum4(d_, s1_, s2_, s3_, s4_) \
   { \
      ATL_vrsum2(d_, s1_, s2_); \
      ATL_vrsum2(s1_, s3_, s4_); \
      ATL_vadd(d_, d_, s1_); \
   }
#endif
#ifndef ATL_vrsum8
   #define ATL_vrsum8(d_, s1_, s2_, s3_, s4_, s5_), s6_, s7_, s8_) \
   { \
      ATL_vrsum4(d_, s1_, s2_, s3_, s4); \
      ATL_vrsum4(s1_, s3_, s5_, s6_, s7_, s8_); \
      ATL_vadd(d_, d_, s1_); \
   }
#endif
#ifndef ATL_vrsum16
   #define ATL_vrsum16(d_, s1_, s2_, s3_, s4_, s5_), s6_, s7_, s8_, \
                           s9_, s10_, s11_, s12_, s13_, s14_, s15_, s16_) \
   { \
      ATL_vrsum8(d_, s1_, s2_, s3_, s4_, s5_, s6_, s7_, s8_); \
      ATL_vrsum8(s1_, s9_, s10_, s11_, s12_ s13_, s14_, s15_); \
      ATL_vadd(d_, d_, s1_); \
   }
#endif
@endskip

#endif  /* end multiple-inclusion guard */
@ROUT atlas_ammsimd.h
/*
 * Special functions for writing M&N or M&K vectorized amm:
 *  ATL_ammcomb<mu>x<ku> : (mu*ku)%VLEN==0 -> used when M&K are both vect
 *  ATL_ammldB<nu> : if defined, load & dup for (mu*nu)%VLEN == 0 code
 *  ATL_ammbcast<nu> : combine with ATL_vld/vld1, etc for MN-vec
 *  
 */
#ifndef ATLAS_AMMSIMD_H
   #define ATLAS_AMMSIMD_H 1
#include "atlas_simd.h"

#if VLEN == 2   /* only 1-d shapes, handled by simd.h */
#elif VLEN == 4
#ifndef ATL_ammcomb2x2
   #define ATL_ammcomb2x2(s0_, s1_, s2_, s3_) \
   { \
     s0_[0] += s0_[1]; \
     s0_[1] = s0_[2] + s0_[3]; \
     s0_[2] = s1_[0] + s1_[1]; \
     s0_[3] = s1_[2] + s1_[3]; \
   }
#endif
#ifndef ATL_ammbcast2x2_0
   #define ATL_ammbcast2x2_0(d_, s_) \
   { \
      d_[0] = d_[1] = s_[0]; \
      d_[2] = d_[3] = s_[1]; \
   }
#endif
#ifndef ATL_ammbcast2x2_1
   #define ATL_ammbcast2x2_1(d_, s_) \
   { \
      d_[0] = d_[1] = s_[2]; \
      d_[2] = d_[3] = s_[3]; \
   }
#endif
#ifndef ATL_ammldB2x2
   #define ATL_ammldB2x2(d_, s_) 
   { \
      d_[0] = d_[1] = *(s_); \
      d_[2] = d_[3] = (s_)[1]; \
   }
#endif
#elif VLEN == 8
#endif

#endif
#if ATL_VLEN 
@ROUT atlas_cplxsimd.h
#ifndef ATLAS_CPLXSIMD_H
   #define ATLAS_CPLXSIMD_H 1
#include "atlas_simd.h"
/*
 *                          FUNCTIONALITY SUMMARY
 * ============================================================================
 * Constant integers: ATL_CXVLEN, ATL_CXSPLDb
 * Load/store for partial vecs (replace I with 0 < I < VLEN/2, 1 always there):
 *    ATL_vcxldI, ATL_vcxuldI, ATL_vcxustI, ATL_vcxustI
 * Macros for axpy-based computation:
 *    ATL_vcxsplitRIld,  ATL_vcxsplitRI, ATL_vcxPrepAlpha
 * Macros for dot-based computation:
 *    ATL_vcxswapRI, ATL_vcxdotcomb
 * ============================================================================
 */
/*
 * ============================================================================
 * This file provides macros for doing the types complex computations 
 * needed by ATLAS in a machine, precision and VLEN-independent manner
 * (i.e., this file changes based on VLEN/SIMD ISA, float/double, VLEN,
 *  but kernels implemented using work unchanged regardless of these variables).
 * ATLAS essentially does dot-product based computations (dot,GEMVT,GEMM)
 * and AXPY-based (AXPY,GER,GER2).  Both types of computation need both
 * load and stores.  We just use the real load/store for full VLEN ops.
 * However, we also need the ability to load/store a single complex number, 
 * which means the ability to load/store pairs of real numbers.  In addition,
 * if we want to be able perform vector cleanup, we need the ability to
 * load/store I complex numbers (0 < I < ATL_VLEN/2), with loads zeroing any
 * elements above the loaded values.  Therefore, this file provides 
 * (ATL_VLEN/2 - 1)*4 routines for loading/store complex numbers:
 *    ATL_vcxldI(r_, p_) : load lower 2*I elts of aligned p_ to r_, zero rest
 *    ATL_vcxuldI(r_, p_): load lower 2*I elts of unaligned p_ to r_, zero rest
 *    ATL_vcxstI(p_, r_) : store lower 2*I real elts of r_ to aligned p_
 *    ATL_vcxustI(p_, r_): store lower 2*I real elts of r_ to unaligned p_
 *
 * There are numerous ways to do complex computations, but this file provides
 * a particular approach for both dot- and axpy-based computations.  
 *
 * For AXPY-based computations, we are performance limited by load/store of Y,
 * so we permute all other ops to allow us to keep Y in natural order.
 * Not all SIMD ISAs allow one to do different operations to different
 * vector elements (eg., ADDSUB), so instead we manipulate alpha outside
 * the main loop so that it is is permuted and scaled appropriately to allow
 * us to do MAC-based AXPY calculations.  We will split X into two vectors
 * with duplicated entries:
 *   {Xr, Xr}*(VLEN/2)          {Xi, Xi}*(VLEN/2)
 * This permutation must be done inside the loop, and is thus expensive.
 * We provide the following functions to accomplish this:
 *    ATL_vcxsplitRIld(rR_, rI, p_): split&dup cplx #s from aligned p_
      ATL_vcxsplitRI(rXr_, rXi_)  : split&dup from natural-order reg rXi_
 * ATL_vcxsplitRIld can be built out of ATL_vld & ATL_vcxsplitRI, which is how
 * it is done for cleanup, but on some systems it is more efficient to
 * do it directly from memory, so we provide a specialized high-performance
 * version.  On some systems, the alignment restrictions for this operation
 * are lower than full VLEN, so we also provide the const macro:
 *    ATL_CXSPLDb : required byte alignment for ATL_vcxsplitRIld.
 * We use ATL_cxsplit for vector cleanup & when X is not aligned to ATL_CXSPLDb.
 * axpy-based calcs are doing Y += alpha * X.  Alpha is loop-invariant, so we
 * can manipulate it outside the loop, even if that manipulation is relatively
 * inefficient.  In order to perform the two real MACs required for cplx MAC,
 * alpha is split into two vectors that match up with our X vecs as in:
 *   {Xr,   Xr}*(VLEN/2)          {Xi,    Xi}*(VLEN/2)
 *   {ALi, Alr}*(VLEN/2)          {ALr, -ALi}*(VLEN/2
 * The first of these is the natural order alpha (alN), and the second scaled 
 * and permuted (alS).  First the scalar complex number is loaded to the
 * register using ATL_cx[u]ld1, then it is transformed with:
 *    ATL_vcxPrepAlpha(alN, alS): alN is input & output, alS output only
 * 
 * The naive approach to performing complex MAC (multiply and accumulate)
 * requires permuting both X and Y inside the loop, which is very expensive.
 * However, we notice that DOT (the accumulator) is loop invariant, so we
 * can instead keep it in permuted & scaled form throughout the loop.  This
 * allows us to avoid either the permute of X or Y (but not both).
 * For DOT-based there is no performance difference between X and Y, so we
 * can choose to permute either one (one must be computed to build the complex
 * multiply and accumulate (MAC) out of real MACs).  In general you can only
 * force one vector to be aligned (vecs may be mutually misaligned), and that
 * load will be cheaper than the unaligned load.  We therefore perform loop
 * peeling to force X to be aligned whenever that is possible, and then
 * permute X rather than Y.  The permute adds to the dependence chain in the
 * loop, so you want dependent it on the fastest load.
 *
 * The technique for DOT-based calculations is that the two half of the MACs
 * are stored in two different dot variables throughout the loop, one storing
 * partial results for the real result, and one for the imaginary result.
 * The real/imag dot vectors must be internally summed up to produce the
 * final answer (this operation performed outside the loop).  The imaginary
 * dot looks like: {Xr*Yi, Xi*Yr}*(VLEN/2), so we add all elts to get the ans.
 * Real looks:     {Xi*Yi, Xr*Yr}*(VLEN/2), so we must subtract the odd elts
 * from the even.  We provide this macro to accomplish this:
 *    ATL_cxdotcomb(rR, rI) : put final ans in low 2 elts of rR
 *
 * Inside the loop, we keep Y in natural order, and have X in both natural
 * order (rN) and with imaginary and complex swapped (rS).  We provide:
 *    ATL_cxriswap(rS, rN): swap imag & real components of rN, store in rS
 *
 * ============================================================================
 */
/*
 * Define some length-specific constants.
 * ATL_VONEPN is used to scale so even words are negated (imag*imag).
@skip * ATL_VONENP is used to scale dot's odd words by -1 (i*i=-1).
 */
#if ATL_VLEN == 2
   #define ATL_CXVLEN 1
   #define ATL_CXVLSH 0
   #define ATL_VONEPN ((ATL_VTYPE){ATL_rone, ATL_rnone})
#elif ATL_VLEN == 4
   #define ATL_CXVLEN 2
   #define ATL_CXVLSH 1
   #define ATL_VONEPN ((ATL_VTYPE){ATL_rone, ATL_rnone,ATL_rone, ATL_rnone})
#elif ATL_VLEN == 8
   #define ATL_CXVLEN 4
   #define ATL_CXVLSH 2
   #define ATL_VONEPN ((ATL_VTYPE){ATL_rone, ATL_rnone,ATL_rone, ATL_rnone,\
                                   ATL_rone, ATL_rnone,ATL_rone, ATL_rnone})
#elif ATL_VLEN == 16
   #define ATL_CXVLEN 8
   #define ATL_CXVLSH 3
   #define ATL_VONEPN ((ATL_VTYPE){ATL_rone, ATL_rnone,ATL_rone, ATL_rnone,\
                                   ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                   ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                   ATL_rone, ATL_rnone,ATL_rone, ATL_rnone})
#elif ATL_VLEN == 32
   #define ATL_CXVLEN 16
   #define ATL_CXVLSH 4
   #define ATL_VONEPN (ATL_VTYPE){ATL_rone, ATL_rnone,ATL_rone, ATL_rnone,\
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone} \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone, \
                                  ATL_rone, ATL_rnone,ATL_rone, ATL_rnone}
#else
   #error "unsupported VLEN!"
#endif

/*
 * Define ld/st I, 0 < I < VLEN/2, I=1 always present (scalar complex ld/st)
 */
#if ATL_VLEN == 2  /* 1 vec == 1 complex: DCPLX&(SSE2||VSX||ARM) or gnuvec */
   #define ATL_vcxld1(r_, p_) ATL_vld(r_, p_)
   #define ATL_vcxuld1(r_, p_) ATL_vuld(r_, p_)
   #define ATL_vcxst1(p_, r_) ATL_vst(p_, r_)
   #define ATL_vcxust1(p_, r_) ATL_vust(p_, r_)
#elif ATL_VLEN >= 4   /* gnuvec or DCPLX & AVX or SCPLX & (VSX || SSE) */
   #if (ATL_VSX) && defined(SCPLX)
      #if 0 /* gnuvec works better for unaligned load */
      #define ATL_vcxuld1(r_, p_) \
      {  ATL_VTYPE t0_, t1_;\
         t0_ = vec_splats(*(p_)); \
         t1_ = vec_splats((p_)[1]); \
         t0_ = vec_vmrglw(t0_, t1_); \
         ATL_vzero(r_); \
         r_ = vec_xxpermdi(t0_, r_, 0); \
      }
      #endif
      #define ATL_vcxld1(r_, p_) r_ = (ATL_VTYPE) \
         ((vector double){*((double*)(p_))})
      #define ATL_vcxust1(p_, r_) { *(p_) = r_[0]; (p_)[1] = r_[1]; }
      #define ATL_vcxst1(p_, r_) ATL_vcxust1(p_, r_)
   #elif (defined(ATL_VECARM1) || defined(ATL_NEON)) && defined(SCPLX)
      #define ATL_vcxuld1(r_, p_) \
         r_ = vcombine_f32(vld1_f32(p_), vdup_n_f32(0.0f))
      #define ATL_vcxust1(p_, r_) vst1_f32(p_, vget_low_f32(r_))
      #define ATL_vcxld1(r_, p_) ATL_vcxuld1(r_, p_)
      #define ATL_vcxst1(p_, r_) ATL_vcxust1(p_, r_)
   #elif defined(ATL_AVX) && defined(DCPLX)
      #define ATL_vcxld1(r_, p_) \
      { \
         ATL_vzero(r_); \
         r_ = _mm256_insertf128_pd(r_, _mm_load_pd(p_), 0); \
      }
      #define ATL_vcxuld1(r_, p_) \
      { \
         ATL_vzero(r_); \
         r_ = _mm256_insertf128_pd(r_, _mm_loadu_pd(p_), 0); \
      }
      #define ATL_vcxst1(p_, r_) _mm_store_pd(p_, _mm256_extractf128_pd(r_, 0))
      #define ATL_vcxust1(p_, r_) _mm_storeu_pd(p_, _mm256_extractf128_pd(r_,0))
   #elif defined(ATL_AVX) && defined(SCPLX)
      #define ATL_vcxld1(r_, p_) \
      {  __m128 t0_;\
         ATL_vzero(r_); \
         t0_ = _mm_setzero_ps(); \
         r_ = _mm256_insertf128_ps(r_, _mm_loadl_pi(t0_,(void*)(p_)), 0); \
      }
      #define ATL_vcxuld1(r_, p_) \
      {  __m128 t0_, t1_;\
         ATL_vzero(r_); \
         t0_ = _mm_load_ss(p_); \
         t1_ = _mm_load_ss((p_)+1); \
         t0_ = _mm_unpacklo_ps(t0_, t1_); \
         r_ = _mm256_insertf128_ps(r_, t0_, 0); \
      }
      #define ATL_vcxst1(p_, r_) \
         _mm_storel_pi((void*)(p_), _mm256_extractf128_ps(r_, 0))
      #define ATL_vcxust1(p_, r_) \
      {  __m128 t_;\
         t_ = _mm256_extractf128_ps(r_,0); \
         _mm_store_ss(p_, t_); \
         _mm_store_ss((p_)+1, _mm_shuffle_ps(t_, t_, 1)); \
      }
   #elif defined(ATL_SSE1) && defined(SCPLX)
      #define ATL_vcxld1(r_, p_) \
      { \
         ATL_vzero(r_); \
         r_ = _mm_loadl_pi(r_, ((void*)(p_))); \
      }
      #define ATL_vcxuld1(r_, p_) \
      {  ATL_VTYPE t_;\
         r_ = _mm_load_ss(p_); \
         t_ = _mm_load_ss((p_)+1); \
         r_ = _mm_unpacklo_ps(r_, t_); \
      }
      #define ATL_vcxst1(p_, r_) _mm_storel_pi((void*)(p_), r_)
      #define ATL_vcxust1(p_, r_) \
      { \
         _mm_store_ss(p_, r_); \
         _mm_store_ss((p_)+1, _mm_shuffle_ps(r_, r_, 1)); \
      }
   #else  /* gnuvec */
      #define ATL_vcxuld1(r_, p_) r_ = (ATL_VTYPE){*(p_), (p_)[1]}
      #define ATL_vcxust1(p_, r_) \
      { \
         *(p_) = (r_)[0]; \
         (p_)[1] = (r_)[1]; \
      }
      #define ATL_vcxld1 ATL_vcxuld1
      #define ATL_vcxst1 ATL_vcxust1
   #endif
/*
 * For VL == 8, is gnuvec or SCPLX&AVX or DCPLX&AVX512
 * For VL > 8, can only be SCPLX&AVX512 or gnuvec
 */
   #if ATL_VLEN >= 8  /* VL>=8, must define add op[2,3] */
      #if defined(SCPLX) && defined(ATL_AVX)
         #define ATL_vcxld2(r_, p_) \
         { \
            ATL_vzero(r_); \
            r_ = _mm256_insertf128_ps(r_, _mm_load_ps(p_), 0); \
         }
         #define ATL_vcxuld2(r_, p_) \
         { \
            ATL_vzero(r_); \
            r_ = _mm256_insertf128_ps(r_, _mm_loadu_ps(p_), 0); \
         }
         #define ATL_vcxld3(r_, p_) \
         { __m128 t_; \
            r_ = _mm256_insertf128_ps(r_, _mm_load_ps(p_), 0); \
            t_ = _mm_setzero_ps(); \
            t_ = _mm_loadl_pi(t_, ((void*)((p_)+4))); \
            r_ = _mm256_insertf128_ps(r_, t_, 1); \
         }
         #define ATL_vcxuld3(r_, p_) \
         { __m128 t0_, t1_; \
            r_ = _mm256_insertf128_ps(r_, _mm_loadu_ps(p_), 0); \
            t0_ = _mm_load_ss((p_)+4); \
            t1_ = _mm_load_ss((p_)+5); \
            t0_ = _mm_unpacklo_ps(t0_, t1_); \
            r_ = _mm256_insertf128_ps(r_, t0_, 1); \
         }
         #define ATL_vcxst2(p_, r_) \
            _mm_store_ps(p_, _mm256_extractf128_ps(r_, 0))
         #define ATL_vcxust2(p_, r_) \
             _mm_storeu_ps(p_, _mm256_extractf128_ps(r_,0))
         #define ATL_vcxst3(p_, r_) \
         {  __m128 t_; \
            ATL_vcxst2(p_, r_); \
            t_ = _mm256_extractf128_ps(r_, 0); \
            _mm_storel_pi((void*)((p_)+4), t_) ; \
         }
         #define ATL_vcxust3(p_, r_) \
         {  __m128 t_; \
            ATL_vcxust2(p_, r_); \
            t_ = _mm256_extractf128_ps(r_, 1); \
            _mm_store_ss((p_)+4, t_); \
            _mm_store_ss((p_)+5, _mm_shuffle_ps(t_, t_, 1)); \
         }
      #elif defined(DCPLX) &&  defined(ATL_AVX512__00)
         #error "AVX512 not presently supported"
      #elif defined(SCPLX) &&  defined(ATL_AVX512__00)
         #error "AVX512 not presently supported"
      #else /* gnuvec */
         #define ATL_vcxuld2(r_, p_) \
            r_ = (ATL_VTYPE){*(p_), (p_)[1], (p_)[2], (p_)[3]}
         #define ATL_vcxust2(p_, r_) \
         { \
            *(p_) = (r_)[0]; \
         @iexp i 1 0 +
         @iwhile i < 4
            (p_)[@(i)] = (r_)[@(i)]; \
            @iexp i @(i) 1 +
         @endiwhile
         }
         #define ATL_vcxuld3(r_, p_) \
            r_ = (ATL_VTYPE){*(p_), (p_)[1], (p_)[2], (p_)[3], (p_)[4], (p_)[5]}
         #define ATL_vcxust3(p_, r_) \
         { \
            *(p_) = (r_)[0]; \
         @iexp i 1 0 +
         @iwhile i < 6
            (p_)[@(i)] = (r_)[@(i)]; \
            @iexp i @(i) 1 +
         @endiwhile
         }

         @iexp i 2 0 +
         @iwhile i < 4
         #define ATL_vcxld@(i) ATL_vcxuld@(i)
         #define ATL_vcxst@(i) ATL_vcxust@(i)
            @iexp i @(i) 1 +
         @endiwhile
      #endif
      #if ATL_VLEN >= 16  /* need [4-7]: gnuvec or SREAL&AVX512 */
         #if defined(SCPLX__0) &&  defined(ATL_AVX512__0)
         #else /* gnuvec */
            #define ATL_vcxuld4(r_, p_) r_ = (ATL_VTYPE)\
               {*(p_), (p_)[1], (p_)[2], (p_)[3], \
                 (p_)[4],(p_)[5],(p_)[6],(p_)[7]}
            #define ATL_vcxuld5(r_, p_) r_ = (ATL_VTYPE)\
               {*(p_), (p_)[1], (p_)[2], (p_)[3], \
                 (p_)[4],(p_)[5],(p_)[6],(p_)[7], \
                 (p_)[8],(p_)[9]}
            #define ATL_vcxuld6(r_, p_) r_ = (ATL_VTYPE)\
               {*(p_), (p_)[1], (p_)[2], (p_)[3], \
                 (p_)[4],(p_)[5],(p_)[6],(p_)[7], \
                 (p_)[8],(p_)[9],(p_)[10],(p_)[11]}
            #define ATL_vcxuld7(r_, p_) r_ = (ATL_VTYPE)\
               {*(p_), (p_)[1], (p_)[2], (p_)[3], \
                 (p_)[4],(p_)[5],(p_)[6],(p_)[7], \
                 (p_)[8],(p_)[9],(p_)[10],(p_)[11], \
                 (p_)[12],(p_)[13]}
   @iexp j 3 1 +
   @iwhile j < 8
            #define ATL_vcxust@(j)(p_, r_) \
            { \
               *(p_) = (r_)[0]; \
         @iexp h @(j) @(j) +
         @iexp i 1 0 +
         @iwhile i < @(h)
               (p_)[@(i)] = (r_)[@(i)]; \
            @iexp i @(i) 1 +
         @endiwhile
            }
      @iexp j @(j) 1 +
   @endiwhile

         @iexp i 4 0 +
         @iwhile i < 8
            #define ATL_vcxld@(i) ATL_vcxuld@(i)
            #define ATL_vcxst@(i) ATL_vcxust@(i)
            @iexp i @(i) 1 +
         @endiwhile
         #endif
         #if ATL_VLEN >= 32

   @iexp j 7 1 +
   @iwhile j < 16
         @iexp h @(j) @(j) +
         #define ATL_vcxuld@(j)(r_, p_) r_ = (ATL_VTYPE){*(p_),\
         @iexp i 1 0 +
         @iwhile i < @(h)
                                        (p_)[@(i)], \
            @iexp i @(i) 1 +
         @endiwhile
                                     }
            #define ATL_vcxust@(j)(p_, r_) \
            { \
               *(p_) = (r_)[0]; \
         @iexp i 1 0 +
         @iwhile i < @(h)
               (p_)[@(i)] = (r_)[@(i)]; \
            @iexp i @(i) 1 +
         @endiwhile
            }
      @iexp j @(j) 1 +
   @endiwhile
         @iexp i 8 0 +
         @iwhile i < 16
            #define ATL_vcxld@(i) ATL_vcxuld@(i)
            #define ATL_vcxst@(i) ATL_vcxust@(i)
            @iexp i @(i) 1 +
         @endiwhile
            #if ATL_VLEN > 32 /* VLEN == 32, gnuvec only */
               #error "Unsupported VLEN > 32"
            #endif
         #endif
      #endif
   #endif
#endif
/*
 * Define ATL_vcxswapRI, ATL_vcxsplitRI.
 * Define ATL_vcxsplitRIld if you dont want vld/splitRI version.
 * Define ATL_vcxdotcomb & ATL_vcxPrepAlpha if you don't want to use 
 * system-indep (slow) versions.  ATL_vcxdotcomb has a fast sys-indep
 * version for VLEN==2.
 */
#ifdef ATL_VSX
   #ifdef SCPLX
      #define ATL_vcxswapRI(d_, s_) d_ = vec_perm(s_,s_,(vector unsigned char) \
         {4, 5, 6, 7, 0, 1, 2, 3, 12, 13, 14, 15, 8, 9, 10, 11})
      #if ATL_FULLGCCVSX   /* not supported by older gcc (eg. 4.8) */
         #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */ \
         { \
            rXr_ = (ATL_VTYPE) vec_mergee((vector unsigned int)(rXi_), \
                                          (vector unsigned int) (rXi_)); \
            rXi_ = (ATL_VTYPE) vec_mergeo((vector unsigned int)(rXi_),\
                                          (vector unsigned int)(rXi_)); \
         }
         #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
         {  ATL_VTYPE t1_;\
            ATL_vmul(rR_, rR_, ATL_VONEPN); \
            t1_ = vec_vmrglw(rR_, rI_); \
            rR_ = vec_vmrghw(rR_, rI_); \
            ATL_vadd(rR_, rR_, t1_); \
            t1_ = vec_xxpermdi(rR_, rR_, 2); \
            ATL_vadd(rR_, rR_, t1_); \
         }
      #else
/*
 *       Using these guys as constants isn't so great: gcc 4.8.2 pulls
 *       the formation of the first iperm vector out of a loop, but then leaves
 *       the formation of the second (in terms of the first) inside the loop.
 *       The fix is to have this file define DECL/INIT macros, where we manually
 *       declare the perm vector, create it, and hoist it ourselves.
 *       We'll keep with crap way, since later gcc supports mergee/mergeo.
 */
         #define ATL_MERGEE (vector unsigned char) \
            {0, 1, 2, 3, 0, 1, 2, 3, 8, 9, 10, 11, 8, 9, 10, 11}
         #define ATL_MERGEO (vector unsigned char) \
            {4, 5, 6, 7, 4, 5, 6, 7, 12, 13, 14, 15, 12, 13, 14, 15}
         #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */ \
         { \
            rXr_ = vec_perm(rXi_, rXi, ATL_MERGEE); \
            rXi_ = vec_perm(rXi_, rXi, ATL_MERGEO); \
         }
      #endif
   #else /* DCPLX */
      #define ATL_vcxswapRI(d_, s_) d_ = vec_xxpermdi(s_, s_, 2)
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */ \
      { \
         rXr_ = vec_xxpermdi(rXi_, rXi_, 0); \
         rXi_ = vec_xxpermdi(rXi_, rXi_, 3); \
      }
      #define ATL_CXSPLDb ATL_VLENb
      #define ATL_vcxsplitRIld(rXr_, rXi_, pX_) \
      { \
         rXr_ = vec_splats(*(pX_)); \
         rXi_ = vec_splats(*((pX_)+1)); \
      }
   #endif
#elif defined(ATL_VECARM1) || defined(ATL_NEON)
   #ifdef SCPLX
      #if 0
      #define ATL_vcxsplitRIld(rXr_, rXi_, pX_) \
      { unsigned long long *lp_=(void*)(pX_), l0_, l1_, rl0_, il0_, rl1_, il1_;\
         l0_ = *lp_;                /* l0 = {i0, r0}   :: cycle 0 */\
         l1_ = lp_[1];              /* l1 = {i1, r1}   :: cycle 0 */\
         rl0_ = l0_ << 32;          /* rl0= {r0,  0}   :: cycle 1 */\
         il0_ = l0_ >> 32;          /* il0= { 0, i0}   :: cycle 1*/\
         rl1_ = l1_ << 32;          /* rl1= {r1,  0}   :: cycle 2*/\
         il1_ = l1_ >> 32;          /* il1= { 0, i1}   :: cycle 2*/\
         rl0_ |= (rl0_>> 32);       /* rl0= {r0, r0}   :: cycle 3*/\
         il0_ |= (il0_<< 32);       /* il0= {i0, i0}   :: cycle 3*/\
         rl1_ |= (rl1_>> 32);       /* rl1= {r1, r1}   :: cycle 4*/\
         il1_ |= (il1_<< 32);       /* il1= {i1, i1}   :: cycle 4*/\
         rXr_ = vcombine_f32(vreinterpret_f32_u64(rl0_), \
                             vreinterpret_f32_u64(rl1_)); /* cycle 5 */\
         rXi_ = vcombine_f32(vreinterpret_f32_u64(il0_), \
                             vreinterpret_f32_u64(il1_)); /* cycle 6 */\
      }
      #endif

      #if defined(ATL_VECARM1)
         #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
         {  \
            rXr_ = vtrn1q_f32(rXi_, rXi_); \
            rXi_ = vtrn2q_f32(rXi_, rXi_); \
         }
      #else
         #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
         { \
            rXr_[0] = rXr_[1] = rXi[0]; \
            rXr_[2] = rXr_[3] = rXi[2]; \
            rXi_[0] = rXi_[1] = rXi[1]; \
            rXi_[2] = rXi_[3] = rXi[3]; \
         }
      #endif
      #define ATL_vcxswapRI(d_, s_) \
         d_ = vreinterpretq_f32_s32(vrev64q_s32(vreinterpretq_s32_f32(s_)))
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      { \
         rR_[0] += (rR_)[2] - (rR_)[1] - (rR_)[3]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3]; \
      }
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      { \
         rALn_ = vreinterpretq_f32_u64(vdupq_lane_u64(\
                    vreinterpret_u64_f32(vget_low_f32(rALn_)),0)); \
         ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
         ATL_vcxswapRI(rALs_, rALs_); \
      }
   #else
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = vdupq_laneq_f64(rXi_, 0); \
         rXi_ = vdupq_laneq_f64(rXi_, 1); \
      }
      #define ATL_vcxswapRI(d_, s_) \
         d_ = vcombine_f64(vget_high_f64(s_),vget_low_f64(s_))
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      { \
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         rR_ = vpaddq_f64(rR_, rI_); \
      }
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      { \
         ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
         ATL_vcxswapRI(rALs_, rALs_); \
      }
   #endif
#elif defined(ATL_AVXMAC) || defined(ATL_AVX)
   #ifdef SCPLX
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm256_moveldup_ps(rXi); \
         rXi_ = _mm256_movehdup_ps(rXi); \
      }
      #define ATL_vcxswapRI(d_, s_) d_ = _mm256_shuffle_ps(s_, s_, 0xB1)
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      {  __m128 t0_, t1_;\
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         rR_ = _mm256_hadd_ps(rR_, rI_); \
         rR_ = _mm256_hadd_ps(rR_, rR_); \
         t0_ =  _mm256_extractf128_ps(rR_, 1); \
         t0_ = _mm_add_ps(t0_, _mm256_extractf128_ps(rR_, 0)); \
         rR_ = _mm256_insertf128_ps(rR_, t0_, 0); \
      }
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      {  __m128 t0_; \
         t0_ = _mm256_extractf128_ps(rALn_,0); \
         t0_ = _mm_movelh_ps(t0_, t0_); \
         rALn_ = _mm256_insertf128_ps(rALn_,t0_, 0); \
         rALn_ = _mm256_insertf128_ps(rALn_,t0_, 1); \
         ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
         ATL_vcxswapRI(rALs_, rALs_); \
      }
   #else  /* DCPLX */
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm256_movedup_pd(rXi); \
         rXi_ = _mm256_shuffle_pd(rXi, rXi, 0xF); \
      }
      #define ATL_vcxswapRI(d_, s_) d_ = _mm256_shuffle_pd(s_, s_, 5)
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      {  __m128d t0_;\
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         rR_ = _mm256_hadd_pd(rR_, rI_); \
         t0_ =  _mm256_extractf128_pd(rR_, 1); \
         t0_ =  _mm_add_pd(t0_, _mm256_extractf128_pd(rR_, 0)); \
         rR_ = _mm256_insertf128_pd(rR_, t0_, 0); \
      }
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      { \
         rALn_ = _mm256_insertf128_pd(rALn_,_mm256_extractf128_pd(rALn_,0),1); \
         ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
         ATL_vcxswapRI(rALs_, rALs_); \
      }
   #endif
#elif defined(ATL_SSE2) && defined(DCPLX)
   #ifdef ATL_SSE3
      #define ATL_CXSPLDb 8
      #define ATL_vcxsplitRIld(rXr_, rXi_, pX_) \
      { \ 
         rXr = _mm_loaddup_pd(pX_); \
         rXi = _mm_loaddup_pd((pX_)+1); \
      }
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm_movedup_pd(rXi); \
         rXi_ = _mm_shuffle_pd(rXi, rXi, 0xF); \
      }
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      { \
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         rR_ = _mm_hadd_pd(rR_, rI_); \
      }
   #else
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm_unpacklo_pd(rXi, rXi); \
         rXi_ = _mm_unpackhi_pd(rXi, rXi); \
      }
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      {  __m128d t1_;\
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         t1_ = _mm_unpacklo_pd(rR_, rI_); \
         rR_ = _mm_unpackhi_pd(rR_, rI_); \
         ATL_vadd(rR_, rR_, t1_); \
      }
   #endif
   #define ATL_vcxswapRI(d_, s_) d_ = _mm_shuffle_pd(s_, s_, 5);
#elif defined(ATL_SSE1) && defined(SCPLX)
   #ifdef ATL_SSE3
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */ \
      { \
         rXr_ = _mm_moveldup_ps(rXi); \
         rXi_ = _mm_movehdup_ps(rXi); \
      }
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      { \
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         rR_ = _mm_hadd_ps(rR_, rI_); \
         rR_ = _mm_hadd_ps(rR_, rR_); \
      }
   #else
      #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
      { \
         rXr_ = _mm_shuffle_ps(rXi, rXi, 0xA0); \
         rXi_ = _mm_shuffle_ps(rXi, rXi, 0xF5); \
      }
      #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR_ gets ans */ \
      {  __m128 t1_;\
         ATL_vmul(rR_, rR_, ATL_VONEPN); \
         t1_ = _mm_unpacklo_ps(rR_, rI_); \
         rR_ = _mm_unpackhi_ps(rR_, rI_); \
         ATL_vadd(rR_, rR_, t1_); \
         t1_ = _mm_movehl_ps(t1_, rR_); \
         ATL_vadd(rR_, rR_, t1_); \
      }
   #endif
   #define ATL_vcxswapRI(d_, s_) d_ = _mm_shuffle_ps(s_, s_, 0xB1)
   #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
   { \
      rALn_ = _mm_movelh_ps(rALn_, rALn_); \
      ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
      ATL_vcxswapRI(rALs_, rALs_); \
   }
#else  /* gnuvec */
   #if ATL_VLEN == 2
      #define ATL_VIPERMR ((ATL_VITYPE){0, 0})
      #define ATL_VIPERMI ((ATL_VITYPE){1, 1})
      #define ATL_vcxswapRI(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0})
      #define ATL_vcxdotcomb(rR_, rI_) \
      { \
         (rR_)[0] -= (rR_)[1]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1]; \
      }
   #elif  ATL_VLEN == 4
      #define ATL_vcxswapRI(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2})
      #define ATL_vcxdotcomb(rR_, rI_) \
      { \
         rR_[0] += (rR_)[2] - (rR_)[1] - (rR_)[3]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3]; \
      }
      #define ATL_VIPERMR ((ATL_VITYPE){0, 0, 2, 2})
      #define ATL_VIPERMI ((ATL_VITYPE){1, 1, 3, 3})
   #elif  ATL_VLEN == 8
      #define ATL_vcxswapRI(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2,5,4,7,6})
      #define ATL_vcxdotcomb(rR_, rI_) \
      { \
         (rR_)[0] += (rR_)[2]+(rR_)[4]+(rR_)[6] \
               - (rR_)[1]-(rR_)[3]-(rR_)[5]-(rR_)[7]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3] \
                  + (rI_)[4] + (rI_)[5] + (rI_)[6] + (rI_)[7]; \
      }
      #define ATL_VIPERMR ((ATL_VITYPE){0, 0, 2, 2, 4, 4, 6, 6})
      #define ATL_VIPERMI ((ATL_VITYPE){1, 1, 3, 3, 5, 5, 7, 7})
   #elif  ATL_VLEN == 16
      #define ATL_vcxswapRI(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2,5,4,7,6, \
                                                   9,8,11,10,13,12,15,14})
      #define ATL_vcxdotcomb(rR_, rI_) \
      { \
         (rR_)[0] += (rR_)[2]+(rR_)[4]+(rR_)[6]+(rR_)[8]+(rR_)[10]+(rR_)[12] \
                   + (rR_)[14] - (rR_)[1]-(rR_)[3]-(rR_)[5]-(rR_)[7] \
                   - (rR_)[9]-(rR_)[11]-(rR_)[13]-(rR_)[15]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3] \
                  + (rI_)[4] + (rI_)[5] + (rI_)[6] + (rI_)[7]  \
                  + (rI_)[8] + (rI_)[9] + (rI_)[10] + (rI_)[11]  \
                  + (rI_)[12] + (rI_)[13] + (rI_)[14] + (rI_)[15]; \
      }
      #define ATL_VIPERMR ((ATL_VITYPE){0, 0, 2, 2, 4, 4, 6, 6, \
                                        8, 8, 10, 10, 12, 12, 14, 14})
      #define ATL_VIPERMI ((ATL_VITYPE){1, 1, 3, 3, 5, 5, 7, 7, \
                                        9, 9, 11, 11, 13, 13, 15, 15})
   #elif  ATL_VLEN == 32
      #define ATL_vcxswapRI(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2,5,4,7,6, \
                                                   9,8,11,10,13,12,15,14, \
                                                   17,16,19,18,21,20,23,22, \
                                                   25,24,27,26,29,28,31,30})
      #define ATL_vcxdotcomb(rR_, rI_) \
      { \
         (rR_)[0] += (rR_)[2]+(rR_)[4]+(rR_)[6] \
                   + (rR_)[8]+(rR_)[10]+(rR_)[12]+(rR_)[14] \
                   + (rR_)[16]+(rR_)[18]+(rR_)[20]+(rR_)[22] \
                   + (rR_)[24]+(rR_)[26]+(rR_)[28]+(rR_)[30] \
                   - (rR_)[1]-(rR_)[3]-(rR_)[5]-(rR_)[7] \
                   - (rR_)[9]-(rR_)[11]-(rR_)[13]-(rR_)[15] \
                   - (rR_)[17]-(rR_)[19]-(rR_)[21]-(rR_)[23] \
                   - (rR_)[25]-(rR_)[27]-(rR_)[29]-(rR_)[31]; \
         (rR_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3] \
                  + (rI_)[4] + (rI_)[5] + (rI_)[6] + (rI_)[7]  \
                  + (rI_)[8] + (rI_)[9] + (rI_)[10] + (rI_)[11]  \
                  + (rI_)[12] + (rI_)[13] + (rI_)[14] + (rI_)[15] \
                  + (rI_)[16] + (rI_)[17] + (rI_)[18] + (rI_)[19] \
                  + (rI_)[20] + (rI_)[21] + (rI_)[22] + (rI_)[23] \
                  + (rI_)[24] + (rI_)[25] + (rI_)[26] + (rI_)[27] \
                  + (rI_)[28] + (rI_)[29] + (rI_)[30] + (rI_)[31]; \
      }
       #define ATL_VIPERMR ((ATL_VITYPE) \
        { 0,  0,  2,  2,  4,  4,  6,  6,  8,  8, 10, 10, 12, 12, 14, 14, \
          16, 16, 18, 18, 20, 20, 22, 22, 24, 24, 26, 26, 28, 28, 30, 30}) 
       #define ATL_VIPERMI ((ATL_VITYPE) \
        { 1,  1,  3,  3,  5,  5,  7,  7,  9,  9, 11, 11, 13, 13, 15, 15, \
         17, 17, 19, 19, 21, 21, 23, 23, 25, 25, 27, 27, 29, 29, 31, 31}) 
   #else
      #error "unsupported ATL_VLEN!"
   #endif
   #define ATL_vcxsplitRI(rXr_, rXi_)  /* rXi input & output */  \
   { \
      rXr_ = __builtin_shuffle(rXi_, ATL_VIPERMR); \
      rXi_ = __builtin_shuffle(rXi_, ATL_VIPERMI); \
   }
#endif
/*
 * brute-force alpha prep works on any gcc-compat compiler & vec ISA
 */
#ifndef ATL_vcxPrepAlpha
   #if ATL_VLEN == 2  /* case that can be vec wt predef ops */
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      { \
         ATL_vmul(rALs_, rALn_, ATL_VONEPN); \
         ATL_vcxswapRI(rALs_, rALs_); \
      }
   #else
      #define ATL_vcxPrepAlpha(rALn_, rALs_) /* rALs={ral,-ial}*(VLEN/2) */ \
      { \
         TYPE mr_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
         TYPE a0_, a1_; int i_; \
         ATL_vst(mr_, rALn_); \
         a0_ = *(mr_); a1_ = mr_[1]; \
         for (i_=2; i_ < ATL_VLEN; i_ += 2) \
         { mr_[i_] = a0_; mr_[i_+1] = a1_; } \
         ATL_vld(rALn_, mr_); \
         a0_ = -a1_; a1_ = *(mr_); \
         for (i_=0; i_ < ATL_VLEN; i_ += 2) \
         { mr_[i_] = a0_; mr_[i_+1] = a1_; } \
         ATL_vld(rALs_, mr_); \
      }
   #endif
#endif
/*
 * brute force combine that will work on any gcc-compatible compiler/vec ISA
 */
#ifndef ATL_vcxdotcomb
   #define ATL_vcxdotcomb(rR_, rI_) /* low 2 elts rR gets ans */ \
   { \
      TYPE mr_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
      TYPE mi_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
      int i_;  \
      register TYPE dr_=ATL_rzero, di_=ATL_rzero; \
      ATL_vst(mr_, rR_); \
      ATL_vst(mi_, rI_); \
      for (i_=0; i_ < ATL_VLEN; i_ += 2) \
      { \
         dr_ += mr_[i_] - mr_[i_+1]; \
         di_ += mi_[i_] + mi_[i_+1]; \
      } \
      mr_[0] = dr_; \
      mr_[1] = di_; \
      ATL_vld(rR_, mr_); \
   }
#endif
/*
 * Default vcxsplitRIld that uses ATL_vld & ATL_vcxsplitRI
 */
#ifndef ATL_CXSPLDb
   #define ATL_CXSPLDb ATL_VLENb
#endif
#ifndef ATL_vcxsplitRIld
   #define ATL_vcxsplitRIld(rXr_, rXi_, pX_) \
   { \
      ATL_vld(rXi_, pX_); \
      ATL_vcxsplitRI(rXr_, rXi_); \
   }
#endif
/*
 * Convenience funcs for one vector iteration of DOT product, aligned &
 * unaligned Y. rX_ comes in already preloaded so that it can be used across mul
 * cols, as in GEMVT.  vX is natural order, vXs real/imag swapped (cxriswap).
 */
#define ATL_vcxdotA(dotR_, dotI_, vX_, vXs_, pY_) \
{\
   register ATL_VTYPE vY_; \
   ATL_vld(vY_, pY_); \
   ATL_vmac(dotR_, vX_, vY_); \
   ATL_vmac(dotI_, vXs_, vY); \
}

#define ATL_vcxdotU(dotR_, dotI_, vX_, vXs_, pY_) \
{\
   register ATL_VTYPE vY_; \
   ATL_vuld(vY_, pY_); \
   ATL_vmac(dotR_, vX_, vY_); \
   ATL_vmac(dotI_, vXs_, vY); \
}
/*
 * Convenience funcs for one vector iteration of AXPLY, [Un]&Aligned pY_
 * X comes in already split into vXr_ (real elts) and vXi_ (imag elts) so
 * that the same X values can be used across multiple Y vecs (which are
 * actually A columns for GER.
 */
#define ATL_vcxaxpyA(pY_, vXr_, vXi_, vALn_, vALs_) \
{                                      /* ALs={ALr,-iAL}; */ \
   register ATL_VTYPE vY_;             /* ALn={iAL,rAL} */ \
   ATL_vld(vY_, pY_);                  /* vY = {iY,rY, ...} */ \
   ATL_vmac(vY_, vXi_, vALs_);         /* vY += {iX*rAL, -iX*iAL} */ \
   ATL_vmac(vY_, vXr_, vALn_);         /* vY += {rX*iAL, rX*rAL} */ \
   ATL_vst(pY_, vY_); \
}

#define ATL_vcxaxpyU(pY_, vXr_, vXi_, vALn_, vALs_) \
{                                      /* ALs={ALr,-iAL}; */ \
   register ATL_VTYPE vY_, vXr_, vXi_; /* ALn={iAL,rAL} */ \
   ATL_vuld(vY_, pY_);                 /* vY = {iY,rY, ...} */ \
   ATL_vmac(vY_, vXi_, vALs_);         /* vY += {iX*rAL, -iX*iAL} */ \
   ATL_vmac(vY_, vXr_, vALn_);         /* vY += {rX*iAL, rX*rAL} */ \
   ATL_vst(pY_, vY_); \
}
/*
 * Remainder load/store functions.  They take 0 < n_ < (ATL_VLEN/2), which
 * is the number of complex elts to load/store from/to the ptr
 */

#if ATL_VLEN <= 4
   #define ATL_vcxldR(r_, p_, n_) ATL_vcxld1(r_, p_)
   #define ATL_vcxuldR(r_, p_, n_) ATL_vcxuld1(r_, p_)
   #define ATL_vcxstR(p_, r_, n_) ATL_vcxst1(p_, r_)
   #define ATL_vcxustR(p_, r_, n_) ATL_vcxust1(p_, r_)
   #define ATL_vcxldXYR(rX_, pX_, rY_, pY_, n_) \
   { \
      ATL_vcxld1(rX_, pX_); \
      ATL_vcxld1(rY_, pY_); \
   }
   #define ATL_vcxldXuYR(rX_, pX_, rY_, pY_, n_) \
   { \
      ATL_vcxld1(rX_, pX_); \
      ATL_vcxuld1(rY_, pY_); \
   }
   #define ATL_vcxlduXuYR(rX_, pX_, rY_, pY_, n_) \
   { \
      ATL_vcxuld1(rX_, pX_); \
      ATL_vcxuld1(rY_, pY_); \
   }
@BEGINPROC ldR2 nm nm1 arg1 nm2 arg2
   #define ATL_vcx@(nm)R(@(arg1),@(arg2),n_) \
   { \
      switch(n_) \
      { \
   @iexp k 2 @(j) /
   @iexp k @(k) -1 +
   @iexp i 1 0 +
   @iwhile i < @(k)
      case @(i) : \
         ATL_vcx@(nm1)@(i)(@(arg1)); \
         ATL_vcx@(nm2)@(i)(@(arg2)); \
         break; \
      @iexp i @(i) 1 +
   @endiwhile
      default: \
         ATL_vcx@(nm1)@(i)(@(arg1)); \
         ATL_vcx@(nm2)@(i)(@(arg2)); \
      } \
   }
@ENDPROC
@BEGINPROC ldstR1 nm arg
   #define ATL_vcx@(nm)R(@(arg),n_) \
   { \
      switch(n_) \
      { \
   @iexp k 2 @(j) /
   @iexp k @(k) -1 +
   @iexp i 1 0 +
   @iwhile i < @(k)
      case @(i) : \
         ATL_vcx@(nm)@(i)(@(arg)); \
         break; \
      @iexp i @(i) 1 +
   @endiwhile
      default: \
         ATL_vcx@(nm)@(i)(@(arg)); \
      } \
   }
@ENDPROC
@iexp j 4 4 +
@iwhile j < 64
#elif ATL_VLEN == @(j)
   @CALLPROC ldR2 ldXY ld rX_,pX_ ld rY_,pY_
   @CALLPROC ldR2 ldXuY ld rX_,pX_ uld rY_,pY_
   @CALLPROC ldR2 lduXuY uld rX_,pX_ uld rY_,pY_
   @CALLPROC ldstR1 ld r_,p_
   @CALLPROC ldstR1 st p_,r_
   @CALLPROC ldstR1 uld r_,p_
   @CALLPROC ldstR1 ust p_,r_
   @iexp j @(j) @(j) +
@endiwhile
#endif    /* end VLEN test for remainder definitions */

#endif   /* end multiple inclusion guard */
@ROUT atlas_cplxsimd.h00
/*
 * Now define the remainder terms, which depend only on VLEN and prior ld/st
 * For VLEN == 2, they should be empty, but we have them call the scalar
 * code so that it is always safe to use them for peeling.
 */
#if ATL_VLEN == 2
   #define ATL_vcxldR(r_, p_, n_) ATL_vcxld1(r_, p_)
   #define ATL_vcxuldR(r_, p_, n_) ATL_vcxuld1(r_, p_)
   #define ATL_vcxstR(p_, r_, n_) ATL_vcxst(p_, r_)
   #define ATL_vcxustR(p_, r_, n_) ATL_vcxst(p_, r_)
@iexp i 4 0 +
@iwhile i < 64
#elif ATL_VLEN == @(i)
   #define ATL_vcxuldR(r_, p_, n_) \
   { \
      switch(n_) \
      { \
   @iexp j 1 0 +
   @iexp h @(i) -1 +
   @iwhile j < @(h)
      case @(j): \
         ATL_vcxuld@(j)(r_, p_); \
         break; \
      @iexp j @(j) 1 +
   @endiwhile
      default: \
         ATL_vcxuld@(h)(r_, p_); \
      } \
   }
   @iexp i @(i) 2 *
@endiwhile
#else
   #error "unsupported ATL_VLEN!"
#endif

/*
 * ============================================================================
 * AXPY-based computation has the following features:
 * (1) Performance limited by load/store of Y, so ops permuted to keep Y in
 *     natural order
 * (2) X is split into real & imaginary components
 * (3) alpha is scaled & permuted to allow for MAC-based computation
 *
 * AXPY-BASED MACROS:
 *    ATL_cxaxp_ldALP(alpN, alpP, pALP)   : ld alpN, perm & scale alpP 
 *    ATL_cxaxp_spltX(realX, imagX, pX)   : split X into real/imag wt dup
 *    ATL_cxaxp_spltX_UA(realX, imagX, pX): above, assume pX is unaligned 
 *       Assuming n = VLEN/2:
 *       realX={real(Xn),real(Xn),...real(X1),real(X1),real(X0),real(X0)}
 *       imagX={imag(Xn),imag(Xn),...imag(X1),imag(X1),imag(X0),imag(X0)}
 * ============================================================================
 */
#if defined(ATL_VSX)
   #ifdef SCPLX
      #if ATL_FULLGCCVSX   /* not supported by older gcc (eg. 4.8) */
         #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
         { \
            ATL_vld(rXi_, pX_); \
            rXr_ = (ATL_VTYPE) vec_mergee((vector unsigned int)(rXi_), \
                                          (vector unsigned int) (rXi_)); \
            rXi_ = (ATL_VTYPE) vec_mergeo((vector unsigned int)(rXi_),\
                                          (vector unsigned int)(rXi_)); \
         }
         #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
         { \
            ATL_vuld(rXi_, pX_); \
            rXr_ = (ATL_VTYPE) vec_mergee((vector unsigned int)(rXi_),\
                                          (vector unsigned int) (rXi_)); \
            rXi_ = (ATL_VTYPE) vec_mergeo((vector unsigned int)(rXi_), \
                                          (vector unsigned int)(rXi_)); \
         }
      #else
/*
 *       Using these guys as constants isn't so great: gcc 4.8.2 pulls
 *       the formation of the first iperm vector out of a loop, but then leaves
 *       the formation of the second (in terms of the first) inside the loop.
 *       The fix is to have this file define DECL/INIT macros, where we manually
 *       declare the perm vector, create it, and hoist it ourselves. 
 *       For now, we'll keep with crap way, since later gcc should switch
 *       to mergee/mergeo anyway.
 */
         #define ATL_MERGEE (vector unsigned char) \
            {0, 1, 2, 3, 0, 1, 2, 3, 8, 9, 10, 11, 8, 9, 10, 11}
         #define ATL_MERGEO (vector unsigned char) \
            {4, 5, 6, 7, 4, 5, 6, 7, 12, 13, 14, 15, 12, 13, 14, 15}
         #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
         { \
            ATL_vld(rXi_, pX_); \
            rXr_ = vec_perm(rXi_, rXi, ATL_MERGEE); \
            rXi_ = vec_perm(rXi_, rXi, ATL_MERGEO); \
         }
         #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
         { \
            ATL_vuld(rXi_, pX_); \
            rXr_ = vec_perm(rXi_, rXi, ATL_MERGEE); \
            rXi_ = vec_perm(rXi_, rXi, ATL_MERGEO); \
         }
      #endif
   #else
      #define ATL_CXAXP_ALGX 8
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         rXr_ = vec_splats(*(pX_)); \
         rXi_ = vec_splats(*((pX_)+1)); \
      }
      #define ATL_cxaxp_spltX_UA ATL_cxaxp_spltX /* only need native algn */
   #endif
#elif defined(ATL_AVXMAC) || defined(ATL_AVX)
   #ifdef SCPLX
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         ATL_vld(rXi_, pX_); \
         rXr_ = _mm256_moveldup_ps(rXi); \
         rXi_ = _mm256_movehdup_ps(rXi); \
      }
      #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
      { \
         ATL_vuld(rXi_, pX_); \
         rXr_ = _mm256_moveldup_ps(rXi); \
         rXi_ = _mm256_movehdup_ps(rXi); \
      }
   #else /* double precision */
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         ATL_vld(rXi_, pX_); \
         rXr_ = _mm256_movedup_pd(rXi); \
         rXi_ = _mm256_shuffle_pd(rXi, rXi, 0xF); \
      }
      #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
      { \
         ATL_vuld(rXi_, pX_); \
         rXr_ = _mm256_movedup_pd(rXi); \
         rXi_ = _mm256_shuffle_pd(rXi, rXi, 0xF); \
      }
   #endif
#elif defined(ATL_SSE3)
   #ifdef SCPLX
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         ATL_vld(rXi_, pX_); \
         rXr_ = _mm_moveldup_ps(rXi); \
         rXi_ = _mm_movehdup_ps(rXi); \
      }
      #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
      { \
         ATL_vuld(rXi_, pX_); \
         rXr_ = _mm_moveldup_ps(rXi); \
         rXi_ = _mm_movehdup_ps(rXi); \
      }
   #else /* double precision */
      #define ATL_CXAXP_ALGX 8
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         rXr_ = _mm_loaddup_pd(pX_); \
         rXi_ = _mm_loaddup_pd(((TYPE*)(pX_))+1); \
      }
      #define ATL_cxaxp_spltX_UA ATL_cxaxp_spltX /* only need native algn */
   #endif
#elif defined(ATL_SSE2) && defined(DCPLX)
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         ATL_vld(rXi_, pX_); \
         rXr_ = _mm_unpacklo_pd(rXi, rXi); \
         rXi_ = _mm_unpackhi_pd(rXi, rXi); \
      }
      #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
      { \
         ATL_vuld(rXi_, pX_); \
         rXr_ = _mm_unpacklo_pd(rXi, rXi); \
         rXi_ = _mm_unpackhi_pd(rXi, rXi); \
      }
#elif defined(ATL_SSE1) && defined(SCPLX)
      #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
      { \
         ATL_vld(rXi_, pX_); \
         rXr_ = _mm_shuffle_ps(rXi, rXi, 0xA0); \
         rXi_ = _mm_shuffle_ps(rXi, rXi, 0xF5); \
      }
      #define ATL_cxaxp_spltX_UA(rXr_, rXi_, pX_) \
      { \
         ATL_vuld(rXi_, pX_); \
         rXr_ = _mm_shuffle_ps(rXi, rXi, 0xA0); \
         rXi_ = _mm_shuffle_ps(rXi, rXi, 0xF5); \
      }
#else /* if all else fails, use gnu built vector  */
   #if ATL_VLEN == 2
      #define ATL_VIPERMR (ATL_VITYPE){0, 0}
      #define ATL_VIPERMI (ATL_VITYPE){1, 1}
      #define ATL_cxaxp_spltX_UA(rR_, rI_, p_) \
      { \
         rR_ = (ATL_VTYPE){*(p_),*(p_)}; \
         rI_ = (ATL_VTYPE){(p_)[1],(p_)[1]}; \
      }
   #elif ATL_VLEN == 4
      #define ATL_VIPERMR (ATL_VITYPE){0, 0, 2, 2}
      #define ATL_VIPERMI (ATL_VITYPE){1, 1, 3, 3}
      #define ATL_cxaxp_spltX_UA(rR_, rI_, p_) \
      { \
         rR_ = (ATL_VTYPE){*(p_),*(p_),(p_)[2],(p_)[2]}; \
         rI_ = (ATL_VTYPE){(p_)[1],(p_)[1],(p_)[3],(p_)[3]}; \
      }
   #elif ATL_VLEN == 8
      #define ATL_VIPERMR (ATL_VITYPE){0, 0, 2, 2, 4, 4, 6, 6}
      #define ATL_VIPERMI (ATL_VITYPE){1, 1, 3, 3, 5, 5, 7, 7}
      #define ATL_cxaxp_spltX_UA(rR_, rI_, p_) \
      { \
         rR_ = (ATL_VTYPE){*(p_),*(p_),(p_)[2],(p_)[2], \
                           (p_)[4],(p_)[4],(p_)[6],(p_)[6]}; \
         rI_ = (ATL_VTYPE){(p_)[1],(p_)[1],(p_)[3],(p_)[3], \
                           (p_)[5],(p_)[5],(p_)[7],(p_)[7]}; \
      }
   #elif ATL_VLEN == 16
      #define ATL_VIPERMR (ATL_VITYPE){0, 0, 2, 2, 4, 4, 6, 6, \
                                       8, 8, 10, 10, 12, 12, 14, 14};
      #define ATL_VIPERMI (ATL_VITYPE){1, 1, 3, 3, 5, 5, 7, 7, \
                                       9, 9, 11, 11, 13, 13, 15, 15};
      #define ATL_cxaxp_spltX_UA(rR_, rI_, p_) \
      { \
         rR_ = (ATL_VTYPE){*(p_),*(p_),(p_)[2],(p_)[2], \
                           (p_)[4],(p_)[4],(p_)[6],(p_)[6], \
                           (p_)[8],(p_)[8],(p_)[10],(p_)[10], \
                           (p_)[12],(p_)[12],(p_)[14],(p_)[14]}; \
         rI_ = (ATL_VTYPE){(p_)[1],(p_)[1],(p_)[3],(p_)[3], \
                           (p_)[5],(p_)[5],(p_)[7],(p_)[7], \
                           (p_)[9],(p_)[9],(p_)[11],(p_)[11], \
                           (p_)[13],(p_)[13],(p_)[15],(p_)[15]}; \
      }
   #elif ATL_VLEN == 32
       #define ATL_VIPERMR (ATL_VITYPE) \
        { 0,  0,  2,  2,  4,  4,  6,  6,  8,  8, 10, 10, 12, 12, 14, 14, \
         16, 16, 18, 18, 20, 20, 22, 22, 24, 24, 26, 26, 28, 28, 30, 30}; \
       #define ATL_VIPERMI (ATL_VITYPE) \
        { 1,  1,  3,  3,  5,  5,  7,  7,  9,  9, 11, 11, 13, 13, 15, 15, \
         17, 17, 19, 19, 21, 21, 23, 23, 25, 25, 27, 27, 29, 29, 31, 31}; \
      #define ATL_cxaxp_spltX_UA(rR_, rI_, p_) \
      { \
         rR_ = (ATL_VTYPE){*(p_),*(p_),(p_)[2],(p_)[2], \
                           (p_)[4],(p_)[4],(p_)[6],(p_)[6], \
                           (p_)[8],(p_)[8],(p_)[10],(p_)[10], \
                           (p_)[12],(p_)[12],(p_)[14],(p_)[14], \
                           (p_)[16],(p_)[18],(p_)[20],(p_)[22], \
                           (p_)[24],(p_)[24],(p_)[26],(p_)[26], \
                           (p_)[28],(p_)[28],(p_)[30],(p_)[30]}; \
         rI_ = (ATL_VTYPE){(p_)[1],(p_)[1],(p_)[3],(p_)[3], \
                           (p_)[5],(p_)[5],(p_)[7],(p_)[7], \
                           (p_)[9],(p_)[9],(p_)[11],(p_)[11], \
                           (p_)[13],(p_)[13],(p_)[15],(p_)[15], \
                           (p_)[17],(p_)[19],(p_)[21],(p_)[23], \
                           (p_)[25],(p_)[25],(p_)[27],(p_)[27], \
                           (p_)[29],(p_)[29],(p_)[31],(p_)[31]};
      }
   #else
      #error "VLEN != {2,4,8,16,32} unsupported "
   #endif
   #define ATL_cxaxp_spltX(rXr_, rXi_, pX_) \
   {  ATL_VTYPE t_; \
      ATL_vld(rXi_, pX_); \
      rXr_ = __builtin_shuffle(rXi_, ATL_VIPERMR); \
      rXi_ = __builtin_shuffle(rXi_, ATL_VIPERMI); \
   }
#endif
/*
 * natural default alignment is default X/y align
 */
#ifndef ATL_CXAXP_ALGY
   #define ATL_CXAXP_ALGY ATL_VLENb
#endif
#ifndef ATL_CXAXP_ALGX
   #define ATL_CXAXP_ALGX ATL_VLENb
#endif
#ifndef ATL_cxaxp_ldALP
/*
 * rAn = {ialpha,  ralpha} repeated VLEN/2 times
 * rAs = {ralpha, -ialpha} repeated VLEN/2 times
 * Not written efficiently for portability.  Assumed called outside optloop.
 * System-specific code can provide more efficient version, then this generic
 * implementation won't be used.
 */
   #define ATL_cxaxp_ldALP(rAn_, rAs_, alp_) \
   {  TYPE al_[ATL_VLEN]; \
      int i;\
      const register TYPE ralp=(*(alp_)), ialp=(alp_)[1], ialpn=-ialp; \
      for (i=0; i < ATL_VLEN; i += 2) \
      { \
         al_[i] = ralp; \
         al_[i+1] = ialp; \
      } \
      ATL_vuld(rAn_, al_); \
      for (i=0; i < ATL_VLEN; i += 2) \
      { \
         al_[i] = ialpn; \
         al_[i+1] = ralp; \
      } \
      ATL_vuld(rAs_, al_); \
   }
#endif
/*
 * Convenience function for cleanup.  If vectorized cleanup not provided,
 * just use this scalar loop
 */
#ifndef ATL_cxaxp_clean
   #define ATL_cxaxp_clean(n_, pX_, pY_, alp_) \
   { \
      if (n_) \
      { \
         const TYPE *px_ = (pX_); \
         TYPE *py_ = (pY_); \
         const register TYPE ra_ = *(alp_), ia_ = (alp_)[1]; \
         int i_=n_; \
         do \
         { \
            const register TYPE rx_=(*px_), ix_=px_[1]; \
            *py_   += ra_*rx_ - ia_*ix_; \
            py_[1] += ra_*ix_ + ia_*rx_; \
            py_ += 2; \
            px_ += 2; \
         } \
         while(--i_); \
      } \
   }
#endif
/*
 * ============================================================================
 * The DOT-based compution is based on the idea of using separate accumulators
 * for real and imaginary computation, and using vector reduction to produce
 * the complete answer from partial results.
 * Doing this requires these macros:
 *    ATL_cxdot_riswap(rd, rs) : rd gets rs, with even/odd words swapped
 *    ATL_cxdot_comb(rR, rI): combine (rR,iR), ans in low 2 wrds rR, 0 upper
 *    ATL_cxdot_cxldR(r_,p_, n_): low n_ cplx elts from aligned p_, rest 0
 *    ATL_cxdot_cxuldR(r_,p_, n_): low n_ cplx elts from unaligned p_, rest 0
 *    -> used for cleanup, n_ < VLEN!
 * ============================================================================
 */
#if defined(ATL_VSX)
   #ifdef SCPLX
      #if ATL_FULLGCCVSX
         #define ATL_cxdot_cxldR(r_, p_, n_) \
         {  ATL_VTYPE zr_;\
            ATL_vld(r_, p_); /* no seg fault VLEN < CL */ \
            ATL_vzero(zr_); \
            r_ = vec_xxpermdi(r_, zr_, 2); \
         }
      #else
         #define ATL_cxdot_cxldR(r_, p_, n_) \
         {  ATL_VTYPE zr_;\
            ATL_vld(r_, p_); /* no seg fault VLEN < CL */ \
            ATL_vzero(zr_); \
            r_ = vec_perm(r_, zr_, ((vector unsigned char) \
               {0,1,2,3,4,5,6,7,8,16,17,18,19,20,21,22,23,24})); \
         }
      #endif
      #define ATL_cxdot_cxuldR(r_, p_, n_) \
      {  ATL_VTYPE zr_;\
         ATL_vld(r_, p_); /* no seg fault VLEN < CL */ \
         ATL_vzero(zr_); \
         r_ = vec_perm(r_, zr_, vec_lvsl(0, p_)); \
      }
      #define ATL_RISWAPV (vector unsigned char) \
          {4, 5, 6, 7, 0, 1, 2, 3, 12, 13, 14, 15, 8, 9, 10, 11}
   #else
      #if ATL_FULLGCCVSX
         #define ATL_cxdot_riswap(rd_, rs_) rd_ = vec_xxpermdi(rs_, rs_, 2)
      #else
         #define ATL_RISWAPV (vector unsigned char) \
             {8, 9, 10, 11, 12, 13, 14, 15, 0, 1, 2, 3, 4, 5, 6, 7}
      #endif
      #define ATL_cxdot_cxldR(r_, p_, n_) ATL_vld(r_, p_)
      #define ATL_cxdot_cxuldR(r_, p_, n_) ATL_vuld(r_, p_)
   #endif
/*
 * If we don't have access to better solution use vec_perm for real/imag swap
 */
   #ifndef ATL_cxdot_riswap
      #define ATL_cxdot_riswap(rd_, rs_) rd_ = vec_perm(rs_, rs_, ATL_RISWAPV)
   #endif
/*
 * brute force combine that will work on any altivec-supporting gcc
 */
   #ifndef ATL_cxdot_comb
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      { \
         TYPE mr_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
         TYPE mi_[ATL_VLEN] __attribute__ ((aligned (ATL_VLENb)));\
         int i_;  \
         register TYPE dr_=ATL_rzero, di_=ATL_rzero; \
         ATL_vst(mr_, rR_); \
         ATL_vst(mi_, rI_); \
         for (i_=0; i_ < ATL_VLEN; i_ += 2) \
         { \
            dr_ += mr_[i_] - mr_[i_+1]; \
            di_ += mi_[i_] + mi_[i_+1]; \
         } \
         *(p_) = dr_; \
         (p_)[1] = di_; \
      }
   #endif
#elif defined(ATL_AVXMAC) || defined(ATL_AVX)
   #ifdef SCPLX
      #define ATL_cxdot_riswap(rd_, rs_) rd_ = _mm256_shuffle_ps(rs_, rs_, 0xB1)
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      {  __m256 h_; __m128 t0_, t1_;\
         ATL_vmul(h_, rR_, ATL_VONEPN); \
         h_ = _mm256_hadd_ps(h_, rI_); \
         h_ = _mm256_hadd_ps(h_, h_); \
         t0_ =  _mm256_extractf128_ps(h_, 1); \
         t0_ = _mm_add_ps(t0_, _mm256_extractf128_ps(h_, 0)); \
         _mm_store_ss(p_, t0_); \
         t0_ = _mm_shuffle_ps(t0_, t0_, 0xE5); \
         _mm_store_ss(((p_)+1), t0_); \
      }
      #define ATL_cxdot_cxldR(r_, p_, n_) \
      {  __m128 t0_; \
         ATL_vzero(r_); \
         if (n_ == 1) \
         { \
            t0_ =  _mm_setzero_ps(); \
            t0_ = _mm_loadl_pi(t0_, (void*)(p_)); \
            r_ = _mm256_insertf128_ps(r_, t0_, 0); \
         } \
         else /* n_ is 2 or 3 */ \
         { \
            r_ = _mm256_insertf128_ps(r_, _mm_load_ps(p_), 0); \
            if (n_ != 2) \
            { \
               t0_ =  _mm_setzero_ps(); \
               t0_ = _mm_loadl_pi(t0_, (void*)((p_)+4)); \
               r_ = _mm256_insertf128_ps(r_, t0_, 1); \
            } \
         } \
      }
      #define ATL_cxdot_cxuldR(r_, p_, n_) \
      { \
         if (n_ == 2) \
         { \
            ATL_vzero(r_); \
            r_ = _mm256_insertf128_ps(r_, _mm_loadu_ps(p_), 0); \
         } \
         else  /* use maskmov for other cases */ \
         { \
             __m256i msk; \
             __m128i mskh; \
             mskh = _mm_setzero_si128(); \
             mskh = _mm_insert_epi64(mskh,(long long)0xFFFFFFFFFFFFFFFF,0);\
             if (n_ == 1) \
             { \
                msk = _mm256_setzero_si256(); \
                msk = _mm256_insertf128_si256(msk, mskh, 0); \
             } \
             else /* n == 3 */ \
             { \
                msk = _mm256_insertf128_si256(msk, mskh, 1); \
                mskh = _mm_unpacklo_epi64(mskh, mskh); \
                msk = _mm256_insertf128_si256(msk, mskh, 0); \
             } \
             r_ = _mm256_maskload_ps(p_, msk); \
         } \
      }
   #else
      #define ATL_cxdot_riswap(rd_, rs_) rd_ = _mm256_shuffle_pd(rs_, rs_, 5)
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      { __m256d h_; __m128d t0_;\
         ATL_vmul(h_, rR_, ATL_VONEPN); \
         h_ = _mm256_hadd_pd(h_, rI_); \
         t0_ =  _mm256_extractf128_pd(h_, 1); \
         t0_ = _mm_add_pd(t0_, _mm256_extractf128_pd(h_, 0)); \
         _mm_storeu_pd(p_, t0_); \
      }
      #define ATL_cxdot_cxldR(r_, p_, n_) \
      { \
         r_ = ATL_vzero(r_); \
         r_ = _mm256_insertf128_pd(r_, _mm_load_pd(p_), 0); \
      }
      #define ATL_cxdot_cxuldR(r_, p_, n_) \
      { \
         r_ = ATL_vzero(r_); \
         r_ = _mm256_insertf128_pd(r_, _mm_loadu_pd(p_), 0); \
      }
   #endif
#elif defined(ATL_SSE2) && defined(DCPLX)
      #define ATL_cxdot_riswap(rd_, rs_) rd_ = _mm_shuffle_pd(rs_, rs_, 1)
      #define ATL_cxdot_cxldR(r_, p_, n_) r_ = _mm_load_pd(p_)
      #define ATL_cxdot_cxuldR(r_, p_, n_) r_ = _mm_loadu_pd(p_)
      #ifdef ATL_SSE3
         #define ATL_cxdot_comb(p_, rR_, rI_) \
         {  __m128d t0_; \
            ATL_vmul(t0_, rR_, ATL_VONEPN)); \
            _mm_storeu_pd(p_, _mm_hadd_pd(t0_, rI_)); \
         }
      #else
         #define ATL_cxdot_comb(p_, rR_, rI_) \
         {  __m128d t0_, t1_; \
            ATL_vmul(t0_, rR_, ATL_VONEPN); \
            t1_ = _mm_unpacklo_pd(t0_, rI_); \
            t0_ = _mm_unpackhi_pd(t0_, rI_); \
            ATL_vadd(t0_, t0_, t1_); \
            _mm_storeu_pd(p_, t0_); \
         }
      #endif
#elif defined(ATL_SSE1) && defined(SCPLX)
      #define ATL_cxdot_riswap(rd_, rs_) rd_ = _mm_shuffle_ps(rs_, rs_, 0xB1)
      #if 0  /* would work if intrinsics weren't retarded */
         #define ATL_cxdot_cxldR(r_, p_, n_) \
            r_ = (ATL_VTYPE) _mm_load_sd((void*)(p_))
         #define ATL_cxdot_cxuldR(r_, p_, n_) \
            r_ = (ATL_VTYPE) _mm_loadu_sd((void*)(p_))
      #else
         #define ATL_cxdot_cxldR(r_, p_, n_) \
         { \
            r_ =  _mm_setzero_ps(); \
            r_ = _mm_loadl_pi(r_, (void*)(p_)); \
         }
         #define ATL_cxdot_cxuldR(r_, p_, n_) \
         {  __m128 t_; \
            r_ = _mm_load_ss(p_); \
            t_ = _mm_load_ss((p_)+1); \
            r_ = _mm_unpacklo_ps(r_, t_); \
         }
      #endif
      #ifdef ATL_SSE3
         #define ATL_cxdot_comb(p_, rR_, rI_) \
         {  __m128 t0_; \
            ATL_vmul(t0_, rR_, ATL_VONEPN); \
            t0_ = _mm_hadd_ps(t0_, rI_); \
            t0_ = _mm_hadd_ps(t0_, t0_); \
            _mm_store_ss(p_, t0_); \
            t0_ = _mm_shuffle_ps(t0_, t0_, 0xE1); \
            _mm_store_ss((p_)+1, t0_); \
         }
      #else
         #define ATL_cxdot_comb(p_, rR_, rI_) \
         {  __m128 t0_, t1_; \
            ATL_vmul(t0_, rR_, ATL_VONEPN); \
            t1_ = _mm_unpacklo_ps(t0_, rI_); \
            t0_ = _mm_unpackhi_ps(t0_, rI_); \
            ATL_vadd(t0_, t0_, t1_); \
            t1_ = _mm_movehl_ps(t1_, t0_); \
            ATL_vadd(t0_, t0_, t1_); \
            _mm_store_ss(p_, t0_); \
            t0_ = _mm_shuffle_ps(t0_, t0_, 0xE1); \
            _mm_store_ss((p_)+1, t0_); \
         }
      #endif
#else   /* gnuvec */
   #if ATL_VLEN == 2
      #define ATL_cxdot_cxuldR(r_, p_, n_) r_ = (ATL_VTYPE) {*(p_)}
      #define ATL_cxdot_riswap(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0})
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      { \
         *(p_) = (rR_)[0] - (rR_)[1]; \
         (p_)[1] = (rI_)[0] + (rI_)[1]; \
      }
   #elif  ATL_VLEN == 4
      #define ATL_cxdot_cxuldR(r_, p_, n_) \
      { \
         if (n_ == 1) \
            r_ = (ATL_VTYPE) {*(p_), (p_)[1]}; \
         else \
            r_ = (ATL_VTYPE) {*(p_), (p_)[1], (p_)[2], (p_)[3]}; \
      }
      #define ATL_cxdot_riswap(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2})
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      { \
         *(p_) = (rR_)[0] + (rR_)[2] - (rR_)[1] - (rR_)[3]; \
         (p_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3]; \
      }
   #elif  ATL_VLEN == 8
      #define ATL_cxdot_riswap(rd_, rs_) \
         rd_ = __builtin_shuffle(rs_, (ATL_VITYPE){1,0,3,2,5,4,7,6})
      #define ATL_cxdot_cxuldR(r_, p_, n_) \
      { \
         if (n_ == 1) \
            r_ = (ATL_VTYPE) {*(p_), (p_)[1]}; \
         else if (n_ == 2) \
            r_ = (ATL_VTYPE) {*(p_), (p_)[1], (p_)[2], (p_)[3]}; \
         else /* if (n_ == 3) */ \
            r_ = (ATL_VTYPE) {*(p_),(p_)[1],(p_)[2],(p_)[3],(p_)[4],(p_)[5]}; \
      }
      #define ATL_cxdot_comb(p_, rR_, rI_) \
      { \
         *(p_) = (rR_)[0]+(rR_)[2]+(rR_)[4]+(rR_)[6] \
               - (rR_)[1]-(rR_)[3]-(rR_)[5]-(rR_)[7]; \
         (p_)[1] = (rI_)[0] + (rI_)[1] + (rI_)[2] + (rI_)[3] \
                 + (rI_)[4] + (rI_)[5] + (rI_)[6] + (rI_)[7]; \
      }
   #elif  ATL_VLEN == 16
   #elif  ATL_VLEN == 32
   #else
      #error "unsupported ATL_VLEN!"
   #endif
   #define ATL_cxdot_cxldR ATL_cxdot_cxuldR
#endif

#endif  /* end multiple inclusion guard */
@ROUT ATL_rk4n4
#include "atlas_misc.h"
#include "atlas_amm.h"
#include "atlas_simd.h"
#if defined(__GNUC__) || \
    (defined(__STDC_VERSION__) && (__STDC_VERSION__/100 >= 1999))
   #define ATL_SINLINE static inline
#else
   #define ATL_SINLINE static
#endif
#if ATL_VLEN > 1
@define up @@
@whiledef up u
   @define ld @ATL_v@(up)ld@
   @define st @ATL_v@(up)st@
ATL_SINLINE void ATL_rk4n4_@(up)vec
(
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   const SCALAR alpha,
   const TYPE *A0,
   ATL_CSZT lda,
   const TYPE *B0,
   ATL_CSZT ldb,
   TYPE *C0,
   ATL_CSZT ldc
)
{
   ATL_VTYPE b00, b10, b20, b30, b01, b11, b21, b31;
   ATL_VTYPE b02, b12, b22, b32, b03, b13, b23, b33;
   const TYPE *A1=A0+lda, *A2=A1+lda, *A3=A2+lda;
   TYPE *C1=C0+ldc, *C2=C1+ldc, *C3=C2+ldc;
   register int i;
   if (TB == AtlasNoTrans)
   {
      const TYPE *B1=B0+ldb, *B2=B1+ldb, *B3=B2+ldb;
      ATL_vbcast(b00, B0);
      ATL_vbcast(b01, B1);
      ATL_vbcast(b02, B2);
      ATL_vbcast(b03, B3);
      ATL_vbcast(b10, B0+1);
      ATL_vbcast(b11, B1+1);
      ATL_vbcast(b12, B2+1);
      ATL_vbcast(b13, B3+1);
      ATL_vbcast(b20, B0+2);
      ATL_vbcast(b21, B1+2);
      ATL_vbcast(b22, B2+2);
      ATL_vbcast(b23, B3+2);
      ATL_vbcast(b30, B0+3);
      ATL_vbcast(b31, B1+3);
      ATL_vbcast(b32, B2+3);
      ATL_vbcast(b33, B3+3);
   }
   else /* TB == AtlasTrans, B NxK */
   {
      const TYPE *B1=B0+ldb, *B2=B1+ldb, *B3=B2+ldb;
      ATL_vbcast(b00, B0);
      ATL_vbcast(b10, B1);
      ATL_vbcast(b20, B2);
      ATL_vbcast(b30, B3);
      ATL_vbcast(b01, B0+1);
      ATL_vbcast(b11, B1+1);
      ATL_vbcast(b21, B2+1);
      ATL_vbcast(b31, B3+1);
      ATL_vbcast(b02, B0+2);
      ATL_vbcast(b12, B1+2);
      ATL_vbcast(b22, B2+2);
      ATL_vbcast(b32, B3+2);
      ATL_vbcast(b03, B0+3);
      ATL_vbcast(b13, B1+3);
      ATL_vbcast(b23, B2+3);
      ATL_vbcast(b33, B3+3);
   }
   if (alpha != 1.0)
   {
      ATL_VTYPE al;
      ATL_vbcast(al, &alpha);
      ATL_vmul(b00, b00, al);
      ATL_vmul(b10, b10, al);
      ATL_vmul(b20, b20, al);
      ATL_vmul(b30, b30, al);
      ATL_vmul(b01, b01, al);
      ATL_vmul(b11, b11, al);
      ATL_vmul(b21, b21, al);
      ATL_vmul(b31, b31, al);
      ATL_vmul(b02, b02, al);
      ATL_vmul(b12, b12, al);
      ATL_vmul(b22, b22, al);
      ATL_vmul(b32, b32, al);
      ATL_vmul(b03, b03, al);
      ATL_vmul(b13, b13, al);
      ATL_vmul(b23, b23, al);
      ATL_vmul(b33, b33, al);
   }
   for (i=0; i < M; i += ATL_VLEN)
   {
      ATL_VTYPE c0, c1, c2, c3, a0;
      @(ld)(c0, C0+i);
      @(ld)(c1, C1+i);
      @(ld)(c2, C2+i);
      @(ld)(c3, C3+i);

      @(ld)(a0, A0+i);
      ATL_vmac(c0, b00, a0);
      ATL_vmac(c1, b01, a0);
      ATL_vmac(c2, b02, a0);
      ATL_vmac(c3, b03, a0);
      @(ld)(a0, A1+i);
      ATL_vmac(c0, b10, a0);
      ATL_vmac(c1, b11, a0);
      ATL_vmac(c2, b12, a0);
      ATL_vmac(c3, b13, a0);
      @(ld)(a0, A2+i);
      ATL_vmac(c0, b20, a0);
      ATL_vmac(c1, b21, a0);
      ATL_vmac(c2, b22, a0);
      ATL_vmac(c3, b23, a0);
      @(ld)(a0, A3+i);
      ATL_vmac(c0, b30, a0);
      ATL_vmac(c1, b31, a0);
      ATL_vmac(c2, b32, a0);
      ATL_vmac(c3, b33, a0);

      @(st)(C0+i, c0);
      @(st)(C1+i, c1);
      @(st)(C2+i, c2);
      @(st)(C3+i, c3);
   }
}
   @undef ld
   @undef st
@endwhile
#endif

ATL_SINLINE void ATL_rk4n4
(
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   const SCALAR alpha,
   const TYPE *A0,
   ATL_CSZT lda,
   const TYPE *B0,
   ATL_CSZT ldb,
   TYPE *C0,
   ATL_CSZT ldc
)

/*
 * This special-case code used for LU, only called when:
 *   TA=AtlasNoTrans, N == K == 4, beta == 1.0
 */
{
   TYPE b00, b10, b20, b30, b01, b11, b21, b31;
   TYPE b02, b12, b22, b32, b03, b13, b23, b33;
   const TYPE *A1=A0+lda, *A2=A1+lda, *A3=A2+lda;
   TYPE *C1=C0+ldc, *C2=C1+ldc, *C3=C2+ldc;
   register int i;

   if (TB == AtlasNoTrans)
   {
      const TYPE *B1=B0+ldb, *B2=B1+ldb, *B3=B2+ldb;
      b00 = alpha * *B0;
      b01 = alpha * *B1;
      b02 = alpha * *B2;
      b03 = alpha * *B3;
      b10 = alpha * B0[1];
      b11 = alpha * B1[1];
      b12 = alpha * B2[1];
      b13 = alpha * B3[1];
      b20 = alpha * B0[2];
      b21 = alpha * B1[2];
      b22 = alpha * B2[2];
      b23 = alpha * B3[2];
      b30 = alpha * B0[3];
      b31 = alpha * B1[3];
      b32 = alpha * B2[3];
      b33 = alpha * B3[3];
   }
   else  /* B == AtlasTrans; B is NxK */
   {
      const TYPE *B1=B0+ldb, *B2=B1+ldb, *B3=B2+ldb;
      b00 = alpha * *B0;
      b10 = alpha * *B1;
      b20 = alpha * *B2;
      b30 = alpha * *B3;
      b01 = alpha * B0[1];
      b11 = alpha * B1[1];
      b21 = alpha * B2[1];
      b31 = alpha * B3[1];
      b02 = alpha * B0[2];
      b12 = alpha * B1[2];
      b22 = alpha * B2[2];
      b32 = alpha * B3[2];
      b03 = alpha * B0[3];
      b13 = alpha * B1[3];
      b23 = alpha * B2[3];
      b33 = alpha * B3[3];
   }
   for (i=0; i < M; i++)
   {
      const register TYPE a0=A0[i], a1=A1[i], a2=A2[i], a3=A3[i];
      TYPE register c0=C0[i], c1=C1[i], c2=C2[i], c3=C3[i];
      c0 += b00*a0;
      c1 += b01*a0;
      c2 += b02*a0;
      c3 += b03*a0;
      c0 += b10*a1;
      c1 += b11*a1;
      c2 += b12*a1;
      c3 += b13*a1;
      c0 += b20*a2;
      c1 += b21*a2;
      c2 += b22*a2;
      c3 += b23*a2;
      c0 += b30*a3;
      c1 += b31*a3;
      c2 += b32*a3;
      c3 += b33*a3;
      C0[i] = c0;
      C1[i] = c1;
      C2[i] = c2;
      C3[i] = c3;
   }
}

int Mjoin(PATL,rk4n4)
(
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   const SCALAR alpha,
   const TYPE *A0,
   ATL_CSZT lda,
   const TYPE *B0,
   ATL_CSZT ldb,
   TYPE *C0,
   ATL_CSZT ldc
)
{
   #if ATL_VLEN < 2
      ATL_rk4n4(TB, M, alpha, A0, lda, B0, ldb, C0, ldc);
   #else
      const int vmod = (ATL_VLEN-1);
      int Mp=0, Mv, Mr;  /* peel, vector, remainder */
      int ALLALIGN=0;
      if (!((ldc&vmod) | (lda&vmod)))
      {
         const size_t VMOD = ((size_t)(ATL_VLEN-1));
         size_t a0, a1;
         int gap0, gap;
         a0 = (size_t) C0;
         a1 = (size_t) A0;
         a0 = ATL_DivBySize(a0);
         a1 = ATL_DivBySize(a1);
         gap0 = a0 & VMOD;
         gap  = a1 & VMOD;
         if (gap0 == gap)
         {
            ALLALIGN=1;
            if (gap)
            {
               Mp = ATL_VLEN - gap;
               Mp = Mmin(Mp, M);
            }
         }
      }
      Mr = M - Mp;
      Mv = Mr & ~vmod;
      Mr -= Mv;

      if (ALLALIGN)
      {
         if (Mp)
         {
            ATL_rk4n4(TB, Mp, alpha, A0, lda, B0, ldb, C0, ldc);
            A0 += Mp; C0 += Mp;
         }
         if (Mv)
         {
            ATL_rk4n4_vec(TB, Mv, alpha, A0, lda, B0, ldb, C0, ldc);
            A0 += Mv; C0 += Mv;
         }
      }
      else if (Mv)
      {
         ATL_rk4n4_uvec(TB, Mv, alpha, A0, lda, B0, ldb, C0, ldc);
         A0 += Mv; C0 += Mv;
      }
      if (Mr)
         ATL_rk4n4(TB, Mr, alpha, A0, lda, B0, ldb, C0, ldc);
   #endif
   return(0);
}
@ROUT ATL_ammm_rk2
#include "atlas_amm.h"
#include "atlas_misc.h"
#include "atlas_lvl2.h"
#include "atlas_level1.h"
/*
 * This is special-case code that handles rank-2 update by calling GER2
 */
int Mjoin(PATL,ammm_rk2)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef DREAL
      const int MB=512, NB=32;
   #else /* SREAL */
      const int MB=512, NB=64;
   #endif
   void *vp;
   TYPE *x, *y, *w, *z;
   size_t j;
   ATL_CSZT incC = NB*ldc;

/*
 * If beta is one, can handle by one call to ger2
 */
   if (SCALAR_IS_ONE(beta))
   {
      if (TA == AtlasNoTrans)
      {
         if (TB == AtlasNoTrans)
            Mjoin(PATL,ger2)(M, N, alpha, A, 1, B, ldb, alpha, A+lda, 1,
                             B+1, ldb, C, ldc);
         else
            Mjoin(PATL,ger2)(M, N, alpha, A, 1, B, 1, alpha, A+lda, 1,
                             B+ldb, 1, C, ldc);
      }
      else if (TB == AtlasNoTrans)
         Mjoin(PATL,ger2)(M, N, alpha, A, lda, B, ldb, alpha, A+1, lda,
                          B+1, ldb, C, ldc);
      else
         Mjoin(PATL,ger2)(M, N, alpha, A, lda, B, 1, alpha, A+1, lda,
                          B+ldb, 1, C, ldc);
      return(0);
   }
/*
 * Later on, do smart think like copy only MB/NB at a time, and don't copy
 * at all if vectors are contiguous, but right now, always do copy up-front
 * so loop does not have to worry about TA/TB; this is a O(N) cost in N^2 alg
 */
   vp = malloc(2*ATL_MulBySize(M+N)+4*ATL_Cachelen);
   if (!vp)
      return(1);
   x = ATL_AlignPtr(vp);
   y = x + M;
   y = ATL_AlignPtr(y);
   w = y + N;
   w = ATL_AlignPtr(w);
   z = w + M;
   z = ATL_AlignPtr(z);
   if (TA == AtlasNoTrans)
   {
      Mjoin(PATL,copy)(M, A, 1, x, 1);
      Mjoin(PATL,copy)(M, A+lda, 1, w, 1);
   }
   else
   {
      Mjoin(PATL,copy)(M, A, lda, x, 1);
      Mjoin(PATL,copy)(M, A+1, lda, w, 1);
   }
   if (SCALAR_IS_ONE(alpha))
   {
      if (TB == AtlasNoTrans)
      {
         Mjoin(PATL,copy)(N, B, ldb, y, 1);
         Mjoin(PATL,copy)(N, B+1, ldb, z, 1);
      }
      else
      {
         Mjoin(PATL,copy)(N, B, 1, y, 1);
         Mjoin(PATL,copy)(N, B+ldb, 1, z, 1);
      }
   }
   else
   {
      if (TB == AtlasNoTrans)
      {
         Mjoin(PATL,cpsc)(N, alpha, B, ldb, y, 1);
         Mjoin(PATL,cpsc)(N, alpha, B+1, ldb, z, 1);
      }
      else
      {
         Mjoin(PATL,cpsc)(N, alpha, B, 1, y, 1);
         Mjoin(PATL,cpsc)(N, alpha, B+ldb, 1, z, 1);
      }
   }
   for (j=0; j < N; j += NB, C += incC)
   {
      size_t i, nb = N-j;
      nb = (nb >= NB) ? NB : nb;
      for (i=0; i < M; i += MB)
      {
         size_t mb = M-i;
         mb = (mb >= MB) ? MB : mb;
         Mjoin(PATL,gescal)(mb, nb, beta, C+i, ldc);
         Mjoin(PATL,ger2)(mb, nb, ATL_rone, x+i, 1, y+j, 1, ATL_rone, 
                          w+i, 1, z+j, 1, C+i, ldc);
      }
   }
   free(vp);
   return(0);
}
@ROUT ATL_cammm_rk2
#include "atlas_amm.h"
#include "atlas_misc.h"
#include "atlas_lvl2.h"
#include "atlas_level1.h"
/*
 * This is special-case code that handles rank-2 update by calling GER2
 */
int Mjoin(PATL,ammm_rk2)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef DCPLX
      const int MB=512, NB=16;
   #else /* SCPLX */
      const int MB=512, NB=32;
   #endif
   void *vp;
   TYPE *x, *y, *w, *z;
   size_t j;
   const TYPE ONE[2] = {ATL_rone, ATL_rzero};
   ATL_CSZT lda2=lda+lda, ldb2=ldb+ldb, ldc2=ldc+ldc, incC = NB*ldc2;

/*
 * If beta is one, can handle by one call to ger2
 */
   if (SCALAR_IS_ONE(beta) && 0)
   {
      if (TA == AtlasNoTrans)
      {
         if (TB == AtlasNoTrans)
            Mjoin(PATL,ger2u)(M, N, alpha, A, 1, B, ldb, alpha, A+lda2, 1,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasConj)
            Mjoin(PATL,ger2c)(M, N, alpha, A, 1, B, ldb, alpha, A+lda2, 1,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasTrans)
            Mjoin(PATL,ger2u)(M, N, alpha, A, 1, B, 1, alpha, A+lda2, 1,
                              B+ldb2, 1, C, ldc);
         else /* if (TB == AtlasConjTrans) */
            Mjoin(PATL,ger2c)(M, N, alpha, A, 1, B, 1, alpha, A+lda2, 1,
                              B+ldb2, 1, C, ldc);
      }
      else if (TA == AtlasTrans)
      {
         if (TB == AtlasNoTrans)
            Mjoin(PATL,ger2u)(M, N, alpha, A, lda, B, ldb, alpha, A+2, lda,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasConj)
            Mjoin(PATL,ger2c)(M, N, alpha, A, lda, B, ldb, alpha, A+2, lda,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasTrans)
            Mjoin(PATL,ger2u)(M, N, alpha, A, lda, B, 1, alpha, A+2, lda,
                              B+ldb2, 1, C, ldc);
         else if (TB == AtlasConjTrans)
            Mjoin(PATL,ger2c)(M, N, alpha, A, lda, B, 1, alpha, A+2, lda,
                              B+ldb2, 1, C, ldc);
      }
/*
 *    If A must be conjugated, copy it
 */
      else  /* TA == AtlasConj || TA == AtlasConjTrans */
      {
         vp = malloc((ATL_MulBySize(M)+ATL_Cachelen)<<1);
         if (!vp)
           return(2);
         x = ATL_AlignPtr(vp);
         w = x + M + M;
         w = ATL_AlignPtr(w);
         if (SCALAR_IS_ONE(alpha))
         {
            if (TA == AtlasConj)
            {
               Mjoin(PATL,copyConj)(M, A, 1, x, 1);
               Mjoin(PATL,copyConj)(M, A+lda2, 1, w, 1);
            }
            else /* if (TA == AtlasConjTrans) */
            {
               Mjoin(PATL,copyConj)(M, A, lda, x, 1);
               Mjoin(PATL,copyConj)(M, A+2, lda, w, 1);
            }
         }
         else
         {
            if (TA == AtlasConj)
            {
               Mjoin(PATL,moveConj)(M, alpha, A, 1, x, 1);
               Mjoin(PATL,moveConj)(M, alpha, A+lda2, 1, w, 1);
            }
            else /* if (TA == AtlasConjTrans) */
            {
               Mjoin(PATL,moveConj)(M, alpha, A, lda, x, 1);
               Mjoin(PATL,moveConj)(M, alpha, A+2, lda, w, 1);
            }
         }
         if (TB == AtlasNoTrans)
            Mjoin(PATL,ger2u)(M, N, ONE, x, 1, B, ldb, ONE, w, 1,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasConj)
            Mjoin(PATL,ger2c)(M, N, ONE, x, 1, B, ldb, ONE, w, 1,
                              B+2, ldb, C, ldc);
         else if (TB == AtlasTrans)
            Mjoin(PATL,ger2u)(M, N, ONE, x, 1, B, 1, ONE, w, 1,
                              B+ldb2, 1, C, ldc);
         else /* if (TB == AtlasConjTrans) */
            Mjoin(PATL,ger2c)(M, N, ONE, x, 1, B, 1, ONE, w, 1,
                              B+ldb2, 1, C, ldc);
         free(vp);
      }
      return(0);
   }
/*
 * Later on, do smart think like copy only MB/NB at a time, and don't copy
 * at all if vectors are contiguous, but right now, always do copy up-front
 * so loop does not have to worry about TA/TB; this is a O(N) cost in N^2 alg
 */
   vp = malloc(2*ATL_MulBySize(M+N)+4*ATL_Cachelen);
   if (!vp)
      return(1);
   x = ATL_AlignPtr(vp);
   y = x + M + M;
   y = ATL_AlignPtr(y);
   w = y + N + N;
   w = ATL_AlignPtr(w);
   z = w + M + M;
   z = ATL_AlignPtr(z);
   if (TA == AtlasNoTrans)
   {
      Mjoin(PATL,copy)(M, A, 1, x, 1);
      Mjoin(PATL,copy)(M, A+lda2, 1, w, 1);
   }
   else if (TA == AtlasConj)
   {
      Mjoin(PATL,copyConj)(M, A, 1, x, 1);
      Mjoin(PATL,copyConj)(M, A+lda2, 1, w, 1);
   }
   else if (TA == AtlasTrans)
   {
      Mjoin(PATL,copy)(M, A, lda, x, 1);
      Mjoin(PATL,copy)(M, A+2, lda, w, 1);
   }
   else if (TA == AtlasConjTrans)
   {
      Mjoin(PATL,copyConj)(M, A, lda, x, 1);
      Mjoin(PATL,copyConj)(M, A+2, lda, w, 1);
   }
   if (SCALAR_IS_ONE(alpha))
   {
      if (TB == AtlasNoTrans)
      {
         Mjoin(PATL,copy)(N, B, ldb, y, 1);
         Mjoin(PATL,copy)(N, B+2, ldb, z, 1);
      }
      else if (TB == AtlasConj)
      {
         Mjoin(PATL,copyConj)(N, B, ldb, y, 1);
         Mjoin(PATL,copyConj)(N, B+2, ldb, z, 1);
      }
      else if (TB == AtlasTrans)
      {
         Mjoin(PATL,copy)(N, B, 1, y, 1);
         Mjoin(PATL,copy)(N, B+ldb2, 1, z, 1);
      }
      else if (TB == AtlasConjTrans)
      {
         Mjoin(PATL,copyConj)(N, B, 1, y, 1);
         Mjoin(PATL,copyConj)(N, B+ldb2, 1, z, 1);
      }
   }
   else  /* alpha non-one; must apply */
   {
      if (TB == AtlasNoTrans)
      {
         Mjoin(PATL,cpsc)(N, alpha, B, ldb, y, 1);
         Mjoin(PATL,cpsc)(N, alpha, B+2, ldb, z, 1);
      }
      else if (TB == AtlasConj)
      {
         Mjoin(PATL,moveConj)(N, alpha, B, ldb, y, 1);
         Mjoin(PATL,moveConj)(N, alpha, B+2, ldb, z, 1);
      }
      else if (TB == AtlasTrans)
      {
         Mjoin(PATL,cpsc)(N, alpha, B, 1, y, 1);
         Mjoin(PATL,cpsc)(N, alpha, B+ldb2, 1, z, 1);
      }
      else /* if (TB == AtlasConjTrans) */
      {
         Mjoin(PATL,moveConj)(N, alpha, B, 1, y, 1);
         Mjoin(PATL,moveConj)(N, alpha, B+ldb2, 1, z, 1);
      }
   }
   for (j=0; j < N; j += NB, C += incC)
   {
      size_t i, nb = N-j;
      nb = (nb >= NB) ? NB : nb;
      for (i=0; i < M; i += MB)
      {
         size_t mb = M-i;
         mb = (mb >= MB) ? MB : mb;
         Mjoin(PATL,gescal)(mb, nb, beta, C+i+i, ldc);
         Mjoin(PATL,ger2u)(mb, nb, ONE, x+i+i, 1, y+j+j, 1, ONE,
                           w+i+i, 1, z+j+j, 1, C+i+i, ldc);
      }
   }
   free(vp);
   return(0);
}
@ROUT ATL_ammmREC
#include "atlas_misc.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

typedef struct ammrec ammrec_t;
struct ammrec
{
   cm2am_t a2blk, b2blk;
   ablk2cmat_t blk2c;
   ammkern_t amm_b0, amm_b1, amm_k1_b0, amm_k1_b1;
   size_t lda, ldb, ldc, incAm, incAk, incBk, incBn, incCn, incCm;
   TYPE alpA, alpB, alpC, beta;
   int mbkb, kbnb, mbnb, nmu, nnu, nmuF, nnuF;
   int mb, nb, kb, KB0, mr, nr, kr;
};


#define v_kp 1
#define v_np 2
#define v_mp 4
#define v_cpA 8
#define v_cpB 16
#define v_cpC 32
#define v_lwC 64  /* last guy to update C must write it out */
#define v_nmA 128 /* don't move A ptr */
#define v_nmB 256 /* don't move B ptr */
#define v_nmC 512 /* don't move C ptr */

#define b_kp 0
#define b_np 1
#define b_mp 2
#define b_cpA 3
#define b_cpB 4
#define b_cpC 5
#define b_lwC 6 
#define b_nmA 7
#define b_nmB 8
#define b_nmC 9 

@beginskip
static void ammmRECf  /* no partial blocks */
(
   const ammrec_t *pd,
   int nmblks,
   int nnblks,
   int nkblks,
   int flag, /* bits: 0:kp, 1:np, 2:mp, 3:cpA, 4:cpyB, 5:cpyC */
   const TYPE *A,
   const TYPE *B, 
   TYPE *C,
   TYPE *a,
   TYPE *b,
   TYPE *c
)
{
/*
 * If only one block remains, stop and do multiply
 */
   ATL_assert((flag & (v_mp|v_np|v_kp)) == 0)
//   if ((nmblks|nnblks|nkblks) == 1)
   if (nmblks == 1 && nnblks == 1 && nkblks == 1)
   {
      TYPE *an = (flag & v_nmA) ? a : a+pd->mbkb;
      TYPE *bn = (flag & v_nmB) ? b : b+pd->kbnb;
      TYPE *cn = (flag & v_nmC) ? c : c+pd->mbnb;
      const ammkern_t amm = (flag & v_cpC) ? pd->amm_b0 : pd->amm_b1;
      if (flag & v_cpA)
         pd->a2blk(pd->kb, pd->mb, pd->alpA, A, pd->lda, a);
      if (flag & v_cpB)
         pd->b2blk(pd->kb, pd->nb, pd->alpB, B, pd->ldb, b);
      amm(pd->nmu, pd->nnu, pd->kb, a, b, c, an, bn, cn);
      if (flag & v_lwC) 
         pd->blk2c(pd->mb, pd->nb, pd->alpC, c, pd->beta, C, pd->ldc);
   }
   else if (nkblks > nmblks && nkblks > nnblks)  /* split K */
   {
      const int nR=(nkblks>>1), nL = nkblks-nR;
      int flg = flag & ~(v_nmA|v_nmB|v_nmC);  /* only one guy doesn't move */
      ammmRECf(pd, nmblks, nnblks, nL, (flag & ~(v_nmA+v_nmB+v_lwC))|v_nmC,
               A, B, C, a, b, c);
      flg = flag & ~v_cpC;
      if (nR == 1)
      {
         if (flag&v_lwC)
            flg |= v_lwC;
         else
            flg &= ~v_lwC;
      }
      ammmRECf(pd, nmblks, nnblks, nR, flg, A+nL*pd->incAk, B+nL*pd->incBk, C,
               a+nL*nmblks*pd->mbkb, b+nL*nnblks*pd->kbnb, c);
   }
   else if (nnblks > nmblks) /* split N */
   {
      const int nR=(nnblks>>1), nL = nnblks-nR;
      ammmRECf(pd, nmblks, nL, nkblks, (flag & ~(v_nmB+v_nmC))|v_nmA, 
               A, B, C, a, b, c);
      ammmRECf(pd, nmblks, nR, nkblks, flag & ~v_cpA,
               A, B+nL*pd->incBn, C+pd->incCn*nL, 
               a, b+nL*nkblks*pd->kbnb, c+nL*nmblks*pd->mbnb);
   }
   else                      /* split M */
   {
      const int nR=(nmblks>>1), nL = nmblks-nR;
      ammmRECf(pd, nL, nnblks, nkblks, (flag & ~(v_nmA+v_nmC))|v_nmB, 
               A, B, C, a, b, c);
      ammmRECf(pd, nR, nnblks, nkblks, flag & ~v_cpB,
               A+nL*pd->incAm, B, C+pd->mb*nL, 
               a+nL*nkblks*pd->mbkb, b, c+nL*nnblks*pd->mbnb);
   }
}
@endskip

static void ammmRECf /* no partial blocks */
(
   const ammrec_t *pd,
   int nmblks,
   int nnblks,
   int nkblks,
   int flag, /* bits: 0:kp, 1:np, 2:mp, 3:cpA, 4:cpyB, 5:cpyC */
   const TYPE *A,
   const TYPE *B,
   TYPE *C,
   TYPE *a,
   TYPE *b,
   TYPE *c
)
{
@skip   ATL_assert((flag & (v_mp|v_np|v_kp)) == 0)
/*
 * Stop recursion and do multiply when only 1 block is left
 */
   if (nmblks == 1 && nnblks == 1 && nkblks == 1)
   {
      TYPE *an = (flag & v_nmA) ? a : a+pd->mbkb;
      TYPE *bn = (flag & v_nmB) ? b : b+pd->kbnb;
      TYPE *cn = (flag & v_nmC) ? c : c+pd->mbnb;
      const ammkern_t amm = (flag & v_cpC) ? pd->amm_b0 : pd->amm_b1;
      if (flag & v_cpA)
         pd->a2blk(pd->kb, pd->mb, pd->alpA, A, pd->lda, a);
      if (flag & v_cpB)
         pd->b2blk(pd->kb, pd->nb, pd->alpB, B, pd->ldb, b);
      amm(pd->nmu, pd->nnu, pd->kb, a, b, c, an, bn, cn);
      if (flag & v_lwC)
         pd->blk2c(pd->mb, pd->nb, pd->alpC, c, pd->beta, C, pd->ldc);
   }
   else if (nnblks >= nkblks && nnblks >= nmblks)   /* recursively divide N */
   {
      const int nR=(nnblks>>1), nL = nnblks-nR;
      ammmRECf(pd, nmblks, nL, nkblks, (flag|v_nmA) & ~(v_nmB+v_nmC), 
               A, B, C, a, b, c);
      ammmRECf(pd, nmblks, nR, nkblks, flag & ~v_cpA,
              A, B+nL*pd->incBn, C+pd->incCn*nL,
              a, b+nL*nkblks*pd->kbnb, c+nL*nmblks*pd->mbnb);
   }
   else if (nmblks >= nkblks)                       /* recursively divide M */
   {
      const int nR=(nmblks>>1), nL = nmblks-nR;
      ammmRECf(pd, nL, nnblks, nkblks, (flag|v_nmB) & ~(v_nmA+v_nmC), 
               A, B, C, a, b, c);
      ammmRECf(pd, nR, nnblks, nkblks, flag & ~v_cpB,
              A+nL*pd->incAm, B, C+pd->mb*nL,
              a+nL*nkblks*pd->mbkb, b, c+nL*nnblks*pd->mbnb);
   }
   else                                             /* recursively divide K */
   {
      const int nR=(nkblks>>1), nL = nkblks-nR;
      ammmRECf(pd, nmblks, nnblks, nL, (flag|v_nmC) & ~(v_nmA+v_nmB+v_lwC), 
               A, B, C, a, b, c);
      ammmRECf(pd, nmblks, nnblks, nR, flag & ~v_cpC, 
               A+nL*pd->incAk, B+nL*pd->incBk, C,
               a+nL*nmblks*pd->mbkb, b+nL*nnblks*pd->kbnb, c);
   }
}

static void ammmREC  /* partial blocks are possible */
(
   const ammrec_t *pd,
   int nmblks,
   int nnblks,
   int nkblks,
   int flag, /* bits: 0:kp, 1:np, 2:mp, 3:cpA, 4:cpyB, 5:cpyC */
   const TYPE *A,
   const TYPE *B,
   TYPE *C,
   TYPE *a,
   TYPE *b,
   TYPE *c
)
{
/*
 * If I only have one possibly partial block left.  Equivalent to:
 * if ( ((nmblks == 1 && !(flag&v_mp)) || nmblks == 0) &&
 *      ((nnblks == 1 && !(flag&v_np)) || nnblks == 0) &&
 *      ((nkblks == 1 && !(flag&v_kp)) || nkblks == 0) )
 */
   if (nmblks < 2 && nnblks < 2 && nkblks < 2 &&
       nmblks != ((flag>>b_mp)&1) &&
       nnblks != ((flag>>b_np)&1) &&
       nkblks != ((flag>>b_kp)&1))
   {
      TYPE *an = (flag & v_nmA) ? a : a+pd->mbkb;
      TYPE *bn = (flag & v_nmB) ? b : b+pd->kbnb;
      TYPE *cn = (flag & v_nmC) ? c : c+pd->mbnb;
/*
 *    If we aren't doing K-cleanup, can always use fastest kernels
 */
      if (!(flag & v_kp))
      {
         const ammkern_t amm = (flag & v_cpC) ? pd->amm_b0 : pd->amm_b1;
         if (!(flag & (v_mp+v_np)))   /* one full block to multiply */
         {
            if (flag & v_cpA)
               pd->a2blk(pd->kb, pd->mb, pd->alpA, A, pd->lda, a);
            if (flag & v_cpB)
               pd->b2blk(pd->kb, pd->nb, pd->alpB, B, pd->ldb, b);
            amm(pd->nmu, pd->nnu, pd->kb, a, b, c, an, bn, cn);
            if (flag & v_lwC)
               pd->blk2c(pd->mb, pd->nb, pd->alpC, c, pd->beta, C, pd->ldc);
         }
         else
         {
            int nmu=pd->nmu, nnu=pd->nnu, m=pd->mb, n=pd->nb, kb=pd->kb;
            if (flag & v_mp)
            {
               nmu = pd->nmuF;
               m = pd->mr;
            }
            if (flag & v_np)
            {
               nnu = pd->nnuF;
               n = pd->nr;
            }
            if (flag & v_cpA)
               pd->a2blk(kb, m, pd->alpA, A, pd->lda, a);
            if (flag & v_cpB)
               pd->b2blk(kb, n, pd->alpB, B, pd->ldb, b);
            amm(nmu, nnu, kb, a, b, c, an, bn, cn);
            if (flag & v_lwC)
               pd->blk2c(m, n, pd->alpC, c, pd->beta, C, pd->ldc);
         }
      }
      else /* if (flag & (v_mp|v_np|v_kp))   partial block to multiply */
      {
         const ammkern_t amm = (flag & v_cpC) ? pd->amm_k1_b0 : pd->amm_k1_b1;
         const int nmu = (nmblks) ? pd->nmu : pd->nmuF;
         const int m = (nmblks) ? pd->mb : pd->mr;
         const int nnu = (nnblks) ? pd->nnu : pd->nnuF;
         const int n = (nnblks) ? pd->nb : pd->nr;
         const int k = (nkblks) ? pd->kb : pd->kr;
         const int KBF = (nkblks) ? k : pd->KB0;

         if (flag & v_cpA)
            pd->a2blk(k, m, pd->alpA, A, pd->lda, a);
         if (flag & v_cpB)
            pd->b2blk(k, n, pd->alpB, B, pd->ldb, b);
         amm(nmu, nnu, KBF, a, b, c, an, bn, cn);
         if (flag & v_lwC)
            pd->blk2c(m, n, pd->alpC, c, pd->beta, C, pd->ldc);
      }
   }
   else if (nnblks >= nkblks && nnblks >= nmblks &&           /* recursively */
            (nnblks > 1 || (flag&v_np)))                      /* divide N    */
   {
      const int nR=(nnblks>>1), nL = nnblks-nR;
      const size_t mblks=(flag&v_mp) ? nmblks+1 : nmblks;
      const size_t kblks=(flag&v_kp) ? nkblks+1 : nkblks;
      const int flg = (flag|v_nmA) & ~(v_np+v_nmB+v_nmC);
      if (flag & (v_mp+v_kp))
         ammmREC(pd, nmblks, nL, nkblks, flg, A, B, C, a, b, c);
      else
         ammmRECf(pd, nmblks, nL, nkblks, flg, A, B, C, a, b, c);
      ammmREC(pd, nmblks, nR, nkblks, flag & ~v_cpA,
              A, B+nL*pd->incBn, C+pd->incCn*nL,
              a, b+nL*kblks*pd->kbnb, c+nL*mblks*pd->mbnb);
   }
   else if (nmblks >= nkblks && (nmblks > 1 || (flag&v_mp)))  /* recursively */
   {                                                          /* divide M    */
      const int nR=(nmblks>>1), nL = nmblks-nR;
      const size_t nblks=(flag&v_np) ? nnblks+1 : nnblks;
      const size_t kblks=(flag&v_kp) ? nkblks+1 : nkblks;
      const int flg = (flag|v_nmB) & ~(v_mp+v_nmA+v_nmC);
      if (flag&(v_np+v_kp))
         ammmREC(pd, nL, nnblks, nkblks, flg, A, B, C, a, b, c);
      else
         ammmRECf(pd, nL, nnblks, nkblks, flg, A, B, C, a, b, c);
      ammmREC(pd, nR, nnblks, nkblks, flag & ~v_cpB,
              A+nL*pd->incAm, B, C+pd->mb*nL,
              a+nL*kblks*pd->mbkb, b, c+nL*nblks*pd->mbnb);
   }
   else                                                       /* recursively */
   {                                                          /* divide K    */
      const int nR=(nkblks>>1), nL = nkblks-nR;
      const size_t mblks=(flag&v_mp) ? nmblks+1 : nmblks;
      const size_t nblks=(flag&v_np) ? nnblks+1 : nnblks;
      const int flg = (flag|v_nmC) & ~(v_kp+v_lwC+v_nmA+v_nmB);
      if (flag & (v_mp+v_np))
         ammmREC(pd, nmblks, nnblks, nL, flg, A, B, C, a, b, c);
      else
         ammmRECf(pd, nmblks, nnblks, nL, flg, A, B, C, a, b, c);
      ammmREC(pd, nmblks, nnblks, nR, flag & ~v_cpC, 
              A+nL*pd->incAk, B+nL*pd->incBk, C,
              a+nL*mblks*pd->mbkb, b+nL*nblks*pd->kbnb, c);
   }
}

int Mjoin(PATL,ammmREC)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   void *vp;
   TYPE *a, *b, *c;
   amminfo_t mminfo;
   ammrec_t pd;
   #if ATL_geAMM_MAXKVEC > 1
      size_t kb0U, KK;
   #else
      #define kb0U kb0
      #define KK K
   #endif
   size_t nmblks, nnblks, nkblks, szA, szB, szC, i, j, k;
   int mb, nb, kb, mu, nu, ku, mr, nr, kr, KB0, flag, appAl;

   pd.alpA = pd.alpB = pd.alpC = ATL_rone;
   appAl = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   pd.mb = mb = mminfo.mb;
   pd.nb = nb = mminfo.nb;
   pd.kb = kb = mminfo.kb;
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   nmblks = M / mb;
   nnblks = N / nb;
   nkblks = K / kb;
   pd.nmu = mb / mu;
   pd.nnu = mb / nu;
   pd.mr = mr = M - nmblks*mb;
   if (mr)
      pd.nmuF = (mr+mu-1)/mu;
   else
      pd.nmuF = pd.nmu;
   pd.nr = nr = N - nnblks*nb;
   if (nr)
      pd.nnuF = (nr+nu-1)/nu;
   else
      pd.nnuF = pd.nnu;
   pd.kr = kr = K - nkblks*kb;
   if (!appAl)
      pd.alpA = alpha;
   else if (appAl == 1)
      pd.alpB = alpha;
   else
      pd.alpC = alpha;
   pd.a2blk = mminfo.a2blk;
   pd.b2blk = mminfo.b2blk;
   pd.blk2c = mminfo.Cblk2cm;
   pd.amm_b0 = mminfo.amm_b0;
   pd.amm_b1 = mminfo.amm_b1;
   if (!kr)
   {
      pd.amm_k1_b0 = mminfo.amm_b0;
      pd.amm_k1_b1 = mminfo.amm_b1;
      KB0 = kb;
   }
/*
 * If last K-block is partial, compute K of gemm (KB0) and K of copy (kr)
 */
   else
   {
/*
 *    K-major require GEMM's K (KB0) to be a mult of ku
 */
      #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KB0 = ((kr+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
         {
            pd.amm_k1_b0 = mminfo.amm_b0;
            pd.amm_k1_b1 = mminfo.amm_b1;
         }
         else
         {
            pd.amm_k1_b0 = mminfo.amm_k1_b0;
            pd.amm_k1_b1 = mminfo.amm_k1_b1;
         }
            
      }
      else
      {
      #endif
         KB0 = kr;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag) && kr == (kr/ku)*ku &&
             kr > mminfo.kbmin)
         {
            pd.amm_k1_b0 = mminfo.amm_b0;
            pd.amm_k1_b1 = mminfo.amm_b1;
         }
         else
         {
            pd.amm_k1_b0 = mminfo.amm_k1_b0;
            pd.amm_k1_b1 = mminfo.amm_k1_b1;
         }
      #if ATL_geAMM_MAXKVEC > 1
      }
      #endif
   }
   pd.mb = mminfo.mb;
   pd.nb = mminfo.nb;
   pd.kb = mminfo.kb;
   pd.mbkb = mminfo.mb * mminfo.kb;
   pd.kbnb = mminfo.kb * mminfo.nb;
   pd.mbnb = mminfo.mb * mminfo.nb;
   pd.lda = lda;
   pd.ldb = ldb;
   pd.ldc = ldc;
   pd.nmu = mminfo.mb / mminfo.mu;
   pd.nnu = mminfo.nb / mminfo.nu;
   pd.beta = beta;
   if (TA == AtlasNoTrans)
   {
      pd.incAm = pd.mb;
      pd.incAk = pd.kb * lda;
   }
   else
   {
      pd.incAm = pd.mb * lda;
      pd.incAk = pd.kb;
   }
   if (TB == AtlasNoTrans)
   {
      pd.incBk = pd.kb;
      pd.incBn = pd.nb * ldb;
   }
   else
   {
      pd.incBk = pd.kb * ldb;
      pd.incBn = pd.nb;
   }
   pd.incCn = nb*ldc;
   pd.incCm = mb;
   pd.KB0 = KB0;
/*
 * Allocate workspace, for now get double amount space required for first
 * recursively divided dimension!
 */
   i = (mr) ? nmblks+1 : nmblks;
   j = (nr) ? nnblks+1 : nnblks;
   k = (kr) ? nkblks+1 : nkblks;
   szA = i*k*pd.mbkb;
   szB = k*j*pd.kbnb;
   szC = i*j*pd.mbnb;
   vp = malloc(ATL_MulBySize(szA+mu + szB+nu + szC+mu*nu) + 3*ATL_Cachelen);
   ATL_assert(vp);
   a = ATL_AlignPtr(vp);
   b = a + szA;
   b = ATL_AlignPtr(b);
   c = b + szB;
   c = ATL_AlignPtr(c);
   flag = (v_cpA | v_cpB | v_cpC | v_nmA | v_nmB | v_nmC | v_lwC);
   if (!(mr|nr|kr))
      ammmRECf(&pd, nmblks, nnblks, nkblks, flag, A, B, C, a, b, c);
   else
   {
      flag |= (mr) ? v_mp : 0;
      flag |= (nr) ? v_np : 0;
      flag |= (kr) ? v_kp : 0;
      ammmREC(&pd, nmblks, nnblks, nkblks, flag, A, B, C, a, b, c);
   }
   free(vp);
}
@ROUT ATL_ammmNMK
#include "atlas_misc.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

int Mjoin(PATL,ammmNMK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   amminfo_t mminfo;
   ATL_INT mb, NB, kb, mu, nu, ku, KRUN;
   #if ATL_geAMM_MAXKVEC > 1
      size_t kb0U, KK;
   #else
      #define kb0U kb0
      #define KK K
   #endif
   size_t nmblks, nnblks, nkblks, mbF, nbF, kb0, nmu, nmuF, MBF, NBF;
   size_t incwA, incAk, incBk, incAk0, incBk0, incAm, incBn, incCn;
   size_t i, j, k, szA, szB, szC, nnu0, nnuF;
   const TYPE *B0 = B;
   TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   TYPE *wA, *wB, *wC, *wA0, *wB0;
   void *vp;
   cm2am_t a2blk, b2blk;
   ablk2cmat_t blk2c;
   ammkern_t amm_b1, amm_b0;
   int appAl;

   appAl = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!appAl)
      alpA = alpha;
   else if (appAl == 1)
      alpB = alpha;
   else
      alpC = alpha;
   mb = mminfo.mb;
   NB = mminfo.nb;
   kb = mminfo.kb;
   KRUN = ATL_AMMFLG_KRUNTIME(mminfo.flag);
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   incwA = mb*kb; 
   nmu = mb / mu;
   amm_b1 = mminfo.amm_b1;
   blk2c = mminfo.Cblk2cm;
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
/*
 * Handle N differently than other dims: since it is outer loop, don't want
 * to peel, so just vary nb inside the main loop.  nnblks therefore includes
 * final block, unlike for M or K.
 */
   if (N >= NB+nu+nu)
   {
      nnblks = N/NB;
      nbF = N - nnblks * NB;
      if (nbF < nu+nu)
         nbF += NB;
      else
         nnblks++;
   }
   else
   {
      nnblks = 1;
      nbF = N;
   }
   nnu0 = NB / nu;
   nnuF = (nbF+nu-1)/nu;
   NBF = nnuF * nu;
/*
 * For M, we must peel the final block to handle any cleanup (can't peel 1st
 * block or we mess up alignment!), so this block is not included in the
 * block count
 */
   if (M >= mb+mu+mu)  /* more than just last block */
   {
      nmblks = M/mb;
      mbF = M - nmblks * mb;
      if (mbF < mu+mu)  /* steal block from main iteration, not enough here! */
      {
         nmblks--;
         mbF += mb;
      }
   }
   else /* put everything in final block */
   {
      mbF = M;
      nmblks = 0;
   }
   nmuF = (mbF+mu-1) / mu;
   MBF = nmuF * mu;
/*
 * For K, we peel the first iteration to set BETA=0, so the nkblks does not
 * include the peeled block
 */
   if (K >= kb)
   {
      nkblks = K/kb;
      kb0 = K - nkblks * kb;
      if (!kb0)
      {
         kb0 = kb;
         nkblks--;
      }
      else
      {
         if (kb0 < 4)
         {
            kb0 += kb;
            nkblks--;
         }
      }
   }
   else /* K < nb */
   {
      kb0 = K;
      nkblks = 0;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KK = ((K+ku-1)/ku)*ku;
         kb0U = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            amm_b0 = mminfo.amm_b0;
         else
            amm_b0 = (mminfo.kb == kb0U) ?  mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
      {
         KK = K;
         kb0U = kb0;
         amm_b0 = (kb0 == mminfo.kb || 
                   (KRUN && kb0 >= mminfo.kbmin && (kb0/ku)*ku == kb0)) ?  
                  mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
   #else
      amm_b0 = (kb0 == mminfo.kb || 
                (KRUN && kb0 >= mminfo.kbmin && (kb0/ku)*ku == kb0)) ?  
               mminfo.amm_b0 : mminfo.amm_k1_b0;
   #endif
   szA = (nmblks*mb+MBF)*KK; /* wrkspc for all of A wt M rounded up to MU*/
   j = Mmax(NB, NBF);
   i = Mmax(MBF, mb);
   szC = i*j;
   szB = KK*j;                     /* workspace for panel of B */

   k = ATL_MulBySize(szA+szB+szC+mu*nu*ku) + 3*ATL_Cachelen;
   if (k > ATL_MaxMalloc)
      return(2);
   vp = malloc(k);
   if (!vp)
      return(1);
   wB0 = wB = ATL_AlignPtr(vp);
   wA = wB + szB;
   wA0 = wA = ATL_AlignPtr(wA);
   wC = wA + szA;
   wC = ATL_AlignPtr(wC);

   if (TA == AtlasNoTrans)
   {
      incAm = mb;
      incAk0 = kb0*lda;
      incAk = kb*lda;
   }
   else
   {
      incAm = mb*lda;
      incAk0 = kb0;
      incAk = kb;
   }
   if (TB == AtlasNoTrans)
   {
      incBk0 = kb0;
      incBk = kb;
      incBn = NB*ldb;
   }
   else
   {
      incBk0 = kb0*ldb;
      incBk = kb*ldb;
      incBn = NB;
   }
   incCn = ldc*NB;

   for (j=0; j < nnblks; j++)
   {
      size_t nb, nbsz, incwB, incwB0, nnu;
      const TYPE *Bn = B+incBn;
      TYPE *Cn = C + incCn;
      if (j != nnblks-1)
      {
         nbsz = nb = NB;
         nnu = nnu0;
      }
      else
      {
         nb = nbF;
         nbsz = NBF;
         nnu = nnuF;
      }
      incwB = nbsz*kb;
      incwB0 = nbsz*kb0U;
/*
 *    Do all M-blocks except final one, which may be of differing size & partial
 */
      for (i=0; i < nmblks; i++)
      {
         TYPE *wAn, *wBn;
         const TYPE *An = A+incAm;
/*
 *       Peel first K it to handle K-cleanup and set BETA=0
 */
         if (!j)
            a2blk(kb0, mb, alpA, A, lda, wA);
         if (!i)
            b2blk(kb0, nb, alpB, B, ldb, wB);
         wAn = wA+mb*kb0U;
         wBn = (nkblks) ? wB+incwB0 : wB;
         amm_b0(nmu, nnu, kb0U, wA, wB, wC, nkblks?wAn:wA, wBn, wC);
         wA = wAn;
         wB = wBn;
         A += incAk0;
         B += incBk0;
/*
 *       If first K-block not the only K-block
 */
         if (nkblks)
         {
            for (k=nkblks-1; k; k--)
            {
               wAn = wA+incwA;
               wBn = wB+incwB;
               if (!j)
                  a2blk(kb, mb, alpA, A, lda, wA);
               if (!i)
                  b2blk(kb, nb, alpB, B, ldb, wB);
               amm_b1(nmu, nnu, kb, wA, wB, wC, wAn, wBn, wC);
               wA = wAn;
               wB = wBn;
               A += incAk;
               B += incBk;
            }
/*
 *          Last K-block peeled to change prefetch pattern
 */
            wAn = wA+incwA;
            if (!j)
               a2blk(kb, mb, alpA, A, lda, wA);
            if (!i)
               b2blk(kb, nb, alpB, B, ldb, wB);
            amm_b1(nmu, nnu, kb, wA, wB, wC, wAn, wB0, wC);
            wA = wAn;
            wB = wB0;
         }
         blk2c(mb, nb, alpC, wC, beta, C, ldc);
         A = An;
         B = B0;
         C += mb;
      }
/*
 *    Do the final peeled M-block, which is of non-constant size mbF
 */
      {
         TYPE *wAn, *wBn;
/*
 *       Peel first K it to handle K-cleanup and set BETA=0
 */
         if (!j)
            a2blk(kb0, mbF, alpA, A, lda, wA);
         if (!i)
            b2blk(kb0, nb, alpB, B, ldb, wB);
         wAn = wA+MBF*kb0U;
         wBn = (nkblks) ? wB+incwB0 : wB;
         amm_b0(nmuF, nnu, kb0U, wA, wB, wC, nkblks?wAn:wA, wBn, wC);
         wA = wAn;
         wB = wBn;
         A += incAk0;
         B += incBk0;
/*
 *       If first K-block not the only K-block
 */
         if (nkblks)
         {
            for (k=nkblks-1; k; k--)
            {
               wAn = wA+MBF*kb;
               wBn = wB+incwB;
               if (!j)
                  a2blk(kb, mbF, alpA, A, lda, wA);
               if (!i)
                  b2blk(kb, nb, alpB, B, ldb, wB);
               amm_b1(nmuF, nnu, kb, wA, wB, wC, wAn, wBn, wC);
               wA += MBF*kb;
               wB = wBn;
               A += incAk;
               B += incBk;
            }
/*
 *          Last K-block peeled to change prefetch pattern
 */
            if (!j)
               a2blk(kb, mbF, alpA, A, lda, wA);
            if (!i)
               b2blk(kb, nb, alpB, B, ldb, wB);
            amm_b1(nmuF, nnu, kb, wA, wB, wC, wA0, wB0, wC);
            wA = wA0;
            wB = wB0;
         }
         blk2c(mbF, nb, alpC, wC, beta, C, ldc);
      }  /* end M-peel */
      wA = wA0;
      B = B0 = Bn;
      C = Cn;
   }
   free(vp);
   return(0);
}
@ROUT ATL_cammmNMK
#include "atlas_misc.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

int Mjoin(PATL,ammmNMK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   amminfo_t mminfo;
   ATL_INT mb, NB, kb, mu, nu, ku, KRUN;
   #if ATL_geAMM_MAXKVEC > 1
      size_t kb0U, KK;
   #else
      #define kb0U kb0
      #define KK K
   #endif
   size_t nmblks, nnblks, nkblks, mbF, nbF, kb0, nmu, nmuF, MBF, NBF;
   size_t incwA, incAk, incBk, incAk0, incBk0, incAm, incBn, incCn;
   size_t i, j, k, szA, szB, szC, nnu0, nnuF;
   const TYPE *B0 = B;
   const TYPE one[2] = {ATL_rone, ATL_rzero};
   const TYPE *alpA=one, *alpB=one, *alpC=one;
   TYPE *wA, *wB, *wC, *rC, *wA0, *wB0;
   void *vp;
   cm2am_t a2blk, b2blk;
   ablk2cmat_t blk2c;
   ammkern_t amm_b1, amm_b0, amm_bn, amm_b1K, amm_bnK;
   int appAl;

   appAl = Mjoin(PATL,GetAmmmInfo)(&mminfo, TA, TB, M, N, K, alpha, beta);
   if (!appAl)
      alpA = alpha;
   else if (appAl == 1)
      alpB = alpha;
   else
      alpC = alpha;
   mb = mminfo.mb;
   NB = mminfo.nb;
   kb = mminfo.kb;
   KRUN = ATL_AMMFLG_KRUNTIME(mminfo.flag);
   mu = mminfo.mu;
   nu = mminfo.nu;
   ku = mminfo.ku;
   incwA = mb*kb; 
   nmu = mb / mu;
   amm_b1 = mminfo.amm_b1;
   amm_bn = mminfo.amm_bn;
   blk2c = mminfo.Cblk2cm;
   a2blk = mminfo.a2blk;
   b2blk = mminfo.b2blk;
/*
 * Handle N differently than other dims: since it is outer loop, don't want
 * to peel, so just vary nb inside the main loop.  nnblks therefore includes
 * final block, unlike for M or K.
 */
   if (N >= NB+nu+nu)
   {
      nnblks = N/NB;
      nbF = N - nnblks * NB;
      if (nbF < nu+nu)
         nbF += NB;
      else
         nnblks++;
   }
   else
   {
      nnblks = 1;
      nbF = N;
   }
   nnu0 = NB / nu;
   nnuF = (nbF+nu-1)/nu;
   NBF = nnuF * nu;
/*
 * For M, we must peel the final block to handle any cleanup (can't peel 1st
 * block or we mess up alignment!), so this block is not included in the
 * block count
 */
   if (M >= mb+mu+mu)  /* more than just last block */
   {
      nmblks = M/mb;
      mbF = M - nmblks * mb;
      if (mbF < mu+mu)  /* steal block from main iteration, not enough here! */
      {
         nmblks--;
         mbF += mb;
      }
   }
   else /* put everything in final block */
   {
      mbF = M;
      nmblks = 0;
   }
   nmuF = (mbF+mu-1) / mu;
   MBF = nmuF * mu;
/*
 * For K, we peel the first iteration to set BETA=0, so the nkblks does not
 * include the peeled block
 */
   if (K >= kb)
   {
      nkblks = K/kb;
      kb0 = K - nkblks * kb;
      if (!kb0)
      {
         kb0 = kb;
         nkblks--;
      }
      else
      {
         if (kb0 < 4)
         {
            kb0 += kb;
            nkblks--;
         }
      }
   }
   else /* K < nb */
   {
      kb0 = K;
      nkblks = 0;
   }
   #if ATL_geAMM_MAXKVEC > 1
      if (ATL_AMMFLG_KMAJOR(mminfo.flag))
      {
         KK = ((K+ku-1)/ku)*ku;
         kb0U = ((kb0+ku-1)/ku)*ku;
         if (ATL_AMMFLG_KRUNTIME(mminfo.flag))
            amm_b0 = mminfo.amm_b0;
         else
            amm_b0 = (mminfo.kb == kb0U) ?  mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
      else
      {
         KK = K;
         kb0U = kb0;
         amm_b0 = (kb0 == mminfo.kb || 
                   (KRUN && kb0 >= mminfo.kbmin && (kb0/ku)*ku == kb0)) ?  
                  mminfo.amm_b0 : mminfo.amm_k1_b0;
      }
   #else
      amm_b0 = (kb0 == mminfo.kb || 
                (KRUN && kb0 >= mminfo.kbmin && (kb0/ku)*ku == kb0)) ?  
               mminfo.amm_b0 : mminfo.amm_k1_b0;
   #endif
   if (amm_b0 == mminfo.amm_b0)
   {
      amm_b1K = amm_b1;
      amm_bnK = amm_bn;
   }
   else
   {
      amm_b1K = mminfo.amm_k1_b1;
      amm_bnK = mminfo.amm_k1_bn;
   }
   szA = (nmblks*mb+MBF)*KK; /* wrkspc for all of A wt M rounded up to MU*/
   j = Mmax(NB, NBF);
   i = Mmax(MBF, mb);
   szC = i*j;
   szB = KK*j;                     /* workspace for panel of B */

   k = ATL_MulBySize(szA+szB+szC+mu*nu*ku) + 3*ATL_Cachelen;
   if (k > ATL_MaxMalloc)
      return(2);
   vp = malloc(k);
   if (!vp)
      return(1);
   wB0 = wB = ATL_AlignPtr(vp);
   wA = wB + szB + szB;
   wA0 = wA = ATL_AlignPtr(wA);
   wC = wA + szA + szA;
   wC = ATL_AlignPtr(wC);
   rC = wC + szC;

   if (TA == AtlasNoTrans)
   {
      incAm = mb SHIFT;
      incAk0 = kb0*lda SHIFT;
      incAk = kb*lda SHIFT;
   }
   else
   {
      incAm = mb*lda SHIFT;
      incAk0 = kb0 SHIFT;
      incAk = kb SHIFT;
   }
   if (TB == AtlasNoTrans)
   {
      incBk0 = kb0 SHIFT;
      incBk = kb SHIFT;
      incBn = NB*ldb SHIFT;
   }
   else
   {
      incBk0 = kb0*ldb SHIFT;
      incBk = kb*ldb SHIFT;
      incBn = NB SHIFT;
   }
   incCn = ldc*NB SHIFT;

   for (j=0; j < nnblks; j++)
   {
      size_t nb, nbsz, incwB, incwB0, nnu;
      const TYPE *Bn = B+incBn;
      TYPE *Cn = C + incCn;
      if (j != nnblks-1)
      {
         nbsz = nb = NB;
         nnu = nnu0;
      }
      else
      {
         nb = nbF;
         nbsz = NBF;
         nnu = nnuF;
      }
      incwB = nbsz*kb;
      incwB0 = nbsz*kb0U;
/*
 *    Do all M-blocks except final one, which may be of differing size & partial
 */
      for (i=0; i < nmblks; i++)
      {
         TYPE *wAn, *wBn;
         const TYPE *An = A+incAm;
/*
 *       Peel first K it to handle K-cleanup and set BETA=0
 */
         wAn = wA+mb*kb0U;
         wBn = wB+incwB0;
         if (!j)
            a2blk(kb0, mb, alpA, A, lda, wAn, wA);
         if (!i)
            b2blk(kb0, nb, alpB, B, ldb, wBn, wB);
         amm_b0(nmu, nnu, kb0U, wA, wB, rC, wAn, wB, wC);
         amm_b0(nmu, nnu, kb0U, wAn, wB, wC, wAn, wBn, rC);
         amm_bnK(nmu, nnu, kb0U, wAn, wBn, rC, wA, wBn, wC);
         wB = wBn+incwB0;
         wAn += mb*kb0U;
         amm_b1K(nmu, nnu, kb0U, wA, wBn, wC, wAn, wB, rC);
         wA = wAn;
         A += incAk0;
         B += incBk0;
/*
 *       If first K-block not the only K-block
 */
         if (nkblks)
         {
            for (k=nkblks-1; k; k--)
            {
               wAn = wA+incwA;
               wBn = wB+incwB;
               if (!j)
                  a2blk(kb, mb, alpA, A, lda, wAn, wA);
               if (!i)
                  b2blk(kb, nb, alpB, B, ldb, wBn, wB);
               amm_bn(nmu, nnu, kb, wA, wB, rC, wAn, wB, wC);
               amm_b1(nmu, nnu, kb, wAn, wB, wC, wAn, wBn, rC);
               amm_bn(nmu, nnu, kb, wAn, wBn, rC, wAn, wB, wC);
               wAn += incwA;
               wB = wBn + incwB;
               amm_b1(nmu, nnu, kb, wA, wBn, wC, wAn, wB, rC);
               wA = wAn;
               A += incAk;
               B += incBk;
            }
/*
 *          Last K-block peeled to change prefetch pattern
 */
            wAn = wA+incwA;
            wBn = wB+incwB;
            if (!j)
               a2blk(kb, mb, alpA, A, lda, wAn, wA);
            if (!i)
               b2blk(kb, nb, alpB, B, ldb, wBn, wB);
            amm_bn(nmu, nnu, kb, wA, wB, rC, wAn, wB, wC);
            amm_b1(nmu, nnu, kb, wAn, wB, wC, wAn, wBn, rC);
            amm_bn(nmu, nnu, kb, wAn, wBn, rC, wAn, wB, wC);
            wAn += incwA;
            amm_b1(nmu, nnu, kb, wA, wBn, wC, wAn, wB0, rC);
            wA = wAn;
            wB = wB0;
         }
         blk2c(mb, nb, alpC, rC, wC, beta, C, ldc);
         A = An;
         B = B0;
         wB = wB0;
         C += mb+mb;
      }
/*
 *    Do the final peeled M-block, which is of non-constant size mbF
 */
      {
         TYPE *wAn, *wBn;
/*
 *       Peel first K it to handle K-cleanup and set BETA=0
 */
         wAn = wA+MBF*kb0U;
         wBn = wB+incwB0;
         if (!j)
            a2blk(kb0, mbF, alpA, A, lda, wAn, wA);
         if (!i)
            b2blk(kb0, nb, alpB, B, ldb, wBn, wB);
         amm_b0(nmuF, nnu, kb0U, wA, wB, rC, wAn, wB, wC);
         amm_b0(nmuF, nnu, kb0U, wAn, wB, wC, wAn, wBn, rC);
         amm_bnK(nmuF, nnu, kb0U, wAn, wBn, rC, wAn, wB, wC);
         wAn += MBF*kb0U;
         wB = wBn + incwB0;
         amm_b1K(nmuF, nnu, kb0U, wA, wBn, wC, nkblks?wAn:wA, wB, rC);
         wA = wAn;
         A += incAk0;
         B += incBk0;
/*
 *       If first K-block not the only K-block
 */
         if (nkblks)
         {
            for (k=nkblks-1; k; k--)
            {
               wAn = wA+MBF*kb;
               wBn = wB+incwB;
               if (!j)
                  a2blk(kb, mbF, alpA, A, lda, wAn, wA);
               if (!i)
                  b2blk(kb, nb, alpB, B, ldb, wBn, wB);
               amm_bn(nmuF, nnu, kb, wA, wB, rC, wAn, wB, wC);
               amm_b1(nmuF, nnu, kb, wAn, wB, wC, wAn, wBn, rC);
               amm_bn(nmuF, nnu, kb, wAn, wBn, rC, wAn, wB, wC);
               wAn += MBF*kb;
               wB = wBn + incwB;
               amm_b1(nmuF, nnu, kb, wA, wBn, wC, wAn, wB, rC);
               wA = wAn;
               A += incAk;
               B += incBk;
            }
/*
 *          Last K-block peeled to change prefetch pattern
 */
            wAn = wA+MBF*kb;
            wBn = wB+incwB;
            if (!j)
               a2blk(kb, mbF, alpA, A, lda, wAn, wA);
            if (!i)
               b2blk(kb, nb, alpB, B, ldb, wBn, wB);
            amm_bn(nmuF, nnu, kb, wA, wB, rC, wAn, wB, wC);
            amm_b1(nmuF, nnu, kb, wAn, wB, wC, wAn, wBn, rC);
            amm_bn(nmuF, nnu, kb, wAn, wBn, rC, wAn, wB, wC);
            amm_b1(nmuF, nnu, kb, wA, wBn, wC, wA0, wB0, rC);
            wA = wA0;
            wB = wB0;
         }
         blk2c(mbF, nb, alpC, rC, wC, beta, C, ldc);
      }  /* end M-peel */
      wA = wA0;
      wB = wB0;
      B = B0 = Bn;
      C = Cn;
   }
   free(vp);
   return(0);
}
@ROUT peaktim
#include "atlas_misc.h"
#include <assert.h>

void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -n <spclen>: workspace to pass\n");
   fprintf(stderr, "   -I <its> : iterations to pass\n");
   fprintf(stderr, "   -# <ntimes> : set # of times to time kernel\n");
   exit(ierr ? ierr : -1);
}
size_t GetFlags(int nargs, char **args, size_t *N, int *NREP)
{
   size_t nits = 10000;
   int i;

   *N = 128;
   *NREP = 3;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);
      switch(args[i][1])
      {
      case 'I':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         nits = atoll(args[i]);
         break;
      case 'n':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *N = atoll(args[i]);
         break;
      case '#':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *NREP = atoi(args[i]);
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   return(nits);
}

double ATL_walltime(void);
void RunKern(size_t nits, void *vp);

int main (int nargs, char **args)
{
   size_t n, nits, i, ifl;
   double t0, mf, mfB;
   void *vp;
   char *cp;
   size_t *lp;
   int nrep;

   nits = GetFlags(nargs, args, &n, &nrep);
   vp = malloc(n+32);
   cp = ATL_AlignPtr(vp);
   lp = (size_t*)cp;
   for (i=0; i < n; i++)
      cp[i] = 0;

   mfB=0;
   for (i=0; i < nrep; i++)
   {
      t0 = ATL_walltime();
      RunKern(nits, (void*)cp);
      t0 = ATL_walltime() - t0;
      ifl = lp[0];
      mf = (((double)ifl)*nits) / (t0 * 1.0e6);
      if (mf > mfB)
         mfB = mf;
      printf("MFLOPS=%.2f\n", mf);
   }
   printf("\nBEST = %.2f\n\n", mfB);

   free(vp);
   return(0);
}
@ROUT cm2amtst
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
#include <string.h>
#include "atlas_misc.h"

void cm2am_tst
(
   ATL_CSZT K,          /* number of rows in A */
   ATL_CSZT N,          /* number of columns in A */
   const SCALAR alpha,  /* scalar for A */
   const TYPE *A,       /* matrix to be copied to access-major format */
   ATL_CSZT lda,        /* stride between row elements */
   TYPE *pA,            /* OUTPUT: access-major block holding real(A) */
   int nu
)
{
   ATL_CINT nfblks = (N/nu), NNU=nfblks*nu, nr = N-NNU;
   for (j=0; j < NNU; j += nu)
   {
      for (k=0; k < k++)
      {
         for (i=0; i < nu; i++)
            *pA++ = A[(j+i)*lda+k]
      }
   }
   for (; j < N; j++)
   {
      for (k=0; k < k++)
      {
         for (i=0; i < nr; i++)
            *pA++ = A[(j+i)*lda+k]
         for (; i < nu; i++)
            *pA++ = ATL_rzero;
      }
   }
}

void InitEntryArray(int M, int N, TYPE *A, int lda)
{
   int i, j;
   for (j=0; j < N; j++)
   {
      for (i=0; i < lda; i++)
         A[i] = lda*j+i;
   }
   
}

main(int nargs, char **args)
{
   int M=12, N=10, lda=14, align=16, maxalign=32, mu=5, k, ierr=0;
   TYPE *A, *pA0, *pA1;
   TYPE alpha = 1.0;
   A = malloc(((2*M+lda)*N + 2*maxalign);
   assert(A);
   pA0 = A + lda*N;
   pA1 = pA0 + M*N;
   assert(maxalign > align);
   pA1 = (TYPE*)((((size_t)pA1)+maxalign-1)/maxalign)*maxalign;
   if (align)
      pA1 = (TYPE*)((size_t)pA1 + align);
   cm2am_tst(N, M, alpha, A, lda, pA0, mu);
   ATL_UCM2AM(N, M, alpha, A, lda, pA1);
   for (k=0; k < M*N; k++)
   {
      if (pA0[i] != pA1[i])
      {
         int i, j, jmu;
         jmu = k / (M*mu);
         j = k - (jmu*M*mu);
         i = j / mu;
         j = j % mu;
         if (pA0[i] != alpha*A[j*lda+i])
         {
            printf(
               "TEST COPY OR INDEX CALC WRONG: pA0[%d] != A[%d,%d] (%g, %g)\n"
                   k, i, j, pA0[i] != A[j*lda+i]);
            return(k+1);
         }
         printf("pA[%d] ([%d,%d] of matrix): expected=%g (%g), got=%g\n",
                i, i, j, pA0[i], A[j*lda+i], pA1[i]);
         ierr++;
      }
   }
   if (!ierr)
      printf("PASSED.\n");
   else
      printf("FAILED: %d\n", ierr);
   return(ierr);
}

@ROUT ATL_GetAmmAlg.c
#include "atlas_amm.h"
#include Mstr(Mjoin(ATLAS_PRE,geamm_blk.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_ablk2cmat.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_aX.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,geamm_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_kern.h))

void GetAmmNMKDetails
(
/*
 * Input parameters describing problem; for now, don't use A/B/C, but might
 * be important to find aliasing later!
 */
   const enum ATLAS_TRANS TA,
   const enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   const TYPE *C,
   ATL_CSZT ldc
/*
 * Output params
 */
   ATL_SZT *mb, ATL_SZT *nb, ATL_SZT *kb,
   int *mu, int *nu, int *ku,
   ammkern_t *amm_b0, ammkern_t *amm_b1, ammkern_t *amm_bn, 
   cm2am_t *a2blk, *b2blk, ablk2cmat_t *blk2c
)
{

   if (SCALAR_IS_ONE(alpha))
   {
      if (SCALAR_IS_ONE(beta))
         *blk2c = ATL_AMM_BLK2C_a1_b1[IK];
      else if (SCALAR_IS_NONE(beta))
         *blk2c = ATL_AMM_BLK2C_a1_bn[IK];
      else if (SCALAR_IS_ZERO(beta))
         *blk2c = ATL_AMM_BLK2C_a1_b0[IK];
      else
         *blk2c = ATL_AMM_BLK2C_a1_bX[IK];
   }
   else if (alpha == ATL_rnone)
   {
      if (SCALAR_IS_ONE(beta))
         *blk2c = ATL_AMM_BLK2C_an_b1[IK];
      else if (SCALAR_IS_NONE(beta))
         *blk2c = ATL_AMM_BLK2C_an_bn[IK];
      else if (SCALAR_IS_ZERO(beta))
         *blk2c = ATL_AMM_BLK2C_an_b0[IK];
      else
         *blk2c = ATL_AMM_BLK2C_an_bX[IK];
   }
   else
   {
      if (beta == ATL_rone)
         *blk2c = ATL_AMM_BLK2C_aX_b1[IK];
      else if (beta == ATL_rnone)
         *blk2c = ATL_AMM_BLK2C_aX_bn[IK];
      else if (beta == ATL_rzero)
         *blk2c = ATL_AMM_BLK2C_aX_b0[IK];
      else
         *blk2c = ATL_AMM_BLK2C_aX_bX[IK];
   }
}
enum ATL_AMMALG ATL_GetAmmAlg
(
   const enum ATLAS_TRANS TA,
   const enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   const TYPE *C,
   ATL_CSZT ldc
{
   enum ATL_AMMALG ret=ATL_NMK;

   if (M <= ATL_geAMM_LASTMB && N <= ATL_geAMM_LASTNB && K <= ATL_geAMM_LASTKB)
      ret = ATL_amm1b;
   else if (K <= ATL_rkAMM_LASTKB)  /* must create this! */
      ret = ATL_ammrkK;
   return(ret);
}
@ROUT genMM
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <assert.h>
enum VECEXT {VEC_None=0, VEC_VSX, VEC_AV, VEC_AVXMAC, VEC_AVXFMA4, VEC_AVX, 
             VEC_SSE3, VEC_SSE2, VEC_SSE1}
typedef enum VECEXT vec_t;
enum STRG {bcastB=0, kmaj};
typedef enum STRG strg_t;

char *typ = "double", *vtyp, *bcast, *mul, *add, *sub, *vld, *vst;
int VLEN, CL;
strg_t STRG=bcastB;

int GetVeclen(char pre, vec_t vec)
{
   int vlen;
   switch(vec)
   {
   case VEC_AVXMAC:
   case VEC_AVXFMA4:
   case VEC_AVX:
      vlen = 8;
      break;
   case VEC_VSX:
   case VEC_AV:
   case VEC_SSE3:
   case VEC_SSE2:
   case VEC_SSE1:
      vlen = 4;
      break;
   default:
      vlen = 1;
   }
   if (pre == 'd' && vlen > 1)
      vlen >>= 1;
}
void SetVecInfo(char pre, vec_t vec)
{
   VLEN = GetVeclen(pre, vec);
   if (pre == 'd')
   {
      switch(vec)
      {
      case VEC_AVXMAC:
      case VEC_AVXFMA4:
      case VEC_AVX:
         vtyp = "__m256d";
         bcast = "_mm256_broadcast_sd";
         mul = "_mm256_mul_pd";
         add = "_mm256_add_pd";
         sub = "_mm256_sub_pd";
         vld = "_mm256_load_pd";
         vst = "_mm256_store_pd";
         vlen = 4;
         break;
      case VEC_VSX:
      case VEC_AV:
      case VEC_SSE3:
      case VEC_SSE2:
      case VEC_SSE1:
         vlen = 4;
         break;
      default:
         vlen = 1;
      }
   }
   else
   {
   }
}
void PrintDecl(FILE *fp)
{
   fprintf(fp, "void ATL_USERMM(ATL_CSZT nmus, ATL_CSZT nnus, ATL_CSZT K,\n");
   fprintf(fp, "                const %s *pA, const %s *pB, %s *pC,\n",
           typ, typ, typ);
   fprintf(fp, "                const %s *pAn, const %s *pBn, const %s *pCn)\n",
           typ, typ, typ);
}
void DoKloop(FILE *fp, char pre, vec_t vec, int kmaj, int kb, 
             int mu, int nu, int ku)
{
   if (kmaj)
   {
      assert(kmaj == VLEN)
      assert(ku%kmaj == 0);
   }
   if (kb)
   {
      assert(kb%ku == 0);
      if (kb > ku)
         fprintf(fp, "      for (k=%d; k < %d; k += %d\n", ku, kb, ku);
   }
   else
      fprintf(fp, "      for (k=%d; k < K; k += %d\n", ku, ku);
   fprintf(fp,    "      {\n");
   fprintf(fp,    "      } /* end of K-loop */ \n");
}
void genMM(FILE *fp, char pre, vec_t vec, int kmaj, int kb, 
           int mu, int nu, int ku)
{
   int i, j;
   int incb = (kmaj) ? kmaj : 1;
   int ia=0, ib=0;
   char *Bld = (kmaj) ? "vld" : "bcast";

   if (kb && ku+ku >= kb)
      ku = kb;
   else
      ku = 0;

   fprintf(fp, "#include <atlas_simd.h>\n\n");
   PrintDecl(fp);
   fprintf(fp, "/*\n");
   fprintf(fp, 
" * Access-major matmul with: pre=%c, KMAJ=%d, kb=%d, mu=%d, nu=%d\n",
           pre, kmaj, kb, mu, nu);
   fprintf(fp, " */\n");
   fprintf(fp, "{\n");
   fprintf(fp, "   size_t i, j, k, incPF\n");
   if (kb)
      fprintf(fp, "   #define incA %d\n", mu*kb);
   else
      fprintf(fp, "   const size_t incA = K*%d\n", mu);
   fprintf(fp, "   const %s *pB0=pB;\n", typ);
   fprintf(fp, "   register ATL_VTYP rA0");
   for (j=1; j < nu; j++)
      fprintf(fp, ", rA%d", j);
   fprintf(fp, ";\n");
   fprintf(fp, "   register ATL_VTYP rB0");
   for (j=1; j < mu; j++)
      fprintf(fp, ", rB%d", j);
   fprintf(fp, ";\n");
   fprintf(fp, "   register ATL_VTYP rC0_0");
   for (j=0; j < nu; j++)
      for (i=0; i < mu; i++)
         if (i | j)
            fprintf(fp, ", rC%d_%d", i, j);
   fprintf(fp, ";\n");
   fprintf(fp, "\n");
   fprintf(fp, "   for (i=0; i < nmus; i++, pA += incA)\n   {\n");
   fprintf(fp, "      const %s *a=pA;\n");
   fprintf(fp, "      for (j=0; j < nnus; j++)\n      {\n");
/*
 * Rewrite to peel X its in order to schedule loads & prefetches, then
 * start loop; will have specialized routines for each case
 */
   fprintf(fp, "/*\n *         K=0 it peeled to zero rCx_x\n */\n");
   for (j=0; j < nu; j++)
      fprintf(fp, "         ATL_v%s(rB%d, pB+%d);\n", Bld, j, j*incb);
   if (!ku)
      fprintf(fp, "         pB += %d;\n", nu*incb);
   else 
      ib += nu*incb;
   for (i=0; i < mu; i++)
      fprintf(fp, "         ATL_vld(rA%d, a+%d);\n", i, i*VLEN);
   if (!ku)
      fprintf(fp, "         pA += %d;\n", VLEN*mu);
   else 
      ia += VLEN*mu;

   for (j=0; j < nu; j++)
   {
      for (i=0; i < mu; i++)
      {
         fprintf(fp, "         ATL_vmul(rC%d_%d, rA%d, rB%d);\n",
                 i, j, i, j);
         if (j==nu-1)
            fprintf(fp, "         ATL_vld(rA%d, a+%d);\n", i, ia+i*VLEN);
      }
      if (j != nu-1)
         fprintf(fp, "         ATL_v%s(rB%d, pB+%d);\n", Bld, j, ib+j*incb);
   }
   if (kb && ku+ku > kb) /* fully unrolled K loop */
   {
      fprintf(fp, "         ATL_v%s(rB0, pB+%d);\n", Bld, nu*incb);
      for (k=VLEN; k < kb; k += VLEN)
      {
         fprintf(fp, "/*\n *         K=%d iteration\n */\n");
      }
   }
   else
   {
      if (kmaj)
      {
         if (kb)
            fprintf(fp, "         for (k=%d; k < %d; k += %d)\n         {\n",
                    VLEN, kb, VLEN);
         else
            fprintf(fp, "         for (k=%d; k < K; k += %d)\n         {\n",
                    VLEN, VLEN);
      }
      else
      {
         fprintf(fp, "         for (k=1; k < K; k++)\n         {\n");
      }
      fprintf(fp, "         }  /* end K-loop */\n");
   }
   fprintf(fp, "         a += %d;\n", mu*VLEN);
   fprintf(fp, "         pB += %d;\n", nu*incb);

   fprintf(fp, "      } /* end j-loop */\n");
   fprintf(fp, "      pB = pB0;\n");
   fprintf(fp, "   } /* end i-loop */\n");

   
   fprintf(fp, "}\n");
   if (kb)
      fprintf(fp, "#undef incA\n");
}
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr, 
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -p [s,d,c,z]: set type/precision prefix (d) \n");
   fprintf(stderr, "   -o <outfile>: path & file to generate\n");
   fprintf(stderr, "   -U[m,n,k]: set unrolling factor\n");
   fprintf(stderr, "   -V [sse1,sse2,sse3,avx,fma3,fma4,ppcav,vsx]\n");
   fprintf(stderr, "   -K # : non-zero number is fixed K loop\n");
   fprintf(stderr, "   -S [B,K]: storage bcastB/KU-major\n");
}

FILE *GetFlags(char *PRE, vec_t *VEC, int *KMAJ, int *KB, 
               int *MU, int *NU, int *KU)
{
   FILE *fpout=stdout;
   *PRE = 'd';
   *VEC = VEC_SSE3;
   *KMAJ = *KB = 0;
   *MU = *NU = 3;
   *KU = 1;
}
int main(int nargs, char **args)
{
   char pre='d';
   int mu, nu, ku, kb;
   FILE *fpout;
   vec_t vec;
   
   fpout = GetFlags(&pre, &vec, &kb, &kmaj, &mu, &nu, &ku);
   if (pre == 's')
      typ = "float";
   genMM(pre, vec, kmaj, kb, mu, nu, ku);
}
@ROUT ATL_GetRankKInfo
#define ATL_NOAMM 1
#include "atlas_misc.h"
#undef ATL_NOAMM
#include Mstr(Mjoin(ATLAS_PRE,rkamm_kern.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_blk.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,rkamm_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_perf.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_cm2am_aX.h))
#include Mstr(Mjoin(ATLAS_PRE,rkamm_ablk2cmat.h))
@ROUT ATL_GetAmmmInfoSQ
#include "atlas_misc.h"
#include Mstr(Mjoin(ATLAS_PRE,sqamm_blk.h))
#include Mstr(Mjoin(ATLAS_PRE,sqamm_ablk2cmat.h))
#include Mstr(Mjoin(ATLAS_PRE,sqamm_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,sqamm_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,sqamm_cm2am_aX.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,sqamm_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,sqamm_kern.h))
#include Mstr(Mjoin(ATLAS_PRE,sqamm_perf.h))
#include Mstr(Mjoin(ATLAS_PRE,skamm_perf.h))

#ifdef ATL_CAMM_MAXINDX
   #define ATL_MAXIDX ATL_CAMM_MAXINDX
#elif defined(ATL_sqAMM_98IDX) && !defined(ATL_sqAMM_66IDX)
   #define ATL_MAXIDX ATL_sqAMM_98IDX
#endif
#ifndef ATL_MAXIDX
   #define ATL_MAXIDX ATL_sqAMM_NCASES-1
#endif

static INLINE void FillInInfo(amminfo_t *out, int id)
{
   out->IDX = id;
   out->nb = out->kb = out->mb = ATL_AMM_KBs[id];
   out->mu = ATL_AMM_MUs[id];
   out->nu = ATL_AMM_NUs[id];
   out->ku = ATL_AMM_KUs[id];
   out->kbmin = ATL_AMM_KBMINs[id];
   out->kbmax = ATL_AMM_KBMAXs[id];
   out->vlen = ATL_AMM_VLENs[id];
   out->flag = ATL_AMM_KFLAG[id];
   out->amm_b0 = ATL_AMM_KERN_b0[id];
   out->amm_b1 = ATL_AMM_KERN_b1[id];
   out->amm_bn = ATL_AMM_KERN_bn[id];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[id];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[id];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[id];
}

@ROUT ATL_GetAmmmInfo
#include "atlas_misc.h"
#include Mstr(Mjoin(ATLAS_PRE,geamm_blk.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_ablk2cmat.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_aX.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,geamm_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_kern.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_perf.h))

@ROUT ATL_GetAmmmInfo  ATL_GetAmmmInfoSQ ATL_GetRankKInfo
static INLINE ablk2cmat_t GetBlk2C(int id, int ialp, int ibet)
{
   if (ialp == 1)
   {
      if (ibet == 1)
         return(ATL_AMM_BLK2C_a1_b1[id]);
      else if (!ibet)
         return(ATL_AMM_BLK2C_a1_b0[id]);
      else if (ibet == -1)
         return(ATL_AMM_BLK2C_a1_bn[id]);
      return(ATL_AMM_BLK2C_a1_bX[id]);
   }
   else if (ialp == -1)
   {
      if (ibet == 1)
         return(ATL_AMM_BLK2C_an_b1[id]);
      else if (!ibet)
         return(ATL_AMM_BLK2C_an_b0[id]);
      else if (ibet == -1)
         return(ATL_AMM_BLK2C_an_bn[id]);
      return(ATL_AMM_BLK2C_an_bX[id]);
   }
   else
   {
      if (ibet == 1)
         return(ATL_AMM_BLK2C_aX_b1[id]);
      else if (!ibet)
         return(ATL_AMM_BLK2C_aX_b0[id]);
      else if (ibet == -1)
         return(ATL_AMM_BLK2C_aX_bn[id]);
      return(ATL_AMM_BLK2C_aX_bX[id]);
   }
}
@ROUT ATL_GetAmmmInfoSQ

#define SyrkTime Mjoin(PATL,sSyrkTimeEst)
double SyrkTime(int id, unsigned int flg, size_t N, size_t K, double symul)
{
   double tot, kfrac;
   size_t nfnblks, nondiag, nfkblks;
   unsigned int nb, kr;

   if (symul > 1.0)  /* <=1.0 means using GEMM for diag blks, not SYRK */
      symul *= 0.5;  /* syrk does half as many flops */
   nb = ATL_AMM_KBs[id];
   nfkblks = K / nb;
   kr = K - nfkblks*nb;
   kfrac = (double)kr / (double)nb;
   nfnblks = N/nb;
   nondiag = (((nfnblks+1)*nfnblks)>>1) - nfnblks;
/*
 * Find total time to compute full GEMM & SYRK blocks
 */
   tot = nondiag * ATL_sqAMM_TIME[id] * (nfkblks + kfrac/ATL_sqAMM_K1RATIO[id]);
   tot += symul * nfnblks * ATL_skAMM_TIME[id] * (nfkblks + kfrac);
   kr = N - nfnblks*nb;
   if (kr)  /* have partial GEMM panel & SYRK block */
   {
      size_t nkb, nnb;
      int i;
      double pen;
      const unsigned int U = (flg) ? ATL_AMM_NUs[id] :ATL_AMM_MUs[id];
      const unsigned int NR = ((kr+U-1)/U)*U;
/*
 *    pen: penalty for doing useless flops
 */
      pen = (double)NR / (double)kr;
      pen *= pen;
/*
 *    Try to find similar size to estimate speed for cleanup dim
 */
      for (i=0; i < ATL_sqAMM_NCASES-1 && ATL_AMM_KBs[i] < NR; i++);
      if (i && ATL_AMM_KBs[i] > NR)
         i--;
      nb = ATL_AMM_KBs[i];
      nkb = (K+nb-1) / nb;
      nnb = (N+nb-1) / nb;
      tot += symul*nkb*ATL_skAMM_TIME[i]; /* SYRK cleanup */
      tot += nkb*pen*nnb*ATL_sqAMM_TIME[i];
   }

#if 0
printf("   D%03d=(%d,%d:%d), time=%e, mf=%.0f\n", 
       id, N, K, nb, tot, 1.0e-6*N*N*K / tot);
#endif
   return(tot);
}

int Mjoin(PATL,GetSyrkIdx) /* returns square amm index to use */
(
   unsigned int flg,     /* bit 0 set: Upper, else Lower */
   ATL_CSZT N,           /* size of triangular matrix */
   ATL_CSZT K,           /* K dim of A/A^T */
   double symul         /* <= 1: use gemm, else syrk/gemm speed (>1) */
@skip   int *NB               /* OUTPUT: suggested nb */
)
{
   double timB;
   int i, iB=0;

   #if 0
   if (K >=  ATL_pmnAMM_MAXKB)
   {
      int *ip = ATL_AMM_NBs;
      if (N >= ATL_pmnAMM_MAXNB)
      for (i=0; i < ATL_pmnAMM_NCASES && ip[i] < N; i++)
   }
   #endif
   timB = SyrkTime(0, flg, N, K, symul);
   for (i=1; i < ATL_sqAMM_NCASES; i++)
   {
      double tim;
      if (ATL_AMM_KBs[i] > K)
         break;
      tim = SyrkTime(i, flg, N, K, symul);
      if (tim < timB)
      {
         timB = tim;
         iB = i;
      }
   }
/*   printf("IDX=%d, NB=%d, tim=%e, mf=%.0f\n", iB, ATL_AMM_KBs[iB], timB, 1.0e-6*N*N*K / timB);  */
   return(iB);
}

int Mjoin(PATL,GetSyrkInfo)  /* returns nb */
(
   amminfo_t *out,
   int ialp,             /* 1:alpha=1.0, -1:-1.0, else alpha=X */
   enum ATLAS_TRANS TA,
   ATL_CSZT N,           /* size of triangular matrix */
   ATL_CSZT K,           /* K dim of A/A^T */
   int ibet              /* 0:beta=0.0 1:beta=1.0, -1:-1.0, else beta=X */
)
{
   int id=0, nb, ibest=0;
   double timB = ((double)N)*N*K*ATL_sqAMM_TIME[0];
   for (id=0; id < ATL_sqAMM_NCASES; id++)
   {
      double tim;
      const int nb=ATL_AMM_KBs[id];
      ATL_SZT ndiag, ncblks;
      ATL_CSZT nnblks=N/nb, nkblks=K/nb;
      const int nr=N-nnblks*nb, kr=K-nkblks*nb;
      if (nb+nb > K)
         break;
      tim = nkblks*ATL_sqAMM_TIME[id];
      if (kr)
      {
         int i;
         double d;
         for (i=id; i > 0; i--)         /* find kb closest to kr to */
            if (ATL_AMM_KBs[i] <= kr)   /* estimate K-clean speed */
               break;
         d = nb;
         d /= (double)ATL_AMM_KBs[i];
         tim += d*ATL_sqAMM_TIME[i]*d*d;
      }
      ndiag = (nr) ? nnblks+1 : nnblks;
      ncblks = ((ndiag-1)*ndiag)>>1;
      tim *= (ndiag+ncblks);
      if (tim < timB)
      {
         timB = tim;
         ibest = id;
      }
   }
   id = ibest;

   FillInInfo(out, id);
// printf("IDX=%d, B=%d, U=(%d,%d,%d)\n", id, out->nb, out->mu,out->nu,out->ku);
   nb = out->nb;
   out->Cblk2cm = GetBlk2C(id, 1, ibet);
   out->Cblk2cm_b1 = ATL_AMM_BLK2C_a1_b0[id]; /* _b1 is really _b0 for SYRK! */
   if (TA == AtlasNoTrans)
   {
      out->a2blk = ATL_AMM_AT2BLK_a1[id];
      if (ialp == 1)
         out->b2blk = ATL_AMM_BT2BLK_a1[id];
      else
         out->b2blk = (ialp == -1)?ATL_AMM_BT2BLK_an[id]:ATL_AMM_BT2BLK_aX[id];
   }
   #ifdef TCPLX
   else if (TA == AtlasConj)  /* means HERK, noTrans */
   {
      out->a2blk = ATL_AMM_AT2BLK_a1[id];
      if (ialp == 1)
         out->b2blk = ATL_AMM_BH2BLK_a1[id];
      else
         out->b2blk = (ialp == -1)?ATL_AMM_BH2BLK_an[id]:ATL_AMM_BH2BLK_aX[id];
   }
   else if (TA == AtlasConjTrans)  /* Means HERK, HermTrans */
   {
      out->a2blk = ATL_AMM_AC2BLK_a1[id];
      if (ialp == 1)
         out->b2blk = ATL_AMM_BN2BLK_a1[id];
      else
         out->b2blk = (ialp == -1)?ATL_AMM_BN2BLK_an[id]:ATL_AMM_BN2BLK_aX[id];
   }
   #endif
   else  /* TA == AtlasTrans */
   {
      out->a2blk = ATL_AMM_AN2BLK_a1[id];
      if (ialp == 1)
         out->b2blk = ATL_AMM_BN2BLK_a1[id];
      else
         out->b2blk = (ialp == -1)?ATL_AMM_BN2BLK_an[id]:ATL_AMM_BN2BLK_aX[id];
   }
   return(nb);
}
#ifdef TREAL
/*
 * For TRSM, we need a kernel with mb == kb, but nb can differ.
 * Alpha for A will be -1, for B it will 1,  and Cblk2cm will be for beta=alpha,
 * while Cbk2cm_b1 will be for beta=1.0.
 * RETURNS: mb to use, 0 if ATL_trsmKL_rk4 should be called instead.
 */
#include "atlas_ttypes.h"
#include Mstr(Mjoin(ATLAS_PRE,tsamm_perf.h))
int Mjoin(PATL,GetTrsmInfo)
(
   amminfo_t *out,
   int ialp,            /* 0 alpha=0.0, 1:alpha=1.0, -1:-1.0, else alpha=X */
   enum ATLAS_TRANS TA,
   ATL_CSZT M,           /* size of triangular matrix */
   ATL_CSZT N,           /* NRHS */
   const SCALAR beta
)
{
   #define MAXIDX ATL_tsAMM_NCASES-1
   int ik = MAXIDX;
   int mu, nu, ku, nb, nnblks, mb, nmblks, mb0, ibest, bbest;
   double tslv;   /* predicted time to solve whole prob wt trsmK */
   double tbest;  /* start it at time using nb=4 (ik=0) */

/*
 * First, find speed of trsmK by taking MB closest to M
 */
   if (M >= ATL_sqAMM_LASTKB)
      tslv = ATL_tsAMM_TIME[MAXIDX];
   else
   {
      int i;
      for (i=MAXIDX; i > 0; i--)
         if (ATL_AMM_KBs[i] <= M)
            break;
      tslv = ATL_tsAMM_TIME[i];
   }
   tslv = ((1.0*M)*M*N) * tslv;
   tbest = tslv;
   ibest = -1;
   bbest = -1;
/*
 * Now loop over all square block factors, and find the best predicted perf
 */
   for (ik=0; ik < ATL_tsAMM_NCASES; ik++)
   {
      const int kb = ATL_AMM_KBs[ik];
      int mb, ndi, nsq;
      double tim, tfl;
      if (kb+kb >= M)  /* don't use blks leading to little amm */
         break;
      ndi = M/kb;              /* # of full diagonal blocks */
      nsq = ((ndi-1)*ndi)>>1; /* # of full amm blks */
      mb = M - ndi*kb;         /* partial block at beginning */
      tfl = kb;                /* triangular flops are half  */
      tfl = tfl*kb*N;          /* of amm flops for same kb */
/*
 *    Compute time to do full blocks portion of algorithm
 */
      tim = (ndi*tfl)*ATL_tsAMM_TIME[ik] +             /* slv time */
            (nsq*(tfl+tfl))*ATL_sqAMM_TIME[ik];        /* amm time */
      if (mb) /* need to find perf of partial block */
      {
         int i;
         const double pfl=(1.0*mb)*kb*N, mmfl=(2.0*ndi)*ndi*N;

         for (i=ik; i > 0; i--)
            if (ATL_AMM_KBs[ik] <= mb)
               break;
         tim += pfl * ATL_tsAMM_TIME[i];   /* extra slvtime */
         tim += mmfl * ATL_sqAMM_TIME[i];  /* extra mmtime */
      }
//    printf("idx=%d, kb=%d(%d), spdup=%e\n", ik, kb, ATL_AMM_KBs[ik], 
//           trk4/tim);
      if (tim <= tbest)
      {
         tbest = tim;
         ibest = ik;
         bbest = kb;
      }
   }
// best=0;   /* FOR TESTING!!!!! */
   if (ibest < 0)
      return(0);
   ik = ibest;

   out->IDX = ik;
   out->mb = mb = out->kb = bbest;
   out->nb = nb = ATL_AMM_NBs[ik];
   out->mu = mu = ATL_AMM_MUs[ik];
   out->nu = nu = ATL_AMM_NUs[ik];
   out->ku = ku = ATL_AMM_KUs[ik];
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->kbmax = ATL_AMM_KBMAXs[ik];
   out->vlen = ATL_AMM_VLENs[ik];
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
   out->a2blk = (TA == AtlasNoTrans) ? 
                ATL_AMM_AT2BLK_an[ik]:ATL_AMM_AN2BLK_an[ik];
   out->b2blk = ATL_AMM_BN2BLK_a1[ik];
   if (ialp == 1)
      out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
   else if (ialp == -1)
      out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
   else
      out->Cblk2cm = (ialp) ? ATL_AMM_BLK2C_a1_bX[ik]:ATL_AMM_BLK2C_a1_b0[ik];
   out->Cblk2cm_b1 = ATL_AMM_BLK2C_a1_b1[ik];
   out->cm2Cblk = NULL;
   printf("ik=%d, mb=%d(%d), nb=%d, pred spdup=%.2f\n", ik, out->mb, mb, 
          out->nb, tslv/tbest);
   return(mb);
}

/*
 * For TRSM, we're going to get our main parellelism from the N dimension
 * We know that mb==kb, but nb is independent.  alpha for A will be -1,
 * and for B it will 1.  Cblk2cm will be beta=0, while Cbk2cm_b1 will be 1.
 * RETURNS: upper bound on useful nthreads to use
 */
#include "atlas_ttypes.h"
int Mjoin(PATL,tGetTrsmInfo)
(
   ATL_ttrsm_amm_t *pd,
   int P,
   enum ATLAS_TRANS TA,
   ATL_CSZT M,
   ATL_CSZT N,
   const SCALAR beta
)
{
   #ifdef ATL_CAMM_MAXINDX
      int ik = ATL_CAMM_MAXINDX;
   #else
      int ik = ATL_tsAMM_NCASES-1;
   #endif
   int mu, nu, ku, nb, nnblks, mb, nmblks, mb0;

@beginskip
   #ifdef TREAL
      nb = ATL_AMM_NBs[ik];
      nnblks = N / nb;
      if (nnblks > P && ik > ATL_AMM_98IDX)
      {
         ik = ATL_AMM_98IDX;
      }
   #endif
@endskip
/*
 * Get a KB smaller than M
 */
   for (; ik > 0 && ATL_AMM_KBs[ik] > M; ik--);

/*
 * Find a kernel where mb can be set to kb; we know these exist, since we insist
 * on square problems of moderate size
 */
   for (; ik > 0; ik--)
   {
      mu = ATL_AMM_MUs[ik];
      mb = ATL_AMM_KBs[ik];
      if (mb > M)
         continue;
/*
 *    Any kernel can be used if it can be called with MB = KB
 */
      if ((mb/mu)*mu == mb)       /* it is legal to call wt MB=KB */
         break;                   /* so use this kernel */
/*
 *    KRUNTIME kernels can vary their KB, and thus be made legal
 */
      if (ATL_AMM_KRUNTIME(ATL_AMM_KFLAG[ik]))
      {
         ku = ATL_AMM_KUs[ik];
         ku = ATL_lcm(ku, mu);
         mb = (mb/ku)*ku;
         if (mb)
            break;
      }
   }
// ik=0;   /* FOR TESTING!!!!! */
   pd->mb = mb = ATL_AMM_KBs[ik];
   nb = ATL_AMM_NBs[ik];
   nu = ATL_AMM_NUs[ik];
@beginskip
/*
 * Restrict either nb or P in order to split up RHS
 */
   if (nb*P > N)
   {
      if (nb > (nu<<2))  /* try reducing large NB to 4*nu,  */
      {                  /* still allows A reuse by factor 4 */
         int k = N / (nu<<2);
         if (k <= P)
         {
            nb = (nu<<2);
            P = (k*nb != N) ? k+1 : k;
         }
      }
      else
         P = (N+nb-1) / nb;
   }
@endskip
   if (P*nb > N)
      P = (N+nb-1)/nb;
   pd->nb = nb;
   mu = ATL_AMM_MUs[ik];
   ku = ATL_AMM_KUs[ik];
   pd->nmu = mb / mu;
   pd->nnu = nb / nu;
   nnblks = N / nb;
   pd->nbf = N - nb*nnblks;
   if (!pd->nbf)
   {
      pd->nbf = nb;
      pd->nnuf = pd->nnu;
   }
   else
   {
      nnblks++;
      pd->nnuf = (pd->nbf+nu-1)/nu;
   }
   pd->nnblks = nnblks;
   pd->amm_b0 = ATL_AMM_KERN_b0[ik];
   pd->amm_b1 = ATL_AMM_KERN_b1[ik];
   nmblks = M/mb;
   mb0 = (M - nmblks*mb);
   if (!mb0)
   {
      pd->MB0 = mb0 = mb;
      pd->nmu0 = pd->nmu;
   }
   else
   {
      nmblks++;
      if (ATL_AMM_KMAJOR(ik))
      {
         pd->MB0 = ((mb0+ku-1)/ku)*ku;
         if (!ATL_AMM_KRUNTIME(ik))
            pd->amm_b0 = ATL_AMM_KERN_K1_b0[ik];
      }
      else if (!ATL_AMM_KRUNTIME(ik) || mb0 != (mb0/ku)*ku ||
               mb0 < ATL_AMM_KBMINs[ik])
      {
         pd->amm_b0 = ATL_AMM_KERN_K1_b0[ik];
         pd->MB0 = mb0;
      }
      else
         pd->MB0 = mb0;
      pd->nmu0 = (mb0+mu-1)/mu;
   }
   pd->mb0 = mb0;
   pd->nmblks = nmblks;
   pd->nxblks = nnblks * nmblks;
   if (P > pd->nxblks)
      P = pd->nxblks;
   pd->mu = mu;
   pd->nu = nu;
   pd->ku = ATL_AMM_KUs[ik];
   #ifdef TCPLX
      if (TA == AtlasConjTrans)
         pd->a2blk = ATL_AMM_AC2BLK_an[ik];
      else if (TA == AtlasConj)
         pd->a2blk = ATL_AMM_AH2BLK_an[ik];
      else
   #endif
   pd->a2blk = (TA == AtlasNoTrans) ? 
               ATL_AMM_AT2BLK_an[ik] : ATL_AMM_AN2BLK_an[ik];
   pd->b2blk = ATL_AMM_BN2BLK_a1[ik];
/*
 * beta != 0, because then trsm simply zeros X and returns
 */
   if (SCALAR_IS_ONE(beta))
      pd->blk2c = ATL_AMM_BLK2C_a1_b1[ik];
   else if (SCALAR_IS_NONE(beta))
      pd->blk2c = ATL_AMM_BLK2C_a1_bn[ik];
   else
      pd->blk2c = ATL_AMM_BLK2C_a1_bX[ik];
// printf("ik=%d, mb=%d(%d), nb=%d(%d), MB0=%d\n", ik, pd->mb, pd->mb0, pd->nb, pd->nbf, pd->MB0);
   return(P);
}

ablk2cmat_t Mjoin(PATL,tGetSyammInfo)
(
   amminfo_t *out,
   const int P,          /* scale you want to use */
   enum ATLAS_TRANS TA,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   ablk2cmat_t dblk2cmat;
   int ik = ATL_MAXIDX;
   int nb, k;
   if (K < ATL_sqAMM_LASTKB)  
   {
      for (ik=0; ik <= ATL_MAXIDX && ATL_AMM_KBs[ik] < K; ik++);
   }
   nb = ATL_AMM_MBs[ik];
   #ifdef ATL_sqAMM_66IDX
      while (ik > ATL_sqAMM_66IDX)
      {
         k = N / nb;
         k = ((k-1)*k)>>1;
         if (k >= P)
            break;
         nb = ATL_AMM_MBs[--ik];
      }
   #endif
   out->IDX = ik;
   nb = Mmax(nb, ATL_AMM_NBs[ik]);
   if (nb > N)
      nb = N;
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   k = ATL_lcm(out->mu, out->nu);
   nb = (nb > k) ? (nb/k)*k : k;
   out->nb = out->mb = nb;
   out->kb = ATL_AMM_KBs[ik];
/*   printf("tGetSyAMM, nb=%d, kb=%d, ik=%d\n", nb, out->kb, ik); */
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->kbmax = ATL_AMM_KBMAXs[ik];
   out->vlen = ATL_AMM_VLENs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
   if (TA == AtlasNoTrans)
   {
      out->a2blk = ATL_AMM_AT2BLK_a1[ik];
      out->b2blk =  ATL_AMM_BT2BLK_a1[ik];
   }
   else
   {
      out->a2blk = ATL_AMM_AN2BLK_a1[ik];
      out->b2blk =  ATL_AMM_BN2BLK_a1[ik];
   }
   if (SCALAR_IS_ONE(alpha))
   {
      dblk2cmat = ATL_AMM_BLK2C_a1_b0[ik];
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
   }
   else if (SCALAR_IS_NONE(alpha))
   {
      dblk2cmat = ATL_AMM_BLK2C_an_b0[ik];
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_an_b1[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_an_bn[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_an_b0[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_an_bX[ik];
   }
   else  /* alpha = X */
   {
      dblk2cmat = ATL_AMM_BLK2C_aX_b0[ik];
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_aX_b1[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_aX_bn[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_aX_b0[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_aX_bX[ik];
   }
   return(dblk2cmat);
}
/*
 * returns cblk2c_b0, cblk2c_b1 is in structure
 */
ablk2cmat_t Mjoin(PATL,tGetSyammInfo_K)
(
   amminfo_t *out,
   const int P,          /* scale you want to use */
   enum ATLAS_TRANS TA,
   ATL_CSZT N,
   ATL_CSZT K
)
{
   ablk2cmat_t dblk2cmat;
   int ik = ATL_sqAMM_NCASES-1;
   int mb, nb, k, mu, nu;

   if (K < ATL_sqAMM_LASTKB)  
      for (ik=0; ik < ATL_sqAMM_NCASES-1 && ATL_AMM_KBs[ik] < K; ik++);
   out->IDX = ik;
   mu = out->mu = ATL_AMM_MUs[ik];
   nu = out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->mb = ((N+mu-1)/mu)*mu;
   out->nb = ((N+nu-1)/nu)*nu;
   out->kb = ATL_AMM_KBs[ik];
/*  printf("tGetSyAMM_K, mb=%d, nb=%d, kb=%d, ik=%d\n", mb, nb, out->kb, ik); */
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->kbmax = ATL_AMM_KBMAXs[ik];
   out->vlen = ATL_AMM_VLENs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
   if (TA == AtlasNoTrans)
   {
      out->a2blk = ATL_AMM_AT2BLK_a1[ik];
      out->b2blk =  ATL_AMM_BT2BLK_a1[ik];
   }
   else
   {
      out->a2blk = ATL_AMM_AN2BLK_a1[ik];
      out->b2blk =  ATL_AMM_BN2BLK_a1[ik];
   }
   out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
   return(ATL_AMM_BLK2C_a1_b0[ik]);
}
#endif
@ROUT ATL_GetRankKInfo
int Mjoin(PATL,GetRankKInfo)
(
   amminfo_t *out,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   const int ik = K-3;
   int appAl;  /* 0:A, 1:B */
   ATL_assert(K > 2 && K <= ATL_rkAMM_LASTKB);
@ROUT ATL_GetAmmmInfo
int Mjoin(PATL,GetAmmmInfo)
(
   amminfo_t *out,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   #ifdef ATL_CAMM_MAXINDX
      int ik=ATL_CAMM_MAXINDX;
   #else
      int ik=ATL_AMM_NCASES-1; 
   #endif
   int appAl;  /* 0:A, 1:B, 2:C */
/*
 * For rank-K update, choose smallest KB that contains required K
 */
   if (K < ATL_geAMM_LASTKB)  
   {
      for (ik=0; ik < ATL_AMM_NCASES && ATL_AMM_KBs[ik] < K; ik++);
   }
@ROUT ATL_GetAmmmInfo ATL_GetRankKInfo
   out->IDX = ik;
   out->mb = ATL_AMM_MBs[ik];
   out->nb = ATL_AMM_NBs[ik];
   out->kb = ATL_AMM_KBs[ik];
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->kbmax = ATL_AMM_KBMAXs[ik];
   out->vlen = ATL_AMM_VLENs[ik];
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
@ROUT ATL_GetAmmmInfo
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
   @define pf @ATL_AMM_@
@ROUT ATL_GetRankKInfo
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   @define pf @ATL_AMM_@
@ROUT ATL_GetAmmmInfo ATL_GetRankKInfo
/*
 * Apply alpha to smallest matrix, and use alpha/beta to pick copy routines
 */
   if (SCALAR_IS_ONE(alpha))
   {
      appAl = 0;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = @(pf)AT2BLK_a1[ik];
         else if (TA == AtlasTrans)
            out->a2blk = @(pf)AN2BLK_a1[ik];
         else if (TA == AtlasConjTrans)
            out->a2blk = @(pf)AC2BLK_a1[ik];
         else
            out->a2blk = @(pf)AH2BLK_a1[ik];
         if (TB == AtlasNoTrans)
             out->b2blk = @(pf)BN2BLK_a1[ik];
         else if (TB == AtlasTrans)
             out->b2blk = @(pf)BT2BLK_a1[ik];
         else if (TB == AtlasConjTrans)
             out->b2blk = @(pf)BH2BLK_a1[ik];
         else
             out->b2blk = @(pf)BC2BLK_a1[ik];
      #else
         out->a2blk = (TA == AtlasNoTrans) ?
            @(pf)AT2BLK_a1[ik]:@(pf)AN2BLK_a1[ik];
         out->b2blk = (TB == AtlasNoTrans) ?
            @(pf)BN2BLK_a1[ik]:@(pf)BT2BLK_a1[ik];
      #endif
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_b1[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_b0[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_bn[ik];
      else
         out->Cblk2cm = @(pf)BLK2C_a1_bX[ik];
   }
   else  /* alpha is not one */
   {
@ROUT ATL_GetRankKInfo
      appAl = (M >= N) ? 1:0;
@ROUT ATL_GetAmmmInfo
      if (M >= N)                  /* A is larger than B, put alpha on C or B */
         appAl = (M >= K) ? 1 : 2;
      else                         /* B is larger than A, put alpha on C or A */
         appAl = (N >= K) ? 0 : 2;
      if (appAl == 2)  /* apply alpha to C */
      {
         #ifdef TCPLX
            if (TA == AtlasNoTrans)
               out->a2blk = @(pf)AT2BLK_a1[ik];
            else if (TA == AtlasTrans)
               out->a2blk = @(pf)AN2BLK_a1[ik];
            else if (TA == AtlasConjTrans)
               out->a2blk = @(pf)AC2BLK_a1[ik];
            else
               out->a2blk = @(pf)AH2BLK_a1[ik];
            if (TB == AtlasNoTrans)
                out->b2blk = @(pf)BN2BLK_a1[ik];
            else if (TB == AtlasTrans)
                out->b2blk = @(pf)BT2BLK_a1[ik];
            else if (TB == AtlasConjTrans)
                out->b2blk = @(pf)BH2BLK_a1[ik];
            else
                out->b2blk = @(pf)BC2BLK_a1[ik];
         #else
            out->a2blk = (TA == AtlasNoTrans) ?
                         @(pf)AT2BLK_a1[ik] : @(pf)AN2BLK_a1[ik];
            out->b2blk = (TB == AtlasNoTrans) ?
                         @(pf)BN2BLK_a1[ik] : @(pf)BT2BLK_a1[ik];
         #endif
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           @(pf)BLK2C_an_b1[ik] : @(pf)BLK2C_aX_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           @(pf)BLK2C_an_b0[ik] : @(pf)BLK2C_aX_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           @(pf)BLK2C_an_bn[ik] : @(pf)BLK2C_aX_bn[ik];
         else
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           @(pf)BLK2C_an_bX[ik] : @(pf)BLK2C_aX_bX[ik];
      }
      else  /* not applying alpha to C */
      {
      @beginindent 1 3
@ROUT ATL_GetAmmmInfo ATL_GetRankKInfo
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_b1[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_b0[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = @(pf)BLK2C_a1_bn[ik];
      else
         out->Cblk2cm = @(pf)BLK2C_a1_bX[ik];
      if (!appAl)  /* apply to alpha to A */
      {
         #ifdef TCPLX
            if (TB == AtlasNoTrans)
                out->b2blk = @(pf)BN2BLK_a1[ik];
            else if (TB == AtlasTrans)
                out->b2blk = @(pf)BT2BLK_a1[ik];
            else if (TB == AtlasConjTrans)
                out->b2blk = @(pf)BH2BLK_a1[ik];
            else
                out->b2blk = @(pf)BC2BLK_a1[ik];
            if (SCALAR_IS_NONE(alpha))
            {
               if (TA == AtlasNoTrans)
                  out->a2blk = @(pf)AT2BLK_an[ik];
               else if (TA == AtlasTrans)
                  out->a2blk = @(pf)AN2BLK_an[ik];
               else if (TA == AtlasConjTrans)
                  out->a2blk = @(pf)AC2BLK_an[ik];
               else
                  out->a2blk = @(pf)AH2BLK_an[ik];
            }
            else
            {
               if (TA == AtlasNoTrans)
                  out->a2blk = @(pf)AT2BLK_aX[ik];
               else if (TA == AtlasTrans)
                  out->a2blk = @(pf)AN2BLK_aX[ik];
               else if (TA == AtlasConjTrans)
                  out->a2blk = @(pf)AC2BLK_aX[ik];
               else
                  out->a2blk = @(pf)AH2BLK_aX[ik];
            }
         #else
            if (SCALAR_IS_NONE(alpha))
               out->a2blk = (TA == AtlasNoTrans) ?
                            @(pf)AT2BLK_an[ik] : @(pf)AN2BLK_an[ik];
            else
               out->a2blk = (TA == AtlasNoTrans) ?
                            @(pf)AT2BLK_aX[ik] : @(pf)AN2BLK_aX[ik];
            out->b2blk = (TB == AtlasNoTrans) ?
                         @(pf)BN2BLK_a1[ik] : @(pf)BT2BLK_a1[ik];
         #endif
      }
      else /* apply alpha to B */
      {
         #ifdef TCPLX
            if (TA == AtlasNoTrans)
               out->a2blk = @(pf)AT2BLK_a1[ik];
            else if (TA == AtlasTrans)
               out->a2blk = @(pf)AN2BLK_a1[ik];
            else if (TA == AtlasConjTrans)
               out->a2blk = @(pf)AC2BLK_a1[ik];
            else
               out->a2blk = @(pf)AH2BLK_a1[ik];
            if (SCALAR_IS_NONE(alpha))
            {
               if (TB == AtlasNoTrans)
                   out->b2blk = @(pf)BN2BLK_an[ik];
               else if (TB == AtlasTrans)
                   out->b2blk = @(pf)BT2BLK_an[ik];
               else if (TB == AtlasConjTrans)
                   out->b2blk = @(pf)BH2BLK_an[ik];
               else
                   out->b2blk = @(pf)BC2BLK_an[ik];
            }
            else
            {
               if (TB == AtlasNoTrans)
                   out->b2blk = @(pf)BN2BLK_aX[ik];
               else if (TB == AtlasTrans)
                   out->b2blk = @(pf)BT2BLK_aX[ik];
               else if (TB == AtlasConjTrans)
                   out->b2blk = @(pf)BH2BLK_aX[ik];
               else
                   out->b2blk = @(pf)BC2BLK_aX[ik];
            }
         #else
            out->a2blk = (TA == AtlasNoTrans) ?
                         @(pf)AT2BLK_a1[ik] : @(pf)AN2BLK_a1[ik];
            if (SCALAR_IS_NONE(alpha))
               out->b2blk = (TB == AtlasNoTrans) ?
                            @(pf)BN2BLK_an[ik] : @(pf)BT2BLK_an[ik];
            else
               out->b2blk = (TB == AtlasNoTrans) ?
                            @(pf)BN2BLK_aX[ik] : @(pf)BT2BLK_aX[ik];
         #endif
      }
@ROUT ATL_GetAmmmInfo 
      @endindent
      }
@ROUT ATL_GetAmmmInfo  ATL_GetRankKInfo 
   }
   return(appAl);
}

@ROUT ATL_GetAmmmInfo 
/*
 * Following routines help pick NB for parallel routines
 */
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
#ifndef ATL_MAXIDX
   #define ATL_MAXIDX ATL_AMM_NCASES-1
#endif

int Mjoin(PATL,tGetAmmmInfo)
(
   amminfo_t *out,
   const unsigned int P,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   int ik=ATL_MAXIDX, mb, nb, nmblks, nnblks, ncblks;
   int appAl;  /* 0:A, 1:B, 2:C */
/*
 * For rank-K update, choose smallest KB that contains required K
 */
   if (K < ATL_geAMM_LASTKB)
   {
      for (ik=0; ik < ATL_AMM_NCASES && ATL_AMM_KBs[ik] < K; ik++);
   }
   ik++;
   do
   {
      ik--;
      mb = ATL_AMM_MBs[ik];
      nb = ATL_AMM_NBs[ik];
      nmblks = M / mb;
      nnblks = N / nb;
      ncblks = nmblks * nnblks;
   }
   while (ik >= ATL_geAMM_66IDX && ncblks < P);
   out->IDX = ik;
   out->mb = mb;
   out->nb = nb;
   out->kb = ATL_AMM_KBs[ik];
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->kbmax = ATL_AMM_KBMAXs[ik];
   out->vlen = ATL_AMM_VLENs[ik];
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
/*
 * Apply alpha to smallest matrix, and use alpha/beta to pick copy routines
 */
   if (SCALAR_IS_ONE(alpha))
   {
      appAl = 0;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = ATL_AMM_AT2BLK_a1[ik];
         else if (TA == AtlasTrans)
            out->a2blk = ATL_AMM_AN2BLK_a1[ik];
         else if (TA == AtlasConjTrans)
            out->a2blk = ATL_AMM_AC2BLK_a1[ik];
         else
            out->a2blk = ATL_AMM_AH2BLK_a1[ik];
         if (TB == AtlasNoTrans)
             out->b2blk = ATL_AMM_BN2BLK_a1[ik];
         else if (TB == AtlasTrans)
             out->b2blk = ATL_AMM_BT2BLK_a1[ik];
         else if (TB == AtlasConjTrans)
             out->b2blk = ATL_AMM_BH2BLK_a1[ik];
         else
             out->b2blk = ATL_AMM_BC2BLK_a1[ik];
      #else
         out->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_a1[ik]:ATL_AMM_AN2BLK_a1[ik];
         out->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_a1[ik]:ATL_AMM_BT2BLK_a1[ik];
      #endif
      out->Cblk2cm_b1 = ATL_AMM_BLK2C_a1_b1[ik];
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
   }
   else  /* alpha is not one */
   {
      if (M >= N)                  /* A is larger than B, put alpha on C or B */
         appAl = (M >= K) ? 1 : 2;
      else                         /* B is larger than A, put alpha on C or A */
         appAl = (N >= K) ? 0 : 2;
      if (appAl == 2)  /* apply alpha to C */
      {
         #ifdef TCPLX
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_a1[ik];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_a1[ik];
            else if (TA == AtlasConjTrans)
               out->a2blk = ATL_AMM_AC2BLK_a1[ik];
            else
               out->a2blk = ATL_AMM_AH2BLK_a1[ik];
            if (TB == AtlasNoTrans)
                out->b2blk = ATL_AMM_BN2BLK_a1[ik];
            else if (TB == AtlasTrans)
                out->b2blk = ATL_AMM_BT2BLK_a1[ik];
            else if (TB == AtlasConjTrans)
                out->b2blk = ATL_AMM_BH2BLK_a1[ik];
            else
                out->b2blk = ATL_AMM_BC2BLK_a1[ik];
         #else
            out->a2blk = (TA == AtlasNoTrans) ?
                         ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
            out->b2blk = (TB == AtlasNoTrans) ?
                         ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
         #endif
         out->Cblk2cm_b1 = SCALAR_IS_NONE(alpha) ?
                        ATL_AMM_BLK2C_an_b1[ik] : ATL_AMM_BLK2C_aX_b1[ik];
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b1[ik] : ATL_AMM_BLK2C_aX_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b0[ik] : ATL_AMM_BLK2C_aX_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bn[ik] : ATL_AMM_BLK2C_aX_bn[ik];
         else
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bX[ik] : ATL_AMM_BLK2C_aX_bX[ik];
      }
      else  /* not applying alpha to C */
      {
         out->Cblk2cm_b1 = ATL_AMM_BLK2C_a1_b1[ik];
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
         else
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
         if (!appAl)  /* apply to alpha to A */
         {
            #ifdef TCPLX
               if (TB == AtlasNoTrans)
                   out->b2blk = ATL_AMM_BN2BLK_a1[ik];
               else if (TB == AtlasTrans)
                   out->b2blk = ATL_AMM_BT2BLK_a1[ik];
               else if (TB == AtlasConjTrans)
                   out->b2blk = ATL_AMM_BH2BLK_a1[ik];
               else
                   out->b2blk = ATL_AMM_BC2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_an[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_an[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_an[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_an[ik];
               }
               else
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_aX[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_aX[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_aX[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_aX[ik];
               }
            #else
               if (SCALAR_IS_NONE(alpha))
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_an[ik] : ATL_AMM_AN2BLK_an[ik];
               else
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_aX[ik] : ATL_AMM_AN2BLK_aX[ik];
               out->b2blk = (TB == AtlasNoTrans) ?
                            ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
            #endif
         }
         else /* apply alpha to B */
         {
            #ifdef TCPLX
               if (TA == AtlasNoTrans)
                  out->a2blk = ATL_AMM_AT2BLK_a1[ik];
               else if (TA == AtlasTrans)
                  out->a2blk = ATL_AMM_AN2BLK_a1[ik];
               else if (TA == AtlasConjTrans)
                  out->a2blk = ATL_AMM_AC2BLK_a1[ik];
               else
                  out->a2blk = ATL_AMM_AH2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_an[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_an[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_an[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_an[ik];
               }
               else
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_aX[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_aX[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_aX[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_aX[ik];
               }
            #else
               out->a2blk = (TA == AtlasNoTrans) ?
                            ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_an[ik] : ATL_AMM_BT2BLK_an[ik];
               else
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_aX[ik] : ATL_AMM_BT2BLK_aX[ik];
            #endif
         }
      }
   }
   return(appAl);
}

@ROUT ATL_GetAmmmInfo  ATL_GetAmmmInfoSQ ATL_GetRankKInfo
static INLINE int ATL_CompBlkPart
   (size_t D, ATL_UINT maxB, ATL_UINT b, ATL_UINT u, 
    ATL_UINT *BS, size_t *NS, size_t *NL)
/*
 * Given dim D, and a blocking that is presently b (b <= maxB), and can be
 * maximally ncreased to maxB, find two blocking factors such that
 *    bL*nL + bS*nS = CEIL(D/u),   bS < bL < maxB
 * --> For D with a lot of blocks, bL = bS + nu.
 * --> For D with low nblocks, small block will just be remainder
 */
{
   size_t nL, nS, bL, bS;  /* # of small/large blks, blksz for lg/sm */
   size_t i; 
   int NU;
   
/*
 * If entire dim fits in max block, just use one block
 */
   NU = (b+u-1)/u;       /* ceiling of number of unrollings in b */
   bL = NU*u;            /* blocking must be a multiple of unrolling */
   i = (((D+u-1)/u)*u);  /* aiming for CEIL(D/u)*u */
   if (i < b+b && i <= maxB)
   {
      nS = bS = 0;
      nL = 1;
      bL = i;
   }
   else  /* have at least two blocks at initial b */
   {
      int r;
      nL = D / bL;    /* number of blocks w/o changing b */
      r = i - nL*bL;
      if (r)          /* if block does not evenly divide D */
      {               /* find 2 block sizes that get us CEIL(D/u)*u */
         if (bL+u <= maxB)          /* increase b to find partition */
         {
            ATL_CUINT nu=(r+u-1)/u; /* CEIL of # of unrollings in remndr */
            if (nL >= nu)           /* can just add u to first nu blks */
            {
               nS = nL - nu;
               nL = nu;
               bS = b;
               bL += u;
            }
            else                   /* otherwise, just dump remndr to small b */
            {
               nS = 1;
               bS = ((r+u-1)/u)*u;
            }
         }
         else                       /* decrease b to find partition */
         {
            ATL_UINT nu;
            bS = bL - u;
            nS = D/bS;
            r = i - bS*nS;
            nu=(r+u-1)/u; /* CEIL of # of unrollings in remndr */
            if (nS >= nu)           /* can just add u to first nu blks */
            {
               nS -= nu;
               nL = nu;
            }
            else                   /* otherwise, just dump remndr to small b */
            {
               nS = 1;
               r = i - nL*bL;
               bS = ((r+u-1)/u)*u;
            }
         }
      }
      else  /* no remainder, means no small blocks, D a mul of orig b */
         bS = nS = 0;
   }
   *BS = bS;
   *NS = nS;
   *NL = nL;
   #ifdef DEBUG
      printf("nS*bS + nL*bL = %d*%d + %d*%d = %d (D=%d, Du=%d)\n", (int)nS, bS,
             (int)nL, bL, (int)(nS*bS+nL*bL), (int)D, (int)(((D+u-1)/u)*u));
      ATL_assert(bS*nS + bL*nL == i);
   #endif
   return(bL);
}

@ROUT ATL_GetAmmmInfoSQ
   @define sh @sq@
@ROUT ATL_GetAmmmInfo
   @define sh @ge@
@ROUT ATL_GetRankKInfo
   @define sh @rk@
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ ATL_GetRankKInfo
double Mjoin(PATL,@(sh)GetAmmInfoDbl)(char wh, int idx)
{
   ATL_assert(idx >= 0 && idx < ATL_@(sh)AMM_NCASES);
   switch(wh)
   {
   case 'P':
      return(ATL_@(sh)AMM_PERF[idx]);
   case 'T':
      return(ATL_@(sh)AMM_TIME[idx]);
   case '1':
@ROUT ATL_GetRankKInfo
      return(1.0);
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
      return(ATL_@(sh)AMM_K1RATIO[idx]);
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ ATL_GetRankKInfo
   default:
      fprintf(stderr, "unknown what='%c'!\n", wh);
      ATL_assert(0);
   }
   return(0.0);
}

int Mjoin(PATL,@(sh)GetAmmInfoInt)(char wh, int idx)
{
   ATL_assert(idx >= 0 && idx < ATL_@(sh)AMM_NCASES);
   switch(wh)
   {
   case 'M':
      return(ATL_AMM_MBs[idx]);
   case 'N':
      return(ATL_AMM_NBs[idx]);
   case 'K':
      return(ATL_AMM_KBs[idx]);
   case 'm':
      return(ATL_AMM_MUs[idx]);
   case 'n':
      return(ATL_AMM_NUs[idx]);
   case 'k':
      return(ATL_AMM_KUs[idx]);
   case 'F':
      return(ATL_AMM_KFLAG[idx]);
   case '>':
      return(ATL_AMM_KBMAXs[idx]);
   case '<':
      return(ATL_AMM_KBMINs[idx]);
   default:
      fprintf(stderr, "unknown what='%c'!\n", wh);
      ATL_assert(0);
   }
   return(0);
}
void *Mjoin(PATL,@(sh)GetAmmInfoPtr)(int idx, int what, int alp, int bet)
{
   void *vp;
   if (!what) /* amm */
   {
      if (bet == 0)
         vp = ATL_AMM_KERN_b0[idx];
      else
         vp = (bet == 1) ? ATL_AMM_KERN_b1[idx] : ATL_AMM_KERN_bn[idx];
   }
   else if (what == 1)  /* blk2c */
      vp = GetBlk2C(idx, alp, bet);
   else if (what == 2)  /* a2blk, beta = trans */
   {
      if (bet == AtlasNoTrans)
      {
         if (alp == -1)
            vp = ATL_AMM_AN2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_AN2BLK_a1[idx] : ATL_AMM_AN2BLK_aX[idx];
      }
      #ifdef TCPLX
      else if (bet == AtlasConjTrans)
      {
         if (alp == -1)
            vp = ATL_AMM_AH2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_AH2BLK_a1[idx] : ATL_AMM_AH2BLK_aX[idx];
      }
      else if (bet == AtlasConj)
      {
         if (alp == -1)
            vp = ATL_AMM_AC2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_AC2BLK_a1[idx] : ATL_AMM_AC2BLK_aX[idx];
      }
      #endif
      else /* AtlasTrans */
      {
         if (alp == -1)
            vp = ATL_AMM_AT2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AT2BLK_aX[idx];
      }
   }
   else /* if (what == 3) */  /* b2blk */
   {
      if (bet == AtlasNoTrans)
      {
         if (alp == -1)
            vp = ATL_AMM_BN2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BN2BLK_aX[idx];
      }
      #ifdef TCPLX
      else if (bet == AtlasConjTrans)
      {
         if (alp == -1)
            vp = ATL_AMM_BH2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_BH2BLK_a1[idx] : ATL_AMM_BH2BLK_aX[idx];
      }
      else if (bet == AtlasConj)
      {
         if (alp == -1)
            vp = ATL_AMM_BC2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_BC2BLK_a1[idx] : ATL_AMM_BC2BLK_aX[idx];
      }
      #endif
      else /* AtlasTrans */
      {
         if (alp == -1)
            vp = ATL_AMM_BT2BLK_an[idx];
         else
            vp = (alp == 1) ? ATL_AMM_BT2BLK_a1[idx] : ATL_AMM_BT2BLK_aX[idx];
      }
   }
   return(vp);
}
@ROUT ATL_GetAmmmInfoSQ
/*
 * Designed for parallelism mainly on C blocks, K > LASTKB (ipinfo, not opinfo)
 * C is known to be Upper or Lower.  Fills in only M/N blocking info in ipinfo.
 */
int Mjoin(PATL,tGetParTriCIndx)(int P, int flg, size_t N, size_t K, int *NB)
{
   unsigned int ik=ATL_sqAMM_NCASES-1, nb, mu, nu, U;
@skip   size_t nmblks, nnblks, ncblks;

   if (K < ATL_@(sh)AMM_LASTKB)
      for (ik=0; ik < ATL_sqAMM_NCASES && ATL_AMM_KBs[ik] < K; ik++);
/*   ik = Mjoin(PATL,GetSyrkIdx)(flg, N, K); */
   nb = ATL_AMM_NBs[ik];
@skip   mu = ATL_AMM_MUs[ik];
@skip   nu = ATL_AMM_NUs[ik];
   U = ATL_lcm(ATL_AMM_MUs[ik],ATL_AMM_NUs[ik]);
   if (N < ATL_sqAMM_LASTNB || 
       (N < ATL_sqAMM_LASTNB+U && K >= P*nb) )
      nb = ((N+U-1)/U)*U;  /* for large U, small N, could be bad! */
@skip   nb0 = nb;
   *NB = nb;
   return(ik);
@BEGINSKIP
   #if 0
/*
 * If blocking tuned to KB provides enough parallelism, just use it
 */
   nnblks = N/nb;
   ncblks = (((nnblks-1)*nnblks)>>1) + nnblks;
   if (ncblks >= P)  /* standard blocking provides enough parallelism */
   {
      *NB = nb;
      return(ik);
   }
/*
 * If we reach here, must reduce nb for parallelism, but don't go below
 * NB that gets 66% of original perf (better to reduce P)
 */
   if (N <= ATL_sqAMM_66NB)
      nb = U*((N+U-1)/U);
   else if (ATL_sqAMM_66NB <= ATL_sqAMM_50NB + U)
      nb = U*((ATL_sqAMM_66NB+U-1)/U);
   else
      nb = U*(ATL_sqAMM_66NB/U);
   #endif
   nnblks = N/nb;
   ncblks = (((nnblks-1)*nnblks)>>1 + nnblks);
   if (ncblks < P)  /* nb at min, so reduce parallelism */
   {
      *NB = nb;
      return(ik);
   }
/*
 * If we get to here, present setting using minimal nb gives enough
 * parallelism, so look at increasing nb towards nb0 until we reach P limit.
 * The idea is that once we have the required parallelism, we want
 * to increase block performance back up towards maximum for KB.
 */
   if (nb0 > N)
      nb0 = ((N+U-1)/U)*U;
   while (1)
   {
      unsigned int nbN=nb;
      size_t cblks, nblks;
      if (nb < nb0)
      {
         nbN += U;
         nblks = N / nbN;
         cblks = ((nblks-1)*nblks)>>1 + nblks;
         if (cblks < P)
            break;
         nnblks = nblks;
      }
      else
         break;
      nb = nbN;
      ncblks = cblks;
   }
   *NB = nb;
   return(ik);
@ENDSKIP
}
@ROUT ATL_GetAmmmInfo
/*
 * Designed for parallelism mainly on C blocks, K > LASTKB (ipinfo, not opinfo)
 * Fills in only M & N blocking info in ipinfo.
 */
int Mjoin(PATL,tGetParCIndx)(ipinfo_t *ip, int P, size_t M, size_t N, size_t K)
{
   unsigned int ik=ATL_AMM_NCASES-1, mb0, mb, nb0, nb, mu, nu;
   size_t nmblks, nnblks, ncblks;
   if (K < ATL_@(sh)AMM_LASTKB)
      for (ik=0; ik < ATL_AMM_NCASES && ATL_AMM_KBs[ik] < K; ik++);
   mu = ATL_AMM_MUs[ik];
   nu = ATL_AMM_NUs[ik];
   mb0 = mb = ATL_AMM_MBs[ik];
   nb0 = nb = ATL_AMM_NBs[ik];
/*
 * If blocking tuned to KB provides enough parallelism, just use it
 */
   nmblks = M/mb;
   nnblks = N/nb;
   ncblks = nmblks*nnblks;
   if (ncblks >= P)  /* standard blocking provides enough parallelism */
   {
      unsigned int n;
      n = M - mb*nmblks;
      if (n)
      {
         ip->nfmblks = nmblks;
         ip->npmblks = 1;
         ip->mb = mb;
         ip->pmb = ((n+mu-1)/mu)*mu;
      }
      else
      {
         ip->nfmblks = nmblks;
         ip->npmblks = 0;
         ip->mb = ip->pmb = mb;
      }
      n = N - nb*nnblks;
      if (n)
      {
         ip->nfnblks = nnblks;
         ip->npnblks = 1;
         ip->nb = nb;
         ip->pnb = ((n+nu-1)/nu)*nu;
      }
      else
      {
         ip->nfnblks = nnblks;
         ip->npnblks = 0;
         ip->nb = ip->pnb = nb;
      }
      return(ik);
   }
/*
 * If we reach here, must reduce mb/nb for parallelism, but don't go below
 * MB&NB that get 66% of original perf (better to reduce P)
 */
   if (M <= ATL_geAMM_66MB)
      mb = mu*((M+mu-1)/mu);
   else if (ATL_geAMM_66MB <= mu || ATL_geAMM_66MB - mu <= ATL_geAMM_50MB)
      mb = mu*((ATL_geAMM_66MB+mu-1)/mu);
   else
      mb = mu*(ATL_geAMM_66MB/mu);
   if (N <= ATL_geAMM_66NB)
      nb = nu*((N+nu-1)/nu);
   else if (ATL_geAMM_66NB <= nu || ATL_geAMM_66NB - nu <= ATL_geAMM_50NB)
      nb = nu*((ATL_geAMM_66NB+nu-1)/nu);
   else
      nb = nu*(ATL_geAMM_66NB/nu);
   nmblks = M/mb;
   nnblks = N/nb;
   if (nmblks*nnblks < P)  /* mb/nb at min, so reduce parallelism */
   {
      unsigned int n;
      n = M - mb*nmblks;
      if (!n)
      {
         ip->pmb = ip->mb = mb;
         ip->npmblks = 0;
         ip->nfmblks = nmblks;
      }
      else if (n < mu || n+mb <= mb0)
      {
         ip->mb = mb + ((n+mu-1)/mu)*mu;
         ip->pmb = mb;
         ip->nfmblks = 1;
         ip->npmblks = (nmblks) ? nmblks-1 : 0;
      }
      else
      {
         ip->mb = mb;
         ip->nfmblks = nmblks;
         ip->npmblks = 1;
         ip->pmb = n;
      }
      n = N - nb*nnblks;
      if (!n)
      {
         ip->pnb = ip->nb = nb;
         ip->npnblks = 0;
         ip->nfnblks = nnblks;
      }
      else if (n < nu || n+nb <= nb0)
      {
         ip->nb = nb + ((n+nu-1)/nu)*nu;
         ip->pnb = nb;
         ip->nfnblks = 1;
         ip->npnblks = (nnblks) ? nnblks - 1 : 0;
      }
      else
      {
         ip->nb = nb;
         ip->nfnblks = nnblks;
         ip->npnblks = 1;
         ip->pnb = n;
      }
      return(ik);
   }
/*
 * If we get to here, present setting using minimal mb/nb gives enough
 * parallelism, so look at increasing mb/nb towards mb0/nb0 until we reach
 * P limit.  The idea is that once we have the required parallelism, we want
 * to increase block performance back up towards maximum for KB.
 */
   if (mb0 > M)
      mb0 = ((M+mu-1)/mu)*mu;
   if (nb0 > N)
      nb0 = ((N+nu-1)/nu)*nu;
   while (1)
   {
      unsigned int mbN=mb, nbN=nb;
      size_t cblks, nblks;
      if (nb < nb0 && (nb <= mb || mb >= mb0))
      {
         nbN += nu;
         nblks = N / nbN;
         cblks = nblks * nmblks;
         if (cblks < P)
            break;
         nnblks = nblks;
      }
      else if (mb < mb0)
      {
         mbN += mu;
         nblks = M / mbN;
         cblks = nblks * nnblks;
         if (cblks < P)
            break;
         nmblks = nblks;
      }
      else
         break;
      mb = mbN;
      nb = nbN;
      ncblks = cblks;
   }
   mb0 = M - nmblks * mb;
   if (mb0 > mu)
   {
      ip->nfmblks = nmblks;
      ip->npmblks = 1;
      ip->mb = mb;
      ip->pmb = ((mb0+mu-1)/mu)*mu;
   }
   else if (!mb0)
   {
      ip->nfmblks = nmblks;
      ip->npmblks = 0;
      ip->pmb = ip->mb = mb;
   }
   else  /* M%mb <= mu */
   {
      ip->nfmblks = 1;
      ip->npmblks = (nmblks) ? nmblks-1 : 0;
      ip->mb = mb+mu;
      ip->pmb = mb;
   }
   nb0 = N - nnblks * nb;
   if (nb0 > nu)
   {
      ip->nfnblks = nnblks;
      ip->npnblks = 1;
      ip->nb = nb;
      ip->pnb = ((nb0+nu-1)/nu)*nu;
   }
   else if (!nb0)
   {
      ip->nfnblks = nnblks;
      ip->npnblks = 0;
      ip->pnb = ip->nb = nb;
   }
   else  /* N%nb <= nu */
   {
      ip->nfnblks = 1;
      ip->npnblks = (nnblks) ? nnblks-1 : 0;
      ip->nb = nb+nu;
      ip->pnb = nb;
   }
   return(ik);
}
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ ATL_GetRankKInfo
int Mjoin(PATL,@(sh)GetAmmmIndx)(size_t M, size_t N, size_t K)
{
   int idx=ATL_@(sh)AMM_NCASES-1;
/*
 * This shouldn't happen, but allow for debugging.
 */
// return(0);
   if (K < ATL_@(sh)AMM_LASTKB)
   {
      for (idx=0; ATL_AMM_KBs[idx] < K; idx++);
      ATL_assert(ATL_AMM_KBs[idx] == K);
   }
   else if (M <= ATL_@(sh)AMM_LASTMB && N <= ATL_@(sh)AMM_LASTNB) 
   {  /* inner product */
      size_t NN, MM;
      int i, nu, mu;
      double mfB;
      mu = ATL_AMM_MUs[idx];
      nu = ATL_AMM_NUs[idx];
      MM = ((M+mu-1)/mu)*mu;
      NN = ((N+nu-1)/nu)*nu;
      mfB = (((double)(NN))*MM) / (((double)(NN-N))*(MM-M));
      mfB *= ATL_@(sh)AMM_PERF[idx];
      for (i=idx-1; i >=0; i++)
      {
         double mf, scal;
         mf = ATL_@(sh)AMM_PERF[i];
         if (mf <= mfB)
            break;
         mu = ATL_AMM_MUs[idx];
         nu = ATL_AMM_NUs[i];
         MM = ((M+mu-1)/mu)*mu;
         NN = ((N+nu-1)/nu)*nu;
         scal = (((double)(NN))*MM) / (((double)(NN-N))*(MM-M));
         mf *= scal;
         if (mf > mfB)
         {
            idx = i;
            mfB = mf;
         }
      }
   }
   else if (N <= ATL_@(sh)AMM_LASTNB)  /* only one col panel */
   {
      size_t NN;
      int i, nu;
      double mfB;
      nu = ATL_AMM_NUs[idx];
      NN = ((N+nu-1)/nu)*nu;
      mfB = (double)(NN) / (double)(NN-N);
      mfB *= ATL_@(sh)AMM_PERF[idx];
      for (i=idx-1; i >=0; i++)
      {
         double mf, scal;
         mf = ATL_@(sh)AMM_PERF[i];
         if (mf <= mfB)
            break;
         nu = ATL_AMM_NUs[i];
         NN = ((N+nu-1)/nu)*nu;
         scal = (double)(NN) / (double)(NN-N);
         mf *= scal;
         if (mf > mfB)
         {
            idx = i;
            mfB = mf;
         }
      }
   }
   else /* no degenerate dim */
   {    /* for now, just return max case, tune for cleanup later */
   }
   #ifdef DEBUG
      printf("idx=%d, B=(%d,%d,%d)\n", idx, 
             ATL_AMM_MBs[idx], ATL_AMM_NBs[idx], ATL_AMM_KBs[idx]);
   #endif
   return(idx);
}
@ROUT ATL_GetAmmmInfoSQ `@define mb @nb@`
@ROUT ATL_GetAmmmInfo `@define mb @mb@`
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
void Mjoin(PATL,@(sh)FillInIPInfo)
(
   ipinfo_t *ip,        /* output */
   int idx,             /* what amm kernel index to use */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   size_t M, 
   size_t N, 
   size_t K, 
   size_t lda,
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta,
@ROUT ATL_GetAmmmInfo
   size_t nfmblks,
   size_t npmblks,
   ATL_UINT mb,
   ATL_UINT pmb,
   size_t nfnblks,
   size_t npnblks,
   ATL_UINT nb,
   ATL_UINT pnb
@ROUT ATL_GetAmmmInfoSQ
   ATL_UINT nb
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
)
{
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      #define CONE ATL_rone
   #endif
   ATL_UINT vlen, mu, nu, ku, kb, nkblks, KB0, kb0, szC;

   ip->mu = mu = ATL_AMM_MUs[idx];
   ip->nu = nu = ATL_AMM_NUs[idx];
   ip->ku = ku = ATL_AMM_KUs[idx];
   ip->kb = kb = ATL_AMM_KBs[idx];
   ip->vlen = vlen = ATL_AMM_VLENs[idx];
   ip->lda = lda;
   ip->ldb = ldb;
   ip->ldc = ldc;

@ROUT ATL_GetAmmmInfo
   ip->mb = mb;
   ip->pmb = pmb;
   ip->nmu = mb / mu;
   ip->pnmu = pmb / mu;
   if (npmblks)
      ip->mF = M - nfmblks*mb - (npmblks-1)*pmb;
   else
      ip->mF = M - (nfmblks-1)*mb;
   ip->nmuF = (ip->mF+mu-1) / mu;

   ip->nb = nb;
   ip->pnb = pnb;
   ip->nnu = nb / nu;
   ip->pnnu = pnb / nu;
   if (npnblks)
      ip->nF = N - nfnblks*nb - (npnblks-1)*pnb;
   else
      ip->nF = N - (nfnblks-1)*nb;
   ip->nnuF = (ip->nF+nu-1) / nu;
@ROUT ATL_GetAmmmInfoSQ
   ip->mF = ip->nF = ip->mb = ip->nb = nb;
   ip->nfmblks = M / nb;
   ip->nfnblks = N / nb;
   ip->nnu = nb / nu;
   ip->nmu = nb / mu;
   kb0 = M - ip->nfmblks * nb;
   if (kb0)
   {
      ip->mF = kb0;
      ip->nmuF = ip->pnmu = (kb0+mu-1) / mu;
      ip->pmb = ip->pnmu * mu;
      ip->npmblks = 1;
   }
   else
   {
      ip->nmuF = ip->nmu;
      ip->pnmu = ip->pmb = ip->npmblks = 0;
   }
   kb0 = N - ip->nfnblks * nb;
   if (kb0)
   {
      ip->nF = kb0;
      ip->nnuF = ip->pnnu = (kb0+nu-1) / nu;
      ip->pnb = ip->pnnu * nu;
      ip->npnblks = 1;
   }
   else
   {
      ip->nnuF = ip->nnu;
      ip->pnnu = ip->pnb = ip->npnblks = 0;
   }

@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ

/*
 * Compute K remainder block, and how it affects kernel to use
 */
   nkblks = K / kb;
   KB0 = kb0 = K - nkblks*kb;
   ip->ammK1_b1 = ip->amm_b1 = ATL_AMM_KERN_b1[idx];
   ip->ammK1_b0 = ip->amm_b0 = ATL_AMM_KERN_b0[idx];  /* default case */
   #ifdef TCPLX
      ip->ONE = CONE;
      ip->ammK1_b1 = ip->amm_b1;
      ip->ammK1_bn = ip->amm_bn = ATL_AMM_KERN_bn[idx];
   #endif
   if (kb0)  /* K not a multiple of kb, need initial block */
   {
      if (ATL_AMM_KMAJOR(idx))
      {
         KB0 = ((kb0+vlen-1)/vlen)*vlen;
         if (KB0 != kb)
         {
            if (ATL_AMM_KRUNTIME(idx))
            {
               ATL_CUINT min=ATL_AMM_KBMINs[idx];
               if ((min && KB0 < min) || (KB0/ku)*ku != KB0)
                  ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
            }
            else
               ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
         }
      }
      else if (ATL_AMM_KRUNTIME(idx))
      {
         ATL_CUINT min=ATL_AMM_KBMINs[idx];
         if ((min && kb0 < min) || (kb0/ku)*ku != kb0 )
            ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
      }
      else if (kb0 != kb) /* compile-time K only works if kb=kb0 */
         ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];

      if (ip->ammK1_b0 != ip->amm_b0)
      {
         ip->ammK1_b1 = ATL_AMM_KERN_K1_b1[idx];
         #ifdef TCPLX
            ip->ammK1_bn = ATL_AMM_KERN_K1_bn[idx];
         #endif
      }
   }
   else
   {
      kb0 = KB0 = kb;
      nkblks--;
      ATL_assert(nkblks >= 0);
   }
   ip->KB0 = KB0;
   ip->kb0 = kb0;
   szC = ((mu*nu+vlen-1)/vlen)*vlen;
   szC *= ip->nnu * ip->nmu;
   ip->szC = szC;


   ip->alpA = ip->alpB = ip->alpC = CONE;
   if (M < N)  /* alpha goes on A or C */
   {
      if (M < K)
         ip->alpC = alpha;
      else
         ip->alpA = alpha;
   }
   else if (N < K)
      ip->alpC = alpha;
   else
      ip->alpB = alpha;
   if (SCALAR_IS_NONE(ip->alpA))
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_an[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_an[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_an[idx] : ATL_AMM_AN2BLK_an[idx];
   }
   else if (SCALAR_IS_ONE(ip->alpA))
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_a1[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_a1[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
   }
   else  /* alphaA = X */
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_aX[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_aX[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_aX[idx] : ATL_AMM_AN2BLK_aX[idx];
   }

   if (SCALAR_IS_NONE(ip->alpB))
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_an[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_an[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_an[idx] : ATL_AMM_BT2BLK_an[idx];
   }
   else if (SCALAR_IS_ONE(ip->alpB))
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_a1[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_a1[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
   }
   else  /* alphaB = X */
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_aX[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_aX[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_aX[idx] : ATL_AMM_BT2BLK_aX[idx];
   }

   if (SCALAR_IS_ONE(ip->alpC))
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_a1_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_a1_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ?
            ATL_AMM_BLK2C_a1_b0[idx] : ATL_AMM_BLK2C_a1_bX[idx];
   }
   else if (SCALAR_IS_NONE(ip->alpC))
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_an_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_an_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ?
            ATL_AMM_BLK2C_an_b0[idx] : ATL_AMM_BLK2C_an_bX[idx];
   }
   else /* alphaC = X */
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_aX_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_aX_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ?
            ATL_AMM_BLK2C_aX_b0[idx] : ATL_AMM_BLK2C_aX_bX[idx];
   }

   ip->nfkblks = nkblks;
   if (IS_COLMAJ(TA))
   {
      ip->incAk  = (kb SHIFT)*lda;
      ip->incAm  = (@(mb) SHIFT);
@ROUT ATL_GetAmmmInfo `      ip->pincAm = (p@(mb) SHIFT);`
@ROUT ATL_GetAmmmInfoSQ `      ip->pincAm = 0;`
   }
   else
   {
      ip->incAk  = (kb SHIFT);
      ip->incAm  = (@(mb) SHIFT)*lda;
@ROUT ATL_GetAmmmInfo `      ip->pincAm = (p@(mb) SHIFT)*lda;`
@ROUT ATL_GetAmmmInfoSQ `      ip->pincAm = 0;`
   }
   if (IS_COLMAJ(TB))
   {
      ip->incBk  = (kb SHIFT);
      ip->incBn  = (nb SHIFT)*ldb;
@ROUT ATL_GetAmmmInfo `      ip->pincBn = (pnb SHIFT)*ldb;`
@ROUT ATL_GetAmmmInfoSQ `      ip->pincBn = 0;`
   }
   else
   {
      ip->incBk  = (kb SHIFT)*ldb;
      ip->incBn  = (nb SHIFT);
@ROUT ATL_GetAmmmInfo `      ip->pincBn = (pnb SHIFT);`
@ROUT ATL_GetAmmmInfoSQ `      ip->pincBn = 0;`
   }
   ip->szA = @(mb)*kb;
   ip->szB = kb*nb;
@ROUT ATL_GetAmmmInfoSQ
   ip->pszA = ip->pmb*kb;
   ip->pszB = kb*ip->pnb;
@ROUT ATL_GetAmmmInfo
   ip->pszA = p@(mb)*kb;
   ip->pszB = kb*pnb;
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
}
#ifndef TCPLX
   #undef ONE
#endif

@ROUT ATL_GetAmmmInfo
int Mjoin(PATL,tGetIPInfo_tMN)
   (ipinfo_t *ip, int P, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, 
    size_t M, size_t N, size_t K, const SCALAR alpha, size_t lda, size_t ldb, 
    const SCALAR beta, size_t ldc)
{
   ATL_UINT idx, mb, nb, kb, mu, nu, nkblks;
/*
 * Eventually, scope all block factors, and find best predicted perf 
 * when scoping mu/nu cleanup.  Will be imprecise since diff kerns for diff
 * blockings, but better than present.  For now, assume large M/N, so use
 * largest kern.
 */
   idx = ATL_geAMM_NCASES-1;
//   idx = 0;   /* just for debugging */
   kb = ATL_AMM_KBs[idx];
   mu = ATL_AMM_MUs[idx];
   mb = ((M+mu-1)/mu)*mu;
   nu = ATL_AMM_NUs[idx];
   nb = ((N+nu-1)/nu)*nu;

   Mjoin(PATL,geFillInIPInfo)(ip, idx, TA, TB, M, N, K, lda, ldb, ldc,
                              alpha, beta, 1, 0, mb, 0, 1, 0, nb, 0);
   nb = ip->nfkblks + 1;
   P = Mmin(P, nb);
   #ifdef TREAL
      ATL_assert(ip->alpC == alpha);
   #else
      ATL_assert(ip->alpC[0] == alpha[0] && ip->alpC[1] == alpha[1]);
   #endif
   return(P);
}
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
/*
 * Given a selected amm index, fill in ipinfo for using inner-product based
 * amm loops
 */
void Mjoin(PATL,@(sh)ComputeIPInfo)
(
   ipinfo_t *ip,
   int idx,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   size_t M, 
   size_t N, 
   size_t K, 
   size_t lda,
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta 
)
{
   size_t npmblks, nmblks, npnblks, nnblks;
   ATL_UINT MB, NB, mb, nb, kb, mu, nu; 
@ROUT ATL_GetAmmmInfoSQ `   ATL_UINT U;`
   ATL_UINT maxMB=ATL_@(sh)AMM_LASTMB, maxNB=ATL_@(sh)AMM_LASTNB;

   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
@ROUT ATL_GetAmmmInfoSQ
   U = ATL_lcm(mu, nu);
   NB = nb = ATL_AMM_KBs[idx];
   Mjoin(PATL,sqFillInIPInfo)(ip, idx, TA, TB, M, N, K, lda, ldb, ldc, 
                              alpha, beta, nb);
/*
 * Eventually, we want ability to expand MB/NB past kb (kb fixed by idx)
 * when operands don't even fill L1, but don't do this now;  Some square
 * routines may need KB=MB, and then this would fail
 */
   #if 0
   if (nb*nb < ATL_L1elts)   /* one operand fits in L1 */
   {                         /* expand to fill L1 */
      if ((nb+nb)*nb < ATL_L1elts)  /* fitting A & B into L1 */
         NB = (ATL_L1elts/nb)>>1;
      else
         NB = (ATL_l1elts/nb);
   }
   #endif

@ROUT ATL_GetAmmmInfo
   mb = ATL_AMM_MBs[idx];
   nb = ATL_AMM_NBs[idx];
   kb = ATL_AMM_KBs[idx];
/*
 * Compute M and N blocking factors to use
 */
   if ((mb+nb)*kb < ATL_L1elts)  /* fitting A & B into L1 */
      maxNB = maxMB = (ATL_L1elts/kb)>>1;
   else if (nb*kb < ATL_L1elts)  /* fitting only B */
   {
      maxMB = mb;
      maxNB = ATL_L1elts / kb;
   }

   MB = ATL_CompBlkPart(M, maxMB, mb, mu, &mb, &npmblks, &nmblks);
   NB = ATL_CompBlkPart(N, maxNB, nb, nu, &nb, &npnblks, &nnblks);
   ip->npmblks = npmblks;
   ip->nfmblks = nmblks;
   ip->npnblks = npnblks;
   ip->nfnblks = nnblks;
   if (!nmblks)  /* all blks small */
      MB = mb;
   if (!nnblks) /* all blks small */
      NB = nb;
   Mjoin(PATL,@(sh)FillInIPInfo)(ip, idx, TA, TB, M, N, K, lda, ldb, ldc,
                            alpha, beta, nmblks, npmblks, MB, mb, 
                            nnblks, npnblks, NB, nb);
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
}

@beginskip
{
   ATL_UINT ku, kb, kb0, KB0, MB, NB, mb, nb, mu, nu, vlen;
   size_t k, nkblks, npmblks, nmblks, npnblks, nnblks;
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else 
      #define CONE ATL_rone
   #endif
   int szC, maxNB=ATL_@(sh)AMM_LASTNB, maxMB=ATL_@(sh)AMM_LASTMB;
   
@ROUT ATL_GetAmmmInfoSQ
   ip->kb = mb = nb = kb = ATL_AMM_KBs[idx];
@ROUT ATL_GetAmmmInfo
   mb = ATL_AMM_MBs[idx];
   nb = ATL_AMM_NBs[idx];
@skip   ip->kb = kb = ATL_AMM_KBs[idx];
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
   ip->mu = mu = ATL_AMM_MUs[idx];
   ip->nu = nu = ATL_AMM_NUs[idx];
   ip->ku = ku = ATL_AMM_KUs[idx];
   vlen = ip->vlen = ATL_AMM_VLENs[idx];
   ip->lda = lda;
   ip->ldb = ldb;
   ip->ldc = ldc;
/*
 * Compute K remainder block, and how it affects kernel to use
 */
   nkblks = K / kb;
   KB0 = kb0 = K - nkblks*kb;
   ip->amm_b1 = ATL_AMM_KERN_b1[idx];
   ip->ammK1_b0 = ATL_AMM_KERN_b0[idx];  /* default case */
   #ifdef TCPLX
      ip->ONE = CONE;
      ip->amm_b0 = ip->ammK1_b0;
      ip->ammK1_b1 = ip->amm_b1;
      ip->ammK1_bn = ip->amm_bn = ATL_AMM_KERN_bn[idx];
   #endif
   if (kb0)  /* K not a multiple of kb, need initial block */
   {
      if (ATL_AMM_KMAJOR(idx))
      {
         KB0 = ((kb0+vlen-1)/vlen)*vlen;
         if (KB0 != kb)
         {
            if (ATL_AMM_KRUNTIME(idx))
            {
               ATL_CUINT min=ATL_AMM_KBMINs[idx];
               if ((min && KB0 < min) || (KB0/ku)*ku != KB0)
                  ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
            }
            else
               ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
         }
      }
      else if (ATL_AMM_KRUNTIME(idx))
      {
         ATL_CUINT min=ATL_AMM_KBMINs[idx];
         if ((min && kb0 < min) || (kb0/ku)*ku != kb0 )
            ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];
      }
      else if (kb0 != kb) /* compile-time K only works if kb=kb0 */
         ip->ammK1_b0 = ATL_AMM_KERN_K1_b0[idx];

   #ifdef TCPLX
      if (ip->ammK1_b0 != ip->amm_b0)
      {
         ip->ammK1_b1 = ATL_AMM_KERN_K1_b1[idx];
         ip->ammK1_bn = ATL_AMM_KERN_K1_bn[idx];
      }
   #endif
   }
   else
   {
      kb0 = KB0 = kb;
      nkblks--;
      ATL_assert(nkblks >= 0);
   }
   ip->KB0 = KB0;
   ip->kb0 = kb0;
/*
 * Compute M and N blocking factors to use
 */
   if ((mb+nb)*kb < ATL_L1elts)  /* fitting A & B into L1 */
      maxNB = maxMB = (ATL_L1elts/kb)>>1;
   else if (nb*kb < ATL_L1elts)  /* fitting only B */
   {
      maxMB = mb;
      maxNB = ATL_L1elts / kb;
   }

@ROUT ATL_GetAmmmInfoSQ
   if (!M)      /* requires N=M  (SYRK/SYR2K) */
   {
      if (mu == nu)
      {
         MB = NB = ATL_CompBlkPart(N, maxNB, nb, nu, &nb, &npnblks, &nnblks);
         npmblks = npnblks;
         nmblks = nnblks;
      }
      else
      {
         NB = nb;
         nnblks = (N/nb);
         nb = N - nnblks*nb;
         npnblks = (nb) ? 1 : 0;
      }
   }
   else if (!K) /* requires N=K  (TRSM/TRMM/SYMM, 'Right' */
   {
      MB = ATL_CompBlkPart(M, maxMB, mb, mu, &mb, &npmblks, &nmblks);
      npnblks = (kb0 != kb);
      nnblks = nkblks + 1 - npnblks;
      NB = kb;
      nb = kb0;
   }
   else if (!N) /* requires M=K  (TRSM/TRMM/SYMM, 'Left' */
   {
      NB = ATL_CompBlkPart(N, maxNB, nb, nu, &nb, &npnblks, &nnblks);
      npmblks = (kb0 != kb);
      nmblks = nkblks + 1 - npmblks;
      MB = kb;
      mb = kb0;
   }
@ROUT ATL_GetAmmmInfo
   MB = ATL_CompBlkPart(M, maxMB, mb, mu, &mb, &npmblks, &nmblks);
   NB = ATL_CompBlkPart(N, maxNB, nb, nu, &nb, &npnblks, &nnblks);
@ROUT ATL_GetAmmmInfo ATL_GetAmmmInfoSQ
   ip->npmblks = npmblks;
   ip->nfmblks = nmblks;
   ip->npnblks = npnblks;
   ip->nfnblks = nnblks;
   if (!nmblks)  /* all blks small */
   {
      ip->mb = ip->pmb = MB = mb;
      ip->nmu = ip->pnmu = mb / mu;
      ip->mF = M - (npmblks-1)*mb;
   }
   else
   {
      int b;
      ip->mb  = MB;
      ip->pmb = mb;
      ip->nmu = MB / mu;
      ip->pnmu = mb / mu;
      b = (npmblks) ? mb : MB;
      ip->mF = M + b - nmblks*MB - npmblks*mb;
   }
   ip->nmuF = ((ip->mF+mu-1)/mu);
   if (!nnblks) /* all blks small */
   {
      ip->nb = ip->pnb = NB = nb;
      ip->nnu = ip->pnnu = nb / nu;
      ip->nF = N - (npnblks-1)*nb;
   }
   else
   {
      int b;
      ip->nb  = NB;
      ip->nnu = NB / nu;
      ip->pnb = nb;
      ip->pnnu = nb / nu;
      b = (npnblks) ? nb : NB;
      ip->nF = N + b - nnblks*NB - npnblks*nb;
   }
   ip->nnuF = ((ip->nF+nu-1)/nu);
   szC = ((mu*nu+vlen-1)/vlen)*vlen;
   szC *= ip->nnu * ip->nmu;
   ip->szC = szC;


   ip->alpA = ip->alpB = ip->alpC = CONE;
   if (M < N)  /* alpha goes on A or C */
   {
      if (M < K)
         ip->alpC = alpha;
      else
         ip->alpA = alpha;
   }
   else if (N < K)
      ip->alpC = alpha;
   else 
      ip->alpB = alpha;
   if (SCALAR_IS_NONE(ip->alpA))
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_an[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_an[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ? 
            ATL_AMM_AT2BLK_an[idx] : ATL_AMM_AN2BLK_an[idx];
   }
   else if (SCALAR_IS_ONE(ip->alpA))
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_a1[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_a1[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ? 
            ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
   }
   else  /* alphaA = X */
   {
      #ifdef TCPLX
      if (TA == AtlasConjTrans)
         ip->a2blk = ATL_AMM_AC2BLK_aX[idx];
      else if (TA == AtlasConj)
         ip->a2blk = ATL_AMM_AH2BLK_aX[idx];
      else
      #endif
         ip->a2blk = (TA == AtlasNoTrans) ? 
            ATL_AMM_AT2BLK_aX[idx] : ATL_AMM_AN2BLK_aX[idx];
   }

   if (SCALAR_IS_NONE(ip->alpB))
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_an[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_an[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ? 
            ATL_AMM_BN2BLK_an[idx] : ATL_AMM_BT2BLK_an[idx];
   }
   else if (SCALAR_IS_ONE(ip->alpB))
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_a1[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_a1[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ? 
            ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
   }
   else  /* alphaB = X */
   {
      #ifdef TCPLX
      if (TB == AtlasConjTrans)
         ip->b2blk = ATL_AMM_BH2BLK_aX[idx];
      else if (TB == AtlasConj)
         ip->b2blk = ATL_AMM_BC2BLK_aX[idx];
      else
      #endif
         ip->b2blk = (TB == AtlasNoTrans) ? 
            ATL_AMM_BN2BLK_aX[idx] : ATL_AMM_BT2BLK_aX[idx];
   }

   if (SCALAR_IS_ONE(ip->alpC))
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_a1_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_a1_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ? 
            ATL_AMM_BLK2C_a1_b0[idx] : ATL_AMM_BLK2C_a1_bX[idx];
   }
   else if (SCALAR_IS_NONE(ip->alpC))
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_an_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_an_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ? 
            ATL_AMM_BLK2C_an_b0[idx] : ATL_AMM_BLK2C_an_bX[idx];
   }
   else /* alphaC = X */
   {
      ip->blk2c_b1 = ATL_AMM_BLK2C_aX_b1[idx];
      if (SCALAR_IS_NONE(beta))
         ip->blk2c = ATL_AMM_BLK2C_aX_bn[idx];
      else if (SCALAR_IS_ONE(beta))
         ip->blk2c = ip->blk2c_b1;
      else
         ip->blk2c = (SCALAR_IS_ZERO(beta)) ? 
            ATL_AMM_BLK2C_aX_b0[idx] : ATL_AMM_BLK2C_aX_bX[idx];
   }

   ip->nfkblks = nkblks;
   if (IS_COLMAJ(TA))
   {
      ip->incAk  = (kb SHIFT)*lda;
      ip->incAm  = (MB SHIFT);
      ip->pincAm = (mb SHIFT);
   }
   else
   {
      ip->incAk  = (kb SHIFT);
      ip->incAm  = (MB SHIFT)*lda;
      ip->pincAm = (mb SHIFT)*lda;
   }
   if (IS_COLMAJ(TB))
   {
      ip->incBk  = (kb SHIFT);
      ip->incBn  = (NB SHIFT)*ldb;
      ip->pincBn = (nb SHIFT)*ldb;
   }
   else
   {
      ip->incBk  = (kb SHIFT)*ldb;
      ip->incBn  = (NB SHIFT);
      ip->pincBn = (nb SHIFT);
   }
   ip->pszA = mb*kb;
   ip->szA = MB*kb;
   ip->pszB = kb*nb;
   ip->szB = kb*NB;
}
#ifndef TCPLX
   #undef ONE
#endif
@endskip

@ROUT ATL_GetAmmmInfo
@beginskip
#define NOPERF 1
#include "atlas_dpmnamm_degen.h"
#undef NOPERF
static double SyrkTimeKpan
   (int id, ATL_UINT flg, size_t N, size_t K, double symul)
/* 
 * NOTE: replace symul wt timings eventually
 */
{
}

int Mjoin(PATL,GetSyrkInfo)  /* returns nb */
(
   amminfo_t *out,
   int ialp,             /* 1:alpha=1.0, -1:-1.0, else alpha=X */
   enum ATLAS_TRANS TA,
   ATL_CSZT N,           /* size of triangular matrix */
   ATL_CSZT K,           /* K dim of A/A^T */
   int ibet              /* 0:beta=0.0 1:beta=1.0, -1:-1.0, else beta=X */
)
{
   unsigned int kb, nb, idx = ATL_pmnAMM_NCASES-1, gidx;
   if (K < ATL_pmnAMM_MAXKB) /* handled by outprod view eventually */
   {                         /* for now, accept any kern that works */
      for (i=ATL_pmnAMM_NCASES-1; i >= 0; i--)
      {
         idx = i;
         if (ATL_pmnAMM_KBs[i] <= K)
            break;
      }
      kb = ATL_pmnAMM_KBs[i];
      if (N < ATL_pmnAMM_NBs[i])
      {
         unsigned int U;
         gidx = ATL_AMM_KIDX[i];
         U = ATL_lcm(ATL_AMM_MUs[gidx], ATL_AMM_MUs[gidx]);
         nb = ((N+U-1)/U)*U;
      }
   }
   else  /* choose kern to use by N, not K */
   {
      for (i=0; i < ATL_pmnAMM_NCASES;
      kb = ATL_pmnAMM_KBs[idx];
   }
}
int Mjoin(PATL,tGetSyrkInfo)
/*
 * RETURNS: bitvec: 0:use PRV ac; 1:use PUB ac,
 */
(
   amminfo_t *out,
   int ialp,             /* 1:alpha=1.0, -1:-1.0, else alpha=X */
   enum ATLAS_TRANS TA,
   ATL_CSZT N,           /* size of triangular matrix */
   ATL_CSZT K,           /* K dim of A/A^T */
   int ibet,             /* 0:beta=0.0 1:beta=1.0, -1:-1.0, else beta=X */
   int *P0,              /* number of threads to use */
   int *NKSHAR,
)
{
   unsigned int idx=ATL_pmnAMM_NCASES-1; /* not amm idx yet */
   unsigned int P=*P0, nkshar=0, i;

   if (K < ATL_pmnAMM_MAXKB) /* handled by outprod view eventually */
   {                         /* for now, accept any kern that works */
       for (i=ATL_pmnAMM_NCASES-1; i >= 0; i--)
       {
          idx = ATL_AMM_KIDX[i];
          if (ATL_pmnAMM_KBs[i] 
       }
   }
   if (P*(size_t)ATL_pmnAMM_MAXNB > N) /* N may not provide full scale */
   {
      if (P*(size_t)ATL_pmnAMM_MAXKB
   }

   *P0 = P;
   *NKSHAR = nkshar;
}
@endskip
@ROUT ATL_GetRankKInfo
@beginskip
static INLINE int ATL_ComputeB   /* RETURNS: selected blocking */
(
   size_t N,   /* problem dimension */
   int nu,     /* unrolling by kernel on this dim */
   int nb,     /* IN: large-case blocking */
   size_t *NS, /* OUT: # of blks of size NB-nu to perform */
   size_t *NT  /* OUT: # of blks to perform */
)
{
   size_t ns, nt, nblks, NN;
/*
 * If the entire problem is less than or equal to the unrolling, choose a block
 * of the ceiling of the unrolling and only do one
 */
   NN=((N+nu-1)/nu)*nu;  /* ceiling of number of unrollings in N */
   if (NN <= nu)
   {
      *NS = 0;
      *NT = 1;
      return(NN);
   }
/*
 * If suggested block size is smaller or same as unrolling, then the blocking
 * size is the unrolling, and we don't have an NB-nu sized-blocks, since that
 * would be zero sized
 */
   if (nb <= nu)
   {
      *NS = 0;
      *NT = NN/nu;
      return(nu);
   }

   nb = (nb/nu)*nu;      /* floor of number of unrollings in a block*/
/*
 * If 1 block is within NU of covering the entire dim, just make the
 * block size the entire dim
 */
   if (nb+nu >= NN)
   {
      *NS = 0;
      *NT = 1;
      return(NN);
   }
/*
 * Otherwise, compute how many blocks we need of each type
 */
   while(1)
   {
      nblks = (N+nb-1)/nb;
      ns = (nblks*nb - NN)/nu;
      if (ns < nblks)
         break;
      nb -= nu;
   }

   *NS = ns;
   *NT = nblks;
   return(nb);
}
@endskip

#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
static INLINE void FillInRankKInf
   (rkinfo_t *out, int idx, enum ATLAS_TRANS TA, enum ATLAS_TRANS TB, 
    ATL_CSZT M, ATL_CSZT N, ATL_CSZT K, size_t lda, size_t ldb, size_t ldc,
    const SCALAR alpha, const SCALAR beta, 
    size_t nfmblks, size_t npmblks, int mb, int pmb,
    size_t nfnblks, size_t npnblks, int nb, int pnb)
{

   #if ATL_rkAMM_MAXKVEC == 0
      const unsigned int kb = K;
   #else
      int unsigned kb = K;
   #endif
   const unsigned int mu=ATL_AMM_MUs[idx], nu=ATL_AMM_NUs[idx];
   const unsigned int ku=ATL_AMM_KUs[idx], vlen=ATL_AMM_VLENs[idx];
   unsigned int sz, nmu, nnu;
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      #define CONE ATL_rone
   #endif

   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   out->nfmblks = nfmblks;
   out->npmblks = npmblks;
   out->mb = mb;
   out->pmb = pmb;
   out->nfnblks = nfnblks;
   out->npnblks = npnblks;
   out->nb = nb;
   out->pnb = pnb;
   out->mu = mu;
   out->nu = nu;
   out->ku = ku;
   out->vlen = vlen;
   out->lda = lda;
   out->ldb = ldb;
   out->ldc = ldc;

   out->nmu = mb / mu;
   out->pnmu = pmb / mu;
   out->nnu = nb / nu;
   out->pnnu = pnb / nu;
   if (npmblks)
   {
      out->mF = M - nfmblks*mb - (npmblks-1)*pmb;
      out->nmuF = (out->mF+mu-1) / mu;
   }
   else
      out->nmuF = out->mF = 0;
   if (npnblks)
   {
      out->nF = N - nfnblks*nb - (npnblks-1)*pnb;
      out->nnuF = (out->nF+nu-1) / nu;
   }
   else
      out->nnuF = out->nF = 0;
   sz = ((mu*nu+vlen-1)/vlen)*vlen;
   sz *= (out->nmu) ? out->nmu : out->pnmu;
   sz *= (out->nnu) ? out->nnu : out->pnnu;
   out->szC = sz;
   out->idx = idx;
   out->amm_b0 = ATL_AMM_KERN_b0[idx];
   #ifdef TCPLX
      out->amm_b1 = ATL_AMM_KERN_b1[idx];
      out->amm_bn = ATL_AMM_KERN_bn[idx];
   #endif
   out->kb = K;
   out->KB = kb;
   out->lda = lda;
   out->ldb = ldb;
   out->ldc = ldc;
   out->pszA = pmb*kb;
   out->szA = kb * ((mb) ? mb:pmb);
   out->pszB = kb*pnb;
   out->szB = kb * ((nb) ? nb:pnb);
   out->alpA = out->alpB = CONE;
   out->beta = beta;
   #ifdef TCPLX
      out->ONE = CONE;
   if (TA == AtlasNoTrans || TA == AtlasConj)
   #else
   if (TA == AtlasNoTrans)
   #endif
   {
      out->incAm  = mb SHIFT;
      out->pincAm = pmb SHIFT;
   }
   else
   {
      out->incAm = lda*(mb SHIFT);
      out->pincAm = lda*(pmb SHIFT);
   }
   #ifdef TCPLX
   if (TB == AtlasNoTrans || TB == AtlasConj)
   #else
   if (TB == AtlasNoTrans)
   #endif
   {
      out->incBn = ldb*(nb SHIFT);
      out->pincBn = ldb*(pnb SHIFT);
   }
   else
   {
      out->incBn  = nb SHIFT;
      out->pincBn = pnb SHIFT;
   }
/*
 * Once we have ATL_ammmN written, put alpha on A if there's only 1 blk of
 * of B.  For now, always put on B and use ATL_ammmM
 */
   #if 0
   if (nnblks > 1 && nmblks < 2) /* If we only have row panel of C */
   {                             /* apply alpha to A */
      #ifdef TCPLX
         if (TB == AtlasNoTrans)
            out->b2blk = ATL_AMM_BN2BLK_a1[idx];
         else if (TB == AtlasTrans)
            out->b2blk = ATL_AMM_BT2BLK_a1[idx];
         else
            out->b2blk = (TB == AtlasConjTrans) ?
               ATL_AMM_BH2BLK_a1[idx] : ATL_AMM_BC2BLK_a1[idx];

         if (SCALAR_IS_ONE(alpha))
         {
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_a1[idx];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_a1[idx];
            else
               out->a2blk = (TA == AtlasConjTrans) ?
                  ATL_AMM_AC2BLK_a1[idx] : ATL_AMM_AH2BLK_a1[idx];
         }
         else if (SCALAR_IS_NONE(alpha))
         {
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_an[idx];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_an[idx];
            else
               out->a2blk = (TA == AtlasConjTrans) ?
                  ATL_AMM_AC2BLK_an[idx] : ATL_AMM_AH2BLK_an[idx];
         }
         else
         {
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_aX[idx];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_aX[idx];
            else
               out->a2blk = (TA == AtlasConjTrans) ?
                  ATL_AMM_AC2BLK_aX[idx] : ATL_AMM_AH2BLK_aX[idx];
         }
      #else
         out->b2blk = (TB == AtlasNoTrans) ?
                      ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
         if (SCALAR_IS_ONE(alpha))
            out->a2blk = (TA == AtlasNoTrans) ?
                      ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
         else if (SCALAR_IS_NONE(alpha))
            out->a2blk = (TA == AtlasNoTrans) ?
                      ATL_AMM_AT2BLK_an[idx] : ATL_AMM_AN2BLK_an[idx];
         else
            out->a2blk = (TA == AtlasNoTrans) ?
                      ATL_AMM_AT2BLK_aX[idx] : ATL_AMM_AN2BLK_aX[idx];
      #endif
   }
   else  /* apply alpha to B */
   #endif
   {
      out->alpB = alpha;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = ATL_AMM_AT2BLK_a1[idx];
         else if (TA == AtlasTrans)
            out->a2blk = ATL_AMM_AN2BLK_a1[idx];
         else
            out->a2blk = (TA == AtlasConjTrans) ?
               ATL_AMM_AC2BLK_a1[idx] : ATL_AMM_AH2BLK_a1[idx];

         if (SCALAR_IS_ONE(alpha))
         {
            if (TB == AtlasNoTrans)
               out->b2blk = ATL_AMM_BN2BLK_a1[idx];
            else if (TB == AtlasTrans)
               out->b2blk = ATL_AMM_BT2BLK_a1[idx];
            else
               out->b2blk = (TB == AtlasConjTrans) ?
                  ATL_AMM_BH2BLK_a1[idx] : ATL_AMM_BC2BLK_a1[idx];
         }
         else if (SCALAR_IS_NONE(alpha))
         {
            if (TB == AtlasNoTrans)
               out->b2blk = ATL_AMM_BN2BLK_an[idx];
            else if (TB == AtlasTrans)
               out->b2blk = ATL_AMM_BT2BLK_an[idx];
            else
               out->b2blk = (TB == AtlasConjTrans) ?
                  ATL_AMM_BH2BLK_an[idx] : ATL_AMM_BC2BLK_an[idx];
         }
         else
         {
            if (TB == AtlasNoTrans)
               out->b2blk = ATL_AMM_BN2BLK_aX[idx];
            else if (TB == AtlasTrans)
               out->b2blk = ATL_AMM_BT2BLK_aX[idx];
            else
               out->b2blk = (TB == AtlasConjTrans) ?
                  ATL_AMM_BH2BLK_aX[idx] : ATL_AMM_BC2BLK_aX[idx];
         }
      #else
         out->a2blk = (TA == AtlasNoTrans) ?
                      ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
         if (SCALAR_IS_ONE(alpha))
            out->b2blk = (TB == AtlasNoTrans) ?
                      ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
         else if (SCALAR_IS_NONE(alpha))
            out->b2blk = (TB == AtlasNoTrans) ?
                      ATL_AMM_BN2BLK_an[idx] : ATL_AMM_BT2BLK_an[idx];
         else
            out->b2blk = (TB == AtlasNoTrans) ?
                      ATL_AMM_BN2BLK_aX[idx] : ATL_AMM_BT2BLK_aX[idx];
      #endif
   }
   if (SCALAR_IS_NONE(beta))
      out->blk2C = ATL_AMM_BLK2C_a1_bn[idx];
   else if (SCALAR_IS_ONE(beta))
      out->blk2C = ATL_AMM_BLK2C_a1_b1[idx];
   else
      out->blk2C = (SCALAR_IS_ZERO(beta)) ?
         ATL_AMM_BLK2C_a1_b0[idx] : ATL_AMM_BLK2C_a1_bX[idx];
}

int Mjoin(PATL,tGetRKInfo_tK)
(
   rkinfo_t *out,
   int P,                   /* max number of cores to use */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   size_t lda, 
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
{
   #if ATL_rkAMM_MAXKVEC == 0
      const int kb = K;
   #else
      int kb=K;
   #endif
   ATL_UINT idx, mb, nb, MB, NB, mu, nu, ku, vlen, szC;
   size_t npmblks, nfmblks, npnblks, nfnblks;

   ATL_assert(K <= ATL_rkAMM_LASTKB && K > 2);
   idx = K-3;
   ku = ATL_AMM_KUs[idx];
   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   mb = ATL_AMM_MBs[idx];
   nb = ATL_AMM_NBs[idx];
   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
/*
 * Calculate M blocking; for now, just use default mb/nb, assume full ||
 */
   nfmblks = M / mb;
   MB = mb;
   if (nfmblks)
   {
      mb = M - nfmblks*MB;
      if (mb)
      {
         npmblks = 1;
         mb = ((mb+mu-1)/mu)*mu;
      }
      else
         npmblks = 0;
   }
   else
   {
      MB = 0;
      mb = ((M+mu-1)/mu)*mu;
      npmblks = 1;
   }
   nfnblks = N / nb;
   NB = nb;
   if (nfnblks)
   {
      nb = N - nfnblks*NB;
      if (nb)
      {
         npnblks = 1;
         nb = ((nb+nu-1)/nu)*nu;
      }
      else
         npnblks = 0;
   }
   else
   {
      NB = 0;
      nb = ((N+nu-1)/nu)*nu;
      npnblks = 1;
   }
   FillInRankKInf(out, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta,
                  nfmblks, npmblks, MB, mb, nfnblks, npnblks, NB, nb);
   {
      double flwant, flgot;
      size_t nblks;

      nblks = nfmblks * nfnblks;
      P = Mmin(P, nblks);
      flwant = (((double)ATL_rkAMM_66MB)*ATL_rkAMM_66NB)*ATL_rkAMM_66KB;
      flgot = ((((double)M)*N)*K);
      nblks = flgot / flwant;
      P = Mmin(P, nblks);
   }
   return(P);
}
int Mjoin(PATL,tGetRKInfo_tNK)
(
   rkinfo_t *out,
   int P,                   /* max number of cores to use */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   size_t lda, 
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
{
   #if ATL_rkAMM_MAXKVEC == 0
      const int kb = K;
   #else
      int kb=K;
   #endif
   ATL_UINT idx, mb, nb, MB, NB, mu, nu, ku, vlen, szC;
   size_t npmblks, nfmblks, npnblks, nfnblks;

   ATL_assert(K <= ATL_rkAMM_LASTKB && K > 2);
   idx = K-3;
   ku = ATL_AMM_KUs[idx];
   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   mb = ATL_AMM_MBs[idx];
   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
   nb = ((N+nu-1)/nu)*nu;
   if (nb != N)
   {
      NB = nfnblks = 0;
      npnblks = 1;
   }
   else
   {
      NB = nb;
      nfnblks = 1;
      nb = npnblks = 0;
   }
   nfmblks = M / mb;
   if (nfmblks < P) /* scope reducing mb for greater parallelism */
   {
      P = nfmblks;  /* for now, just reduce parallelism */
   }
   #if 0  // don't adjust mb until initial debug is done
/*
 * If there's enough parallelism, consider increasing mb
 */
   else if (nfmblks >= P+P && mb < ATL_rkAMM_LASTMB)
   {
      if (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts) /* keep it in L1 */
      {                                           /* if it presently fits */
         do 
         {
            mb += mu;
         }
         while (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts);
         mb -= mu;
      }
      else  /* if L1 exceeded, maximize MB to min # of times B is flushed */
         mb = ((ATL_rkAMM_LASTMB+mu-1)/mu)*mu;
   }
   #endif
   MB = mb;
   nfmblks = M / MB;
   if (nfmblks)
   {
      mb = M - nfmblks*MB;
      if (mb)
      {
         npmblks = 1;
         mb = ((mb+mu-1)/mu)*mu;
      }
      else
         npmblks = 0;
   }
   else
   {
      MB = 0;
      mb = ((M+mu-1)/mu)*mu;
      npmblks = 1;
   }
   FillInRankKInf(out, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta,
                  nfmblks, npmblks, MB, mb, nfnblks, npnblks, NB, nb);
   return(P);
}

void Mjoin(PATL,GetSyrkOP)
(
   rkinfo_t *out,           /* what to use for K-cleanup */
   int flag,                /* bit 0: if set, only block & remainder */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT N,
   ATL_CSZT K,
   size_t lda, 
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
{
   size_t nfnblks, npnblks;
   int idx=K-3, mu, nu, ku, nb, pnb, pmb, kb, Umn, nr;

/*
 * if we've only got one block of C, entire problem will be done by SYRK,
 * so just return bogus info so it works
 */
   if (N < Mmin(ATL_rkAMM_LASTNB,ATL_rkAMM_LASTMB))
   {
      FillInRankKInf(out, 0, TA, TB, N, N, K, lda, lda, ldc, alpha, beta,
                     0, 1, 0, N, 0, 1, 0, N);
      return;
   }
   ATL_assert(K <= ATL_rkAMM_LASTKB && K > 2);
   ku = ATL_AMM_KUs[idx];
   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
   Umn = ATL_lcm(mu, nu);
   nb = ((K+Umn-1)/Umn)*Umn;
   if (nb > Mmin(ATL_rkAMM_LASTNB,ATL_rkAMM_LASTMB) && nb > Umn)
      nb -= Umn;
   nfnblks = N / nb;
   nr = N - nfnblks*nb;
   if (nr)
   {
      npnblks = 1;
      pmb = ((nr+mu-1)/mu)*mu;
      pnb = ((nr+nu-1)/nu)*nu;
   }
   else 
      pmb = pnb = npnblks = 0;
   FillInRankKInf(out, idx, TA, TB, N, N, K, lda, lda, ldc, alpha, beta,
                  nfnblks, npnblks, nb, pmb, nfnblks, npnblks, nb, pnb);
}
void Mjoin(PATL,GetRKInfo)
(
   rkinfo_t *out,           /* what to use for K-cleanup */
   int flag,                /* bit 0: if set, only block & remainder */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   size_t lda, 
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
{
   #if ATL_rkAMM_MAXKVEC == 0
      const int kb = K;
   #else
      int kb=K;
   #endif
   ATL_UINT idx, mb, nb, MB, NB, NMU, NNU, nmu, nnu, mu, nu, ku, vlen, szC;
   size_t npmblks, nfmblks, npnblks, nfnblks;

   ATL_assert(K <= ATL_rkAMM_LASTKB && K > 2);
   idx = K-3;
   out->ku = ku = ATL_AMM_KUs[idx];
   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
   mb = ATL_AMM_MBs[idx];
   nb = ATL_AMM_NBs[idx];
   mu = ATL_AMM_MUs[idx];
   nu = ATL_AMM_NUs[idx];
/*
 * If 4 operands (C, wC, A, B) all fit in L1, use small, near-square shapes.
 * otherwise, use MB/NB from largest KB, which we know fits in some level
 * of cache.  Using larger M/N will tend to minimize function call overhead,
 * and shouldn't have much negative effect once L1 is overflowed.
 */
   if (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts)
   {
      MB = mb;
      NB = nb;
      while (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts && (mb < M || nb < N))
      {
         MB = mb;
         NB = nb;
         if (nb >= N || (mb <= nb && mb < M))
            mb += mu;
         else if (nb < N)
            nb += nu;
      }
      nfmblks = M / MB;
      if (nfmblks)
      {
         mb = ((M - MB*nfmblks + mu-1)/mu)*mu;
         npmblks = (mb) ? 1 : 0;
      }
      else
      {
         MB = 0;
         mb = ((M+mu-1)/mu)*mu;
         npmblks = 1;
      }
      nfnblks = N / NB;
      if (nfnblks)
      {
         nb = ((N - NB*nfnblks + nu-1)/nu)*nu;
         npnblks = (nb) ? 1 : 0;
      }
      else
      {
         NB = 0;
         nb = ((N+nu-1)/nu)*nu;
         npnblks = 1;
      }
   }
/*
 * If we don't fit in cache, start with assumption we'll use largest M/N blk,
 * but if the remainder block is very small, while the initial blks are large,
 * try to rebalance (if allowed by flag).
 */
   else
   {
      if (ATL_rkAMM_LASTMB > M)  /* only 1 blk in M dim */
      {
         nmu = (M+mu-1)/mu;
         mb = nmu*mu;
         if (mb == M)
         {
            MB = mb;
            nfmblks = 1;
            npmblks = mb = 0;
         }
         else
         {
            MB = nfmblks = 0;
            npmblks = 1;
         }
      }
      else                      /* at least one M blk */
      {
         NMU = ATL_rkAMM_LASTMB / mu;
         MB = NMU*mu;
         nfmblks = M / MB;
         mb = M - nfmblks*MB;
         if (mb)
         {
            int b = ATL_AMM_MBs[idx];
            nmu = (mb+mu-1)/mu;
            if (nmu < 4 && b >= nmu*mu && (flag&1)==0 && NMU > 5)
            {
               MB = ATL_CompBlkPart(M, MB, b, mu, &mb, &npmblks, &nfmblks);
               if (!npmblks && M != nfmblks*MB)
               {
                  MB = (--nfmblks) ? MB : 0;
                  npmblks = 1;
                  mb = ((M - nfmblks*MB + mu-1)/mu)*mu;
               }
            }
            else
            {
               npmblks = 1;
               mb = nmu*mu;
            }
         }
         else
            npmblks = 0;

      }
      if (ATL_rkAMM_LASTNB > N)  /* only 1 blk in N dim */
      {
         nnu = (N+nu-1)/nu;
         nb = nnu*nu;
         if (nb == N)
         {
            NB = nb;
            nfnblks = 1;
            npnblks = nb = 0;
         }
         else
         {
            NB = nfnblks = 0;
            npnblks = 1;
         }
      }
      else                      /* at least one M blk */
      {
         NNU = ATL_rkAMM_LASTNB / nu;
         NB = NNU*nu;
         nfnblks = N / NB;
         nb = N - nfnblks*NB;
         if (nb)
         {
            int b = ATL_AMM_NBs[idx];
            nnu = (nb+nu-1)/nu;
            if (nnu < 4 && b >= nnu*nu && (flag&1)==0 && NNU > 5)
            {
               NB = ATL_CompBlkPart(N, NB, b, nu, &nb, &npnblks, &nfnblks);
               if (!npnblks && N != nfnblks*NB)
               {
                  NB = (--nfnblks) ? NB : 0;
                  npnblks = 1;
                  nb = ((N - nfnblks*NB + nu-1)/nu)*nu;
               }
            }
            else
            {
               npnblks = 1;
               nb = nnu*nu;
            }
         }
         else
            npnblks = 0;
      }
   }
   FillInRankKInf(out, idx, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta, 
                  nfmblks, npmblks, MB, mb, nfnblks, npnblks, NB, nb);
@beginskip
   ATL_UINT maxMB=ATL_rkAMM_LASTMB, maxNB=ATL_rkAMM_LASTNB;
   #ifdef TCPLX
      static const TYPE CONE[2] = {ATL_rone, ATL_rzero};
   #else
      #define CONE ATL_rone
   #endif

   ATL_assert(K <= ATL_rkAMM_LASTKB && K > 2);
   idx = K-3;
   out->ku = ku = ATL_AMM_KUs[idx];
   #if ATL_rkAMM_MAXKVEC > 0
      if (ATL_AMM_KMAJOR(idx))
         kb = ((K + ku - 1)/ku)*ku;
   #endif
/*
 * If 4 operands (C, wC, A, B) all fit in L1, use small, near-square shapes.
 * otherwise, use MB/NB from largest KB, which we know fits in some level
 * of cache.  Using larger M/N will tend to minimize function call overhead,
 * and shouldn't have much negative effect when in-cache.
 */
   mb = ATL_AMM_MBs[idx];
   nb = ATL_AMM_NBs[idx];
   out->mu = mu = ATL_AMM_MUs[idx];
   out->nu = nu = ATL_AMM_NUs[idx];
   if (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts)
   {
      MB = mb;
      NB = nb;
      while (((mb*nb)<<1) + (mb+nb)*K <= ATL_L1elts && (mb < M || nb < N))
      {
         MB = mb;
         NB = nb;
         if (nb >= N || (mb <= nb && mb < M)) 
            mb += mu;
         else if (nb < N)
            nb += nu;
      }
   }
   else
   {
      MB = ATL_rkAMM_LASTMB;
      NB = ATL_rkAMM_LASTNB;
   }
   if (MB >= M)
   {
      mb = 0;
      npmblks = 0;
      nmblks = 1;
      NMU = (M+mu-1)/mu; 
      MB = NMU*mu;
   }
   else
   {
      NMU = MB/mu; 
      MB = NMU*mu;
      nmblks = M/MB;
      mb = M - nmblks*MB;
      if (mb)
      {
         npmblks = 1;
         nmu = (mb+mu-1)/mu;
      }
      else
         nmu = npmblks = 0;
      if (nmu < 4 && (flag&1)==0 && NMU > 4)
      {
         MB = ATL_CompBlkPart(M, maxMB, ATL_AMM_MBs[idx], mu, 
                              &mb, &npmblks, &nmblks);
         NMU = MB / mu;
         if (!nmblks)
         {
            nmblks = npmblks;
            npmblks = 0;
            MB = mb;
            nmu = NMU = mb / mu;
         }
         else
            nmu = mb / mu;
      }
      mb = nmu*mu;
   }
   out->nfmblks = nmblks;
   out->npmblks = npmblks;
   out->mb = MB;
   out->pmb = mb;
   out->nmu = NMU;
   out->pnmu = mb / mu;
   out->mF = M + ((npmblks)?mb:MB) - nmblks*MB - npmblks*mb;
   if (NB >= N)
   {
      nb = 0;
      npnblks = 0;
      nnblks = 1;
      NNU = (N+nu-1)/nu; 
      out->nF = NB = NNU*nu;
   }
   else
   {
      NNU = NB/nu; 
      NB = NNU*nu;
      nnblks = N/NB;
      nb = N - nnblks*NB;
      if (nb)
      {
         nnu = (nb+nu-1)/nu;
         npnblks = 1;
      }
      else
         nnu = npnblks = 0;
      if (nnu < 4 && (flag&1)==0 && NNU > 4)
      {
         NB = ATL_CompBlkPart(N, maxNB, ATL_AMM_NBs[idx], nu, 
                              &nb, &npnblks, &nnblks);
         NNU = NB / nu;
         if (!nnblks)
         {
            nnblks = npnblks;
            npnblks = 0;
            NB = nb;
            nnu = NNU = nb / nu;
         }
         else
            nnu = nb / nu;
      }
      nb = nnu*nu;
   }
   out->nfnblks = nnblks;
   out->npnblks = npnblks;
   out->nb = NB;
   out->pnb = nb;
   out->nnu = NNU;
   out->pnnu = nb / nu;
   out->nF = N + ((npnblks)?nb:NB) - nnblks*NB - npnblks*nb;
   out->vlen = vlen = ATL_AMM_VLENs[idx];
   szC = ((mu*nu+vlen-1)/vlen)*vlen;
   szC *= NMU*NNU;
   out->szC = szC;
   out->idx = idx;
   out->amm_b0 = ATL_AMM_KERN_b0[idx];
   #ifdef TCPLX
      out->amm_b1 = ATL_AMM_KERN_b1[idx];
      out->amm_bn = ATL_AMM_KERN_bn[idx];
   #endif
   out->kb = K;
   out->KB = kb;
   out->lda = lda;
   out->ldb = ldb;
   out->ldc = ldc;
   out->pszA = mb*kb;
   out->szA = MB*kb;
   out->pszB = kb*nb;
   out->szB = kb*NB;
   out->alpA = out->alpB = CONE;
   out->beta = beta;
   #ifdef TCPLX
   out->ONE = CONE;
   if (TA == AtlasNoTrans || TA == AtlasConj)
   #else
   if (TA == AtlasNoTrans)
   #endif
   {
      out->incAm  = MB SHIFT;
      out->pincAm = mb SHIFT;
   }
   else
   {
      out->incAm = lda*(MB SHIFT);
      out->pincAm = lda*(mb SHIFT);
   }
   #ifdef TCPLX
   if (TB == AtlasNoTrans || TB == AtlasConj)
   #else
   if (TB == AtlasNoTrans)
   #endif
   {
      out->incBn = ldb*(NB SHIFT);
      out->pincBn = ldb*(nb SHIFT);
   }
   else
   {
      out->incBn  = NB SHIFT;
      out->pincBn = nb SHIFT;
   }
/*
 * Once we have ATL_ammmN written, put alpha on A if there's only 1 blk of
 * of B.  For now, always put on B and use ATL_ammmM
 */
   #if 0
   if (nnblks > 1 && nmblks < 2) /* If we only have row panel of C */
   {                             /* apply alpha to A */
      #ifdef TCPLX
         if (TB == AtlasNoTrans)
            out->b2blk = ATL_AMM_BN2BLK_a1[idx];
         else if (TB == AtlasTrans)
            out->b2blk = ATL_AMM_BT2BLK_a1[idx];
         else
            out->b2blk = (TB == AtlasConjTrans) ?
               ATL_AMM_BH2BLK_a1[idx] : ATL_AMM_BC2BLK_a1[idx];

   @define else @@
   @multidef at NONE ONE
   @whiledef an X n 1
      @ifdef ! at
         else
      @endifdef
      @ifdef at
         @(else)if (SCALAR_IS_@(at)(alpha))
         @undef at
      @endifdef
      @undef else
      @define else @else @
         {
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_a@(an)[idx];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_a@(an)[idx];
            else
               out->a2blk = (TA == AtlasConjTrans) ?
                  ATL_AMM_AC2BLK_a@(an)[idx] : ATL_AMM_AH2BLK_a@(an)[idx];
         }
   @endwhile
   @undef else
      #else
         out->b2blk = (TB == AtlasNoTrans) ? 
                      ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
         if (SCALAR_IS_ONE(alpha))
            out->a2blk = (TA == AtlasNoTrans) ? 
                      ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
         else if (SCALAR_IS_NONE(alpha))
            out->a2blk = (TA == AtlasNoTrans) ? 
                      ATL_AMM_AT2BLK_an[idx] : ATL_AMM_AN2BLK_an[idx];
         else
            out->a2blk = (TA == AtlasNoTrans) ? 
                      ATL_AMM_AT2BLK_aX[idx] : ATL_AMM_AN2BLK_aX[idx];
      #endif
   }
   else  /* apply alpha to B */
   #endif
   {
      out->alpB = alpha;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = ATL_AMM_AT2BLK_a1[idx];
         else if (TA == AtlasTrans)
            out->a2blk = ATL_AMM_AN2BLK_a1[idx];
         else
            out->a2blk = (TA == AtlasConjTrans) ?
               ATL_AMM_AC2BLK_a1[idx] : ATL_AMM_AH2BLK_a1[idx];

   @define else @@
   @multidef at NONE ONE
   @whiledef an X n 1
      @ifdef ! at
         else
      @endifdef
      @ifdef at
         @(else)if (SCALAR_IS_@(at)(alpha))
         @undef at
      @endifdef
      @undef else
      @define else @else @
         {
            if (TB == AtlasNoTrans)
               out->b2blk = ATL_AMM_BN2BLK_a@(an)[idx];
            else if (TB == AtlasTrans)
               out->b2blk = ATL_AMM_BT2BLK_a@(an)[idx];
            else
               out->b2blk = (TB == AtlasConjTrans) ?
                  ATL_AMM_BH2BLK_a@(an)[idx] : ATL_AMM_BC2BLK_a@(an)[idx];
         }
   @endwhile
   @undef else
      #else
         out->a2blk = (TA == AtlasNoTrans) ? 
                      ATL_AMM_AT2BLK_a1[idx] : ATL_AMM_AN2BLK_a1[idx];
         if (SCALAR_IS_ONE(alpha))
            out->b2blk = (TB == AtlasNoTrans) ? 
                      ATL_AMM_BN2BLK_a1[idx] : ATL_AMM_BT2BLK_a1[idx];
         else if (SCALAR_IS_NONE(alpha))
            out->b2blk = (TB == AtlasNoTrans) ? 
                      ATL_AMM_BN2BLK_an[idx] : ATL_AMM_BT2BLK_an[idx];
         else
            out->b2blk = (TB == AtlasNoTrans) ? 
                      ATL_AMM_BN2BLK_aX[idx] : ATL_AMM_BT2BLK_aX[idx];
      #endif
   }
   if (SCALAR_IS_NONE(beta))
      out->blk2C = ATL_AMM_BLK2C_a1_bn[idx];
   else if (SCALAR_IS_ONE(beta))
      out->blk2C = ATL_AMM_BLK2C_a1_b1[idx];
   else
      out->blk2C = (SCALAR_IS_ZERO(beta)) ? 
         ATL_AMM_BLK2C_a1_b0[idx] : ATL_AMM_BLK2C_a1_bX[idx];
@endskip
@skip   printf("IDR=%d, B=(%d,%d,%d), U=(%d,%d,%d)\n",
@skip          idx, out->mb, out->nb, out->kb, out->mu, out->nu, ku);
}

@beginskip
void Mjoin(PATL,GetBestKBInfo)
(
   rkinfo_t *out,            /* what to use for full-KB blocks */
   rkinfo_t *outR,           /* what to use for K-cleanup */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   size_t lda, 
   size_t ldb,
   size_t ldc,
   const SCALAR alpha,
   const SCALAR beta
)
{
   int idx;        /* amm index to use for full kb calls */
   int idr=(-1);   /* amm index for final colpan (-1: use ger1/2) */
   int KR;         /* K%kb */
   int i;

   #if 1
   if (K <= ATL_rkAMM_LASTKB)
   {
      idx = -1;
      idr = (K > 2) ? K-3 : -1;
      KR = K;
   }
   else
   #endif
   {
      int ibest=0;
      double timB=M*N*K*ATL_rkAMM_TIME[0];
      for (i=0; i < ATL_rkAMM_NCASES; i++)
      {
         ATL_CINT kb=ATL_AMM_KBs[i], nkb=K/kb, kr=K-nkb*kb;
         ATL_CINT mb=ATL_AMM_MBs[i], nb=ATL_AMM_MBs[i], nmb=M/mb, nnb=N/nb;
         ATL_CINT mu = ATL_AMM_MUs[i], mr = M-nmb*mb;
         ATL_CINT nu = ATL_AMM_NUs[i], nr = N-nnb*nb;
         double nfcblks, tkr, tpan, tim;

         nfcblks = nmb;
         nfcblks *= nnb;
         if (kr > 2)
         {
            idr = kr-3;
            tkr = ATL_rkAMM_TIME[idr];
            tkr /= ((double)ATL_AMM_KBs[idr])*ATL_AMM_MBs[idr]*ATL_AMM_KBs[idr];
            tkr *= ((double)mb)*nb*kb;
         }
         else if (!kr)
         {
            idr = -2;
            tkr = 0.0;
         }
/*
 *       Strongly penalize kr==1,2, since they require double write of C
 */
         else
         {
            if (kr == 1)
               tkr = ATL_rkAMM_TIME[0] * 8.0;
            else 
               tkr = ATL_rkAMM_TIME[0] * 6.0;
            tkr *= (0.015625*mb)*nb*kb;  /* b^3/4^3 */
         }
         tpan = nkb*ATL_rkAMM_TIME[i] + tkr;
         tim = nfcblks*tpan;
/*
 *       Rank-K perf not much affected by MB, so M cleanup only reduced
 *       by extra computation
 */
         if (mr)
            tim += nmb*tpan*mr / (double)mb;
#if 1
/*
 *       Small N drastically affects rank-K perf, so estimate it's speed
 *       as being equal to the mininum of rank-K or rank-nr
 *       We ignore kr for this, shouldn't be a big deal.
 */
         if (nr)
         {
            if (nr < K)
            {
               const int kk = (nr >= 3) ? nr-3 : 0;
               double tpe = ATL_rkAMM_TIME[kk];        /* time per element */
               tpe /= ((double)ATL_AMM_MBs[kk])*ATL_AMM_NBs[kk]*ATL_AMM_KBs[kk];
               tpe *= ((double)mb)*nr*kb;
               tim += tpe*nmb;
            }
            else
               tim += tpan;
         }
#endif
         if (tim < timB)
         {
            timB = tim;
            ibest = i;
            KR = kr;
         }
      }
#if 0
      ibest = 1;
      KR = K%4;
#elif 0
      ibest = 17;
      KR = K%20;
#endif
      idx = ibest;
      if (KR > 2)
         idr = KR-3;
      else
         idr = (KR == 0) ? -2 : -1;
   }
   out->idx = idx;
   if (idx != -1)
      FillInRankKInf(out, idx, TA, TB, M, N, K, lda, ldb, ldc,alpha,beta,0,0);
   outR->idx = idr;
   if (idr != -2)
   {
      const int mu=out->mu, nu=out->nu;
      int GOLOOK=(idr == -1);  /* should we look for kern wt same MU/NU? */

      if (!GOLOOK)
         GOLOOK = (mu != ATL_AMM_MUs[idr] || nu != ATL_AMM_NUs[idr]);
/*
 *    If present K-clean candidate doesn't have same C format, search
 *    for one that does
 */
      if (idx != -1 && GOLOOK)
      {
         int kbmin = ATL_AMM_KBMINs[idx];
/*
 *       See if present kernel can perform K-cleanup itself
 */
         if (ATL_AMM_KRUNTIME(idx) && ATL_AMM_KBMINs[idx] <= KR)
            idr = idx;
/*
 *       Look thru all avail kerns for one that matches MU/NU & can handle KR
 */
         else
         {
            int nidr=(-1);
            for (i=0; i < ATL_rkAMM_NCASES; i++)
            {
               if (ATL_AMM_KRUNTIME(i) && ATL_AMM_KBMINs[i] <= KR)
               {
                  nidr = i;
                  if (!ATL_AMM_KMAJOR(i)) /* K-vect kerns slow for small KR */
                     break;               /* so only quit if not K-vect */
               }
            }
/*
 *          May later want to search thru sq/ge KClean kerns for matching kerns.
 *          This will complicate things slighly, since the idx will be for
 *          the wrong header files.  For now, call present search OK
 */
            #if 0
            if (nidr == -1)
            {
               nidr = sqFindrkKClean(outR, mu, nu, KR);
               if (nidr == -1)
                  nidr = geFindrkKClean(outR, mu, nu, KR);
            }
            #endif
            if (nidr != -1)
               idr = nidr;
         }
      }
      if (idr >= 0)
      {
/*
 *       If we want to use this, will need to change amminstall to ensure
 *       this.  For now, simply assert it so we can assume compatible C
 */
         if (idx > 0)
         {
            FillInRankKInf(outR, idr, TA, TB, M, N, KR, lda, ldb, ldc, 
                           alpha, beta, out->mb, out->nb);
            ATL_assert(outR->mu == mu && outR->nu == nu);
         }
         else
            FillInRankKInf(outR, idr, TA, TB, M, N, KR, lda, ldb, ldc, 
                           alpha, beta, 0, 0);
      }
   }
   if (idx >= 0)
      printf("IDX=%d, B=(%d,%d,%d), U=(%d,%d,%d)\n",
             idx, out->mb, out->nb, out->kb, out->mu, out->nu, out->ku);
   else
      printf("IDX=%d\n", idx);
   if (idr >= 0)
      printf("IDR=%d, B=(%d,%d,%d), U=(%d,%d,%d)\n",
             idr, outR->mb, outR->nb, outR->kb, outR->mu, outR->nu, outR->ku);
   else
      printf("IDR=%d\n", idr);
}
@endskip

@ROUT ATL_GetRankKInfo0000 
/*
 * This function provides an estimate on max number of threads to use to
 * perform a rank-K update.
 */
size_t GetRankKNthr(ATL_CSZT M, ATL_CSZT N, ATL_CSZT K)
{
   size_t nnblks=N/ATL_rkAMM_LASTNB, nmblks=M/ATL_rkAMM_LASTMB;
/*
 * For degenerate cases, require 32 blocks to pay for parallel overhead
 */
   if (N <= ATL_rkAMM_LASTNB)
      return(nmblks>>5);
   if (M <= ATL_rkAMM_LASTMB)
      return(nnblks>>5);
/*
 * In general case, rank-K is bus noisy, so ask that all threads have at least
 * 4 big blocks of C.  On some systems where memory scales poorly this will
 * vastly overestimate, and will underestimate on very good scaling, but
 * very good memory scaling should only occur for low number of cores, where
 * this won't hurt.
 */
   return((nnblks*nmblks)>>2);
}
@ROUT ATL_GetAmmmInfo00
/*
 * This function provides an estimate on max number of threads to use to
 * perform a access-major GEMM.
 */
size_t GetAmmmNthr(ATL_CSZT M, ATL_CSZT N, ATL_CSZT K)
{
   int GetRankNthr(ATL_CSZT M, ATL_CSZT N, ATL_CSZT K);
   size_t nnblks, nmblks, nkblks, p;

   nmblks = (M >= ATL_AMM_66MB) ? M/ATL_AMM_66MB : 1;
   nnblks = (N >= ATL_AMM_66NB) ? N/ATL_AMM_66NB : 1;
   nkblks = (K >= ATL_AMM_66KB) ? K/ATL_AMM_66KB : 1;
/*
 * Any shape with two degenerate dimensions causes a lot of bus traffic,
 * with very little computation to overcome threading overheads,
 * so demand at least 32 blocks before parallelizing
 */
   if ((nmblks==1 && nnblks==1) || (nmblks==1 && nkblks==1) || 
       (nnblks==1 && nkblks==1))
      return((nnblks*nmblks*nkblks)>>5)
/*
 * If it is a rank-K update, ask to have 4 big blocks of C
 */
   if (K <= ATL_rkAMM_LASTMB)
   {
      nnblks=N/ATL_rkAMM_LASTNB, nmblks=M/ATL_rkAMM_LASTMB;
      return((nnblks*nmblks)>>2);
   }
   
/*
 * By default, give everyone 32 blocks to compute; for square problems,
 * the number of blocks is cubic, so this should not meaningfully restrict
 * parallelism.
 */
   return((nmblks*nnblks*nkblks)>>5);
}
@ROUT cnbtune
#include "atlas_misc.h"
#include Mstr(Mjoin(ATLAS_PRE,geamm_blk.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_ablk2cmat.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_aX.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,geamm_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_kern.h))

static int IK=ATL_AMM_NCASES-1, MB=0, NB=0, KB=0;
#ifdef DCPLX
   static char MY_PRE='z', MY_PRE2='Z';
#elif defined(SCPLX)
   static char MY_PRE='c', MY_PRE2='C';
#elif defined(SREAL)
   static char MY_PRE='s', MY_PRE2='S';
#else
   static char MY_PRE='d', MY_PRE2='D';
#endif
/*
 * This routine overrides normal GetAmmmInfo, so we can tune kernel params
 */
int Mjoin(PATL,GetAmmmInfo)
(
   amminfo_t *out,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   int ik=IK, appAl;  /* 0:A, 1:B, 2:C */

   ATL_assert(ik >= 0 && ik < ATL_AMM_NCASES);
   while (K < ATL_AMM_KBs[ik] && ik)
      ik--;
   out->IDX = ik;
   out->mb = (MB) ? MB : ATL_AMM_MBs[ik];
   out->nb = (NB) ? NB : ATL_AMM_NBs[ik];
   out->kb = (KB) ? KB : ATL_AMM_KBs[ik];
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
/*
 * Apply alpha to smallest matrix, and use alpha/beta to pick copy routines
 */
   if (SCALAR_IS_ONE(alpha))
   {
      appAl = 0;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = ATL_AMM_AT2BLK_a1[ik];
         else if (TA == AtlasTrans)
            out->a2blk = ATL_AMM_AN2BLK_a1[ik];
         else if (TA == AtlasConjTrans)
            out->a2blk = ATL_AMM_AC2BLK_a1[ik];
         else
            out->a2blk = ATL_AMM_AH2BLK_a1[ik];
         if (TB == AtlasNoTrans)
             out->b2blk = ATL_AMM_BN2BLK_a1[ik];
         else if (TB == AtlasTrans)
             out->b2blk = ATL_AMM_BT2BLK_a1[ik];
         else if (TB == AtlasConjTrans)
             out->b2blk = ATL_AMM_BH2BLK_a1[ik];
         else
             out->b2blk = ATL_AMM_BC2BLK_a1[ik];
      #else
         out->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_a1[ik]:ATL_AMM_AN2BLK_a1[ik];
         out->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_a1[ik]:ATL_AMM_BT2BLK_a1[ik];
      #endif
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
   }
   else  /* alpha is not one */
   {
      if (M >= N)                  /* A is larger than B, put alpha on C or B */
         appAl = (M >= K) ? 1 : 2;
      else                         /* B is larger than A, put alpha on C or A */
         appAl = (N >= K) ? 0 : 2;
      if (appAl == 2)  /* apply alpha to C */
      {
         #ifdef TCPLX
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_a1[ik];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_a1[ik];
            else if (TA == AtlasConjTrans)
               out->a2blk = ATL_AMM_AC2BLK_a1[ik];
            else
               out->a2blk = ATL_AMM_AH2BLK_a1[ik];
            if (TB == AtlasNoTrans)
                out->b2blk = ATL_AMM_BN2BLK_a1[ik];
            else if (TB == AtlasTrans)
                out->b2blk = ATL_AMM_BT2BLK_a1[ik];
            else if (TB == AtlasConjTrans)
                out->b2blk = ATL_AMM_BH2BLK_a1[ik];
            else
                out->b2blk = ATL_AMM_BC2BLK_a1[ik];
         #else
            out->a2blk = (TA == AtlasNoTrans) ?
                         ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
            out->b2blk = (TB == AtlasNoTrans) ?
                         ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
         #endif
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b1[ik] : ATL_AMM_BLK2C_aX_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b0[ik] : ATL_AMM_BLK2C_aX_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bn[ik] : ATL_AMM_BLK2C_aX_bn[ik];
         else
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bX[ik] : ATL_AMM_BLK2C_aX_bX[ik];
      }
      else  /* not applying alpha to C */
      {
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
         else
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
         if (!appAl)  /* apply to alpha to A */
         {
            #ifdef TCPLX
               if (TB == AtlasNoTrans)
                   out->b2blk = ATL_AMM_BN2BLK_a1[ik];
               else if (TB == AtlasTrans)
                   out->b2blk = ATL_AMM_BT2BLK_a1[ik];
               else if (TB == AtlasConjTrans)
                   out->b2blk = ATL_AMM_BH2BLK_a1[ik];
               else
                   out->b2blk = ATL_AMM_BC2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_an[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_an[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_an[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_an[ik];
               }
               else
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_aX[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_aX[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_aX[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_aX[ik];
               }
            #else
               if (SCALAR_IS_NONE(alpha))
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_an[ik] : ATL_AMM_AN2BLK_an[ik];
               else
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_aX[ik] : ATL_AMM_AN2BLK_aX[ik];
               out->b2blk = (TB == AtlasNoTrans) ?
                            ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
            #endif
         }
         else /* apply alpha to B */
         {
            #ifdef TCPLX
               if (TA == AtlasNoTrans)
                  out->a2blk = ATL_AMM_AT2BLK_a1[ik];
               else if (TA == AtlasTrans)
                  out->a2blk = ATL_AMM_AN2BLK_a1[ik];
               else if (TA == AtlasConjTrans)
                  out->a2blk = ATL_AMM_AC2BLK_a1[ik];
               else
                  out->a2blk = ATL_AMM_AH2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_an[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_an[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_an[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_an[ik];
               }
               else
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_aX[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_aX[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_aX[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_aX[ik];
               }
            #else
               out->a2blk = (TA == AtlasNoTrans) ?
                            ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_an[ik] : ATL_AMM_BT2BLK_an[ik];
               else
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_aX[ik] : ATL_AMM_BT2BLK_aX[ik];
            #endif
         }
      }
   }
   return(appAl);
}

double time00();
double Time2Mflops(int M, int N, int K, double t0)
{
   return((((2.0*M)*N)*K) / (1000000.0*t0));
}

int FindLowerBlock(int *M, int *N, int *K)
{
   int iret=1;
   if (ATL_AMM_KRUNTIME(ATL_AMM_KFLAG[IK]) && *K > *M && *K > *N &&
       *K-ATL_AMM_KUs[IK] >=  ATL_AMM_KBMINs[IK])
      *K -= ATL_AMM_KUs[IK];
   else if (*M >= *N && *M > ATL_AMM_MUs[IK])
      *M -= ATL_AMM_MUs[IK];
   else if (*N > ATL_AMM_NUs[IK])
      *N -= ATL_AMM_NUs[IK];
   else 
      iret = 0;
   return(iret);
}

double GetMflops(ATL_CINT M, ATL_CINT N, ATL_CINT K, TYPE *A, TYPE *B, TYPE *C)
{
   double t0;
   const TYPE ONE[2] = {ATL_rone, ATL_rzero};

   t0 = time00();
   Mjoin(PATL,ammm)(AtlasNoTrans, AtlasNoTrans, M, N, K, ONE, A, M, B, K,
                    ONE, C, M);
   t0 = time00() - t0;
   return(Time2Mflops(M, N, K, t0));
}

double TuneBlocking(int M, int N, int K, TYPE *A, TYPE *B, TYPE *C, 
                    int *MB_, int *NB_, int *KB_)
{
   int mbB=ATL_AMM_MBs[IK], nbB=ATL_AMM_NBs[IK], kbB=ATL_AMM_KBs[IK];
   int mb=mbB, nb=nbB, kb=kbB, m, n, k;
   double t0, t1, mf0, mf, mfB;

   printf("\nTRYING REDUCED BLOCKING WITH INDEX=%d\n", IK);
   printf("        M       N       K  IDX   MB   NB   KB         MFLOPS\n");
   printf("   ======  ======  ======  ===  ===  ===  ===  =============\n");
   m = (M/mbB)*mbB;
   n = (N/nbB)*nbB;
   k = (K/kbB)*kbB;
   mf0 = mf = mfB = GetMflops(m, n, k, A, B, C);
   printf("  %7d %7d %7d %4d %4d %4d %4d %14.2f\n", 
          m, n, k, IK, mb, nb, kb, 4.0*mf);
   while(FindLowerBlock(&mb, &nb, &kb))
   {
      MB = mb;
      NB = nb;
      KB = kb;
      m = (M/mb)*mb;
      n = (N/nb)*nb;
      k = (K/kb)*kb;
      mf = GetMflops(m, n, k, A, B, C);
      printf("  %7d %7d %7d %4d %4d %4d %4d %14.2f\n", 
             m, n, k, IK, mb, nb, kb, 4.0*mf);
      if (mf > mfB)
      {
         mbB = mb;
         nbB = nb;
         kbB = kb;
         mfB = mf;
      }
      else if (mf*1.02 <= mfB)
         break;
   }
   printf("BEST BLOCKING: MB=%d, NB=%d, KB=%d speedup=%.3f\n", 
          mbB, nbB, kbB, (mfB/mf0));
   *MB_ = mbB;
   *NB_ = nbB;
   *KB_ = kbB;
   return(mfB);
}

int TuneIndx(int M, int N, int K, TYPE *A, TYPE *B, TYPE *C)
{
   double mfB=0.0, mf;
   int ik, iB=ATL_AMM_NCASES-1;

   printf("\n\nFINDING BEST INDEX:\n");
   printf("        M       N       K  IDX   MB   NB   KB         MFLOPS\n");
   printf("   ======  ======  ======  ===  ===  ===  ===  =============\n");
   for (ik=iB; ik >= 0; ik--)
   {
      const int mb=ATL_AMM_MBs[ik],nb=ATL_AMM_NBs[ik],kb=ATL_AMM_KBs[ik];
      const int m=(M/mb)*mb, n=(N/nb)*nb, k=(K/kb)*kb;
      IK = ik;
      mf = GetMflops(m, n, k, A, B, C);
      printf("  %7d %7d %7d %4d %4d %4d %4d %14.2f\n", 
             m, n, k, ik, mb, nb, kb, 4.0*mf);
      if (mf > mfB)
      {
         iB = ik;
         mfB = mf;
      }
      else if (ATL_AMM_KBs[ik] < 16)
         break;
   }
   printf("\nBEST INDEX=%d (%.2f)\n", iB, mfB);
   return(iB);
}

void TuneCplxNB(FILE *fpout, int M, int N, int K, TYPE *A, TYPE *B, TYPE *C)
{
   int ik, mb, nb, kb;
   double mfB;
   ik = TuneIndx(M, N, K, A, B, C);
   IK = ik;
   mfB = TuneBlocking(M, N, K, A, B, C, &mb, &nb, &kb);
   fprintf(fpout, "#ifndef ATL_%cAMM_SUM_H\n   #define ATLAS_%cAMM_SUM_H\n\n",
           MY_PRE2, MY_PRE2);
   fprintf(fpout, "   #define ATL_CAMM_MAXINDX %d\n", IK);
   fprintf(fpout, "   #define ATL_CAMM_MAXMB %d\n", mb);
   fprintf(fpout, "   #define ATL_CAMM_MAXNB %d\n", nb);
   fprintf(fpout, "   #define ATL_CAMM_MAXKB %d\n", kb);
   fprintf(fpout, "   #define ATL_CAMM_APERF %e\n", 4.0*mfB);
   fprintf(fpout, "\n#endif\n");
   fclose(fpout);
}

FILE *GetFlags(int nargs, char **args, int *M, int *N, int *K)
{
   FILE *fp=NULL;
   *K = 1200;
   *M = *N = 2000;
   if (!fp)
   {
      char nam[32];
      sprintf(nam, "res/atlas_%samm_sum.h", Mstr(PRE));
      fp = fopen(nam, "w");
      ATL_assert(fp);
   }
   return(fp);
}


int main(int nargs, char **args)
{
   void *vp;
   TYPE *A, *B, *C;
   int M, N, K;
   size_t szA, szB, szC;
   FILE *fpout;

   fpout = GetFlags(nargs, args, &M, &N, &K);
   M = ((M+ATL_geAMM_LASTMB-1)/ATL_geAMM_LASTMB)*ATL_geAMM_LASTMB;
   N = ((N+ATL_geAMM_LASTNB-1)/ATL_geAMM_LASTNB)*ATL_geAMM_LASTNB;
   K = ((K+ATL_geAMM_LASTKB-1)/ATL_geAMM_LASTKB)*ATL_geAMM_LASTKB;
   szA = M*K;
   szB = K*N;
   szC = M*N;
   vp = malloc(ATL_MulBySize(szA + szB + szC) + 3*ATL_Cachelen);
   ATL_assert(vp);
   A = ATL_AlignPtr(vp);
   B = A + szA+szA;
   B = ATL_AlignPtr(B);
   C = B + szB+szB;
   C = ATL_AlignPtr(C);
   Mjoin(PATL,zero)(szA, A, 1);
   Mjoin(PATL,zero)(szB, B, 1);
   Mjoin(PATL,zero)(szC, C, 1);
   TuneCplxNB(fpout, M, N, K, A, B, C);
   free(vp);
   return(0);
}
@ROUT ATL_GetSqMNAmmmInfo
#include "atlas_misc.h"
#include Mstr(Mjoin(ATLAS_PRE,geamm_blk.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_ablk2cmat.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_a1.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_an.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_cm2am_aX.h))
@skip #include Mstr(Mjoin(ATLAS_PRE,geamm_flag.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_kern.h))
#include Mstr(Mjoin(ATLAS_PRE,geamm_perf.h))
#include Mstr(Mjoin(ATLAS_PRE,amm_sum.h))

/*
 * Chooses good square M & N blocking; starts from size that gets 98% of
 * performance, since smaller produces less wasted flops for triangular and
 * symmetric operations, which are what usually demand square M/N blocking
 */
int Mjoin(PATL,GetSqMNAmmmInfo)
(
   amminfo_t *out,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const SCALAR beta
)
{
   int ik=ATL_sqAMM_98IDX;
   int appAl;  /* 0:A, 1:B, 2:C */
/*
 * For rank-K update, choose smallest KB that contains required K
 */
   if (K < ATL_rkAMM_LASTKB)
   {
      for (ik=0; ik < ATL_AMM_NCASES && ATL_AMM_KBs[ik] < K; ik++);
   }
   out->IDX = ik;
   u = ATL_98LCMMN;
   mb = ATL_AMM_MBs[ik];
   nb = ATL_AMM_NBs[ik];
   out->kb = ATL_AMM_KBs[ik];
   if(mb != nb)
      nb = (mb > u) ? (mb/u)*u : u;
   out->mb = mb = out->nb = nb;
   out->kbmin = ATL_AMM_KBMINs[ik];
   out->mu = ATL_AMM_MUs[ik];
   out->nu = ATL_AMM_NUs[ik];
   out->ku = ATL_AMM_KUs[ik];
   out->flag = ATL_AMM_KFLAG[ik];
   out->amm_b0 = ATL_AMM_KERN_b0[ik];
   out->amm_b1 = ATL_AMM_KERN_b1[ik];
   out->amm_bn = ATL_AMM_KERN_bn[ik];
   out->amm_k1_b0 = ATL_AMM_KERN_K1_b0[ik];
   out->amm_k1_b1 = ATL_AMM_KERN_K1_b1[ik];
   out->amm_k1_bn = ATL_AMM_KERN_K1_bn[ik];
/*
 * Apply alpha to smallest matrix, and use alpha/beta to pick copy routines
 */
   if (SCALAR_IS_ONE(alpha))
   {
      appAl = 0;
      #ifdef TCPLX
         if (TA == AtlasNoTrans)
            out->a2blk = ATL_AMM_AT2BLK_a1[ik];
         else if (TA == AtlasTrans)
            out->a2blk = ATL_AMM_AN2BLK_a1[ik];
         else if (TA == AtlasConjTrans)
            out->a2blk = ATL_AMM_AC2BLK_a1[ik];
         else
            out->a2blk = ATL_AMM_AH2BLK_a1[ik];
         if (TB == AtlasNoTrans)
             out->b2blk = ATL_AMM_BN2BLK_a1[ik];
         else if (TB == AtlasTrans)
             out->b2blk = ATL_AMM_BT2BLK_a1[ik];
         else if (TB == AtlasConjTrans)
             out->b2blk = ATL_AMM_BH2BLK_a1[ik];
         else
             out->b2blk = ATL_AMM_BC2BLK_a1[ik];
      #else
         out->a2blk = (TA == AtlasNoTrans) ?
            ATL_AMM_AT2BLK_a1[ik]:ATL_AMM_AN2BLK_a1[ik];
         out->b2blk = (TB == AtlasNoTrans) ?
            ATL_AMM_BN2BLK_a1[ik]:ATL_AMM_BT2BLK_a1[ik];
      #endif
      if (SCALAR_IS_ONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
      else if (SCALAR_IS_ZERO(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
      else if (SCALAR_IS_NONE(beta))
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
      else
         out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
   }
   else  /* alpha is not one */
   {
      if (M >= N)                  /* A is larger than B, put alpha on C or B */
         appAl = (M >= K) ? 1 : 2;
      else                         /* B is larger than A, put alpha on C or A */
         appAl = (N >= K) ? 0 : 2;
      if (appAl == 2)  /* apply alpha to C */
      {
         #ifdef TCPLX
            if (TA == AtlasNoTrans)
               out->a2blk = ATL_AMM_AT2BLK_a1[ik];
            else if (TA == AtlasTrans)
               out->a2blk = ATL_AMM_AN2BLK_a1[ik];
            else if (TA == AtlasConjTrans)
               out->a2blk = ATL_AMM_AC2BLK_a1[ik];
            else
               out->a2blk = ATL_AMM_AH2BLK_a1[ik];
            if (TB == AtlasNoTrans)
                out->b2blk = ATL_AMM_BN2BLK_a1[ik];
            else if (TB == AtlasTrans)
                out->b2blk = ATL_AMM_BT2BLK_a1[ik];
            else if (TB == AtlasConjTrans)
                out->b2blk = ATL_AMM_BH2BLK_a1[ik];
            else
                out->b2blk = ATL_AMM_BC2BLK_a1[ik];
         #else
            out->a2blk = (TA == AtlasNoTrans) ?
                         ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
            out->b2blk = (TB == AtlasNoTrans) ?
                         ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
         #endif
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b1[ik] : ATL_AMM_BLK2C_aX_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_b0[ik] : ATL_AMM_BLK2C_aX_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bn[ik] : ATL_AMM_BLK2C_aX_bn[ik];
         else
            out->Cblk2cm = SCALAR_IS_NONE(alpha) ?
                           ATL_AMM_BLK2C_an_bX[ik] : ATL_AMM_BLK2C_aX_bX[ik];
      }
      else  /* not applying alpha to C */
      {
         if (SCALAR_IS_ONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b1[ik];
         else if (SCALAR_IS_ZERO(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_b0[ik];
         else if (SCALAR_IS_NONE(beta))
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bn[ik];
         else
            out->Cblk2cm = ATL_AMM_BLK2C_a1_bX[ik];
         if (!appAl)  /* apply to alpha to A */
         {
            #ifdef TCPLX
               if (TB == AtlasNoTrans)
                   out->b2blk = ATL_AMM_BN2BLK_a1[ik];
               else if (TB == AtlasTrans)
                   out->b2blk = ATL_AMM_BT2BLK_a1[ik];
               else if (TB == AtlasConjTrans)
                   out->b2blk = ATL_AMM_BH2BLK_a1[ik];
               else
                   out->b2blk = ATL_AMM_BC2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_an[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_an[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_an[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_an[ik];
               }
               else
               {
                  if (TA == AtlasNoTrans)
                     out->a2blk = ATL_AMM_AT2BLK_aX[ik];
                  else if (TA == AtlasTrans)
                     out->a2blk = ATL_AMM_AN2BLK_aX[ik];
                  else if (TA == AtlasConjTrans)
                     out->a2blk = ATL_AMM_AC2BLK_aX[ik];
                  else
                     out->a2blk = ATL_AMM_AH2BLK_aX[ik];
               }
            #else
               if (SCALAR_IS_NONE(alpha))
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_an[ik] : ATL_AMM_AN2BLK_an[ik];
               else
                  out->a2blk = (TA == AtlasNoTrans) ?
                               ATL_AMM_AT2BLK_aX[ik] : ATL_AMM_AN2BLK_aX[ik];
               out->b2blk = (TB == AtlasNoTrans) ?
                            ATL_AMM_BN2BLK_a1[ik] : ATL_AMM_BT2BLK_a1[ik];
            #endif
         }
         else /* apply alpha to B */
         {
            #ifdef TCPLX
               if (TA == AtlasNoTrans)
                  out->a2blk = ATL_AMM_AT2BLK_a1[ik];
               else if (TA == AtlasTrans)
                  out->a2blk = ATL_AMM_AN2BLK_a1[ik];
               else if (TA == AtlasConjTrans)
                  out->a2blk = ATL_AMM_AC2BLK_a1[ik];
               else
                  out->a2blk = ATL_AMM_AH2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_an[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_an[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_an[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_an[ik];
               }
               else
               {
                  if (TB == AtlasNoTrans)
                      out->b2blk = ATL_AMM_BN2BLK_aX[ik];
                  else if (TB == AtlasTrans)
                      out->b2blk = ATL_AMM_BT2BLK_aX[ik];
                  else if (TB == AtlasConjTrans)
                      out->b2blk = ATL_AMM_BH2BLK_aX[ik];
                  else
                      out->b2blk = ATL_AMM_BC2BLK_aX[ik];
               }
            #else
               out->a2blk = (TA == AtlasNoTrans) ?
                            ATL_AMM_AT2BLK_a1[ik] : ATL_AMM_AN2BLK_a1[ik];
               if (SCALAR_IS_NONE(alpha))
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_an[ik] : ATL_AMM_BT2BLK_an[ik];
               else
                  out->b2blk = (TB == AtlasNoTrans) ?
                               ATL_AMM_BN2BLK_aX[ik] : ATL_AMM_BT2BLK_aX[ik];
            #endif
         }
      }
   }
   return(appAl);
}
@ROUT ATL_ammmN ATL_cammmN
#include "atlas_amm.h"
/*
 * This function loops only over N.  Therefore, it updates 1 row-panel
 * of C using a rank-kb update.
 * If B2blk non-NULL, copy B, else assume already available in b.
 */
void Mjoin(PATL,ammmN) /* C <= beta*C + A*B, B/C nb-wide colpan */
(
   rkinfo_t *rkinf,
   int M,              /* # of cols to do */
   int mb,             /* CEIL(N/nu)*nu */
   int nmu,            /* nb/nu */
   const TYPE *a,      /* access-major kb*nb copy of B */
   TYPE *b,            /* workspace for A */
   int INCB,           /* 0: don't increment b, else do */
   TYPE *c,            /* access-major mb*nb workspace for C */
   const TYPE *B,      /* col/row-major (original) A */
   TYPE *C,            /* col-major (original) C */
   const SCALAR beta   /* scale factor for C */
)
@ROUT ATL_ammmN
{
   ammkern_t amm=rkinf->amm_b0;
   ablk2cmat_t blk2C=rkinf->blk2C;/* frm C's access-maj storage to col-maj */
   cm2am_t b2blk=rkinf->b2blk;    /* copy from row/col major A to access-maj */
   const size_t nsnblks=rkinf->nsnblks, nnblks=rkinf->nnblks;
   const size_t incBnS=rkinf->incBnS, incBn=rkinf->incBn; 
   const size_t ldb=rkinf->ldb, ldc=rkinf->ldc;
   size_t n, incC;
   ATL_CINT nu=rkinf->nu, kb=rkinf->kb, K=rkinf->K;
   ATL_INT j, nb, nnu, incb;
/*
 * Loop over small N-blks of size NNU-1
 */
   nb = rkinf->nb - nu;
   nnu = rkinf->nnu - 1;
   incC = nb * ldc;
   incb = (INCB) ? rkinf->incaS : 0;
   for (n=rkinf->N, j=0; j < nsnblks; n -= nb, j++)
   {
      TYPE *bn = b + incb;
      const int nn = Mmin(n, nb);

      if (b2blk)
      {
         b2blk(K, nn, ATL_rone, B, ldb, b);
         B += incBnS;
      }
      amm(nmu, nnu, kb, a, b, c, a, bn, c);
      if (blk2C)
      {
         blk2C(M, nn, ATL_rone, c, beta, C, ldc);
         C += incC;
      }
      b = bn;
   }
/*
 * Now, finish col-panel out by looping over full blocks
 */
   nnu++;
   nb += nu;
   incC = nb * ldc;
   incb = (INCB) ? rkinf->inca : 0;
   for (; j < nnblks; j++, n -= nb)
   {
      TYPE *bn = b + incb;
      const int nn = Mmin(n, nb);

      if (b2blk)
      {
         b2blk(K, nn, ATL_rone, B, ldb, b);
         B += incBn;
      }
      amm(nmu, nnu, kb, a, b, c, a, bn, c);
      if (blk2C)
      {
         blk2C(M, nn, ATL_rone, c, beta, C, ldc);
         C += incC;
      }
      b = bn;
   }
}
@ROUT ATL_cammmN
{
   ammkern_t amm_b0=rkinf->amm_b0, amm_b1=rkinf->amm_b1,amm_bn=rkinf->amm_bn;
   ablk2cmat_t blk2C=rkinf->blk2C;/* frm C's access-maj storage to col-maj */
   cm2am_t b2blk=rkinf->b2blk;    /* copy from row/col major A to access-maj */
   TYPE *iB=b, *iC=c, *rC;
   const TYPE *rA, *iA=a;
   const size_t nsnblks=rkinf->nsnblks, nnblks=rkinf->nnblks;
   const size_t incBnS=rkinf->incBnS, incBn=rkinf->incBn; 
   const size_t ldb=rkinf->ldb, ldc=rkinf->ldc;
   size_t n, incC;
   ATL_CINT nu=rkinf->nu, kb=rkinf->kb, K=rkinf->K;
   ATL_INT j, nb, nnu, incb;
   TYPE ONE[2] = {ATL_rone, ATL_rzero};

   rA = iA + rkinf->mb*kb;
/*
 * Loop over small N blks of size NNU-1
 */
   nb = rkinf->nb - nu;
   incC = nb * (ldc+ldc);
   rC = iC + rkinf->szC;
   nnu = rkinf->nnu - 1;
   incb = rkinf->incaS;
   for (n=rkinf->N, j=0; j < nsnblks; n -= nb, j++)
   {
      TYPE *rB = iB + incb, *bn = (INCB) ? rB + incb : iB;
      const int nn = Mmin(n, nb);

      if (b2blk)
      {
         b2blk(K, nn, ONE, B, ldb, rB, iB);
         B += incBnS;
      }
      amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, rA, bn, iC);
      if (blk2C)
      {
         blk2C(M, nn, ONE, rC, iC, beta, C, ldc);
         C += incC;
      }
      iB = bn;
   }
/*
 * Now, finish col-panel out by looping over full blocks
 */
   nb += nu;
   incC = nb * (ldc+ldc);
   nnu++;
@skip   rC = iC + mb*nb;
   incb = rkinf->inca;
   for (; j < nnblks; j++, n -= nb)
   {
      TYPE *rB = iB + incb, *bn = (INCB) ? rB + incb : iB;
      const int nn = Mmin(n, nb);

      if (b2blk)
      {
         b2blk(K, nn, ONE, B, ldb, rB, iB);
         B += incBn;
      }
      amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, rA, bn, iC);
      if (blk2C)
      {
         blk2C(M, nn, ONE, rC, iC, beta, C, ldc);
         C += incC;
      }
      iB = bn;
   }
}
@ROUT ATL_ammmM ATL_cammmM
#include "atlas_amm.h"
/*
 * This function loops only over M.  Therefore, it updates 1 column-panel
 * of C using a rank-kb update of a column-panel of A * colpan of B
 * If A2blk non-NULL, copy A, else assume already available in a.
 */
void Mjoin(PATL,ammmM) /* C <= beta*C + A*B, B/C nb-wide colpan */
(
   rkinfo_t *rkinf,
   int N,              /* # of cols to do */
   int nb,             /* CEIL(N/nu)*nu */
   int nnu,            /* nb/nu */
   TYPE *a,            /* workspace for A */
   int INCA,           /* 0: don't increment a, else do */
   const TYPE *b,      /* access-major kbXnb workspace for B */
   TYPE *c,            /* access-major mbXnb workspace for C */
   const TYPE *A,      /* col/row-major (original) A */
   TYPE *C,            /* col-major (original) C */
   const SCALAR beta   /* scale factor for C */
)
@ROUT ATL_ammmM
{
   ammkern_t amm=rkinf->amm_b0;
   ablk2cmat_t blk2C=rkinf->blk2C;/* frm C's access-maj storage to col-maj */
   cm2am_t a2blk=rkinf->a2blk;    /* copy from row/col major A to access-maj */
   const size_t nsmblks=rkinf->nsmblks, nmblks=rkinf->nmblks;
   const size_t incAmS=rkinf->incAmS, incAm=rkinf->incAm; 
   const size_t lda=rkinf->lda, ldc=rkinf->ldc;
   size_t m;
   ATL_CINT mu=rkinf->mu, kb=rkinf->kb, K=rkinf->K;
   ATL_INT i, mb, nmu, inca;
/*
 * Loop over small M-blks of size NMU-1
 */
   mb = rkinf->mb - mu;
   nmu = rkinf->nmu - 1;
   inca = (INCA) ? rkinf->incaS : 0;
   for (m=rkinf->M, i=0; i < nsmblks; m -= mb, i++)
   {
      TYPE *an = a + inca;
      const int mm = Mmin(m, mb);

      if (a2blk)
      {
         a2blk(K, mm, ATL_rone, A, lda, a);
         A += incAmS;
      }
      amm(nmu, nnu, kb, a, b, c, an, b, c);
      if (blk2C)
      {
         blk2C(mm, N, ATL_rone, c, beta, C, ldc);
         C += mb;
      }
      a = an;
   }
/*
 * Now, finish col-panel out by looping over full blocks
 */
   nmu++;
   mb += mu;
   inca = (INCA) ? rkinf->inca : 0;
   for (; i < nmblks; i++, m -= mb)
   {
      TYPE *an = a + inca;
      const int mm = Mmin(m, mb);
// fprintf(stderr, "i=%d, mm=%d\n", (int)i, (int)mm);

      if (a2blk)
      {
         a2blk(K, mm, ATL_rone, A, lda, a);
         A += incAm;
      }
      amm(nmu, nnu, kb, a, b, c, an, b, c);
      if (blk2C)
      {
         blk2C(mm, N, ATL_rone, c, beta, C, ldc);
         C += mb;
      }
      a = an;
   }
}
@ROUT ATL_cammmM
{
   ammkern_t amm_b0=rkinf->amm_b0, amm_b1=rkinf->amm_b1,amm_bn=rkinf->amm_bn;
   ablk2cmat_t blk2C=rkinf->blk2C;/* frm C's access-maj storage to col-maj */
   cm2am_t a2blk=rkinf->a2blk;    /* copy from row/col major A to access-maj */
   TYPE *iA=a, *iC=c, *rC;
   const TYPE *rB, *iB=b;
   const size_t nsmblks=rkinf->nsmblks, nmblks=rkinf->nmblks;
   const size_t incAmS=rkinf->incAmS, incAm=rkinf->incAm; 
   const size_t lda=rkinf->lda, ldc=rkinf->ldc;
   size_t m;
   ATL_CINT mu=rkinf->mu, kb=rkinf->kb, K=rkinf->K;
   ATL_INT i, mb, mb2, nmu, inca;
   TYPE ONE[2] = {ATL_rone, ATL_rzero};

   rB = iB + rkinf->nb*kb;
/*
 * Loop over small M-blks of size NMU-1
 */
   mb = rkinf->mb - mu;
   rC = iC + mb*nb;
   mb2 = mb + mb;
   nmu = rkinf->nmu - 1;
   inca = rkinf->incaS;
   for (m=rkinf->M, i=0; i < nsmblks; m -= mb, i++)
   {
      TYPE *rA = iA + inca, *an = (INCA) ? rA + inca : iA;
      const int mm = Mmin(m, mb);

      if (a2blk)
      {
         a2blk(K, mm, ONE, A, lda, rA, iA);
         A += incAmS;
      }
      amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, an, iB, iC);
      if (blk2C)
      {
         blk2C(mm, N, ONE, rC, iC, beta, C, ldc);
         C += mb2;
      }
      iA = an;
   }
/*
 * Now, finish col-panel out by looping over full blocks
 */
   nmu++;
   mb += mu;
   rC = iC + mb*nb;
   mb2 = mb + mb;
   inca = rkinf->inca;
   for (; i < nmblks; i++, m -= mb)
   {
      TYPE *rA = iA + inca, *an = (INCA) ? rA + inca : iA;
      const int mm = Mmin(m, mb);

      if (a2blk)
      {
         a2blk(K, mm, ONE, A, lda, rA, iA);
         A += incAm;
      }
      amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, an, iB, iC);
      if (blk2C)
      {
         blk2C(mm, N, ONE, rC, iC, beta, C, ldc);
         C += mb2;
      }
      iA = an;
   }
}
@ROUT ATL_ammm_rkK
#include "atlas_amm.h"
/*
 * This routine called when 2 < K <= MAXK
 */
int Mjoin(PATL,ammm_rkK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   void *vp;
   TYPE *a, *b, *iC, *rC;
   rkinfo_t op;
   size_t nnblks;
   #ifdef TCPLX
      const size_t ldc2=ldc+ldc;
   #else
      #define ldc2 ldc
   #endif
      

   if (K < 3)
   {
      Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
      return(0);
   }
   Mjoin(PATL,GetRKInfo)(&op, 0, TA, TB, M, N, K, lda, ldb, ldc, alpha, beta);
   #if 0
   printf("MB=(%d,%d), mb=(%d,%d); NB=(%d,%d), nb=(%d,%d)\n",
          op.mb, (int)op.nfmblks, op.pmb, (int)op.npmblks,
          op.nb, (int)op.nfnblks, op.pnb, (int)op.npnblks);
   #endif
/*
 *  Usual case, compute column-panel of C at a time, need workspace of
 *  1 block of B and C, and 1 col-panel of A.
 */
   if (op.nfmblks+op.npmblks != 1)
   {
      const size_t nnblks = op.nfnblks+op.npnblks;
      size_t sz, szA, j;
      if (nnblks > 1)
         szA = op.szA*op.nfmblks + op.pszA*op.npmblks;
      else 
         szA = op.szA;
      sz = szA + op.szC + op.szB + (op.mu<<1)*op.nu;
      vp = malloc(ATL_MulBySize(sz) + 3*ATL_Cachelen);
      if (!vp)
         return(1);
      a = ATL_AlignPtr(vp);
      b = a + (szA SHIFT);
      b = ATL_AlignPtr(b);
      iC = b + (op.szB SHIFT);
      iC = ATL_AlignPtr(iC);
      #ifdef TCPLX
         rC = iC + op.szC;
      #else
         rC = iC;
      #endif

      if (nnblks == 1)
         Mjoin(PATL,oploopsM)(&op, 0, 0, A, B, C, 0, a, b, rC, iC);
      else
      {
         for (j=0; j < nnblks; j++)
         {
            Mjoin(PATL,oploopsM)(&op, 0, j, A, B, C, 1, a, b, rC, iC);
            A = NULL;
         }
      }
   }
   else  /* only 1 block of A, traverse C row-wise */
   {
      size_t sz;
      sz = op.szA + op.szB + op.szC + (op.mu<<1)*op.nu;
      vp = malloc(ATL_MulBySize(sz) + 3*ATL_Cachelen);
      if (!vp)
         return(1);
      a = ATL_AlignPtr(vp);
      b = a + (op.szA SHIFT);
      b = ATL_AlignPtr(b);
      iC = b + (op.szB SHIFT);
      iC = ATL_AlignPtr(iC);
      #ifdef TCPLX
         rC = iC + op.szC;
      #else
         rC = iC;
      #endif
      Mjoin(PATL,oploopsN)(&op, 0, 0, A, B, C, 0, a, b, rC, iC);
   }
   free(vp);
   return(0);
}
@beginskip
{
   void *vp;
   TYPE *a, *b, *c;
   size_t szA, szB, szC, incC, incBn, nnblks, nsnblks, nmblks, nsmblks;
   rkinfo_t rkinf;
   ATL_UINT kb, NOREP, mb, MB, NB, NNU, mu, nu;
   #ifdef TCPLX
      TYPE *rB;
      const size_t ldc2=ldc+ldc;
   #else
      #define ldc2 ldc
   #endif
      

   if (K < 3)
   {
      Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
      return(0);
   }
   Mjoin(PATL,GetRKInfo)(&rkinf, 0,TA, TB, M, N, K, lda, ldb, ldc, alpha, beta);

   kb = rkinf.kb;
   nnblks = rkinf.nnblks;
   nsnblks = rkinf.nsnblks;
   nmblks = rkinf.nmblks;
   nsmblks = rkinf.nsmblks;
   MB = rkinf.mb;
   NB = rkinf.nb;
   NNU = rkinf.nnu;
   mu = rkinf.mu;
   nu = rkinf.nu;
   mb = MB - mu;
   NOREP = (nnblks < 2 || nmblks < 2);
   if (NOREP)
      szA = MB*kb;
   else
      szA = (mb*kb)*nsmblks + (MB*kb)*(nmblks-nsmblks);
   szB = NB*kb;
@skip   szC = MB*NB;
   szC = rkinf.szC;
   vp = malloc(3*ATL_Cachelen + ATL_MulBySize(szA+szB+szC+2*mu*nu*rkinf.ku));
   ATL_assert(vp);
   if (!vp)
      return(1);
   a = ATL_AlignPtr(vp);
   b = a + (szA SHIFT);
   b = ATL_AlignPtr(b);
   c = b + (szB SHIFT);
   c = ATL_AlignPtr(c);

/*
 * If we have a degenerate case of 1 row-panel of C, handle that seperately
 */
   if (nmblks < 2 && nnblks > 1)
   {
      cm2am_t a2blk = rkinf.a2blk;
      size_t M=rkinf.M;
      int nmu = rkinf.nmu;

      #ifdef TCPLX
         a2blk(K, M, alpha, A, lda, a+szA, a);
      #else
         a2blk(K, M, alpha, A, lda, a);
      #endif
      if (nsmblks)
         nmu--;
      else
         mb = MB;
      Mjoin(PATL,ammmN)(&rkinf, M, mb, nmu, a, b, 0, c, B, C, beta);
   }
   else  /* usual case, work on column-panel of C at a time */
   {
      cm2am_t b2blk = rkinf.b2blk;
      size_t n, j;
      #ifdef TCPLX
         TYPE *rB = b + szB;
      #endif

      for (n=N,j=0; j < nnblks; j++)
      {
         size_t incB;
         int nmu, mb, nnu, nb, nn;
   
         if (j < nsnblks)
         {
            nb = NB-nu;
            nnu = NNU-1;
            incB = rkinf.incBnS;
         }
         else
         {
            nb = NB;
            nnu = NNU;
            incB = rkinf.incBn;
         }
         nn = Mmin(n, nb);
         #ifdef TCPLX
            b2blk(K, nn, alpha, B, ldb, rB, b);
         #else
            b2blk(K, nn, alpha, B, ldb, b);
         #endif
         B += incB;
         Mjoin(PATL,ammmM)(&rkinf, nn, nb, nnu, a, !NOREP, b, c, A, C, beta);
         rkinf.a2blk = NULL;  /* A copied fully in this 1 call */
         C += nb*ldc2;
         n -= nb;
      }
   }
   free(vp);
   return(0);
}
@endskip
#ifdef ldc2
   #undef ldc2
#endif
@ROUT ATL_ammmNKM
#include "atlas_amm.h"

static void Mjoin(PATL,ammmKM)/* computes full answer for one col-panel of C */
(                      /* by looping over both M&K */
   rkinfo_t *rkinf,    /* amm info for kb-width cols */
   rkinfo_t *krinf,    /* amm info for K remainder cols */
   int nb,             /* # of cols to do */
   int nnu,            /* NB/nu */
   TYPE *a,            /* workspace for A */
   ATL_CINT incam,     /* gap between blocks (>= mb*kb) */
   ATL_CINT incak,     /* 0: reuse same col of a, else a M*K in size */
   TYPE *b,            /* access-major kbXnb workspace for B */
   TYPE *c,            /* access-major mbXnb workspace for C */
   ATL_CINT inccm,     /* 0: write to C, else: write only to c */
   const TYPE *A,      /* col/row-major (original) A */
   const TYPE *B,      /* col/row-major (original) B */
   TYPE *C,            /* col-major (original) C */
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   const SCALAR alpha, /* scale factor for B */
   const SCALAR beta   /* scale factor for C */
)
{
   const size_t incAk=rkinf->incAk, incBk=rkinf->incBk;
   const size_t ldb=rkinf->ldb;
   cm2am_t b2blk=rkinf->b2blk;
   ablk2cmat_t blk2c=rkinf->blk2c;
   ammkern_t amm=rkinf->amm_b0, amm_b1=rkinf->amm_b1;
   ATL_CINT idr=krinf->idx;
   ATL_CINT kb=rkinf->kb, kbL=rkinf->kbL, nfkblks=rkinf->nfkb;
   ATL_INT k, nk=rkinf->nfkb, DOPEEL=1;
   
   ATL_assert(rkinf->idx != -1);  /* don't call w/o more than 1 K block */
/*
 * The last block must be peeled to write C unless the last block is actually
 * a partial K-block, which isn't handled here anyway.  We also must peel and
 * write C if the K-block doesn't use the same C storage, which requires
 * an additional write to the original C to handle.  So, the only time we
 * don't peel an iteration is when the K-cleaner exists, and uses the 
 * the same format as the mainline K
 */
   if (kbL == 0 || idr == -1) /* no K-clean or GER/GER2 clean forces peel */
      nk--;
   else if (krinf->mu != rkinf->mu || krinf->nu != rkinf->nu)
      nk--;
   else
      DOPEEL=0;

   rkinf->blk2c = NULL;           /* don't write C out until K loop done */
   for (k=0; k < nk; k++, A += incAk, B += incBk)
   {
      b2blk(kb, nb, alpha, B, ldb, b);
      Mjoin(PATL,ammmM)(rkinf, nb, nnu, amm, a, incam, b, c, inccm, A, C, beta);
      amm = amm_b1;
      a += incak;
   }
   rkinf->blk2c = blk2c;  /* next ammmM call should write to C */
/*
 * If we peeled to write C, do that along with last full M block
 */
   if (DOPEEL)
   {
      b2blk(kb, nb, alpha, B, ldb, b);
      Mjoin(PATL,ammmM)(rkinf, nb, nnu, amm, a, incam, b, c, inccm, A, C, beta);
      a += incak;
      A += incAk;
      B += incBk;
   }
/*
 * Do we have K-cleanup to do?
 */
   if (kbL)
   {
      if (idr >= 0)  /* K cleanup uses gemm kernel */
      {
         krinf->kb = kbL;
         krinf->b2blk(kbL, nb, alpha, B, ldb, b);
         Mjoin(PATL,ammmM)(krinf, nb, nnu, krinf->amm_b1, a, incam, b, 
                           c, inccm, A, C, (DOPEEL)?ATL_rone:beta);
      }
/*
 *    If we use GER1/GER2 for cleanup, beta has already been applied above
 */
      else if (kbL == 2)  /* use GER2 to clean up */
         Mjoin(PATL,ammm_rk2)(TA, TB, M, nb, alpha, A, rkinf->lda, B, ldb, 
                              ATL_rone, C, rkinf->ldc);
      else /* kbL == 1, use GER1 */
      {
         #ifdef TCPLX
            ATL_CINT incA = (TA==AtlasNoTrans || TA==AtlasConj) ? 1:rkinf->lda;
            ATL_CINT incB = (TB==AtlasNoTrans || TB==AtlasConj) ? ldb:1;
         #else
            ATL_CINT incA = (TA==AtlasNoTrans) ? 1:rkinf->lda;
            ATL_CINT incB = (TB==AtlasNoTrans) ? ldb:1;
         #endif
         Mjoin(PATL,ger)(M, nb, alpha, A, incA, B, incB, C, rkinf->ldc);
      }
   }
}


static int ATL_ammm_rkK
(
   rkinfo_t *krinf,
   ATL_CSZT N,
   const SCALAR alpha,
   const TYPE *A,
   const TYPE *B,
   TYPE *C,
   const SCALAR beta
)
{
   const size_t ldb=krinf->ldb, ldc=krinf->ldc;
   ATL_CINT NB=krinf->nb, mu=krinf->mu, MB=krinf->mb, kb=krinf->kb;
   ATL_CINT mbL=krinf->mbL, nfnb=krinf->nfnb, nnu=krinf->nnu;
   ATL_INT inca, j;
   const size_t incC=NB*ldc, incBn=krinf->incBn;
   size_t szA, szB, szC;
   cm2am_t b2blk = krinf->b2blk;
   TYPE *a, *b, *c;
   void *vp;

   if (N > NB)
   {
      szA = (MB*krinf->nfmb + krinf->MBL)*kb;
      inca = MB*kb;
   }
   else
   {
      szA = MB*kb;
      inca = 0;
   }
   szB = NB*kb;
@skip   szC = MB*NB;
   szC = krinf->szC;
   vp = malloc(3*ATL_Cachelen + ATL_MulBySize(szA+szB+szC));
   ATL_assert(vp);
   if (!vp)
      return(1);
   a = ATL_AlignPtr(vp);
   b = a + szA;
   b = ATL_AlignPtr(b);
   c = b + szB;
   c = ATL_AlignPtr(c);

   if (nfnb)
   {
      b2blk(kb, NB, alpha, B, ldb, b);
      Mjoin(PATL,ammmM)(krinf, NB, nnu, krinf->amm_b0, a, inca, b, c, 0, A, 
                        C, beta);
      krinf->a2blk = NULL;
      C += incC;
      B += incBn;
      for (j=1; j < nfnb; j++, C += incC, B += incBn)
      {
         b2blk(kb, NB, alpha, B, ldb, b);
         Mjoin(PATL,ammmM)(krinf, NB, nnu, krinf->amm_b0, a, inca, b, c, 0, A, 
                           C, beta);
      }
   }
   if (krinf->nbL)
   {
      b2blk(kb, krinf->nbL, alpha, B, ldb, b);
      Mjoin(PATL,ammmM)(krinf, krinf->nbL, krinf->nnuL, krinf->amm_b0, a, inca,
                        b, c, 0, A, C, beta);
   }
   free(vp);
}

int Mjoin(PATL,ammmNKM)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   rkinfo_t kbinf, krinf;
   size_t szA, szB, szC, incak, inccm, incBn, incC;
   ATL_INT j, mb, nfmb, nb, mbL, kb, kbL, incam, nfnb, nfkb, RCPYA=0;
   ATL_INT nnu, nmblks, nkblks;
   TYPE *a, *b, *c;
   void *vp;
   void Mjoin(PATL,GetBestKBInfo)
      (rkinfo_t*, rkinfo_t*, enum ATLAS_TRANS, enum ATLAS_TRANS,
       ATL_CSZT, ATL_CSZT, ATL_CSZT, size_t, size_t, size_t,
       const SCALAR, const SCALAR);

   if (K < 3)
   {
      Mjoin(PATL,ammm)(TA, TB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc);
      return(0);
   }
   Mjoin(PATL,GetBestKBInfo)(&kbinf, &krinf, TA, TB, M, N, K, lda, ldb, ldc,
                             alpha, beta);
   if (kbinf.idx == -1)
      return(ATL_ammm_rkK(&krinf, N, alpha, A, B, C, beta));

   mb = kbinf.mb;
   nb = kbinf.nb;
   kb = kbinf.kb;
   mbL = kbinf.mbL;
   kbL = kbinf.kbL;
   nfmb = kbinf.nfmb;
   nfnb = kbinf.nfnb;
   nfkb = kbinf.nfkb;
   nmblks = (mbL) ? nfmb+1 : nfmb;
   nkblks = (kbL) ? nfkb+1 : nfkb;
   nnu = kbinf.nnu;
   incBn = kbinf.incBn;
   incC = nb*ldc;
   if (K > kb)
   {
      inccm = mb*nb;
      szC = (nfmb*mb+kbinf.MBL)*nb;
   }
   else
   {
      szC = mb*nb;
      inccm = 0;
   }
   if (N > nb)
   {
      incam = mb*kb;        
      incak = incam*nmblks;
      szA = incak * nkblks;
   }
   else
   {
      incam = incak = 0;
      szA = mb * kb;
   }

   if (krinf.idx >= 0)
      RCPYA = krinf.a2blk != kbinf.a2blk;
   szB = kb*nb;
   vp = malloc(3*ATL_Cachelen + ATL_MulBySize(szA+szB+szC));
   ATL_assert(vp);
   a = ATL_AlignPtr(vp);
   b = a + szA;
   b = ATL_AlignPtr(b);
   c = b + szB;
   c = ATL_AlignPtr(c);
   for (j=0; j < nfnb; j++, C += incC, B += incBn)
      Mjoin(PATL,ammmKM)(&kbinf, &krinf, nb, nnu, a, incam, incak, b,
                         c, inccm, A, B, C, TA, TB, M, N, alpha, beta);
   if (kbinf.nbL)
   {
      Mjoin(PATL,ammmKM)(&kbinf, &krinf, kbinf.nbL, kbinf.nnuL, a, incam, incak,
                         b, c, inccm, A, B, C, TA, TB, M, N, alpha, beta);
   }
   free(vp);
   return(0);
}
@ROUT ATL_oploops
/*
 * These loops are used for outer product GEMM formulations, 
 * where K <= ATL_rkAMM_LASTKB.
 * 
 */
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
/*
 * This function used primarily by threaded rank-K update cases.  It has
 * following options:
 *   If A/B i/j block can be copied by passing base A/B ptr 
 *   If rC is NULL, then do only the indicated A/B copy, w/o ammm
 */
void Mjoin(PATL,opblk)
(
   rkinfo_t *op,
   size_t i,      /* which global row blk of C is being computed */
   size_t j,      /* which global column blk of C is being computed */
   const TYPE *A, /* if non-NULL, base A ptr to copy */
   const TYPE *B, /* if non-NULL, base B ptr to copy */
   TYPE *C,       /* C <- alpha * A * B + beta * C */
   TYPE *pA,      /* wrkspace for block-copied A */
   TYPE *pAn,     /* next A wrkspc to be prefetched */
   TYPE *pB,      /* wrkspace for block-copied B */
   TYPE *pBn,     /* next B wrkspc to be prefetched */
   TYPE *rC,      /* if non-NULL: ptr to real part of access-major C wrkspc */
   TYPE *iC       /* ptr to cplx portion of access-major C workspace */
)
{
   #ifdef TCPLX
      TYPE *iA=pA, *iB=pB;
      TYPE *rA = pA + ((i < op->nfmblks) ? op->szA:op->pszA);
      TYPE *rB = pB + ((j < op->nfnblks) ? op->szB:op->pszB);
   #endif
   ATL_CUINT kb = op->KB, K=op->kb;
   int nb, nnu, mb, nmu;

   if (B || rC)  /* need to copy A or setup nb / adjust C */
   {
      const size_t nfnblks=op->nfnblks, nnblks=nfnblks+op->npnblks;
      size_t n;

      if (j < nfnblks)
      {
         nb = op->nb;
         nnu = op->nnu;
         n = j;
      }
      else if (j != nnblks-1)
      {
         nb = op->pnb;
         nnu = op->pnnu;
         n = nfnblks;
      }
      else
      {
         nb = op->nF;
         nnu = op->nnuF;
         n = nfnblks;
      }
      j -= n;
      if (B)
      {
         B += op->incBn * n + op->pincBn * j;
         #ifdef TCPLX
            op->b2blk(K, nb, op->alpB, B, op->ldb, rB, iB);
         #else
            op->b2blk(K, nb, op->alpB, B, op->ldb, pB);
         #endif
      }
      if (rC)
         C += (op->nb * n + op->pnb * j)*((op->ldc)SHIFT);
   }
   if (A || rC)  /* need to copy a portion of A to access-major */
   {
      const size_t nfmblks=op->nfmblks, nmblks=nfmblks+op->npmblks;
      size_t m;

      if (i < nfmblks)
      {
         mb = op->mb;
         nmu = op->nmu;
         m = i;
      }
      else if (i != nmblks-1)
      {
         mb = op->pmb;
         nmu = op->pnmu;
         m = nfmblks;
      }
      else
      {
         mb = op->mF;
         nmu = op->nmuF;
         m = nfmblks;
      }
      i -= m;
      if (A)
      {
         A += op->incAm * m + op->pincAm * i;
         #ifdef TCPLX
            op->a2blk(K, mb, op->alpA, A, op->lda, rA, iA);
         #else
            op->a2blk(K, mb, op->alpA, A, op->lda, pA);
         #endif
      }
      if (rC)
         C += (op->mb * m + op->pmb * i)SHIFT;
   }

   if (rC)   /* want to do matrix multiplication */
   {
      #ifdef TCPLX
         ammkern_t amm_b0=op->amm_b0, amm_b1=op->amm_b1, amm_bn=op->amm_bn;
         amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
         amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
         amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
         amm_b1(nmu, nnu, kb, iA, rB, iC, pAn, pBn, rC);
         op->blk2C(mb, nb, op->ONE, rC, iC, op->beta, C, op->ldc);
      #else
         op->amm_b0(nmu, nnu, kb, pA, pB, rC, pAn, pBn, rC);
         op->blk2C(mb, nb, ATL_rone, rC, op->beta, C, op->ldc);
      #endif
   }
}
void Mjoin(PATL,oploopsM)
(
   rkinfo_t *op,
   size_t i,      /* which global row blk of C is being computed */
   size_t j,      /* which global column blk of C is being computed */
   const TYPE *A, /* if non-NULL, portion of A to copy */
   const TYPE *B, /* if non-NULL, portion of B to copy */
   TYPE *C,       /* C <- alpha * A * B + beta * C */
   int MV,        /* 1: move a */
   TYPE *a,       /* wrkspace for block-copied A */
   TYPE *b,       /* wrkspace for block-copied B */
   TYPE *rC,      /* ptr to real portion of access-major C workspace */
   TYPE *iC       /* ptr to cplx portion of access-major C workspace */
)
{
   #ifdef TCPLX
      TYPE *iA=a, *rA, *iB=b, *rB=b+op->szB;
      const TYPE *alpA=op->alpA, *alpB=op->alpB, *beta=op->beta;
      const ammkern_t amm0=op->amm_b0, amm1=op->amm_b1, ammN=op->amm_bn;
   #else
      const ammkern_t amm=op->amm_b0;
   #endif
   const cm2am_t a2blk=op->a2blk, b2blk=op->b2blk;
   const ablk2cmat_t blk2C=op->blk2C;
   const size_t nfmblks=op->nfmblks, nmblks=op->npmblks+nfmblks, lda=op->lda;
   const size_t nfnblks=op->nfnblks, nnblks=op->npnblks+nfnblks;
   #ifndef TCPLX
      const TYPE alpA=op->alpA, alpB=op->alpB, beta=op->beta;
   #endif
   ATL_CUINT kb=op->kb, KB=op->KB;
   ATL_CUINT mu=op->mu, nu=op->nu;
   ATL_UINT nmu, mb, nnu=op->nnu, nb=op->nb;

/*
 * If needed, copy B block before starting operations
 */
   if (B)
   {
      if (j)  /* need to increment B & C before copy */
      {
         const size_t incCn=(op->ldc)SHIFT;
         size_t nblks=Mmin(j, nfnblks);
         B += nblks * op->incBn;
         C += nblks*nb*incCn;
         if (j >= nfnblks)  /* need to switch to smaller nb */
         {
            #ifdef TCPLX
               rB = iB + op->pszB;
            #endif
            nb = op->pnb;
            nnu = op->pnnu;
            nblks = j - nfnblks;
            B += nblks*op->pincBn;
            C += nblks*nb*incCn;
         }
      }
      if (j == nnblks-1 && j >= nfnblks)
      {
         nb = op->nF;
         nnu = op->nnuF;
      }
      #ifdef TCPLX
         b2blk(kb, nb, alpB, B, op->ldb, rB, iB);
      #else
         b2blk(kb, nb, alpB, B, op->ldb, b);
      #endif
   }
   else   /* still need to inc C ptr & set nnu/nb */
   {
      size_t incBn=op->incBn, incCn=(op->ldc)SHIFT;
      size_t nblks=Mmin(j, nfnblks);
      C += nblks*nb*incCn;
      if (j >= nfnblks)  /* need to switch to smaller nb */
      {
         #ifdef TCPLX
            rB = iB + op->pszB;
         #endif
         nb = op->pnb;
         nnu = op->pnnu;
         nblks = j - nfnblks;
         C += nblks*nb*incCn;
         if (j == nnblks-1)
         {
            nb = op->nF;
            nnu = op->nnuF;
         }
      }
   }
/*
 * If present block is one of first large blocks, loop over large blks
 */
   if (i < nfmblks)
   {
      const size_t incAm = (A) ? op->incAm:0, incCm = (op->mb)SHIFT, m;
      ATL_UINT szA = op->szA;

      if (i)               /* if we need to skip some blocks */
      {                    /* Increment A/C ptrs as needed for i */
         if (A)
            A += i * incAm;   
         C += i * incCm;
      }
      #ifdef TCPLX
         rA = iA + szA;
      #endif
      nmu = op->nmu;
      mb = op->mb;
      for (; i < nfmblks; i++)
      {
         #ifdef TCPLX
            TYPE *an=iA;
         #else
            TYPE *an=a;
         #endif
@skip         mb = (i != nmblks-1) ? op->mb : op->mF;
         if (A)
         {
            #ifdef TCPLX
               a2blk(kb, mb, alpA, A, lda, rA, iA);
            #else
               a2blk(kb, mb, alpA, A, lda, a);
            #endif
            A = (nmblks != 1) ? (A+incAm) : NULL;
         }
         if (MV&1)
         #ifdef TCPLX
            an = rA + szA;
         #else
            an += szA;
         #endif
         #ifdef TCPLX
            amm0(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
            amm0(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
            ammN(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
            amm1(nmu, nnu, KB, iA, rB, iC, an, iB, iC);
            blk2C(mb, nb, op->ONE, rC, iC, beta, C, op->ldc);
            iA = an;
            rA = an + szA;
         #else
            amm(nmu, nnu, KB, a, b, rC, an, b, rC);
            blk2C(mb, nb, ATL_rone, rC, beta, C, op->ldc);
            a = an;
         #endif
         C += incCm;
      }
   }
/*
 * If present block past end of large blocks, increment A/C appropriately
 */
   else if (i && nfmblks)
   {
      if (A)
         A += nfmblks * op->incAm;
      C += nfmblks * ((op->mb)SHIFT);
   }
/*
 * If there are still small blocks to do after doing all large blocks
 */
   if (i < nmblks)
   {
      const size_t incAm = (A) ? op->pincAm:0, incCm = (op->pmb)SHIFT;
      ATL_UINT szA = op->pszA;

      if (i > nfmblks)  /* I need to move past some small blocks too */
      {
         size_t nblks = i - nfmblks;
         A += nblks * incAm;
         C += nblks * incCm;
      }
      mb = op->pmb;
      nmu = op->pnmu;
      for (; i < nmblks; i++)
      {
         #ifdef TCPLX
            TYPE *an=iA;
         #else
            TYPE *an=a;
         #endif
         if (i == nmblks-1)
         {
            mb = op->mF;
            nmu = op->nmuF;
         }
@skip         mb = (i != nmblks-1) ? mb : op->mF;
         #ifdef TCPLX
            rA = iA + szA;
         #endif
         if (A)
         {
            #ifdef TCPLX
               a2blk(kb, mb, alpA, A, lda, rA, iA);
            #else
               a2blk(kb, mb, alpA, A, lda, a);
            #endif
            A = (nmblks != 1) ? (A+incAm) : NULL;
         }
         #ifdef TCPLX
            if (MV&1)
               an = rA + szA;
            amm0(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
            amm0(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
            ammN(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
            amm1(nmu, nnu, KB, iA, rB, iC, an, iB, iC);
            blk2C(mb, nb, op->ONE, rC, iC, beta, C, op->ldc);
            iA = an;
            rA = an + szA;
         #else
            if (MV&1)
               an += szA;
            amm(nmu, nnu, KB, a, b, rC, an, b, rC);
            blk2C(mb, nb, ATL_rone, rC, beta, C, op->ldc);
            a = an;
         #endif
         C += incCm;
      }
   }
}
void Mjoin(PATL,oploopsN)
(
   rkinfo_t *op,
   size_t i,      /* which global row blk of C is being computed */
   size_t j,      /* which global column blk of C is being computed */
   const TYPE *A, /* if non-NULL, portion of A to copy */
   const TYPE *B, /* if non-NULL, portion of B to copy */
   TYPE *C,       /* C <- alpha * A * B + beta * C */
   int MV,        /* 2: move b */
   TYPE *a,       /* wrkspace for block-copied A */
   TYPE *b,       /* wrkspace for block-copied B */
   TYPE *rC,      /* ptr to real portion of access-major C workspace */
   TYPE *iC       /* ptr to cplx portion of access-major C workspace */
)
{
   #ifdef TCPLX
      TYPE *iA=a, *rA=a+op->szA, *iB=b, *rB;
      const TYPE *alpA=op->alpA, *alpB=op->alpB, *beta=op->beta;
      const ammkern_t amm0=op->amm_b0, amm1=op->amm_b1, ammN=op->amm_bn;
   #else
      const ammkern_t amm=op->amm_b0;
   #endif
   const cm2am_t a2blk=op->a2blk, b2blk=op->b2blk;
   const ablk2cmat_t blk2C=op->blk2C;
   const size_t nfmblks=op->nfmblks, nmblks=op->npmblks+nfmblks, ldb=op->ldb;
   const size_t nfnblks=op->nfnblks, nnblks=op->npnblks+nfnblks, ldc=op->ldc;
   #ifndef TCPLX
      const TYPE alpA=op->alpA, alpB=op->alpB, beta=op->beta;
   #endif
   ATL_CUINT kb=op->kb, KB=op->KB;
   ATL_CUINT mu=op->mu, nu=op->nu;
   ATL_UINT nmu=op->nmu, mb=op->mb, nnu, nb;

/*
 * If needed, copy A block before starting operations
 */
   if (A)
   {
      if (i)  /* need to increment A & C before copy */
      {
         size_t nblks=Mmin(i, nfmblks);
         A += nblks * op->incAm;
         C += nblks*(mb SHIFT);
         if (i >= nfmblks)  /* need to switch to smaller mb */
         {
            #ifdef TCPLX
               rA = iA + op->pszA;
            #endif
            mb = op->pmb;
            nmu = op->pnmu;
            nblks = i - nfmblks;
            A += nblks*op->pincAm;
            C += nblks*(mb SHIFT);
         }
      }
      if (i == nmblks-1 && i >= nfmblks)
      {
         mb = op->mF;
         nmu = op->nmuF;
      }
      #ifdef TCPLX
         a2blk(kb, mb, alpA, A, op->lda, rA, iA);
      #else
         a2blk(kb, mb, alpA, A, op->lda, a);
      #endif
   }
   else   /* still need to inc C ptr & set nnu/nb */
   {
      size_t nblks=Mmin(i, nfmblks);
      C += nblks*(mb SHIFT);
      if (i >= nfmblks)  /* need to switch to smaller mb */
      {
         #ifdef TCPLX
            rA = iA + op->pszA;
         #endif
         mb = op->pmb;
         nmu = op->pnmu;
         nblks = i - nfmblks;
         C += nblks*(mb SHIFT);
         if (i == nmblks-1)
         {
            mb = op->mF;
            nmu = op->nmuF;
         }
      }
   }
/*
 * If present block is one of first large blocks, loop over large blks
 */
   if (j < nfnblks)
   {
      const size_t incBn = (B) ? op->incBn:0, incCn = ldc*(op->nb)SHIFT;
      ATL_UINT szB = op->szB;
      ATL_CUINT incBw = (MV&2) ? ((szB)SHIFT):0;

      if (j)               /* if we need to skip some blocks */
      {                    /* Increment B/C ptrs as needed for j */
         if (B)
            B += j * incBn;
         C += j * incCn;
      }
      #ifdef TCPLX
         rB = iB + szB;
      #endif
      nnu = op->nnu;
      nb = op->nb;
      for (; j < nfnblks; j++)
      {
         #ifdef TCPLX
            TYPE *bn=iB+incBw;
         #else
            TYPE *bn=b+incBw;
         #endif
         if (B)
         {
            #ifdef TCPLX
               b2blk(kb, nb, alpB, B, ldb, rB, iB);
            #else
               b2blk(kb, nb, alpB, B, ldb, b);
            #endif
            B = (nnblks != 1) ? (B+incBn) : NULL;
         }
         #ifdef TCPLX
            amm0(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
            amm0(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
            ammN(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
            amm1(nmu, nnu, KB, iA, rB, iC, iA, bn, iC);
            blk2C(mb, nb, op->ONE, rC, iC, beta, C, ldc);
            iB = bn;
            rB = bn + szB;
         #else
            amm(nmu, nnu, KB, a, b, rC, a, bn, rC);
            blk2C(mb, nb, ATL_rone, rC, beta, C, ldc);
            b = bn;
         #endif
         C += incCn;
      }
   }
/*
 * If present block past end of large blocks, increment B/C appropriately
 */
   else if (j && nfnblks)
   {
      if (B)
         B += nfnblks * op->incBn;
      C += nfnblks * (op->nb * ldc)SHIFT;
   }
/*
 * If there are still small blocks to do after doing all large blocks
 */
   if (j < nnblks)
   {
      const size_t incBn = (B) ? op->pincBn:0, incCn = ldc*(op->pnb)SHIFT;
      ATL_UINT szB = op->pszB;
      ATL_CUINT incBw = (MV&2) ? ((szB)SHIFT):0;

      if (j > nfnblks)  /* I need to move past some small blocks too */
      {
         size_t nblks = j - nfnblks;
         B += nblks * incBn;
         C += nblks * incCn;
      }
      nb = op->pnb;
      nnu = op->pnnu;
      for (; j < nnblks; j++)
      {
         #ifdef TCPLX
            TYPE *bn = iB + incBw;
         #else
            TYPE *bn = b + incBw;
         #endif
         if (j == nnblks-1)
         {
            nb = op->nF;
            nnu = op->nnuF;
         }
         #ifdef TCPLX
            rB = iB + szB;
         #endif
         if (B)
         {
            #ifdef TCPLX
               b2blk(kb, nb, alpB, B, ldb, rB, iB);
            #else
               b2blk(kb, nb, alpB, B, ldb, b);
            #endif
            B = (nnblks != 1) ? (B+incBn) : NULL;
         }
         #ifdef TCPLX
            amm0(nmu, nnu, KB, iA, iB, rC, rA, iB, iC);
            amm0(nmu, nnu, KB, rA, iB, iC, rA, rB, rC);
            ammN(nmu, nnu, KB, rA, rB, rC, iA, rB, iC);
            amm1(nmu, nnu, KB, iA, rB, iC, iA, bn, iC);
            blk2C(mb, nb, op->ONE, rC, iC, beta, C, op->ldc);
            iB = bn;
            rB = bn + szB;
         #else
            amm(nmu, nnu, KB, a, b, rC, a, bn, rC);
            blk2C(mb, nb, ATL_rone, rC, beta, C, op->ldc);
            b = bn;
         #endif
         C += incCn;
      }
   }
}
@ROUT ATL_iploops ATL_ciploops
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))
/*
 * A & B ptrs should point to start of K iteration in this rout
 */
void Mjoin(PATL,iploopsK)
(
   ipinfo_t *ip,
   size_t i,              /* which global row block of C is being computed */
   size_t j,              /* which global col block of C is being computed */
   const TYPE *A,         /* if non-NULL, Portion A to cpy */
   const TYPE *B,         /* if non-NULL, Portion B to cpy, else ignored */
   TYPE *C,               /* original C to write ans to at end of Kloop */
   int MV,                /* 1: move a, 2: move b, 3: move A & B */
   TYPE *a,               /* wrkspace for block-copied A */
   TYPE *b,               /* wrkspace for block-copied B */
   TYPE *rC,              /* ptr to real portion of C access-major workspace */
   TYPE *iC,              /* ptr to complex C workspace */
   const SCALAR beta,     /* scaling factor for C */
   const ablk2cmat_t blk2c   /* C = alpC*(rC,iC) + beta*C */
)
{
   cm2am_t a2blk=ip->a2blk, b2blk=ip->b2blk;
   ammkern_t amm=ip->ammK1_b0;
   ATL_CUINT kb=ip->kb, kb0=ip->kb0, KB0=ip->KB0;
   ATL_CUINT mu=ip->mu, nu=ip->nu;
   ATL_UINT nmu, nnu, mb, nb;
   const size_t nfmblks=ip->nfmblks, nfnblks=ip->nfnblks, nfkblks=ip->nfkblks;
   const size_t nmblks=ip->npmblks+nfmblks, nnblks=ip->npnblks+nfnblks;
   const size_t lda=ip->lda, ldb=ip->ldb;
   const size_t incAk=ip->incAk, incBk=ip->incBk;
   size_t inca, incb, k;
   TYPE *an, *bn;
   #ifdef TCPLX
      ammkern_t amm_bn=ip->amm_bn, amm_b1=ip->amm_b1;
      size_t cinca, cincb;
      const TYPE *alpA=ip->alpA, *alpB=ip->alpB;
   #else
      const TYPE alpA=ip->alpA, alpB=ip->alpB;
   #endif

   if (i == nmblks-1)
   {
      nmu = ip->nmuF;
      mb = ip->mF;
      inca = (i < nfmblks) ? ip->szA : ip->pszA;
   }
   else if (i < nfmblks)
   {
      nmu = ip->nmu;
      mb = ip->mb;
      inca = ip->szA;
   }
   else
   {
      nmu = ip->pnmu;
      inca = ip->pszA;
      mb = ip->pmb;
   }
   
   if (j == nnblks-1)
   {
      nnu = ip->nnuF;
      nb = ip->nF;
      incb = (j < nfnblks) ? ip->szB : ip->pszB;
   }
   else if (j < nfnblks)
   {
      nnu = ip->nnu;
      incb = ip->szB;
      nb = ip->nb;
   }
   else
   {
      nnu = ip->pnnu;
      incb = ip->pszB;
      nb = ip->pnb;
   }

#ifdef TCPLX
   cinca = inca;
   cincb = incb;
   inca = (MV&1) ? inca+inca : 0;
   incb = (MV&2) ? incb+incb : 0;
/*
 * =========================================================
 * Peel first iteration to handle K remainder and use beta=0
 * =========================================================
 */
/* 
 * If last K block of different size, take it from end of vector to avoid
 * screwing up alignment
 */
   if (kb0 != kb)
   {
      TYPE *iA, *rA, *iB, *rB;
      an = a; bn = b;
      iA = a + nfkblks*inca;
      rA = iA + cinca;
      if (A)
         a2blk(kb0, mb, alpA, A+incAk*nfkblks, lda, rA, iA);
      iB = b + nfkblks*incb;
      rB=iB+cincb;
      if (B)
         b2blk(kb0, nb, alpB, B+incBk*nfkblks, ldb, rB, iB);
      if (iC)
      {
         amm(nmu, nnu, KB0, iA, iB, rC, rA, iB, iC);
         amm(nmu, nnu, KB0, rA, iB, iC, rA, rB, rC);
         ip->ammK1_bn(nmu, nnu, KB0, rA, rB, rC, iA, rB, iC);
         ip->ammK1_b1(nmu, nnu, KB0, iA, rB, iC, an, bn, rC);
      }
   }
/*
 * Otherwise just take first block, so any hardware prefetch isn't confused
 */
   else
   {
      TYPE *iA=a, *rA=iA+cinca, *iB=b, *rB=iB+cincb;
      an=a+inca; bn=b+incb;
      if (A)
      {
         a2blk(kb0, mb, alpA, A, lda, rA, iA);
         A += incAk;
      }
      if (B)
      {
         b2blk(kb0, nb, alpB, B, ldb, rB, iB);
         B += incBk;
      }
      if (iC)
      {
         amm(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
         amm(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
         ip->ammK1_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
         ip->ammK1_b1(nmu, nnu, kb, iA, rB, iC, an, bn, rC);
      }
   }
   a = an;
   b = bn;

   for (k=0; k < nfkblks; k++)
   {
      TYPE *iA=a, *rA=iA+cinca, *iB=b, *rB=iB+cincb;
      an=a+inca; bn=b+incb;
      if (A)
      {
         a2blk(kb, mb, alpA, A, lda, rA, iA);
         A += incAk;
      }
      if (B)
      {
         b2blk(kb, nb, alpB, B, ldb, rB, iB);
         B += incBk;
      }
      an = a + inca;
      bn = b + incb;
      if (iC)
      {
         amm_bn(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
         amm_b1(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
         amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
         amm_b1(nmu, nnu, kb, iA, rB, iC, an, bn, rC);
      }

      a = an;
      b = bn;
   }
   if (blk2c)
      blk2c(mb, nb, ip->alpC, rC, iC, beta, C, ip->ldc);
#else
   if (!(MV&1))
      inca = 0;
   if (!(MV&2))
      incb = 0;
/*
 * =========================================================
 * Peel first iteration to handle K remainder and use beta=0
 * =========================================================
 */
/* 
 * If last K block of different size, take it from end of vector to avoid
 * screwing up alignment
 */
   if (kb0 != kb)
   {
      an=a; bn=b;
      a += nfkblks*inca;
      if (A)
         a2blk(kb0, mb, alpA, A+incAk*nfkblks, lda, a);
      b += nfkblks*incb;
      if (B)
         b2blk(kb0, nb, alpB, B+incBk*nfkblks, ldb, b);
      if (rC)
         amm(nmu, nnu, KB0, a, b, rC, an, bn, rC);
   }
/*
 * Otherwise just take first block, so any hardware prefetch isn't confused
 */
   else
   {
      an=a+inca; bn=b+incb;
      if (A)
      {
         a2blk(kb0, mb, alpA, A, lda, a);
         A += incAk;
      }
      if (B)
      {
         b2blk(kb0, nb, alpB, B, ldb, b);
         B += incBk;
      }
      if (rC)
         amm(nmu, nnu, KB0, a, b, rC, an, bn, rC);
   }
   amm = ip->amm_b1;
   a = an;
   b = bn;

   for (k=0; k < nfkblks; k++)
   {
      if (A)
      {
         a2blk(kb, mb, alpA, A, lda, a);
         A += incAk;
      }
      if (B)
      {
         b2blk(kb, nb, alpB, B, ldb, b);
         B += incBk;
      }
      an = a + inca;
      bn = b + incb;
      if (rC)
         amm(nmu, nnu, kb, a, b, rC, an, bn, rC);
      a = an;
      b = bn;
   }
   if (blk2c)
      blk2c(mb, nb, ip->alpC, rC, beta, C, ip->ldc);
#endif
}

/*
 * MVS: bit pattern with following meaning by bit position:
 *   0: set: move A workspace;  unset: A work only mb*nb
 *   1: set: move B workspace;  unset: B work only kb*nb
 *   2: set: A wrkspc hold full mat;  unset: A wrkspc holds panel only
 *      if bit 0 unset, this bit has no affect
 *   3: set: B wrkspc hold full mat;  unset: B wrkspc holds panel only
 *      if bit 1 unset, this bit has no affect
 *
 * NOTE: we assume global (i,j), but this function assumes any j indexing
 *       has been rolled into the B/C ptrs.  It does only i indexing for A&C.
 *       When i|j > 0, we do *NOT* move around in the workspace as we would 
 *       if we copied them ourselves.  This allows callers that don't need 
 *       full workspace (eg., triangular loops) to avoid allocating it.
 */
void Mjoin(PATL,iploopsMK)
(
   ipinfo_t *ip,
   size_t i,              /* which glbl rowblk to start at (ignore blks <i) */
   size_t j,              /* which global col block of C is being computed */
   const TYPE *A,         /* if non-NULL, A to cpy, else ignored */
   const TYPE *B,         /* if non-NULL, Portion B to cpy, else ignored */
   TYPE *C,               /* original C to write ans to at end of Kloop */
   const int MVS,         /* 1:move A workspace, 2:move B wrkspc, 3: mv both */
   TYPE *a,               /* wrkspace for block-copied A */
   TYPE *b,               /* wrkspace for block-copied B */
   TYPE *rC,              /* ptr to real portion of C access-major workspace */
   TYPE *iC,              /* ptr to complex C workspace */
   const SCALAR beta,     /* scaling factor for C */
   const ablk2cmat_t blk2c   /* C = alpC*(rC,iC) + beta*C */
)
{
   const size_t nfmblks=ip->nfmblks, nmblks=ip->npmblks+nfmblks;
   const size_t BA=((MVS&1)&&(MVS&4)) ? (~0):0;
   const TYPE *pB=B;
   if (i < nfmblks)
   {
      const size_t incAm = (A) ? ip->incAm:0, incCm = (ip->mb)SHIFT;
      const size_t pansz = BA & ((ip->nfkblks + 1)*((ip->szA)SHIFT));
      if (i)
      {
         A += i * incAm;
         C += i * incCm;
      }
      for (; i < nfmblks; i++)
      {
         Mjoin(PATL,iploopsK)(ip, i, j, A, pB, C, MVS, a, b, 
                              rC, iC, beta, blk2c);
         A += incAm;
         C += incCm;
         a += pansz;
         pB = NULL;  /* copy B col-panel only on first iteration */
      }
   }
   else if (i && nfmblks)
   {
      if (A)
         A += nfmblks * ip->incAm;
      C += nfmblks * ((ip->mb)SHIFT);
   }
   if (i < nmblks)
   {
      const size_t incAm = (A) ? ip->pincAm:0, incCm = (ip->pmb)SHIFT;
      const size_t pansz = BA & ((ip->nfkblks + 1)*((ip->pszA)SHIFT));
      if (i > nfmblks)
      {
         size_t k = i - nfmblks;
         A += k * incAm;
         C += k * incCm;
      }
      for (; i < nmblks; i++)
      {
         Mjoin(PATL,iploopsK)(ip, i, j, A, pB, C, MVS, a, b,
                              rC, iC, beta, blk2c);
         A += incAm;
         C += incCm;
         a += pansz;
         pB = NULL;  /* copy B col-panel only on first iteration */
      }
   }
}
/*
 * MVS: bit pattern with following meaning by bit position:
 *   0: set: move A workspace;  unset: A work only mb*nb
 *   1: set: move B workspace;  unset: B work only kb*nb
 *   2: set: A wrkspc hold full mat;  unset: A wrkspc holds panel only
 *      if bit 0 unset, this bit has no affect
 *   3: set: B wrkspc hold full mat;  unset: B wrkspc holds panel only
 *      if bit 1 unset, this bit has no affect
 *
 * NOTE: we assume global (i,j), but this function assumes any i indexing
 *       has been rolled into the A/C ptrs.  It does only j indexing for B&C.
 *       When i|j > 0, we do *NOT* move around in the workspace as we would 
 *       if we copied them ourselves.  This allows callers that don't need 
 *       full workspace (eg., triangular loops) to avoid allocating it.
 */
void Mjoin(PATL,iploopsNK)
(
   ipinfo_t *ip,
   size_t i,              /* which global row block of C is being computed */
   size_t j,              /* which glbl colblk to start at (ignore blks <j) */
   const TYPE *A,         /* if non-NULL, A to cpy, else ignored */
   const TYPE *B,         /* if non-NULL, Portion B to cpy, else ignored */
   TYPE *C,               /* original C to write ans to at end of Kloop */
   const int MVS,         /* 1:move A workspace, 2:move B wrkspc, 3: mv both */
   TYPE *a,               /* wrkspace for block-copied A */
   TYPE *b,               /* wrkspace for block-copied B */
   TYPE *rC,              /* ptr to real portion of C access-major workspace */
   TYPE *iC,              /* ptr to complex C workspace */
   const SCALAR beta,     /* scaling factor for C */
   const ablk2cmat_t blk2c   /* C = alpC*(rC,iC) + beta*C */
)
{
   const size_t nfnblks=ip->nfnblks, nnblks=ip->npnblks+nfnblks;
   const size_t BB=((MVS&2)&&(MVS&8)) ? (~0):0;
   const TYPE *pA=A;
   if (j < nfnblks)
   {
      const size_t incBn = (B) ? ip->incBn:0, incCn = ip->ldc*((ip->nb)SHIFT);
      const size_t pansz = BB & ((ip->nfkblks + 1)*((ip->szB)SHIFT));
      if (j)
      {
         B += j * incBn;
         C += j * incCn;
      }
      for (; j < nfnblks; j++)
      {
         Mjoin(PATL,iploopsK)(ip, i, j, pA, B, C, MVS, a, b, 
                              rC, iC, beta, blk2c);
         B += incBn;
         C += incCn;
         b += pansz;
         pA = NULL;  /* copy A row-panel only on first iteration */
      }
   }
   else if (j && nfnblks)
   {
      if (B)
         B += nfnblks * ip->incBn;
      C += nfnblks * ip->ldc * ((ip->mb)SHIFT);
   }
   if (j < nnblks)
   {
      const size_t incBn = (B) ? ip->pincBn:0, incCn = ip->ldc*((ip->pnb)SHIFT);
      const size_t pansz = BB & ((ip->nfkblks + 1)*((ip->pszB)SHIFT));
      if (j > nfnblks)
      {
         size_t k = j - nfnblks;
         B += k * incBn;
         C += k * incCn;
      }
      for (; j < nnblks; j++)
      {
         Mjoin(PATL,iploopsK)(ip, i, j, pA, B, C, MVS, a, b,
                              rC, iC, beta, blk2c);
         B += incBn;
         C += incCn;
         b += pansz;
         pA = NULL;  /* copy A row-panel only on first iteration */
      }
   }
}

/*
 * A & B ptrs should always be base ptrs to this func.
 * MVS: bit pattern with following meaning by bit position:
 *   0: set: move A workspace;  unset: A work only mb*nb
 *   1: set: move B workspace;  unset: B work only kb*nb
 *   2: set: A wrkspc hold full mat;  unset: A wrkspc holds panel only
 *      if bit 0 unset, this bit has no affect
 *   3: set: B wrkspc hold full mat;  unset: B wrkspc holds panel only
 *      if bit 1 unset, this bit has no affect
 *
 */
void Mjoin(PATL,iploopsNMK)
(
   ipinfo_t *ip,
   size_t i,              /* which glbl rowblk to start at (ignore blks <i) */
   size_t j,              /* which global col block of C is being computed */
   const TYPE *A,         /* if non-NULL, A to cpy, else ignored */
   const TYPE *B,         /* if non-NULL, Portion B to cpy, else ignored */
   TYPE *C,               /* original C to write ans to at end of Kloop */
   const int MVS,         /* 1:move A workspace, 2:move B wrkspc, 3: mv both */
   TYPE *a,               /* wrkspace for block-copied A */
   TYPE *b,               /* wrkspace for block-copied B */
   TYPE *rC,              /* ptr to real portion of C access-major workspace */
   TYPE *iC,              /* ptr to complex C workspace */
   const SCALAR beta,     /* scaling factor for C */
   const ablk2cmat_t blk2c   /* C = alpC*(rC,iC) + beta*C */
)
{
   const size_t nfnblks=ip->nfnblks, nnblks=ip->npnblks+nfnblks, ldc=ip->ldc;
   const size_t BMSKA=((MVS&1)&&(MVS&4)) ? 0:(~0);
   const size_t BMSKB=((MVS&2)&&(MVS&8)) ? (~0):0;
   if (j < nfnblks)
   {
      const size_t pansz = BMSKB & ((ip->nfkblks+1)*((ip->szB)SHIFT));
      const size_t incBn = ip->incBn, incCn = ldc*((ip->nb)SHIFT);
      if (j)
      {
         B += j*incBn;
         C += j*incCn;
      }
      for (; j < nfnblks; j++)
      {
         Mjoin(PATL,iploopsMK)(ip, i, j, A, B, C, MVS, a, b,
                               rC, iC, beta, blk2c);
         A = (TYPE*)(((size_t)A) & BMSKA);
         b += pansz;
         B += incBn;
         C += incCn;
      }
   }
   else if (j && nfnblks)
   {
      B += j * ip->incBn;
      C += j * ldc * ((ip->nb)SHIFT);
   }
   if (j < nnblks)
   {
      const size_t incBn = ip->pincBn, incCn = ldc*((ip->pnb)SHIFT);
      const size_t pansz = BMSKB & ((ip->nfkblks+1)*((ip->pszB)SHIFT));
      if (j > nfnblks)
      {
         size_t k = j - nfnblks;
         B += k * incBn;
         C += k * incCn;
      }
      for(; j < nnblks; j++)
      {
         Mjoin(PATL,iploopsMK)(ip, i, j, A, B, C, MVS, a, b,
                               rC, iC, beta, blk2c);
         A = (TYPE*)(((size_t)A) & BMSKA);
         b += pansz;
         B += incBn;
         C += incCn;
      }
   }
}
/*
 * A & B ptrs should always be base ptrs to this func.
 * MVS: bit pattern with following meaning by bit position:
 *   0: set: move A workspace;  unset: A work only mb*nb
 *   1: set: move B workspace;  unset: B work only kb*nb
 *   2: set: A wrkspc hold full mat;  unset: A wrkspc holds panel only
 *      if bit 0 unset, this bit has no affect
 *   3: set: B wrkspc hold full mat;  unset: B wrkspc holds panel only
 *      if bit 1 unset, this bit has no affect
 *
 */
void Mjoin(PATL,iploopsMNK)
(
   ipinfo_t *ip,
   size_t i,              /* which glbl rowblk to start at (ignore blks <i) */
   size_t j,              /* which global col block of C is being computed */
   const TYPE *A,         /* if non-NULL, A to cpy, else ignored */
   const TYPE *B,         /* if non-NULL, Portion B to cpy, else ignored */
   TYPE *C,               /* original C to write ans to at end of Kloop */
   const int MVS,         /* 1:move A workspace, 2:move B wrkspc, 3: mv both */
   TYPE *a,               /* wrkspace for block-copied A */
   TYPE *b,               /* wrkspace for block-copied B */
   TYPE *rC,              /* ptr to real portion of C access-major workspace */
   TYPE *iC,              /* ptr to complex C workspace */
   const SCALAR beta,     /* scaling factor for C */
   const ablk2cmat_t blk2c   /* C = alpC*(rC,iC) + beta*C */
)
{
   const size_t nfmblks=ip->nfmblks, nmblks=ip->npmblks+nfmblks, ldc=ip->ldc;
   const size_t BMSKA=((MVS&1)&&(MVS&4)) ? (~0):0;
   const size_t BMSKB=((MVS&2)&&(MVS&8)) ? 0:(~0);
   if (i < nfmblks)
   {
      const size_t pansz = BMSKA & ((ip->nfkblks+1)*((ip->szA)SHIFT));
      const size_t incAm = ip->incAm, incCm = (ip->mb)SHIFT;
      if (i)
      {
         A += i*incAm;
         C += i*incCm;
      }
      for (; i < nfmblks; i++)
      {
         Mjoin(PATL,iploopsNK)(ip, i, j, A, B, C, MVS, a, b,
                               rC, iC, beta, blk2c);
         B = (TYPE*)(((size_t)B) & BMSKB);
         a += pansz;
         A += incAm;
         C += incCm;
      }
   }
   else if (i && nfmblks)
   {
      A += i * ip->incAm;
      C += i * ((ip->mb)SHIFT);
   }
   if (i < nmblks)
   {
      const size_t incAm = ip->pincAm, incCm = (ip->pmb)SHIFT;
      const size_t pansz = BMSKA & ((ip->nfkblks+1)*((ip->pszA)SHIFT));
      if (i > nfmblks)
      {
         size_t k = i - nfmblks;
         A += k * incAm;
         C += k * incCm;
      }
      for(; i < nmblks; i++)
      {
         Mjoin(PATL,iploopsNK)(ip, i, j, A, B, C, MVS, a, b,
                               rC, iC, beta, blk2c);
         B = (TYPE*)(((size_t)B) & BMSKB);
         a += pansz;
         A += incAm;
         C += incCm;
      }
   }
}
@ROUT ATL_ammmK ATL_cammmK
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

void Mjoin(PATL,ammmK)
(
   amminfo_t *mminf,
   const int mb,           /* # of rows of C to compute */
   const int nmu,          /* CEIL(mb/mu) */
   const int nb,  
   const int nnu,
   ATL_CINT nfkblks, /* FLOOR(K/kb) */
   const int kb,
   const int kb0,
   const int KB0,
   const TYPE *A,
   const size_t lda,   
   const size_t incAk, /* 0: no need to copy A, else incK for cpying A */
   const TYPE *B,
   const size_t ldb,   
   const size_t incBk, /* 0: no need to copy B, else incK for cpying A */
   const ablk2cmat_t blk2c,
   TYPE *C,
   const size_t ldc,   
   TYPE *a,
   ATL_CINT inca,      /* size of blocks of A, or 0 to reuse space */
   TYPE *b,
   ATL_CINT incb,      /* size of blocks of B, or 0 to reuse space */
   TYPE *rC, 
   TYPE *iC, 
   const SCALAR alpA,
   const SCALAR alpB,
   const SCALAR alpC,
   const SCALAR beta
)
@ROUT ATL_ammmK
{
   cm2am_t a2blk=mminf->a2blk, b2blk=mminf->b2blk;
   ammkern_t amm=mminf->amm_b0;
   TYPE *an=a+inca, *bn=b+incb;
   ATL_INT k;
/*
 * Peel first iteration to handle KR and use beta=0
 */
   if (kb0 != kb)
   {
      ATL_CINT ku=mminf->ku;
      amm = mminf->amm_k1_b0;
      if ( ATL_AMMFLG_KRUNTIME(mminf->flag) && (mminf->kbmin <= KB0) && 
           (ATL_AMMFLG_KMAJOR(mminf->flag) || (KB0 == kb0)) &&
           (kb0/ku)*ku == kb0)
         amm = mminf->amm_b0;
      if (incAk)
         a2blk(kb0, mb, alpA, A+incAk*nfkblks, lda, a);
      if (incBk)
         b2blk(kb0, nb, alpB, B+incBk*nfkblks, ldb, b);
      amm(nmu, nnu, KB0, a, b, rC, an, bn, rC);
   }
   else
   {
      if (incAk)
      {
         a2blk(kb0, mb, alpA, A, lda, a);
         A += incAk;
      }
      if (incBk)
      {
         b2blk(kb0, nb, alpB, B, ldb, b);
         B += incBk;
      }
      amm(nmu, nnu, KB0, a, b, rC, an, bn, rC);
   }
   amm = mminf->amm_b1;
   a = an;
   b = bn;

   for (k=0; k < nfkblks; k++)
   {
      if (incAk)
      {
         a2blk(kb, mb, alpA, A, lda, a);
         A += incAk;
      }
      if (incBk)
      {
         b2blk(kb, nb, alpB, B, ldb, b);
         B += incBk;
      }
      an = a + inca;
      bn = b + incb;
      amm(nmu, nnu, kb, a, b, rC, an, bn, rC);
      a = an;
      b = bn;
   }
   if (blk2c)
      blk2c(mb, nb, alpC, rC, beta, C, ldc);
}
@ROUT ATL_ammmKn
@ROUT ATL_cammmK
{
   cm2am_t a2blk=mminf->a2blk, b2blk=mminf->b2blk;
   ammkern_t amm_b0=mminf->amm_b0, amm_b1=mminf->amm_b1, amm_bn=mminf->amm_bn;
   ATL_CINT inca2=inca+inca, incb2=incb+incb;
   ATL_INT szA = inca, szB = incb;
   TYPE *iA=a, *iB=b, *rA, *rB;
   TYPE *an=iA+inca2, *bn=iB+incb2;
   ATL_INT k;
   if (!szA)
      szA = nmu*mminf->mu*Mmax(kb,KB0);
   if (!szB)
      szB = nnu*mminf->nu*Mmax(kb,KB0);
   rA = iA + szA;
   rB = iB + szB;
/*
 * Peel first iteration to handle KR and use beta=0
 */
   if (kb0 != kb)
   {
      amm_b0 = mminf->amm_k1_b0;
      if (ATL_AMMFLG_KRUNTIME(mminf->flag) && (mminf->kbmin <= KB0))
      {
         int ku = mminf->ku;
         #if ATL_geAMM_MAXKVEC > 1
         if (ATL_AMMFLG_KMAJOR(mminf->flag))
            amm_b0 = mminf->amm_b0;
         else
         #endif
         if ((kb0/ku)*ku == kb0)
            amm_b0 = mminf->amm_b0;
      }
      if (amm_b0 != mminf->amm_b0)
      {
         amm_b1 = mminf->amm_k1_b1;
         amm_bn = mminf->amm_k1_bn;
      }
      if (incAk)
         a2blk(kb0, mb, alpA, A+incAk*nfkblks, lda, rA, iA);
      if (incBk)
         b2blk(kb0, nb, alpB, B+incBk*nfkblks, ldb, rB, iB);

      amm_b0(nmu, nnu, KB0, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, KB0, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, KB0, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, KB0, iA, rB, iC, an, bn, rC);

      amm_b1 = mminf->amm_b1;
      amm_bn = mminf->amm_bn;
   }
   else
   {
      if (incAk)
      {
         a2blk(kb, mb, alpA, A, lda, rA, iA);
         A += incAk;
      }
      if (incBk)
      {
         b2blk(kb, nb, alpB, B, ldb, rB, iB);
         B += incBk;
      }
      amm_b0(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b0(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, an, bn, rC);
   }

   for (k=0; k < nfkblks; k++)
   {
      iA = an;
      iB = bn;
      rA = iA + szA;
      rB = iB + szB;
      an = iA + inca2;
      bn = iB + incb2;
      if (incAk)
      {
         a2blk(kb, mb, alpA, A, lda, rA, iA);
         A += incAk;
      }
      if (incBk)
      {
         b2blk(kb, nb, alpB, B, ldb, rB, iB);
         B += incBk;
      }
      amm_bn(nmu, nnu, kb, iA, iB, rC, rA, iB, iC);
      amm_b1(nmu, nnu, kb, rA, iB, iC, rA, rB, rC);
      amm_bn(nmu, nnu, kb, rA, rB, rC, iA, rB, iC);
      amm_b1(nmu, nnu, kb, iA, rB, iC, an, bn, rC);
   }
   if (blk2c)
      blk2c(mb, nb, alpC, rC, iC, beta, C, ldc);
}
@ROUT ATL_ammmKNMK
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

@beginskip
static void ATL_ammmMK
(
   amminfo_t *mminf,
   ATL_CSZT nfmblks,         /* FLOOR(M/mb) */
   const int mbL,            /* mbL=M%mb */
   const int nmuL,
   const int nb,
   const int nnu,
   ATL_CSZT nfkblks,         /* FLOOR(K/kb) */
   const int kb0,
   const int KB0,
   const TYPE *A,
   const size_t lda,
   const size_t incAk,       /* 0: no need to copy A, else incK for cpying A */
   const size_t incAm,
   const TYPE *B,
   const size_t ldb,
   const size_t incBk0,      /* 0: no need to copy B, else incK for cpying A */
   TYPE *C,
   const size_t ldc,
   const size_t incCm,
   TYPE *a,
   ATL_CINT inca,      /* size of blocks of A, or 0 to reuse space */
   ATL_CSZT incam,
   TYPE *b,
   ATL_CINT incb,      /* size of blocks of B, or 0 to reuse space */
   TYPE *rC,
   TYPE *iC,
   const SCALAR alpA,
   const SCALAR alpB,
   const SCALAR alpC,
   const SCALAR beta
)
{
   ATL_SZT i, incBk=incBk0;
   const int mu=mminf->mu, mb=mminf->mb, nmu=(mb+mu-1)/mu; 
   const int kb=mminf->kb;
   ablk2cmat_t blk2c=mminf->Cblk2cm;

   for (i=0; i < nfmblks; i++, A += incAm, C += incCm, a += incam)
   {
      Mjoin(PATL,ammmK)(mminf, mb, nmu, nb, nnu, nfkblks, kb, kb0, KB0, 
                        A, lda, incAk, B, ldb, incBk, blk2c, C, ldc, 
                        a, inca, b, incb, rC, iC, alpA, alpB, alpC, beta);
      incBk = 0; /* reuse B for rest of C colum panel */
   }
   if (mbL)
      Mjoin(PATL,ammmK)(mminf, mbL, nmuL, nb, nnu, nfkblks, kb, kb0, KB0, 
                        A, lda, incAk, B, ldb, incBk, blk2c, C, ldc, 
                        a, inca, b, incb, rC, iC, alpA, alpB, alpC, beta);
}

static void ATL_ammmNMK
(
   amminfo_t *mminf,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   TYPE *C,
   ATL_CSZT ldc,
   ATL_SZT nmblks,            /* CEIL(M/mb) */
   ATL_SZT nkblks,            /* CEIL(K/kb) */
   TYPE *a,
   TYPE *b, 
   TYPE *c,
   const SCALAR alpA,
   const SCALAR alpB,
   const SCALAR alpC,
   const SCALAR beta
)
{
   const int mb=mminf->mb, nb=mminf->nb, kb=mminf->kb;
   const int mu=mminf->mu, nu=mminf->nu, ku=mminf->ku;
   const int nmu=(mb+mu-1)/mu, nnu=(nb+nu-1)/nu;
   const int inca=mb*kb, incb=kb*nb;
   int mbL=0, nmuL=0, nbF=nb, nnuF=nnu, KB0, kb0;
   ATL_CSZT incam = nkblks*(inca SHIFT), incCn = nb*(ldc SHIFT);
   ATL_SZT j, incAm, incAk, incBk, incBn, incBnF;
   ATL_SZT nnblks = (N-1)/nb;
   #ifdef TCPLX
      TYPE *iC=c, *rC=c+mb*nb;
      const int mb2=mb+mb;
   #else
      #define rC c
      #define iC c
      #define mb2 mb
   #endif

   j = nmblks*mb;
   if (j != M)
   {
      nmblks--;
      mbL = M - j + mb;
      nmuL = (mbL+mu-1)/mu;
   }
   j = nnblks*nb;
   nbF = N - j;
   if (nbF != nb)
      nnuF = (nbF+nu-1)/nu;
   nkblks--;
   j = nkblks*kb;
   KB0 = kb0 = K - j;
   #if ATL_geAMM_MAXKVEC > 1
      if (kb0 != kb && ATL_AMMFLG_KMAJOR(mminf->flag))
         KB0 = ((kb0+ku-1)/ku)*ku;
   #endif
   if (IS_COLMAJ(TA))
   {
      incAk = kb*lda;
      incAm = mb;
   }
   else
   {
      incAk = kb;
      incAm = mb*lda;
   }
   if (IS_COLMAJ(TB))
   {
      incBk = kb;
      incBn = nb*ldb;
      incBnF = nbF*ldb;
   }
   else
   {
      incBk = kb*ldb;
      incBn = nb;
      incBnF = nbF;
   }
   #ifdef TCPLX
      incAk += incAk;
      incAm += incAm;
      incBk += incBk;
      incBn += incBn;
      incBnF += incBnF;
   #endif
/*
 * In first nbF-wide panel, we copy all of A into workspace
 */
   ATL_ammmMK(mminf, nmblks, mbL, nmuL, nbF, nnuF, nkblks, kb0, KB0,
              A, lda, incAk, incAm, B, ldb, incBk, C, ldc, mb2,
              a, inca, incam, b, incb, rC, iC, alpA, alpB, alpC, beta);
   C += ldc*(nbF SHIFT);
   B += incBnF;
/*
 * In all other N-panel computation, reuse previously copied A!
 */
   if (nnblks)
   {
      incAk = 0;
      for (j=0; j < nnblks; j++, C += incCn, B += incBn)
         ATL_ammmMK(mminf, nmblks, mbL, nmuL, nb, nnu, nkblks, kb0, KB0,
                    A, lda, incAk, incAm, B, ldb, incBk, C, ldc, mb2,
                    a, inca, incam, b, incb, rC, iC, alpA, alpB, alpC, beta);
   }
}
#ifndef TCPLX
   #undef rC
   #undef iC
   #undef mb2
#endif

int Mjoin(PATL,ammmKNMK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef TCPLX
      const TYPE ONE[2]={ATL_rone,ATL_rzero}, ZERO[2]={ATL_rzero,ATL_rzero};
      const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
   #else
      #define ONE ATL_rone
      TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   #endif
   void *vp=NULL;
   TYPE *a, *b, *c;
   ATL_SZT szA, szB, szC, sz, nmblks, nkblks, nkblksP, k;
   ATL_INT nkP=0;
   int mu, nu, mb, nb, kb, incak, incbk;
   amminfo_t mminf;


   mu = Mjoin(PATL,GetAmmmInfo)(&mminf, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminf.mu;
   nu = mminf.nu;
   mb = mminf.mb;
   nb = mminf.nb;
   kb = mminf.kb;
   nmblks = (M+mb-1)/mb;
   nkblksP = nkblks = (K+kb-1)/kb;
   nkblksP <<= 1;
   incak = mb*kb;
   incbk = kb*nb;
   szC = mb*nb;
   #if 0
   if (nkblks > 1)
   {
      nkP++;
      nkblksP >>= 1;
   }
   #endif
   do
   {
      nkP++;
      nkblksP >>= 1;
      szA = nkblksP*nmblks*incak;
      szB = nkblksP*incbk;
      sz = ATL_MulBySize(szA+szB+szC+(mu+mu)*nu) + 2*ATL_Cachelen;
      if (sz <= ATL_MaxMalloc)
         vp = malloc(sz);
   }
   while (!vp && nkblksP >= 3);
   if (!vp)
      return(1);

   a = ATL_AlignPtr(vp);
   b = a + (szA SHIFT);
   c = b + (szB SHIFT);
   
   if (nkblksP == nkblks)
      ATL_ammmNMK(&mminf, TA, TB, M, N, K, A, lda, B, ldb, C, ldc, nmblks, 
                  nkblks, a, b, c, alpA, alpB, alpC, beta);
   else
   {
      ATL_CSZT KK = nkblksP*kb;
      ATL_SZT incAkp, incBkp;
      incBkp = incAkp = KK SHIFT;
      if (IS_COLMAJ(TA))
         incAkp *= lda;
      if (!IS_COLMAJ(TB))
         incBkp *= ldb;
      for (k=0; k < nkblks; k += nkblksP, A += incAkp, B += incBkp)
      {
         ATL_SZT nk=nkblks-k, kk;
         if (nk > nkblksP)
         {
            kk = KK;
            nk = nkblksP;
         }
         else
            kk = K - k*kb;
         ATL_ammmNMK(&mminf, TA, TB, M, N, kk, A, lda, B, ldb, C, ldc, nmblks, 
                     nk, a, b, c, alpA, alpB, alpC, beta);
      }
   }
   free(vp);
   return(0);
}
@endskip
int Mjoin(PATL,ammmKNMK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   TYPE *a, *b, *c;
   void *vp=NULL;
   size_t szA, szB, nfkblks, nkblksP;
   #ifdef TCPLX
      TYPE *rC;
      const TYPE *bet=beta;
   #else
      TYPE bet=beta;
      #define rC c
   #endif
   int i, kb, extra;
   ipinfo_t ip;

   i = Mjoin(PATL,geGetAmmmIndx)(M, N, K);
   Mjoin(PATL,geComputeIPInfo)(&ip, i, TA, TB, M, N, K, lda, ldb, ldc,
                               alpha, beta);
/*
 * Figure out a partition of K that should allow malloc to succeed. 
 * In this routine, we need to allocate space for a block of C,
 * a column-panel of B, and the full matrix A.  If we can't get that
 * much space, we partition K into Kp, and reduce Kp until the malloc
 * succeeds.  If Kp drops below 3*LASTKB, we give up and return non-zero,
 * to indicate that recursion should be used to cut all dims until a malloc
 * can succeed.
 */
   kb = ip.kb;
   nkblksP = nfkblks = ip.nfkblks;
/*
 * Set up extra to have all sizes that are independent of K.
 * sz[A,B] will be multiplied by number of K blks to get final answer.
 */
   extra = (ip.mu<<1)*ip.nu;
   extra = ATL_MulBySize(ip.szC+extra) + 3 * ATL_Cachelen; 
   szA = ip.szA*ip.nfmblks + ip.pszA*ip.npmblks;
   szB = ip.szB;
   while(1)
   {
      size_t sz;
      sz = ATL_MulBySize((szA+szB)*(nkblksP+1)) + extra;
      if (sz <= ATL_MaxMalloc)
         vp = malloc(sz);
      if (vp)
         break;
      nkblksP = (nkblksP>>1);
      if (nkblksP < 3)
         return(1);
   }
@skip   ATL_assert(nkblksP);
@skip printf("nkblksP=%d of %d, K=%d\n", (int)nkblksP, (int)nfkblks, (int)K);
   szA *= (nkblksP+1);
   szB *= (nkblksP+1);
   a = ATL_AlignPtr(vp);
   b = a + (szA SHIFT);
   b = ATL_AlignPtr(b);
   c = b + (szB SHIFT);
   c = ATL_AlignPtr(c);
   #ifdef TCPLX
      rC=c+ip.szC;
   #endif

   if (nkblksP == nfkblks)
      Mjoin(PATL,iploopsNMK)(&ip, 0, 0, A, B, C, 1|2|4, a, b, 
                             rC, c, beta, ip.blk2c);
   else   /* have partitioned K into areas of at most (nkblksP+1)*kb */
   {
      const size_t incAk=ip.incAk*(nkblksP+1);
      const size_t incBk=ip.incBk*(nkblksP+1), Kp=(nkblksP+1)*kb;
      size_t k;
      ablk2cmat_t blk2c = ip.blk2c;

      for (k=Kp; k < K; k += Kp)
      {
         Mjoin(PATL,geComputeIPInfo)(&ip, i, TA, TB, M, N, Kp, lda, ldb, ldc,
                                     alpha, bet);
         Mjoin(PATL,iploopsNMK)(&ip, 0, 0, A, B, C, 1|2|4, a, b, 
                                rC, c, bet, ip.blk2c);
         #ifdef TCPLX
            bet = ip.ONE;
         #else
            bet = ATL_rone;
         #endif
         A += incAk;
         B += incBk;
      }
      k = K - k + Kp;
      Mjoin(PATL,geComputeIPInfo)(&ip, i, TA, TB, M, N, k, lda, ldb, ldc,
                                  alpha, bet);
      Mjoin(PATL,iploopsNMK)(&ip, 0, 0, A, B, C, 1|2|4, a, b, 
                             rC, c, bet, ip.blk2c);
   }

   free(vp);
   return(0);
}
#ifndef TCPLX
   #undef rC
#endif
@ROUT ATL_ammmKMNK
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

int Mjoin(PATL,ammmKMNK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   TYPE *a, *b, *c;
   void *vp=NULL;
   size_t szA, szB, nfkblks, nkblksP;
   #ifdef TCPLX
      TYPE *rC;
      const TYPE *bet=beta;
   #else
      TYPE bet=beta;
      #define rC c
   #endif
   int i, kb, extra;
   ipinfo_t ip;

   i = Mjoin(PATL,geGetAmmmIndx)(M, N, K);
   Mjoin(PATL,geComputeIPInfo)(&ip, i, TA, TB, M, N, K, lda, ldb, ldc,
                               alpha, beta);
/*
 * Figure out a partition of K that should allow malloc to succeed.
 * In this routine, we need to allocate space for a block of C,
 * a row-panel of A, and the full matrix B.  If we can't get that
 * much space, we partition K into Kp, and reduce Kp until the malloc
 * succeeds.  If Kp drops below 3*LASTKB, we give up and return non-zero,
 * to indicate that recursion should be used to cut all dims until a malloc
 * can succeed.
 */
   kb = ip.kb;
   nkblksP = nfkblks = ip.nfkblks;
/*
 * Set up extra to have all sizes that are independent of K.
 * sz[A,B] will be multiplied by number of K blks to get final answer.
 */
   extra = (ip.mu<<1)*ip.nu;
   extra = ATL_MulBySize(ip.szC+extra) + 3 * ATL_Cachelen;
   szB = ip.szB*ip.nfnblks + ip.pszB*ip.npnblks;
   szA = ip.szA;
   while(1)
   {
      size_t sz;
      sz = ATL_MulBySize((szA+szB)*(nkblksP+1)) + extra;
      if (sz <= ATL_MaxMalloc)
         vp = malloc(sz);
      if (vp)
         break;
      nkblksP = (nkblksP>>1);
      if (nkblksP < 3)
         return(1);
   }
   szA *= (nkblksP+1);
   szB *= (nkblksP+1);
   a = ATL_AlignPtr(vp);
   b = a + (szA SHIFT);
   b = ATL_AlignPtr(b);
   c = b + (szB SHIFT);
   c = ATL_AlignPtr(c);
   #ifdef TCPLX
      rC=c+ip.szC;
   #endif

   if (nkblksP == nfkblks)
      Mjoin(PATL,iploopsMNK)(&ip, 0, 0, A, B, C, 1|2|8, a, b,
                             rC, c, beta, ip.blk2c);
   else   /* have partitioned K into areas of at most (nkblksP+1)*kb */
   {
      const size_t incAk=ip.incAk*(nkblksP+1);
      const size_t incBk=ip.incBk*(nkblksP+1), Kp=(nkblksP+1)*kb;
      size_t k;
      ablk2cmat_t blk2c = ip.blk2c;

      for (k=Kp; k < K; k += Kp)
      {
         Mjoin(PATL,geComputeIPInfo)(&ip, i, TA, TB, M, N, Kp, lda, ldb, ldc,
                                     alpha, bet);
         Mjoin(PATL,iploopsMNK)(&ip, 0, 0, A, B, C, 1|2|8, a, b,
                                rC, c, bet, ip.blk2c);
         #ifdef TCPLX
            bet = ip.ONE;
         #else
            bet = ATL_rone;
         #endif
         A += incAk;
         B += incBk;
      }
      k = K - k + Kp;
      Mjoin(PATL,geComputeIPInfo)(&ip, i, TA, TB, M, N, k, lda, ldb, ldc,
                                  alpha, bet);
      Mjoin(PATL,iploopsMNK)(&ip, 0, 0, A, B, C, 1|2|8, a, b,
                             rC, c, bet, ip.blk2c);
   }

   free(vp);
   return(0);
}
#ifndef TCPLX
   #undef rC
#endif
@beginskip
static void ATL_ammmNK
(
   amminfo_t *mminf,
   const int mb,
   const int nmu,
   ATL_CSZT nfnblks,         /* FLOOR(N/nb) */
   const int nbL,            /* nbL=N%nb */
   const int nnuL,
   ATL_CSZT nfkblks,         /* FLOOR(K/kb) */
   const int kb0,
   const int KB0,
   const TYPE *A,
   const size_t lda,
   const size_t incAk0,      /* 0: no need to copy A, else incK for cpying A */
   const TYPE *B,
   const size_t ldb,
   const size_t incBk,       /* 0: no need to copy B, else incK for cpying A */
   const size_t incBn,
   TYPE *C,
   const size_t ldc,
   const size_t incCn,
   TYPE *a,
   ATL_CINT inca,      /* size of blocks of A, or 0 to reuse space */
   TYPE *b,
   ATL_CINT incb,      /* size of blocks of B, or 0 to reuse space */
   ATL_CSZT incbn,
   TYPE *rC,
   TYPE *iC,
   const SCALAR alpA,
   const SCALAR alpB,
   const SCALAR alpC,
   const SCALAR beta
)
{
   ATL_SZT j, incAk=incAk0;
   const int nu=mminf->nu, nb=mminf->nb, nnu=(nb+nu-1)/nu;
   const int kb=mminf->kb;
   ablk2cmat_t blk2c=mminf->Cblk2cm;

   for (j=0; j < nfnblks; j++, B += incBn, C += incCn, b += incbn)
   {
      Mjoin(PATL,ammmK)(mminf, mb, nmu, nb, nnu, nfkblks, kb, kb0, KB0,
                        A, lda, incAk, B, ldb, incBk, blk2c, C, ldc,
                        a, inca, b, incb, rC, iC, alpA, alpB, alpC, beta);
      incAk = 0; /* reuse A for rest of C row panel */
   }
   if (nbL)
      Mjoin(PATL,ammmK)(mminf, mb, nmu, nbL, nnuL, nfkblks, kb, kb0, KB0,
                        A, lda, incAk, B, ldb, incBk, blk2c, C, ldc,
                        a, inca, b, incb, rC, iC, alpA, alpB, alpC, beta);
}
static void ATL_ammmMNK
(
   amminfo_t *mminf,
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   TYPE *C,
   ATL_CSZT ldc,
   ATL_SZT nnblks,            /* CEIL(N/nb) */
   ATL_SZT nkblks,            /* CEIL(K/kb) */
   TYPE *a,
   TYPE *b, 
   TYPE *c,
   const SCALAR alpA,
   const SCALAR alpB,
   const SCALAR alpC,
   const SCALAR beta
)
{
   const int mb=mminf->mb, nb=mminf->nb, kb=mminf->kb;
   const int mu=mminf->mu, nu=mminf->nu, ku=mminf->ku;
   const int nmu=(mb+mu-1)/mu, nnu=(nb+nu-1)/nu;
   const int inca=mb*kb, incb=kb*nb;
   int nbL=0, nnuL=0, mbF=mb, nmuF=nmu, KB0, kb0;
   ATL_CSZT incbn = nkblks*(incb SHIFT), incCn = nb*(ldc SHIFT);
   ATL_SZT j, incAm, incAk, incBk, incBn, incAmF;
   ATL_SZT nmblks = (M-1)/mb;
   #ifdef TCPLX
      TYPE *iC=c, *rC=c+mb*nb;
      const int mb2=mb+mb;
   #else
      #define rC c
      #define iC c
      #define mb2 mb
   #endif

   j = nnblks*nb;
   if (j != N)
   {
      nnblks--;
      nbL = N - j + nb;
      nnuL = (nbL+nu-1)/nu;
   }
   j = nmblks*mb;
   mbF = M - j;
   if (mbF != mb)
      nmuF = (mbF+mu-1)/mu;
   nkblks--;
   j = nkblks*kb;
   KB0 = kb0 = K - j;
   #if ATL_geAMM_MAXKVEC > 1
      if (kb0 != kb && ATL_AMMFLG_KMAJOR(mminf->flag))
         KB0 = ((kb0+ku-1)/ku)*ku;
   #endif
   if (IS_COLMAJ(TA))
   {
      incAk = kb*lda;
      incAm = mb;
      incAmF = mbF;
   }
   else
   {
      incAk = kb;
      incAm = mb*lda;
      incAmF = mbF*lda;
   }
   if (IS_COLMAJ(TB))
   {
      incBk = kb;
      incBn = nb*ldb;
   }
   else
   {
      incBk = kb*ldb;
      incBn = nb;
   }
   #ifdef TCPLX
      incAk += incAk;
      incAm += incAm;
      incBk += incBk;
      incBn += incBn;
      incAmF += incAmF;
   #endif
/*
 * In first mbF-wide panel, we copy all of B into workspace
 */
   ATL_ammmNK(mminf, mbF, nmuF, nnblks, nbL, nnuL, nkblks, kb0, KB0,
              A, lda, incAk, B, ldb, incBk, incBn, C, ldc, incCn,
              a, inca, b, incb, incbn, rC, iC, alpA, alpB, alpC, beta);
   C += (mbF SHIFT);
   A += incAmF;
/*
 * In all other M-panel computation, reuse previously copied B!
 */
   if (nmblks)
   {
      for (j=0; j < nmblks; j++, C += mb2, A += incAm)
         ATL_ammmNK(mminf, mb, nmu, nnblks, nbL, nnuL, nkblks, kb0, KB0,
                    A, lda, incAk, B, ldb, 0, incBn, C, ldc, incCn,
                    a, inca, b, incb, incbn, rC, iC, alpA, alpB, alpC, beta);
   }
}
#ifndef TCPLX
   #undef rC
   #undef iC
   #undef mb2
#endif

int Mjoin(PATL,ammmKMNK)
(
   enum ATLAS_TRANS TA,
   enum ATLAS_TRANS TB,
   ATL_CSZT M,
   ATL_CSZT N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const TYPE *B,
   ATL_CSZT ldb,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   #ifdef TCPLX
      const TYPE ONE[2]={ATL_rone,ATL_rzero}, ZERO[2]={ATL_rzero,ATL_rzero};
      const TYPE *alpA=ONE, *alpB=ONE, *alpC=ONE;
   #else
      #define ONE ATL_rone
      TYPE alpA=ATL_rone, alpB=ATL_rone, alpC=ATL_rone;
   #endif
   void *vp=NULL;
   TYPE *a, *b, *c;
   ATL_SZT szA, szB, szC, sz, nnblks, nkblks, nkblksP, k;
   ATL_INT nkP=0;
   int mu, nu, mb, nb, kb, incak, incbk;
   amminfo_t mminf;


   mu = Mjoin(PATL,GetAmmmInfo)(&mminf, TA, TB, M, N, K, alpha, beta);
   if (!mu)
      alpA = alpha;
   else if (mu == 1)
      alpB = alpha;
   else
      alpC = alpha;

   mu = mminf.mu;
   nu = mminf.nu;
   mb = mminf.mb;
   nb = mminf.nb;
   kb = mminf.kb;
   nnblks = (N+nb-1)/nb;
   nkblksP = nkblks = (K+kb-1)/kb;
   nkblksP <<= 1;
   incak = mb*kb;
   incbk = kb*nb;
   szC = mb*nb;
   do
   {
      nkP++;
      nkblksP >>= 1;
      szA = nkblksP*incak;
      szB = nkblksP*nnblks*incbk;
      sz = ATL_MulBySize(szA+szB+szC+(mu+mu)*nu) + 2*ATL_Cachelen;
      if (sz <= ATL_MaxMalloc)
         vp = malloc(sz);
   }
   while (!vp && nkblksP >= 3);
   if (!vp)
      return(1);

   b = ATL_AlignPtr(vp);
   a = b + (szB SHIFT);
   c = a + (szA SHIFT);

   if (nkblksP == nkblks)
      ATL_ammmMNK(&mminf, TA, TB, M, N, K, A, lda, B, ldb, C, ldc, nnblks,
                  nkblks, a, b, c, alpA, alpB, alpC, beta);
   else
   {
      ATL_CSZT KK = nkblksP*kb;
      ATL_SZT incAkp, incBkp;
      incBkp = incAkp = KK SHIFT;
      if (IS_COLMAJ(TA))
         incAkp *= lda;
      if (!IS_COLMAJ(TB))
         incBkp *= ldb;
      for (k=0; k < nkblks; k += nkblksP, A += incAkp, B += incBkp)
      {
         ATL_SZT nk=nkblks-k, kk;
         if (nk > nkblksP)
         {
            kk = KK;
            nk = nkblksP;
         }
         else
            kk = K - k*kb;
         ATL_ammmMNK(&mminf, TA, TB, M, N, kk, A, lda, B, ldb, C, ldc, nnblks,
                     nk, a, b, c, alpA, alpB, alpC, beta);
      }
   }
   free(vp);
   return(0);
}
@endskip
@ROUT ATL_ammm_syrk
#include "atlas_misc.h"
#include "atlas_amm.h"
#include Mstr(Mjoin(Mjoin(ATLAS_PRE,amm),_sum.h))

@beginskip
int Mjoin(PATL,ammm_syrk2)
(
   const enum ATLAS_UPLO  Uplo,
   const enum ATLAS_TRANS TA,
   ATL_CSZT  N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   int i;
   ipinfo_t ip;
   i = Mjoin(PATL,sqGetAmmmIndx)(0, N, K);
   Mjoin(PATL,sqComputeIPInfo)(&ip, TA, 0, 0, N, K, lda, 0, ldc, alpha, beta);
   return(0);
}
@endskip

int Mjoin(PATL,ammm_syrk)
(
   const enum ATLAS_UPLO  Uplo,
   const enum ATLAS_TRANS TA,
   ATL_CSZT  N,
   ATL_CSZT K,
   const SCALAR alpha,
   const TYPE *A,
   ATL_CSZT lda,
   const SCALAR beta,
   TYPE *C,
   ATL_CSZT ldc
)
{
   ablk2cmat_t blk2c, blk2c_b0;
   ATL_CSZT ldcp1=(ldc+1)SHIFT;
   ATL_SZT i, j, szA, pansz, sz, nnblks, nkblks, incCn, incAk, incAn, incAnF;
   const TYPE *B = A;
   const TYPE *a;
   TYPE *wa, *ar, *wb, *wc, *wC, *c;
   void *vp=NULL;
   const int ISHERK=(TA == AtlasConj || TA == AtlasConjTrans);
   int ibet=1, ialp=1;
   int mu, nu, ku, incw, nb, nnu, nmu, nbF, nnuF, nmuF, kb0, KB0;
   #ifdef TCPLX
      const TYPE ONE[2] = {ATL_rone, ATL_rzero};
      const TYPE ZERO[2] = {ATL_rzero, ATL_rzero};
      TYPE *rC, *CC=C;
      int incw2, nb2;
   #else
      #define ONE ATL_rone
      #define ZERO ATL_rzero
      #define rC wc
      #define incw2 incw
      #define nb2 nb
   #endif
   amminfo_t mminf;


//   printf("UP=%c, N=%d, K=%d\n", Uplo==AtlasLower?'L':'U', (int)N, (int)K);
   if (SCALAR_IS_NONE(alpha))
      ialp = -1;
   else if (!SCALAR_IS_ONE(alpha))
      ialp = 2;
   if (SCALAR_IS_ZERO(beta))
      ibet = 0;
   else if (SCALAR_IS_NONE(beta))
      ibet = -1;
   else if (!SCALAR_IS_ONE(beta))
      ibet = 2;

   nb = Mjoin(PATL,GetSyrkInfo)(&mminf, ialp, TA, N, K, ibet);
   blk2c = mminf.Cblk2cm;
   blk2c_b0 = mminf.Cblk2cm_b1;
   mu = mminf.mu;
   nu = mminf.nu;
   ku = mminf.ku;
   nmu = (nb+mu-1)/mu;
   nnu = (nb+nu-1)/nu;
   nnblks = (N+nb-1)/nb;
   nkblks = (K+nb-1)/nb;
   incw = nb*nb;
   #ifdef TCPLX
      nb2 = nb + nb;
      incw2 = incw + incw;
   #endif
   pansz = nkblks*incw;
   szA = Mmax(nnblks-1,1);
   szA *= pansz;
   sz = szA + pansz + incw + incw + (mu+mu)*nu;
   sz = ATL_MulBySize(sz) + ATL_Cachelen;
   if (sz <= ATL_MaxMalloc)
      vp = malloc(sz);
   if (!vp)
      return(1);
   #ifdef TCPLX
      pansz += pansz;
   #endif
   wa = ATL_AlignPtr(vp);
   wb = wa + (szA SHIFT);
   wc = wb + pansz;
   wC = wc + incw2;

   nbF = N - (--nnblks)*nb;
   if (nbF == nb)
   {
      nmuF = nmu;
      nnuF = nnu;
   }
   else
   {
      nmuF = (nbF+mu-1)/mu;
      nnuF = (nbF+nu-1)/nu;
   }
   KB0 = kb0 = K - (--nkblks)*nb;
   #if ATL_geAMM_MAXKVEC > 1
      if (kb0 != nb && ATL_AMMFLG_KMAJOR(mminf.flag))
         KB0 = ((kb0+ku-1)/ku)*ku;
   #endif
   #ifdef TCPLX
      rC = wc + incw;
   #endif
   if (IS_COLMAJ(TA))
   {
      incAk = nb*(lda SHIFT);
      incAn = nb2;
      incAnF = nbF SHIFT;
   }
   else
   {
      incAk = nb2;
      incAn = lda SHIFT;
      incAnF = incAn * nbF;
      incAn *= nb;
   }
   incCn = nb*ldcp1;
   if (Uplo == AtlasLower)
   {
/*
 *    Peel first column of C computation, which will handle all partial blocks
 *    First rowpan of A not reused, so set inca=0
 */
      Mjoin(PATL,ammmK)(&mminf, nbF, nmuF, nbF, nnuF, nkblks, nb, kb0, KB0,
                        A, lda, incAk, B, lda, incAk, blk2c_b0, wC, nb,
                        wa, 0, wb, incw, rC, wc, ONE, alpha, ONE, ZERO);
      Mjoin(PATL,tradd)(Uplo, nbF, wC, nb, beta, C, ldc);
      if (ISHERK)
         Mjoin(PATLU,zero)(nbF, C+1, ldcp1);
      c = C + (nbF SHIFT);
      A += incAnF;
      B += incAnF;
      C += nbF*ldcp1;
      ar = wa;
      for (i=0; i < nnblks; i++, c += nb2, A += incAn, ar += pansz)
         Mjoin(PATL,ammmK)(&mminf, nb, nmu, nbF, nnuF, nkblks, nb, kb0, KB0,
                           A, lda, incAk, B, lda, 0, blk2c, c, ldc,
                           ar, incw, wb, incw, rC, wc, ONE, alpha, ONE, beta);
      for (j=0; j < nnblks; j++, B += incAn, C += incCn, wa += pansz)
      {
         Mjoin(PATL,ammmK)(&mminf, nb, nmu, nb, nnu, nkblks, nb, kb0, KB0,
                           A, lda, 0, B, lda, incAk, blk2c_b0, wC, nb,
                           wa, incw, wb, incw, rC, wc, ONE, alpha, ONE, ZERO);
         Mjoin(PATL,tradd)(Uplo, nb, wC, nb, beta, C, ldc);
         if (ISHERK)
            Mjoin(PATLU,zero)(nb, C+1, ldcp1);
         c = C + nb2;
         ar = wa + pansz;
         for (i=j+1; i < nnblks; i++, c += nb2, ar += pansz)
            Mjoin(PATL,ammmK)(&mminf, nb, nmu, nb, nnu, nkblks, nb, kb0, KB0,
                              A, lda, 0, B, lda, 0, blk2c, c, ldc, ar, incw,
                              wb, incw, rC, wc, ONE, alpha, ONE, beta);
      }
   }
/*
 * Upper runs backwards: start from last (partial) colpan, go left.  This
 * allows col-major access on Upper, avoiding TLB problems on C access.
 * Within the panel, start at diag on bottom and go up.  This allows us to
 * use less A storage, as with lower.  
 */
   else /* if (TA == AtlasUpper) */
   {
      C += nnblks*incCn;
      A += nnblks*incAn;
      B = A;
      Mjoin(PATL,ammmK)(&mminf, nbF, nmuF, nbF, nnuF, nkblks, nb, kb0, KB0,
                        A, lda, incAk, B, lda, incAk, blk2c_b0, wC, nb,
                        wa, 0, wb, incw, rC, wc, ONE, alpha, ONE, ZERO);
      Mjoin(PATL,tradd)(Uplo, nbF, wC, nb, beta, C, ldc);
      if (ISHERK)
         Mjoin(PATLU,zero)(nbF, C+1, ldcp1);
      c = C - nb2;
      C -= incCn;
      A -= incAn;
      B -= incAn;
      ar = wa;
      for (i=0; i < nnblks; i++, c -= nb2, A -= incAn, ar += pansz)
         Mjoin(PATL,ammmK)(&mminf, nb, nmu, nbF, nnuF, nkblks, nb, kb0, KB0,
                           A, lda, incAk, B, lda, 0, blk2c, c, ldc,
                           ar, incw, wb, incw, rC, wc, ONE, alpha, ONE, beta);
      for (j=0; j < nnblks; j++, B -= incAn, C -= incCn, wa += pansz)
      {
         Mjoin(PATL,ammmK)(&mminf, nb, nmu, nb, nnu, nkblks, nb, kb0, KB0,
                           A, lda, 0, B, lda, incAk, blk2c_b0, wC, nb,
                           wa, incw, wb, incw, rC, wc, ONE, alpha, ONE, ZERO);
         Mjoin(PATL,tradd)(Uplo, nb, wC, nb, beta, C, ldc);
         if (ISHERK)
            Mjoin(PATLU,zero)(nb, C+1, ldcp1);
         c = C - nb2;
         ar = wa + pansz;
         for (i=j+1; i < nnblks; i++, c -= nb2, ar += pansz)
            Mjoin(PATL,ammmK)(&mminf, nb, nmu, nb, nnu, nkblks, nb, kb0, KB0,
                              A, lda, 0, B, lda, 0, blk2c, c, ldc, ar, incw,
                              wb, incw, rC, wc, ONE, alpha, ONE, beta);
      }
   }
   return(0);
}
#ifndef TCPLX
   #undef ONE
   #undef ZERO
   #undef rC
   #undef incw2
#endif
@ROUT prefparse
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags:\n", name);
   fprintf(stderr, "   -b <ipf> : translate pref bitvec to string\n");
   fprintf(stderr, "   -p <Ab> <Bb> <C> <Ak> <Bk>\n");
   fprintf(stderr, "      Each arg to -p is the cache level to prefetch to.\n");
   fprintf(stderr, "      0 means do not prefetch, 3 means pfX\n");
   exit(ierr ? ierr : -1);
}

int GetFlags(int nargs, char **args, int ipfs[5])
{
   int i, k, ipf;
   if (nargs < 2)
   {
      fprintf(stderr, "\nMUST SPECIFY EITHER -p OR -b!\n");
      PrintUsage(args[0], 1, NULL);
   }
   ipf = 0;
   ipfs[0] = -1;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'b':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         ipf = atoi(args[i]);
         break;
      case 'p':
         for (k=0; k < 5; k++)
         {
            int j;
            if (++i >= nargs)
                PrintUsage(args[0], i-1, NULL);
            j = ipfs[k] = atoi(args[i]);
            if (j > 3 || j < 0)
               PrintUsage(args[0], i, "Cache level out of range");
         }
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (ipf && ipfs[0] != -1)
   {
      printf("\nCANNOT SPECIFY BOTH -p AND -b!\n");
      PrintUsage(args[0], 1, NULL);
   }
   return(ipf);
}

int main(int nargs, char **args)
{
   int ipf, ipfs[5];

   ipf = GetFlags(nargs, args, ipfs);
   if (ipfs[0] == -1)  /* translating bitvec to string */
   {
      printf("IPF=%d:", ipf);
      PrintPref(stdout, ipf);
      printf("\n");
   }
   else  /* translate pref setting to bitvec */
   {     /* ipfs = 0:Ab 1:Bb 2:C 3:Ak 4:Bk */
      ipf = 0;
      if (ipfs[0])
      {
         ipf |= 2;
         if (ipfs[0] == 1)
            ipf |= 64;
         else if (ipfs[0] == 3)
            ipf |= 512;
      }
      if (ipfs[1])
      {
         ipf |= 4;
         if (ipfs[1] == 1)
            ipf |= 128;
         else if (ipfs[1] == 3)
            ipf |= 1024;
      }
      if (ipfs[2])
      {
         ipf |= 1;
         if (ipfs[2] == 1)
            ipf |= 32;
         else if (ipfs[2] == 3)
            ipf |= 256;
      }
      if (ipfs[3])
      {
         ipf |= 8;
         if (ipfs[3] == 1)
            ipf |= 2048;
         else if (ipfs[3] == 3)
            ipf |= 8192;
      }
      if (ipfs[4])
      {
         ipf |= 16;
         if (ipfs[4] == 1)
            ipf |= 4096;
         else if (ipfs[4] == 3)
            ipf |= 16384;
      }
      printf("Ab=%d, Bb=%d, C=%d, Ak=%d, Bk=%d: bitvec=%d\n", 
             ipfs[0],ipfs[1],ipfs[2],ipfs[3],ipfs[4], ipf);
   }/* ipfs = 0:Ab 1:Bb 2:C 3:Ak 4:Bk */
   return(0);
}
@ROUT szblk
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
int main(int nargs, char **args)
{
   int i, iarr[5];
   if (nargs != 6)
   {
      /* entry in iarr:            0    1    2    3      4 */
      fprintf(stderr, "USAGE: %s <mb> <nb> <mu> <nu> <vlen>\n", args[0]);
      exit(1);
   }
   for (i=0; i < 5; i++)
   {
      int k;
      k = atoi(args[i+1]);
      assert (k > 0);
      if (i == 2 || i == 3)
         assert(k < iarr[i-2]);
      iarr[i] = k;
   }
   i = getsz(iarr[0],iarr[1],iarr[2],iarr[3],iarr[4]);
   printf("BLOCKSIZE=%d\n", i);
   return(0);
}
@ROUT uammgen
@extract -b @(topd)/cw.inc lang=C -def cwdate 2015 
#include "atlas_misc.h"
#include "atlas_mmgen.h"
#include "atlas_sys.h"

#define NMMLISTS 2
#define IUSR   0
#define IUSRK1 1

   static int UID=0, UIL=1;
   static char unam[16];

@extract -b @(basd)/atlas.base rout=Mylcm
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -p [s,d]: set type/precision prefix (d) \n");
   fprintf(stderr, "      s/d will generate for complex (c/z) as well\n");
   fprintf(stderr, "   -d <outdir>: directory to dump files to\n");
   fprintf(stderr, 
      "   -I <ID>: unique non-negative ID for header/kern files\n");
   fprintf(stderr, "   -ub [r,c] <user-case kernel file> \n");
   fprintf(stderr, "   -uk [r,c] <user-case KClean file (if needed)>\n");
   exit(ierr ? ierr : -1);
}


/*
 * RETURNS: precision prefix [s,d,c,z]
 */
char *GetFlags(int nargs, char **args, char *PRE, ATL_mmnode_t **lists)
{
   int i, j=0, n, k;
   int GotAnySumFile = 0;
   char pre='d', cpre, ch;
   char *outd=NULL;
   char *fn[2]={"uAMMRES.sum","uAMMKCLEAN.sum"};

   for (i=0; i < 2*NMMLISTS; i++)
      lists[i] = NULL;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         pre = tolower(args[i][0]);
         if (pre == 'z')
            pre = 'd';
         else if (pre == 'c')
            pre = 's';
         assert(pre == 's' || pre == 'd');
         cpre = (pre == 'd') ? 'z' : 'c';
         break;
      case 'I':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         UID = atoi(args[i]);
         for (k=10; k<=UID; k*=10)
            UIL++;
         break;
      case 'u':
         GotAnySumFile = 1;
         switch(args[i][2])
         {
      @multidef i   0 1
      @whiledef flg b k
         case '@(flg)': /* [r,c] <file> */
            if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            ch = args[i][0];
            if (ch == 'c')
               k = NMMLISTS + @(i);
            else if (ch == 'r')
               k = @(i);
            else
               PrintUsage(args[0],i, "1st arg to -u@(flg) must be 'r' or 'c'!");
            if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            lists[k] = ReadMMFile(args[i]);
            assert(lists[k]);
            break;
      @undef i
      @endwhile
         default:
            PrintUsage(args[0], i, args[i]);
         }
         break;
      case 'd':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        outd = DupString(args[i]);
        break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   *PRE = pre;
   sprintf(unam, "u%d", UID);
/*
 * Fill in any required list entry
 */
   for (i=0; i < 2*NMMLISTS; i++)
   {
      const char pr=(i<NMMLISTS) ? pre : cpre;
      const int k = (i<NMMLISTS) ? i : i-NMMLISTS;
      if (!lists[i] && (!GotAnySumFile || (i&1==0)))
         lists[i] = ReadMMFileWithPath(pr, "res", fn[k]);
      if (!lists[i])
         fprintf(stderr, "CANNOT FIND FILE 'res/%c%s'!\n", pr, fn[k]);
      if (i&1 == 0) assert(lists[i]);
   }
   return(outd);
}


double GenPerfH(char pre, char *outd, char *cn, double mfMax,
                ATL_mmnode_t *mb, ATL_mmnode_t *k1)
{
   FILE *fp;
   ATL_mmnode_t *mp;
   #define NTHRSH 11
   int THRSH[NTHRSH] = {25, 33, 50, 66, 75, 80, 85, 90, 95, 98, 99};
   int idxT[NTHRSH];
   ATL_mmnode_t *mpT[NTHRSH];
   const int FNDMAX = (mfMax == 0.0);
   int i, n, idxMax=0;
   double fcnt;

   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "perf", mb);
/*
 * If not already set, compute the max perf & its index.  We'll use this
 * max as the denominator in our PERF array.
 */
   if (FNDMAX)
   {
      for (i=0; i < NTHRSH; i++)
         mpT[i] = NULL;
      for (n=0,mp=mb; mp; n++, mp = mp->next)
      {
         if (mp->mflop[0] > mfMax)
         {
            mfMax = mp->mflop[0];
            idxMax = n;
         }
      }
   }
/*
 * If our denom comes from other file, just count the number of entries
 */
   else
   {
      for (n=0,mp=mb; mp; n++, mp = mp->next);
      idxMax = -1;
   }
   fprintf(fp, "#define ATL_%sAMM_NCASES %d\n", cn, n);
   fprintf(fp, "#define ATL_%sAMM_DENOM %le /* (%.2f)*/ \n", cn,
           mfMax, mfMax);
   fprintf(fp, "#define ATL_%sAMM_MAXMFLOPIDX %d\n\n", cn, idxMax);
   if (FNDMAX)
   {
      for (n=0,mp=mb; mp; mp = mp->next, n++)
      {
         double mf = mp->mflop[0] / mfMax;
         for (i=0; i < NTHRSH; i++)
         {
            if (!mpT[i] && THRSH[i]*0.01*mfMax < mp->mflop[0])
            {
               mpT[i] = mp;
               idxT[i] = n;
            }
         }
      }
      for (i=0; i < NTHRSH; i++)
      {
         mp = mpT[i];
         fprintf(fp, "#define ATL_%sAMM_%dLCMU %d\n", cn, THRSH[i],
                 Mylcm(Mylcm(mp->mu,mp->nu),mp->ku));
         fprintf(fp, "#define ATL_%sAMM_%dLCMMN %d\n", cn, THRSH[i],
                 Mylcm(mp->mu,mp->nu));
         fprintf(fp, "#define ATL_%sAMM_%dMB %d\n", cn, THRSH[i], mp->mbB);
         fprintf(fp, "#define ATL_%sAMM_%dNB %d\n", cn, THRSH[i], mp->nbB);
         fprintf(fp, "#define ATL_%sAMM_%dKB %d\n", cn, THRSH[i], mp->kbB);
         fprintf(fp, "#define ATL_%sAMM_%dIDX %d\n", cn, THRSH[i], idxT[i]);
      }
      mp = ATL_FindLastNode(mb, GetOffset(&mb->next, mb));
      fprintf(fp, "#define ATL_%sAMM_LCMU %d\n", cn, 
              Mylcm(Mylcm(mp->mu,mp->nu),mp->ku));
      fprintf(fp, "#define ATL_%sAMM_LCMMN %d\n", cn, Mylcm(mp->mu,mp->nu));
      fprintf(fp, "\n");
   }

   fprintf(fp, "#if !defined(NOPERF) && !defined(NOARRS)\n");
   fprintf(fp, "static const float ATL_%sAMM_PERF[%d] =\n", cn, n);
   fprintf(fp, "{  /* %% of performance of best kernel */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d, mf=%.0f */\n", mp->mflop[0]/mfMax,
              (mp->next)?',':' ', i, mp->kbB, mp->mflop[0]);
   fprintf(fp, "};\n#endif\n\n");

   if (k1)
   {
      ATL_mmnode_t *kp;
      fprintf(fp, "#if !defined(NOK1RATIO) && !defined(NOARRS)\n");
      fprintf(fp, "static const float ATL_%sAMM_K1RATIO[%d] =\n", cn, n);
      fprintf(fp, "{  /* ratio of %sAMM perf wt that of its K=1 K-cleaner */\n",
              cn);
      for (i=0,mp=mb,kp=k1; mp; i++,mp = mp->next,kp = kp->next)
         fprintf(fp, "   %f%c  /* IDX=%d, KB=%d IDs=[%d,%d]*/\n", 
                 kp->mflop[0]/mp->mflop[0], (mp->next)?',':' ', i, mp->kbB,
                 mp->ID, kp->ID);
      fprintf(fp, "};\n#endif\n\n");
   }

   fprintf(fp, "#if !defined(NOTIME) && !defined(NOARRS)\n");
   fprintf(fp, "static const float ATL_%sAMM_TIME[%d] =\n", cn, n);
   fprintf(fp, "{  /* actual seconds to compute one block */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      if (mp->blask == 0)
         fcnt = (2.0*mp->mbB)*mp->nbB*mp->kbB;  /* gemm flop count */
      else
         fcnt = (1.0*mp->mbB)*mp->nbB*mp->kbB;  /* roughly right */
      fprintf(fp, "   %e%c  /* IDX=%d, B=(%d,%d,%d) */\n",
              fcnt / (mp->mflop[0]*1.0e6),
              (mp->next)?',':' ', i, mp->mbB, mp->nbB, mp->kbB);
   }
   fprintf(fp, "};\n#endif\n");
   CloseGenHeader(fp);
   return(mfMax);
}

void GenKernH
   (char pre, char *outd, char *cn, ATL_mmnode_t *mb, ATL_mmnode_t *mkb,
    ATL_mmnode_t *ub)
{
   FILE *fp;
   int ib, inxt, iaut;
   char bes[3] = {'0', '1', 'n'};

   inxt = GetOffset(&mb->next, mb);
   iaut = GetOffset(&ub->auth, ub);
   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "kern", mb);
   for (ib=0; ib < 3; ib++)
      PrintMMProtos(fp, pre, "KERN", ub, iaut, bes[ib]);
   for (ib=0; ib < 3; ib++)
   {
      PrintStrArrAtOff(fp, pre, "KERN", mb, inxt, iaut, "ammkern_t", 
                       0, 0, bes[ib]);
      if (mkb)
         PrintStrArrAtOff(fp, pre, "KERN_K1", mkb, inxt, iaut, "ammkern_t", 
                          0, 0, bes[ib]);
   }
   CloseGenHeader(fp);
}

void PrintFlagArr(FILE *fp, ATL_mmnode_t *mb)
{
   ATL_mmnode_t *mp;
   int n;

   n = CountListEntries(mb, GetOffset(&mb->next, mb));
   fprintf(fp, "#ifndef NOKFLAG\n");
   fprintf(fp, "static const unsigned char ATL_AMM_KFLAG[%d] =\n{\n", n);
   for (n=0,mp=mb; mp; n++, mp = mp->next)
   {
      unsigned char flag=FLAG_IS_SET(mp->flag, MMF_KRUNTIME) ? 1 : 0;
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         flag |= 2;
      fprintf(fp, "%6d%c   /* IDX=%d */\n", flag, mp->next ? ',':' ', n);
   }
   fprintf(fp, "};\n");
   fprintf(fp, "   #define ATL_AMM_KRUNTIME(idx_) (ATL_AMM_KFLAG[idx_] & 1)\n");
   fprintf(fp, "   #define ATL_AMM_KMAJOR(idx_) (ATL_AMM_KFLAG[idx_] & 2)\n");
   fprintf(fp, "#endif\n");
}
void GenBlkH(char pre, char *outd, char *cn, ATL_mmnode_t *mb)
{
   FILE *fp;
   ATL_mmnode_t *mp;
   int *KUs;
   int i, n, inxt;

   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "blk", mb);
   inxt = GetOffset(&mb->next, mb);
   mp = ATL_FindLastNode(mb, inxt);
   fprintf(fp, "#define ATL_%sAMM_LASTMB %d\n", cn, mp->mbB);
   fprintf(fp, "#define ATL_%sAMM_LASTNB %d\n", cn, mp->nbB);
   fprintf(fp, "#define ATL_%sAMM_LASTKB %d\n", cn, mp->kbB);
   fprintf(fp, "\n");
/*
 * Save original KUs, and overwrite compile-time-K KUs with kbB for printing
 */
   n = CountListEntries(mb, inxt);
   KUs = malloc(sizeof(int)*n*3);
   assert(KUs);
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      KUs[i] = mp->ku;
      KUs[i+n] = mp->kbmin;
      KUs[i+n+n] = mp->kbmax;
      #if 0
      if (FLAG_IS_SET(mp->flag,MMF_KUISKB))
         mp->kbmin = mp->kbmax = mp->ku = mp->kbB;
      else if (!FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
         mp->kbmin = mp->kbmax = mp->kbB;
      #endif
   }
   @multidef st VLENs KBMAXs KBMINs KUs NUs MUs KBs NBs MBs
   @whiledef iv vlen  kbmax  kbmin  ku  nu  mu  kbB nbB mbB
@skip   PrintMMIntOffArr(fp, pre, "@(st)", mb, GetOffset(&mb->@(iv), mb));
   PrintIntArrAtOff(fp, pre, "@(st)", mb, inxt, GetOffset(&mb->@(iv), mb),0,0);
      @undef st
   @endwhile
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      mp->ku = KUs[i];
      mp->kbmin = KUs[i+n];
      mp->kbmax = KUs[i+n+n];
   }
   PrintFlagArr(fp, mb);
   free(KUs);
   CloseGenHeader(fp);
}

int StrFindReplace(char **org, char *find, char *replace)
{
   char *pre, *post, *final;
   char *orig = *(org);
   int idx = (strstr(orig, find) - orig) / sizeof(char);
   int len = strlen(orig);
   int flen = strlen(find);
   int rlen = strlen(replace);
   if (idx < 0) return(len); /* not found */
   pre = malloc(sizeof(char)*idx + 1);
   post = malloc(sizeof(char)*(len - idx - flen) + 1);
   strncpy(pre, orig, idx);
   pre[idx] = '\0';
   strcpy(post, orig+idx+flen);
   len = len - flen + rlen;
   free(orig);
   orig = malloc(sizeof(char)*(len) + 1);
   strcpy(orig, pre);
   strcat(orig, replace);
   strcat(orig, post);
   *org = orig;
   return(len);
}

void AdjustCPNamesWithID(char pre, ATL_mmcp_t *cb)
{
   char find[24] = "";
   char replace[24] = "";
   ATL_mmcp_t *cp;
   sprintf(find, "ATL_%c", pre);
   sprintf(replace, "ATL_%cu%d", pre, UID);
   for (cp=cb; cp; cp=cp->next)
      cp->rtlen = StrFindReplace(&cp->rout, find, replace);
}

void GenCpyA(char pre, char *outd, char *cn, char dir, char alp, 
             ATL_mmnode_t *mb)
// presently leaving alp='[1,n,X]', cn=[ge,sq,rk], dir='[F,T]' to caller
{
   FILE *fp;
   const int nt = (pre == 'd' || pre == 's') ? 2 : 4;
   int flag=0, i, j, it, im;
   char tas[4] = {'N', 'T', 'C', 'H'};
   char mats[2] = {'A', 'B'};
   char arrnm[12]={'x', 'x', '2', 'B', 'L', 'K', '_', 'a', alp, '\0'};
   char fn[12];
   int mati, transi;

   if (dir == 'T')
   {
      sprintf(fn, "cm2am_a%c", alp);
      mati = 0; transi = 1;
   }
   else
   {
      sprintf(fn, "am2cm_a%c", alp);
      sprintf(arrnm, "BLK2xx_a%c", alp);
      mati = 4; transi = 5;
   }
   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, fn, mb);
   fn[6] = 't'; fn[7] = '\0';  /* switch fn to type name */

   for (im=0; im < 2; im++)
   {
      arrnm[mati] = mats[im];
      for (it=0; it < nt; it++)
      {
         ATL_mmcp_t *cb, *ucb;
         int i;
         const char ta = tas[it]; 

         arrnm[transi] = ta;
         cb = GetMMCopyFromMMNodes(MMCopyEncode(pre, dir, mats[im], ta), mb);
         assert(cb);
         AdjustCPNamesWithID(pre, cb);
         ucb = AddUniqueCopyNode(NULL, cb);
         arrnm[6] = '\0';
         PrintMMCpProtosA(fp, arrnm, ucb, dir, alp);
         KillAllCopyNodes(ucb);
         PrintStrArrAtOff(fp, pre, arrnm, cb, GetOffset(&cb->next, cb),
                          GetOffset(&cb->rout, cb), fn, ta, alp, 0);
         KillAllCopyNodes(cb);
      }
   }
   CloseGenHeader(fp);
}

void GenCpyC(FILE *fp, char pre, char *outd, char *cn, char dir, char *type, 
             char alp, char bet, ATL_mmnode_t *mb)
{
   char *arrnm = (dir == 'T') ? "C2BLK" : "BLK2C";
   ATL_mmcp_t *cb, *ucb;
   int flag=0, i, j;

   cb = GetMMCopyFromMMNodes(MMCopyEncode(pre, dir, 'c', 'n'), mb);
   assert(cb);
   AdjustCPNamesWithID(pre, cb);
   #ifdef Debug
      i = CountListEntries(cb, GetOffset(&cb->next, cb));
      j = CountListEntries(mb, GetOffset(&mb->next, mb));
      fprintf(stderr, "ncpy=%d, nmm=%d!\n", i, j);
   #endif
   ucb = AddUniqueCopyNode(NULL, cb);
   PrintMMCpProtosC(fp, arrnm, ucb, dir, alp, bet);
   KillAllCopyNodes(ucb);
   PrintStrArrAtOff(fp, pre, arrnm, cb, GetOffset(&cb->next, cb),
                    GetOffset(&cb->rout, cb), type, 0, alp, bet);
   KillAllCopyNodes(cb);
}

void PrintDiv(FILE *fp, char *exp, int v)
/* 
 * Prints either exp/v or exp>>lg2(v), dep on v being power of 2 or not 
 * caller must put parens where appropriate (if exp is not a simple variable
 * name, it must have parens to produce the right answer!).
 */
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "%s>>%d", exp, p);
   else
      fprintf(fp, "%s/%d", exp, v);
}
void PrintCeil(FILE *fp, char *exp, int v)
/* 
 * Prints either ((exp+v-1)/v)*v or same things wt shifts if power of 2.
 */
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "((%s+%d)>>%d)", exp, v-1, p);
   else
      fprintf(fp, "((%s+%d)/%d)", exp, v-1, v);
}
void PrintCeilMul(FILE *fp, char *exp, int v)
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "(((%s+%d)>>%d)<<%d)", exp, v-1, p, p);
   else
      fprintf(fp, "(((%s+%d)/%d)*%d)", exp, v-1, v, v);
}

void GenFullCpyC(char pre, char *outd, char dir, char *cn, ATL_mmnode_t *mb)
{
   ATL_mmnode_t *mp;
   FILE *fp;
   int ib, NEEDSZF=0;
   char rt[16];
   char bets[4] = {'0', '1', 'n', 'X'};

/*
 * Create atlas_<pre><cn>szC.h if necessary
 */
   for (mp=mb; mp; mp = mp->next)
      if (FLAG_IS_SET(mp->flag, MMF_KVEC) && ib == -1 &&
          (mp->mu*mp->nu) % mp->vlen != 0)
         break;
   if (mp)
   {
      ATL_mmcp_t *cb, *ucb, *cp;
      int n;
      NEEDSZF=1;
      fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "szC", mb);
      cb = GetMMCopyFromMMNodes(MMCopyEncode(pre, dir, 'c', 'n'), mb);
      assert(cb);
      AdjustCPNamesWithID(pre, cb);
      ucb = AddUniqueCopyNode(NULL, cb);
      KillAllCopyNodes(cb);
/*
 *    Generate needed funcs for size query
 */
      for (cp=ucb; cp; cp = cp->next)
      {
         const unsigned int mu=cp->mu, nu=cp->nu, kvec=cp->kvec, b = mu*nu;
         const unsigned int B = (kvec > 1) ? ((b+kvec-1)/kvec)*kvec : 0;
         fprintf(fp, "#define uint unsigned int\n");
         if (b != B)
         {
            assert(!cp->ID);
            fprintf(fp, "static uint ATL_szC_%dx%d(uint M, uint N, "
                        "uint mu, uint nu, uint vlen)", mu, nu);
            fprintf(fp, "\n{\n");
            fprintf(fp, "   return(");
            PrintCeilMul(fp, "M", mu);
            fprintf(fp, "*");
            PrintCeilMul(fp, "N", nu);
            fprintf(fp, "*");
            fprintf(fp, "%d);\n", B);
            fprintf(fp, "}\n");
         }
         fprintf(fp, "typedef uint (*szC_t)(uint,uint,uint,uint,uint);\n");
         fprintf(fp, "#undef uint\n");
         for (n=0,cp=cb; cp; n++, cp = cp->next);
         fprintf(fp, "static szC_t ATL_AMM_SZCW[%d] =\n{\n", n);
         for (cp=cb,n=0; cp; cp = cp->next,n++)
         {
            const unsigned int mu=cp->mu, nu=cp->nu, kvec=cp->kvec, b = mu*nu;
            const unsigned int B = (kvec > 1) ? ((b+kvec-1)/kvec)*kvec : 0;
            fprintf(fp, "/* IDX=%d */ ", n);
            if (b != B)
               fprintf(fp, "ATL_szC_%dx%d", mu, nu);
            else
               fprintf(fp, "NULL"); 
            if (cp->next)
               fprintf(fp, ",\n");
            else
               fprintf(fp, "\n");
         }
      }
      KillAllCopyNodes(cb);
      CloseGenHeader(fp);
   }
#if 0
#endif

   if (dir == 'T')
      strcpy(rt, "cmat2ablk");
   else
      strcpy (rt, "ablk2cmat");

   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, rt, mb);
   if(NEEDSZF)
   {
      fprintf(fp, "#ifndef NOSZC\n");
      fprintf(fp, "   #include \"atlas_%c%sszC.h\"\n", pre, cn);
      fprintf(fp, "#endif\n");
   }
   rt[9] = '_'; rt[10] = 't'; rt[11] = '\0';
@skip   strcpy(rt, dir == 'T' ? "cmat2ablk_t" : "ablk2cmat_t");
   for (ib=0; ib < 4; ib++)
   {
      int ia;
      char alps[3] = {'1', 'n', 'X'};
      const char bet = bets[ib];

      for (ia=0; ia < 3; ia++)
         GenCpyC(fp, pre, outd, cn, dir, rt, alps[ia], bet, mb);
   }
   CloseGenHeader(fp);
}

void GenAllCpyC(char pre, char *outd, char dir, ATL_mmnode_t *ub)
{
   if (ub)
      GenFullCpyC(pre, outd, dir, unam, ub);
}
void GenAllCpyA(char pre, char *outd, char dir, ATL_mmnode_t *ub)
// presently leaving dir='[F,T]' to caller
{
   int ia;
   char alps[3] = {'1', 'n', 'X'};

   for (ia=0; ia < 3; ia++)
   {
      if (ub)
         GenCpyA(pre, outd, unam, dir, alps[ia], ub);
   }
}

double PrintSum(FILE *fp, char *cn, ATL_mmnode_t *b, double mfGE)
{
   int inxt, max, i, kvec;
   double mf;
   ATL_mmnode_t *mp;

   inxt = GetOffset(&b->next, b);
   fprintf(fp, "#define ATL_%sAMM_NCASES %d\n", cn, CountListEntries(b, inxt));
   mp = ATL_FindLastNode(b, inxt);
   fprintf(fp, "#define ATL_%sAMM_LASTMB %d\n", cn, mp->mbB);
   fprintf(fp, "#define ATL_%sAMM_LASTNB %d\n", cn, mp->nbB);
   fprintf(fp, "#define ATL_%sAMM_LASTKB %d\n", cn, mp->kbB);
   mf = mp->mflop[0];
   fprintf(fp, "#define ATL_%sAMM_LASTMU %d\n", cn, mp->mu);
   fprintf(fp, "#define ATL_%sAMM_LASTNU %d\n", cn, mp->nu);
   fprintf(fp, "#define ATL_%sAMM_LASTKU %d\n", cn, mp->nu);
   fprintf(fp, "#define ATL_%sAMM_LASTLCMMN %d\n\n", cn, Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_%sAMM_LASTLCMU %d\n\n", cn,
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   #if 0
   fprintf(fp, "#define ATL_%sAMM_LASTMFLOP %e\n", cn, mf);
   if (mfGE > 0.0)
      fprintf(fp, "#define ATL_%sAMM_MFLOP_RATIO %e\n", cn, mf/mfGE);
   #endif
   for (kvec=0,mp=b; mp; mp = mp->next)
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         kvec = Mmax(kvec, mp->vlen);
   fprintf(fp, "#ifndef  ATL_%sAMM_MAXKVEC\n", cn);
   fprintf(fp, "   #define ATL_%sAMM_MAXKVEC %d\n", cn, kvec);
   fprintf(fp, "#endif\n");
   fprintf(fp, "\n");
   return(mf);
}

void GenSumH(char pre, char *outd, ATL_mmnode_t *ub)
/*
 * cn:[u%d]
 * For [u%d] report: ncases, max[nb,mb,kb]
 * -> for maxB, report: perf,time,ratio wt best user-case
 */
{
   FILE *fp;
   double mf;
   int i;

   fp = OpenMMGenHeader(outd, 0, pre, unam, 0, 0, "sum", ub);
   mf = PrintSum(fp, unam, ub, 0.0);
   CloseGenHeader(fp);
}

void GenAllHeaders(char pre, char *outd, ATL_mmnode_t **lists)
{
   ATL_mmcp_t *cb;
   ATL_mmnode_t *mb;
   char *nm="perf";
   double mfMax;
   int i, k, SKSAME;
   char pr;

/*
 * Handle [perf,blk,flag,sum] which require only ordered lists
 */
   for (pr=pre,k=0; k < 2*NMMLISTS; k += NMMLISTS)
   {
      mfMax = GenPerfH(pr, outd, unam, 0.0, lists[k+IUSR], lists[k+IUSRK1]);

      GenBlkH(pr, outd, unam, lists[k+IUSR]); 
      pr = (pre == 'd') ? 'z' : 'c';
   }
   GenSumH(pre, outd, lists[IUSR]);
   GenSumH(pr, outd, lists[IUSR+NMMLISTS]);
/*
 * Create lists of only the unique kernels for [ub] in real & cplx
 * for use in prototyping.  We combine kern & K1 lists for each.
 * We can now gen [kern].
 */
   for (pr=pre,k=0; k < 2; k++)
   {
      for (i=0; i < 1; i++)
      {
         ATL_mmnode_t *ulst;  /* unordered list of only unique kernels */
         const int h = i+i+k*NMMLISTS, u=k+i;
         ulst = AddUniqueMMKernCompList(NULL, lists[h]);
         ulst = AddUniqueMMKernCompList(ulst, lists[h+1]);
         GenKernH(pr, outd, unam, lists[h], lists[h+1], ulst);
         KillAllMMNodes(ulst);  /* done with these! */
      }
      pr = (pre == 's') ? 'c' : 'z';
   }
/*
 * [cmat2ablk_a[1,n,X]_b[0,1,n,X],ablk2cmat_a?_b?,am2cm_a[1,n,X]]
 * -> have never genned, can we?: am2rm_a[1,n,X],
 */
   GenAllCpyA(pre, outd, 'T', lists[IUSR]);
   GenAllCpyA(pre, outd, 'F', lists[IUSR]);
   GenAllCpyA(pr, outd, 'T', lists[IUSR+NMMLISTS]);
   GenAllCpyA(pr, outd, 'F', lists[IUSR+NMMLISTS]); // for now

   GenAllCpyC(pre, outd, 'F', lists[IUSR]);
   GenAllCpyC(pre, outd, 'T', lists[IUSR]);
   GenAllCpyC(pr, outd, 'F', lists[IUSR+NMMLISTS]);
   GenAllCpyC(pr, outd, 'T', lists[IUSR+NMMLISTS]); // for now
}

static void AddAlpBetSuf(char *rt, int rl, int ial, int ibe)
/*
 * Add _aXbX suffix to rt, which is presently of length rl
 */
{
   rt[rl] = '_';
   rt[rl+1] = 'a';
   if (ial == -1)
      rt[rl+2] = 'n';
   else if (ial == 2)
      rt[rl+2] = 'X';
   else
      rt[rl+2] = ial+48;
   rt[rl+3] = 'b';
   if (ibe == -1)
      rt[rl+4] = 'n';
   else if (ibe > 1)
      rt[rl+4] = 'X';
   else
      rt[rl+4] = ibe+48;
}

void GenAllKerns(char pre, char *outd, ATL_mmnode_t *rb, 
                 ATL_mmcp_t *cpA, ATL_mmcp_t *cpC)
{
   ATL_mmcp_t *last, *cp;
   ATL_mmnode_t *mp;
   char *sgen;
   int i, len, dlen, mID, mU;
   char pr=pre;
/*
 * join all copy routs into one list temporarily
 */
   last = FindLastCopyNode(cpA);
   last->next = cpC;
/*
 * Get a string of max length for all system calls
 */
   mID=mU=len=i=0;
   for (cp=(!i)?cpA:cpC; cp; cp = cp->next)
   {
      len = Mmax(len, cp->rtlen);
      mID = Mmax(mID, cp->ID);
      mU = Mmax(mU, cp->mu);
      mU = Mmax(mU, cp->nu);
      mU = Mmax(mU, cp->kvec);
   }
   dlen = strlen(outd);
   len += dlen + 1;  /* outd */
   len += 17;  /* " > /dev/null 2>&1" */
   assert(mID == 0);  /* just until we support user copies */
   len += 64 - 2*4;  /* C format string */
   len += 4*NumDecDigits(mU); /* mu,nu,kvec */
   len += 2;                  /* extra for syrk */
   sgen = malloc(len+1);
   assert(sgen);
/*
 * Generate all needed copy routines
 */
   printf("\nGENERATING MMCOPY FILES\n");
   for (cp=cpA; cp; cp = cp->next)
   {
      int flag = cp->flag;
      int k;
      char pr;
      pr = MMCopyGetPre(cp->flag);
      printf("   -> %s\n", cp->rout);
      if (flag & (1<<MMCP_CBLK))
      {
         if (flag & (1<<MMCP_SYRK))
         {
            k = sprintf(sgen, 
"make genall_syblk2C pre=%c vec=NA vlen=%d mu=%d nu=%d cpvlen=1 rt=%s/%s.c",
                        pr, cp->kvec ? cp->kvec:1, cp->mu, cp->nu, outd, cp->rout);
         }
         else if (flag & (1<<MMCP_CBLK))
         {
            k = sprintf(sgen, 
      "make genall_%s pre=%c vec=NA vlen=%d mu=%d nu=%d cpvlen=1 rt=%s/%s.c",
                        (flag&(1<<MMCP_TOBLK)) ? "C2blk":"blk2C", pr, 
                        cp->kvec ? cp->kvec:1, cp->mu, cp->nu, outd, cp->rout);
         }
      }
      else /* generate A/B copy */
      {
         char *targ;
         if (flag & (1<<MMCP_REAL))
            targ = (flag & (1<<MMCP_TOBLK)) ? "A2blk":"blk2A";
         else
            targ = (flag & (1<<MMCP_TOBLK)) ? "cA2blk":"cblk2A";
         k = sprintf(sgen, 
             "make genall_%s pre=%c kmaj=%d vlen=%d UR=%d cpvlen=1 rt=%s/%s.c",
                     targ, pr, cp->kvec, cp->kvec ? cp->kvec:1, 
                     cp->nu, outd, cp->rout);
      }
      assert(k < len);
      k += sprintf(sgen+k, " > /dev/null 2>&1");
      assert(k <= len);
      if ((k=system(sgen)))
      {
         fprintf(stderr, "\n\ncpgenstr='%s' returns %d!\n\n", sgen, k);
         exit(k);
      }
   }
   printf("DONE GENERATING MMCOPY FILES\n");
   last->next = NULL;  /* disconnect A/C lists */
/*
 * Generate/copy all required kernels.  This list has files with compile-time
 * K repeated, but we'll check ID to avoid repeated copies of user-supplied, 
 * and generated kernels need a new generation for each required KB.
 */
   printf("\nGENERATING AMM KERNS:\n");
   for (mp=rb; mp; mp = mp->next)
   {
      const int id=mp->ID;
      if (!id)
      {
         printf("   -> %s\n", mp->rout);
         assert(mp->genstr);
         if ( (i=system(mp->genstr)) )
         {
            fprintf(stderr, "GENSTR RETURNS %d:\n'%s'\n", i, mp->genstr);
            exit(i);
         }
      }
      else /* user-supplied kernel */
      {
         ATL_mmnode_t *p;
         for (p=rb; p != mp && p->ID != id; p = p->next);
         if (p == mp)  /* this is first mention of this ID */
         {
            printf("   %s -> %s\n", mp->genstr, mp->rout);
            i = strlen(mp->genstr) + strlen(mp->rout) + dlen + 16;
            if (i > len)
            {
               free(sgen);
               sgen = malloc(i*sizeof(char));
               assert(sgen);
               len = i;
            }
            sprintf(sgen, "cp AMMCASES/%s %s/%s", mp->genstr, outd, mp->rout);
            
            if ( (i=system(sgen)) )
            {
               fprintf(stderr, "FAILED CP='%s'\n", sgen);
               exit(i);
            }
         }
         else /* they better have same filename! */
         {
            if (strcmp(mp->rout, p->rout))
            {
               printf("rout=(%s,%s)!\n", mp->rout, p->rout);
               exit(1);
            }
         }
      }
   }
   printf("DONE GENERATING AMM KERNS.\n");
   free(sgen);
}

void GenMake(char pre, char *outd, ATL_mmnode_t *mb,
             ATL_mmcp_t *cpA, ATL_mmcp_t *cpC)
/*
 * mb files have already been made at least compile-time unique (same source
 * file might occur multiple times due to need to compile with -DKB)
 */
{
   FILE *fp;
   char *fn;
   ATL_mmcp_t *cp;
   ATL_mmnode_t *mp;
   char *sals[3] = {"1", "N1", "X"};
   char als[3] = {'1', 'n', 'X'};
   char *sbes[4] = {"0", "1", "N1", "X"};
   char bes[4] = {'0', '1', 'n', 'X'};  /* use 1st 3 for mmkerns */
   char ctas[4] = {'N', 'T', 'C', 'H'};
   char dcomp[8] = {'$', '(', 'D', 'M', 'C', ')', '\0'};
   char dflags[12] = {'$','(','D','M','C','F','L','A','G','S',')','\0'};


   fn = malloc(strlen(outd)+11);
   assert(fn);
   sprintf(fn, "%s/%cMake_amm", outd, pre);
   fp = fopen(fn, "w");
   assert(fp);
   free(fn);
   fprintf(fp, "include ../Make.inc\n");
   fprintf(fp, "CDEFS2=$(CDEFS)\n\n");
/*
 * Spew out kernels to be compiled
 */
   fprintf(fp, "objs =");
   for (mp=mb; mp; mp = mp->next)
   {
      int ib;
      for (ib=0; ib < 3; ib++)
         fprintf(fp, " \\\n       %s_b%c.o", mp->auth, bes[ib]);
   }
   for (cp=cpC; cp; cp = cp->next)  /* C copy routs */
   {
      int ib;
      for (ib=0; ib < 4; ib++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
            fprintf(fp, " \\\n       %s_a%cb%c.o", cp->rout, als[ia], bes[ib]);
      }
   }

   for (cp=cpA; cp; cp = cp->next)  /* A/B copy routs */
   {
      const int NTA = (cp->flag & (1<<MMCP_REAL)) ? 2:4;
      int it;
      for (it=0; it < NTA; it++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
            fprintf(fp, " \\\n       %s_%ca%c.o", cp->rout, ctas[it], als[ia]);
      }
   }
   fprintf(fp, "\n");
/*
 * library make targets
 */
   fprintf(fp, "\n\nlib : %clib.grd\nall : %clib.grd\n%clib : %clib.grd\n",
           pre, pre, pre, pre);
   fprintf(fp, "%clib.grd : $(objs)\n", pre);
   fprintf(fp, "\t$(ARCHIVER) $(ARFLAGS) $(UAMMlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(UAMMlib)\n");
   fprintf(fp, "\t touch %clib.grd\n", pre);
   fprintf(fp, "clean : %cclean\n", pre);
   fprintf(fp, "%cclean:\n\t- rm -f $(objs)\n", pre);
   fprintf(fp, "killall : %ckillall\n", pre);
   fprintf(fp, "%ckillall : %cclean\n", pre, pre);
   fprintf(fp, "\t- $(ARCHIVER) d $(UAMMlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(UAMMlib)\n");
   fprintf(fp, "\t- rm -f ATL_%c*.[S,c]\n\n", pre);
/*
 * Make targets for amm kerns
 */
   fprintf(fp, "#\n#  AMM kernel rules\n#\n");
   fn = (pre == 'd' || pre == 'z') ?  "-DDREAL=1" : "-DSREAL";
   for (mp=mb; mp; mp = mp->next)
   {
      int ib;
      char *comp, *flgs;

      comp = GetMMKernComp(mp, dcomp, dflags, &flgs);
      for (ib=0; ib < 3; ib++)
      {
         char *sp=" ";
         fprintf(fp, "%s_b%c.o : %s\n", mp->auth, bes[ib], mp->rout);
         fprintf(fp, "\t%s $(CDEFS2) %s -DBETA%s=1 \\\n", comp, fn, sbes[ib]);
         if (!FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
            fprintf(fp, "        -DMB=%d -DNB=%d -DKB=%d", 
                    mp->mbB, mp->nbB, mp->kbB);
         else
            sp = "        ";
   @whiledef mtx C B A
         if (FLAG_IS_SET(mp->flag, MMF_MV@(mtx)))
         {
            fprintf(fp, "%s-DATL_MOVE@(mtx)", sp);
            sp = " ";
         }
   @endwhile
         fprintf(fp, " \\\n        %s \\\n", flgs);
         fprintf(fp, 
                 "        -DATL_USERMM=%s_b%c \\\n        -c -o %s_b%c.o \\\n",
                 mp->auth, bes[ib], mp->auth, bes[ib]);
         fprintf(fp, "        %s\n", mp->rout);
      }
   }
/*
 * Make targets for C copy routines
 */
   fprintf(fp, "#\n#  C copy rules\n#\n");
   dflags[3] = dcomp[3] = 'K';
   for (cp=cpC; cp; cp = cp->next)  /* C copy routs */
   {
      char *styp;
      int ib;
      char pr;

      styp = MMCopyGetCompType(cp->flag);
      for (ib=0; ib < 4; ib++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
         {
            fprintf(fp, "%s_a%cb%c.o : %s.c\n", cp->rout, als[ia], bes[ib], 
                    cp->rout);
            fprintf(fp, "\t%s %s -c $(CDEFS) -D%s=1 -DBETA%s=1 -DALPHA%s=1",
                    dcomp, dflags, styp, sbes[ib], sals[ia]);
            fprintf(fp, 
            " \\\n           -DATL_USERCPMM=%s_a%c_b%c -DATL_MU=%d -DATL_NU=%d",
                    cp->rout, als[ia], bes[ib], cp->mu, cp->nu);
            fprintf(fp, " \\\n           -o %s_a%cb%c.o %s.c\n", 
                    cp->rout, als[ia], bes[ib], cp->rout);
         }
      }
   }
/*
 * Make targets for A/B copy routines
 */
   fprintf(fp, "#\n#  A/B copy rules\n#\n");
   for (cp=cpA; cp; cp = cp->next) 
   {
      char *styp, *cnj[2] = {"", "-DConj_=1"};
      const int flag = cp->flag;
      const int NC = (flag&(1<<MMCP_REAL)) ? 1 : 2;
      int ic;
      char pr;
      styp = MMCopyGetCompType(cp->flag);
      for (ic=0; ic < NC; ic++)
      {
         int it;
         for (it=0; it < 2; it++)
         {
            int ia;
            const int itc = ic*NC+it;
            for (ia=0; ia < 3; ia++)
            {
               fprintf(fp, "%s_%ca%c.o : %s.c\n", cp->rout, ctas[itc], 
                       als[ia], cp->rout);
               fprintf(fp, "\t%s %s -c $(CDEFS) -D%s=1 -DALPHA%s=1",
                       dcomp, dflags, styp, sals[ia]);
               fprintf(fp, " \\\n           -DATL_NU=%d -DTRANS%c_=1 %s", 
                       cp->nu, ctas[it],  cnj[ic]);
               fprintf(fp, " \\\n           -DATL_USERCPMM=%s_%ca%c", cp->rout, 
                       ctas[itc], als[ia]);
               fprintf(fp, " \\\n           -o %s_%ca%c.o %s.c\n", 
                       cp->rout, ctas[itc], als[ia], cp->rout);
            }
         }
      }
   }
   fclose(fp);
}

void GenAllFiles(char pre, char *outd, ATL_mmnode_t **lists)
{
   FILE *fp;
   int i, RCSAME;
   ATL_mmnode_t *rb=NULL, *ib=NULL, *mp;
   ATL_mmcp_t *cpA=NULL, *cpC=NULL, *ncp;
   const char cpr = (pre == 'd') ? 'z' : 'c';
/*
 * First, generate performance files, which require routs separated by
 * various lists
 */
   printf("\nGENERATING HEADER FILES\n");
   GenAllHeaders(pre, outd, lists);
   printf("DONE HEADER GENERATION\n");

/*
 * Generating kernels & Makefile do not care which list kernels came from,
 * or their order, so combine them all into one list for each data type 
 * (2 lists total: real,complex), and remove any redundancies.
 * NOTE2: I think we should generate copy routs at this time and then
 *        can pass info to GenAllKerns & GenMake.
 */
   for (i=0; i < NMMLISTS; i++)
   {
      rb = AddUniqueMMKernCompList(rb, lists[i]);
      KillAllMMNodes(lists[i]);
      ib = AddUniqueMMKernCompList(ib, lists[NMMLISTS+i]);
      KillAllMMNodes(lists[NMMLISTS+i]);
   }
/*
 * Now create lists of copy routines for both real & complex
 */
   GetMMAllUniqueCopyFromMMNodes(pre, 'F', 'T', rb, &cpA, &cpC);
   GetMMAllUniqueCopyFromMMNodes(pre, 'T', 'F', rb, &cpA, &cpC);
   GetMMAllUniqueCopyFromMMNodes(cpr, 'F', 'T', ib, &cpA, &cpC);
   GetMMAllUniqueCopyFromMMNodes(cpr, 'T', 'F', ib, &cpA, &cpC); // for now
/*
 * Now, kerns are compiled the same for real and complex, so reduce real
 * and complex to one unique list
 */
   rb = AddUniqueMMKernCompList(rb, ib);
   KillAllMMNodes(ib);
   AdjustCPNamesWithID(pre, cpA);
   AdjustCPNamesWithID(cpr, cpA);
   AdjustCPNamesWithID(pre, cpC);
   AdjustCPNamesWithID(cpr, cpC);
   GenAllKerns(pre, outd, rb, cpA, cpC);
   GenMake(pre, outd, rb, cpA, cpC);
   KillAllMMNodes(rb);
   KillAllCopyNodes(cpA);
   KillAllCopyNodes(cpC);
}

void AdjustMMNamesWithID(char pre, ATL_mmnode_t *mb)
{
   char find[24] = "";
   char replace[24] = "";
   ATL_mmnode_t *mp;
   sprintf(find, "ATL_%c", pre);
   sprintf(replace, "ATL_%cu%d", pre, UID);
   for (mp=mb; mp; mp=mp->next)
      StrFindReplace(&mp->auth, find, replace);
}

int main(int nargs, char **args)
{
   char *outd;
   ATL_mmnode_t *lists[2*NMMLISTS];
   int i;
   char pre, cpr;

   outd = GetFlags(nargs, args, &pre, lists);
   cpr = (pre == 'd') ? 'z' : 'c';
/*
 * Prep file for generation.  Free present values, and replace with:
 * ->auth  : kernel name without _b[1,n,0] suffix
 * ->genstr: for ID=0: genstr, else user kernel name (came in ->rout)
 * ->rout  : correct present filename
 */
   for (i=0; i < 2*NMMLISTS; i++)
   {
      PrepMMForGen(pre, outd, "amm", lists[i]);
   }
   for (i=0; i < 2*NMMLISTS; i++)
      AdjustMMNamesWithID(pre, lists[i]);

   GenAllFiles(pre, outd, lists);

   free(outd);
   return(0);
}
@ROUT ammgen
@extract -b @(topd)/cw.inc lang=C -def cwdate 2015 
#include "atlas_misc.h"
#include "atlas_mmgen.h"
#include "atlas_sys.h"

#define NMMLISTS 8
#define IGE   0
#define IGEK1 1
#define ISQ   2
#define ISQK1 3
#define IRKK  4
#define ITRSM 5
#define ISYRK 6
#define ISYRKT 7

@extract -b @(basd)/atlas.base rout=Mylcm
void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -p [s,d]: set type/precision prefix (d) \n");
   fprintf(stderr, "      s/d will generate for complex (c/z) as well\n");
   fprintf(stderr, "   -d <outdir>: directory to dump files to\n");
   fprintf(stderr, "   -g [r,c] <rect kern file> <geKCleanFile>\n");
   fprintf(stderr, "   -r [r,c] <rank-K kernel file> \n");
   fprintf(stderr, "   -s [r,c] <square-case kernel file> <sqKCleanFile>\n");
   fprintf(stderr, "   -t [r,c] <trsm file> : should match -s\n");
   fprintf(stderr, "   -k syrk <syrk file> \n");
   exit(ierr ? ierr : -1);
}


/*
 * RETURNS: precision prefix [s,d,c,z]
 */
char *GetFlags(int nargs, char **args, char *PRE, ATL_mmnode_t **lists)
{
   int i, j=0, n, k;
   char pre='d', cpre, ch;
   char *outd=NULL;
   char *fn[8]={"geAMMRES.sum","geAMMKCLEAN.sum",
      "sqAMMRES.sum","sqAMMKCLEAN.sum", "rkAMMRES.sum", 
      "tsAMMRES.sum","gAMSYRK.sum", "syrkK.sum"};

   for (i=0; i < 2*NMMLISTS; i++)
      lists[i] = NULL;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'p':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        pre = tolower(args[i][0]);
        if (pre == 'z')
           pre = 'd';
        else if (pre == 'c')
           pre = 's';
        assert(pre == 's' || pre == 'd');
        cpre = (pre == 'd') ? 'z' : 'c';
        break;
   @multidef i   0 2
   @whiledef flg g s
      case '@(flg)': /* [r,c] <amm file> <K1file> */
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        ch = args[i][0];
        if (ch == 'c')
           k = NMMLISTS + @(i);
        else if (ch == 'r')
           k = @(i);
        else
            PrintUsage(args[0], i, "1st arg to -@(flg) must be 'r' or 'c'!");
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        lists[k] = ReadMMFile(args[i]);
        assert(lists[k]);
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        lists[++k] = ReadMMFile(args[i]);
        assert(lists[k]);
        break;
      @undef i
   @endwhile
   @multidef i   4 5
   @whiledef flg r t
      case '@(flg)': /* [r,c] <amm file> */
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        ch = args[i][0];
        if (ch == 'c')
           k = NMMLISTS + @(i);
        else if (ch == 'r')
           k = @(i);
        else
            PrintUsage(args[0], i, "1st arg to -@(flg) must be 'r' or 'c'!");
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        lists[k] = ReadMMFile(args[i]);
        assert(lists[k]);
      @undef i
   @endwhile
      case 'k':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        assert(!strcmp(args[i], "syrk"));
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        k = ISYRK;
        lists[k] = ReadMMFile(args[i]);
        break;
      case 'd':
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
        outd = DupString(args[i]);
        break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   *PRE = pre;
/*
 * Fill in any required list entry
 */
   for (i=0; i < 2*NMMLISTS; i++)
   {
      const char pr=(i<NMMLISTS) ? pre : cpre;
      const int k = (i<NMMLISTS) ? i : i-NMMLISTS;
      if (i == NMMLISTS+ITRSM) /* complex trsm not */
         continue;             /* presently used */
      if (!lists[i])
         lists[i] = ReadMMFileWithPath(pr, "res", fn[k]);
      if (!lists[i])
         fprintf(stderr, "CANNOT FIND FILE 'res/%c%s'!\n", pr, fn[k]);
      assert(lists[i]);
   }
   return(outd);
}

void GenSyrkH(char pre, char *outd, ATL_mmnode_t *mb, int RCSAME)
{
   ATL_mmcp_t *cb;
   FILE *fp;
   const int ntr = (pre == 'd' || pre == 's') ? 2 : 4;
   int ial, ibe, itr;
   const char be[3] = {'0', '1', 'n'};
   char bes[4] = {'1', 'n', 'X', '0'};
   char trs[4] = {'N', 'T', 'C', 'H'};
   char rcs[4] = {'c', 'r', 'c', 'r'};
   char cjs[4] = {' ', ' ', 'C', 'C'};


   if (!mb)
      return;
   assert(!mb->next);
   fp = OpenMMGenHeader(outd, 0, pre, NULL, 0, 0, "syrk", NULL);
   fprintf(fp, "#define SYRK_NB %d\n", mb->kbB);
   fprintf(fp, "#define ATL_SYRKK_VLEN %d\n", mb->vlen);
   fprintf(fp, "#define ATL_SYRKK_KVEC %d\n", 
           FLAG_IS_SET(mb->flag, MMF_KVEC) ? mb->vlen:0);
   fprintf(fp, "#define ATL_SYRKK_NU %d\n", mb->nu);
   fprintf(fp, "#define ATL_SYRKK_KU %d\n", mb->ku);
/*
 * Prototype ATL_<pre>_amsyrkK kernel
 */
   if (RCSAME && (pre == 'c' || pre == 'z'))
   {
      const char upr = (pre == 'z') ? 'd' : 's';
      for (ibe=0; ibe < 3; ibe++)
         fprintf(fp, "#define ATL_%camsyrkK_b%c ATL_%camsyrkK_b%c\n", 
                 pre, be[ibe], upr, be[ibe]);
   }
   for (ibe=0; ibe < 3; ibe++)
   {
      fprintf(fp, 
"void ATL_%camsyrkK_b%c(ATL_CSZT,ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,\n",
              pre, be[ibe]);
      fprintf(fp, 
      "                     TYPE*, const TYPE*, const TYPE*, const TYPE*);\n");
   }
/*
 * Prototype/rename all A cpy routs: ATL_<pre>cm2am_syrk<TA>
 */
#if 1
   cb = AddMMUniqueACopyFromMMNodes(pre, 'T', mb, NULL);
   fprintf(fp, "#define ATL_%ca2blk_syrkN %s_Na1\n", 
           pre, cb->rout);
   fprintf(fp, "#define ATL_%ca2blk_syrkT %s_Ta1\n", 
           pre, cb->rout);
   for (itr=0; itr < 2; itr++)
   {
      char tr = itr ? 'T' : 'N';
      fprintf(fp, "void ATL_%ca2blk_syrk%c", pre, tr);
      if (pre == 'd' || pre == 's')
         fprintf(fp, 
         "(ATL_CSZT,ATL_CSZT,const TYPE,const TYPE*,ATL_CSZT,TYPE*);\n");
      else
         fprintf(fp, 
         "(ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
   }
   KillAllCopyNodes(cb);
#else
   for (itr=0; itr < ntr; itr++)
   {
      fprintf(fp, "#define ATL_%ccm2am_syrk%c ATL_%c%cm2am_a1_%dx%d%c\n", 
              pre, trs[itr], pre, rcs[itr], mb->nu, 
              FLAG_IS_SET(mb->flag, MMF_KVEC)?mb->vlen:0, cjs[itr]);
      fprintf(fp, "void ATL_%ccm2am_syrk%c", pre, trs[itr]);
      if (pre == 'd' || pre == 's')
         fprintf(fp, 
         "(ATL_CSZT,ATL_CSZT,const TYPE,const TYPE*,ATL_CSZT,TYPE*);\n");
      else
         fprintf(fp, 
         "(ATL_CSZT,ATL_CSZT,const TYPE*,const TYPE*,ATL_CSZT,TYPE*,TYPE*);\n");
   }
#endif
/*
 * Prototype all C cpy routs: ATL_<pre>syblk2cmat_a<alp>_b<bet>
 */
   for (ial=0; ial < 3; ial++)
   {
      for (ibe=0; ibe < 4; ibe++)
      {
         fprintf(fp, "void ATL_%csyblk2cmat_a%c_b%c\n", pre,bes[ial],bes[ibe]);
         if (pre == 's' || pre == 'd')
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const SCALAR, TYPE *,ATL_CSZT);\n");
         else
            fprintf(fp, "   (ATL_CSZT,ATL_CSZT,const SCALAR,const TYPE*,const TYPE*,const SCALAR, TYPE *,ATL_CSZT);\n");
      }
   }
   CloseGenHeader(fp);
}

double GenPerfH(char pre, char *outd, char *cn, double mfMax,
                ATL_mmnode_t *mb, ATL_mmnode_t *k1)
{
   FILE *fp;
   ATL_mmnode_t *mp;
   #define NTHRSH 11
   int THRSH[NTHRSH] = {25, 33, 50, 66, 75, 80, 85, 90, 95, 98, 99};
   int idxT[NTHRSH];
   ATL_mmnode_t *mpT[NTHRSH];
   const int FNDMAX = (mfMax == 0.0);
   int i, n, idxMax=0;
   double fcnt;

   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "perf", mb);
/*
 * If not already set, compute the max perf & its index.  We'll use this
 * max as the denominator in our PERF array.
 */
   if (FNDMAX)
   {
      for (i=0; i < NTHRSH; i++)
         mpT[i] = NULL;
      for (n=0,mp=mb; mp; n++, mp = mp->next)
      {
         if (mp->mflop[0] > mfMax)
         {
            mfMax = mp->mflop[0];
            idxMax = n;
         }
      }
   }
/*
 * If our denom comes from other file, just count the number of entries
 */
   else
   {
      for (n=0,mp=mb; mp; n++, mp = mp->next);
      idxMax = -1;
   }
   fprintf(fp, "#define ATL_%sAMM_NCASES %d\n", cn, n);
   fprintf(fp, "#define ATL_%sAMM_DENOM %le /* (%.2f)*/ \n", cn,
           mfMax, mfMax);
   fprintf(fp, "#define ATL_%sAMM_MAXMFLOPIDX %d\n\n", cn, idxMax);
   if (FNDMAX)
   {
      for (n=0,mp=mb; mp; mp = mp->next, n++)
      {
         double mf = mp->mflop[0] / mfMax;
         for (i=0; i < NTHRSH; i++)
         {
            if (!mpT[i] && THRSH[i]*0.01*mfMax < mp->mflop[0])
            {
               mpT[i] = mp;
               idxT[i] = n;
            }
         }
      }
      for (i=0; i < NTHRSH; i++)
      {
         mp = mpT[i];
         fprintf(fp, "#define ATL_%sAMM_%dLCMU %d\n", cn, THRSH[i],
                 Mylcm(Mylcm(mp->mu,mp->nu),mp->ku));
         fprintf(fp, "#define ATL_%sAMM_%dLCMMN %d\n", cn, THRSH[i],
                 Mylcm(mp->mu,mp->nu));
         fprintf(fp, "#define ATL_%sAMM_%dMB %d\n", cn, THRSH[i], mp->mbB);
         fprintf(fp, "#define ATL_%sAMM_%dNB %d\n", cn, THRSH[i], mp->nbB);
         fprintf(fp, "#define ATL_%sAMM_%dKB %d\n", cn, THRSH[i], mp->kbB);
         fprintf(fp, "#define ATL_%sAMM_%dIDX %d\n", cn, THRSH[i], idxT[i]);
      }
      mp = ATL_FindLastNode(mb, GetOffset(&mb->next, mb));
      fprintf(fp, "#define ATL_%sAMM_LCMU %d\n", cn, 
              Mylcm(Mylcm(mp->mu,mp->nu),mp->ku));
      fprintf(fp, "#define ATL_%sAMM_LCMMN %d\n", cn, Mylcm(mp->mu,mp->nu));
      fprintf(fp, "\n");
   }

   fprintf(fp, "#if !defined(NOPERF) && !defined(NOARRS)\n");
   fprintf(fp, "static const float ATL_%sAMM_PERF[%d] =\n", cn, n);
   fprintf(fp, "{  /* %% of performance of best kernel */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
      fprintf(fp, "   %f%c  /* IDX=%d, KB=%d, mf=%.0f */\n", mp->mflop[0]/mfMax,
              (mp->next)?',':' ', i, mp->kbB, mp->mflop[0]);
   fprintf(fp, "};\n#endif\n\n");

   if (k1)
   {
      ATL_mmnode_t *kp;
      fprintf(fp, "#if !defined(NOK1RATIO) && !defined(NOARRS)\n");
      fprintf(fp, "static const float ATL_%sAMM_K1RATIO[%d] =\n", cn, n);
      fprintf(fp, "{  /* ratio of %sAMM perf wt that of its K=1 K-cleaner */\n",
              cn);
      for (i=0,mp=mb,kp=k1; mp; i++,mp = mp->next,kp = kp->next)
         fprintf(fp, "   %f%c  /* IDX=%d, KB=%d IDs=[%d,%d]*/\n", 
                 kp->mflop[0]/mp->mflop[0], (mp->next)?',':' ', i, mp->kbB,
                 mp->ID, kp->ID);
      fprintf(fp, "};\n#endif\n\n");
   }

   fprintf(fp, "#if !defined(NOTIME) && !defined(NOARRS)\n");
   fprintf(fp, "static const float ATL_%sAMM_TIME[%d] =\n", cn, n);
   fprintf(fp, "{  /* actual seconds to compute one block */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      if (mp->blask == 0)
         fcnt = (2.0*mp->mbB)*mp->nbB*mp->kbB;  /* gemm flop count */
      else
         fcnt = (1.0*mp->mbB)*mp->nbB*mp->kbB;  /* roughly right */
      fprintf(fp, "   %e%c  /* IDX=%d, B=(%d,%d,%d) */\n",
              fcnt / (mp->mflop[0]*1.0e6),
              (mp->next)?',':' ', i, mp->mbB, mp->nbB, mp->kbB);
   }
   fprintf(fp, "};\n#endif\n");
   CloseGenHeader(fp);
   return(mfMax);
}

void GenKernH
   (char pre, char *outd, char *cn, ATL_mmnode_t *mb, ATL_mmnode_t *mkb,
    ATL_mmnode_t *ub)
{
   FILE *fp;
   int ib, inxt, iaut;
   char bes[3] = {'0', '1', 'n'};

   inxt = GetOffset(&mb->next, mb);
   iaut = GetOffset(&ub->auth, ub);
   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "kern", mb);
   for (ib=0; ib < 3; ib++)
      PrintMMProtos(fp, pre, "KERN", ub, iaut, bes[ib]);
   for (ib=0; ib < 3; ib++)
   {
      PrintStrArrAtOff(fp, pre, "KERN", mb, inxt, iaut, "ammkern_t", 
                       0, 0, bes[ib]);
      if (mkb)
         PrintStrArrAtOff(fp, pre, "KERN_K1", mkb, inxt, iaut, "ammkern_t", 
                          0, 0, bes[ib]);
   }
   CloseGenHeader(fp);
}

void PrintFlagArr(FILE *fp, ATL_mmnode_t *mb)
{
   ATL_mmnode_t *mp;
   int n;

   n = CountListEntries(mb, GetOffset(&mb->next, mb));
   fprintf(fp, "#ifndef NOKFLAG\n");
   fprintf(fp, "static const unsigned char ATL_AMM_KFLAG[%d] =\n{\n", n);
   for (n=0,mp=mb; mp; n++, mp = mp->next)
   {
      unsigned char flag=FLAG_IS_SET(mp->flag, MMF_KRUNTIME) ? 1 : 0;
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         flag |= 2;
      fprintf(fp, "%6d%c   /* IDX=%d */\n", flag, mp->next ? ',':' ', n);
   }
   fprintf(fp, "};\n");
   fprintf(fp, "   #define ATL_AMM_KRUNTIME(idx_) (ATL_AMM_KFLAG[idx_] & 1)\n");
   fprintf(fp, "   #define ATL_AMM_KMAJOR(idx_) (ATL_AMM_KFLAG[idx_] & 2)\n");
   fprintf(fp, "#endif\n");
}
void GenBlkH(char pre, char *outd, char *cn, ATL_mmnode_t *mb)
{
   FILE *fp;
   ATL_mmnode_t *mp;
   int *KUs;
   int i, n, inxt;

   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "blk", mb);
   inxt = GetOffset(&mb->next, mb);
   mp = ATL_FindLastNode(mb, inxt);
   fprintf(fp, "#define ATL_%sAMM_LASTMB %d\n", cn, mp->mbB);
   fprintf(fp, "#define ATL_%sAMM_LASTNB %d\n", cn, mp->nbB);
   fprintf(fp, "#define ATL_%sAMM_LASTKB %d\n", cn, mp->kbB);
   fprintf(fp, "\n");
/*
 * Save original KUs, and overwrite compile-time-K KUs with kbB for printing
 */
   n = CountListEntries(mb, inxt);
   KUs = malloc(sizeof(int)*n*3);
   assert(KUs);
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      KUs[i] = mp->ku;
      KUs[i+n] = mp->kbmin;
      KUs[i+n+n] = mp->kbmax;
      #if 0
      if (FLAG_IS_SET(mp->flag,MMF_KUISKB))
         mp->kbmin = mp->kbmax = mp->ku = mp->kbB;
      else if (!FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
         mp->kbmin = mp->kbmax = mp->kbB;
      #endif
   }
   @multidef st VLENs KBMAXs KBMINs KUs NUs MUs KBs NBs MBs
   @whiledef iv vlen  kbmax  kbmin  ku  nu  mu  kbB nbB mbB
@skip   PrintMMIntOffArr(fp, pre, "@(st)", mb, GetOffset(&mb->@(iv), mb));
   PrintIntArrAtOff(fp, pre, "@(st)", mb, inxt, GetOffset(&mb->@(iv), mb),0,0);
      @undef st
   @endwhile
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      mp->ku = KUs[i];
      mp->kbmin = KUs[i+n];
      mp->kbmax = KUs[i+n+n];
   }
   PrintFlagArr(fp, mb);
   free(KUs);
   CloseGenHeader(fp);
}

void GenCpyA(char pre, char *outd, char *cn, char dir, char alp, 
             ATL_mmnode_t *mb)
// presently leaving alp='[1,n,X]', cn=[ge,sq,rk], dir='[F,T]' to caller
{
   FILE *fp;
   const int nt = (pre == 'd' || pre == 's') ? 2 : 4;
   int flag=0, i, j, it, im;
   char tas[4] = {'N', 'T', 'C', 'H'};
   char mats[2] = {'A', 'B'};
   char arrnm[12]={'x', 'x', '2', 'B', 'L', 'K', '_', 'a', alp, '\0'};
   char fn[12];

   if (dir == 'T')
      sprintf(fn, "cm2am_a%c", alp);
   else
      sprintf(fn, "am2cm_a%c", alp);
   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, fn, mb);
   fn[6] = 't'; fn[7] = '\0';  /* switch fn to type name */

   for (im=0; im < 2; im++)
   {
      arrnm[0] = mats[im];
      for (it=0; it < nt; it++)
      {
         ATL_mmcp_t *cb, *ucb;
         int i;
         const char ta = tas[it]; 

         arrnm[1] = ta;
         cb = GetMMCopyFromMMNodes(MMCopyEncode(pre, dir, mats[im], ta), mb);
         assert(cb);
         ucb = AddUniqueCopyNode(NULL, cb);
         arrnm[6] = '\0';
         PrintMMCpProtosA(fp, arrnm, ucb, dir, alp);
         KillAllCopyNodes(ucb);
         PrintStrArrAtOff(fp, pre, arrnm, cb, GetOffset(&cb->next, cb),
                          GetOffset(&cb->rout, cb), fn, ta, alp, 0);
         KillAllCopyNodes(cb);
      }
   }
   CloseGenHeader(fp);
}

void GenCpyC(FILE *fp, char pre, char *outd, char *cn, char dir, char *type, 
             char alp, char bet, ATL_mmnode_t *mb)
{
   char *arrnm = (dir == 'T') ? "C2BLK" : "BLK2C";
   ATL_mmcp_t *cb, *ucb;
   int flag=0, i, j;

   cb = GetMMCopyFromMMNodes(MMCopyEncode(pre, dir, 'c', 'n'), mb);
   assert(cb);
   #ifdef Debug
      i = CountListEntries(cb, GetOffset(&cb->next, cb));
      j = CountListEntries(mb, GetOffset(&mb->next, mb));
      fprintf(stderr, "ncpy=%d, nmm=%d!\n", i, j);
   #endif
   ucb = AddUniqueCopyNode(NULL, cb);
   PrintMMCpProtosC(fp, arrnm, ucb, dir, alp, bet);
   KillAllCopyNodes(ucb);
   PrintStrArrAtOff(fp, pre, arrnm, cb, GetOffset(&cb->next, cb),
                    GetOffset(&cb->rout, cb), type, 0, alp, bet);
   KillAllCopyNodes(cb);
}

void PrintDiv(FILE *fp, char *exp, int v)
/* 
 * Prints either exp/v or exp>>lg2(v), dep on v being power of 2 or not 
 * caller must put parens where appropriate (if exp is not a simple variable
 * name, it must have parens to produce the right answer!).
 */
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "%s>>%d", exp, p);
   else
      fprintf(fp, "%s/%d", exp, v);
}
void PrintCeil(FILE *fp, char *exp, int v)
/* 
 * Prints either ((exp+v-1)/v)*v or same things wt shifts if power of 2.
 */
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "((%s+%d)>>%d)", exp, v-1, p);
   else
      fprintf(fp, "((%s+%d)/%d)", exp, v-1, v);
}
void PrintCeilMul(FILE *fp, char *exp, int v)
{
   int p;
   assert(v > 0);  /* 0 cannot be supported, no need for neg now */
   if (v == 1)
      fprintf(fp, "%s", exp);
   for (p=1; (1<<p) < v; p++);
   if (v == (1<<p))
      fprintf(fp, "(((%s+%d)>>%d)<<%d)", exp, v-1, p, p);
   else
      fprintf(fp, "(((%s+%d)/%d)*%d)", exp, v-1, v, v);
}

void GenFullCpyC(char pre, char *outd, char dir, char *cn, ATL_mmnode_t *mb)
{
   ATL_mmnode_t *mp;
   FILE *fp;
   int ib, NEEDSZF=0;
   char rt[16];
   char bets[4] = {'0', '1', 'n', 'X'};

/*
 * Create atlas_<pre><cn>szC.h if necessary
 */
   for (mp=mb; mp; mp = mp->next)
      if (FLAG_IS_SET(mp->flag, MMF_KVEC) && ib == -1 &&
          (mp->mu*mp->nu) % mp->vlen != 0)
         break;
   if (mp)
   {
      ATL_mmcp_t *cb, *ucb, *cp;
      int n;
      NEEDSZF=1;
      fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "szC", mb);
      cb = GetMMCopyFromMMNodes(MMCopyEncode(pre, dir, 'c', 'n'), mb);
      assert(cb);
      ucb = AddUniqueCopyNode(NULL, cb);
      KillAllCopyNodes(cb);
/*
 *    Generate needed funcs for size query
 */
      for (cp=ucb; cp; cp = cp->next)
      {
         const unsigned int mu=cp->mu, nu=cp->nu, kvec=cp->kvec, b = mu*nu;
         const unsigned int B = (kvec > 1) ? ((b+kvec-1)/kvec)*kvec : 0;
         fprintf(fp, "#define uint unsigned int\n");
         if (b != B)
         {
            assert(!cp->ID);
            fprintf(fp, "static uint ATL_szC_%dx%d(uint M, uint N, "
                        "uint mu, uint nu, uint vlen)", mu, nu);
            fprintf(fp, "\n{\n");
            fprintf(fp, "   return(");
            PrintCeilMul(fp, "M", mu);
            fprintf(fp, "*");
            PrintCeilMul(fp, "N", nu);
            fprintf(fp, "*");
            fprintf(fp, "%d);\n", B);
            fprintf(fp, "}\n");
         }
         fprintf(fp, "typedef uint (*szC_t)(uint,uint,uint,uint,uint);\n");
         fprintf(fp, "#undef uint\n");
         for (n=0,cp=cb; cp; n++, cp = cp->next);
         fprintf(fp, "static szC_t ATL_AMM_SZCW[%d] =\n{\n", n);
         for (cp=cb,n=0; cp; cp = cp->next,n++)
         {
            const unsigned int mu=cp->mu, nu=cp->nu, kvec=cp->kvec, b = mu*nu;
            const unsigned int B = (kvec > 1) ? ((b+kvec-1)/kvec)*kvec : 0;
            fprintf(fp, "/* IDX=%d */ ", n);
            if (b != B)
               fprintf(fp, "ATL_szC_%dx%d", mu, nu);
            else
               fprintf(fp, "NULL"); 
            if (cp->next)
               fprintf(fp, ",\n");
            else
               fprintf(fp, "\n");
         }
      }
      KillAllCopyNodes(cb);
      CloseGenHeader(fp);
   }
#if 0
#endif

   if (dir == 'T')
      strcpy(rt, "cmat2ablk");
   else
      strcpy (rt, "ablk2cmat");

   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, rt, mb);
   if(NEEDSZF)
   {
      fprintf(fp, "#ifndef NOSZC\n");
      fprintf(fp, "   #include \"atlas_%c%sszC.h\"\n", pre, cn);
      fprintf(fp, "#endif\n");
   }
   rt[9] = '_'; rt[10] = 't'; rt[11] = '\0';
@skip   strcpy(rt, dir == 'T' ? "cmat2ablk_t" : "ablk2cmat_t");
   for (ib=0; ib < 4; ib++)
   {
      int ia;
      char alps[3] = {'1', 'n', 'X'};
      const char bet = bets[ib];

      for (ia=0; ia < 3; ia++)
         GenCpyC(fp, pre, outd, cn, dir, rt, alps[ia], bet, mb);
   }
   CloseGenHeader(fp);
}

void GenAllCpyC(char pre, char *outd, char dir, ATL_mmnode_t *gb, 
                ATL_mmnode_t *sb, ATL_mmnode_t *rb)
{
   if (gb)
      GenFullCpyC(pre, outd, dir, "ge", gb);
   if (sb)
      GenFullCpyC(pre, outd, dir, "sq", sb);
   if (rb)
      GenFullCpyC(pre, outd, dir, "rk", rb);
}
void GenAllCpyA(char pre, char *outd, char dir, ATL_mmnode_t *gb,
                ATL_mmnode_t *sb, ATL_mmnode_t *rb)
// presently leaving dir='[F,T]' to caller
{
   int ia;
   char alps[3] = {'1', 'n', 'X'};

   for (ia=0; ia < 3; ia++)
   {
      if (gb)
         GenCpyA(pre, outd, "ge", dir, alps[ia], gb);
      if (sb)
         GenCpyA(pre, outd, "sq", dir, alps[ia], sb);
      if (rb)
         GenCpyA(pre, outd, "rk", dir, alps[ia], rb);
   }
}

double PrintSum(FILE *fp, char *cn, ATL_mmnode_t *b, double mfGE)
{
   int inxt, max, i, kvec;
   double mf;
   ATL_mmnode_t *mp;

   inxt = GetOffset(&b->next, b);
   fprintf(fp, "#define ATL_%sAMM_NCASES %d\n", cn, CountListEntries(b, inxt));
   mp = ATL_FindLastNode(b, inxt);
   fprintf(fp, "#define ATL_%sAMM_LASTMB %d\n", cn, mp->mbB);
   fprintf(fp, "#define ATL_%sAMM_LASTNB %d\n", cn, mp->nbB);
   fprintf(fp, "#define ATL_%sAMM_LASTKB %d\n", cn, mp->kbB);
   mf = mp->mflop[0];
   fprintf(fp, "#define ATL_%sAMM_LASTMU %d\n", cn, mp->mu);
   fprintf(fp, "#define ATL_%sAMM_LASTNU %d\n", cn, mp->nu);
   fprintf(fp, "#define ATL_%sAMM_LASTKU %d\n", cn, mp->nu);
   fprintf(fp, "#define ATL_%sAMM_LASTLCMMN %d\n\n", cn, Mylcm(mp->mu, mp->nu));
   fprintf(fp, "#define ATL_%sAMM_LASTLCMU %d\n\n", cn,
           Mylcm(Mylcm(mp->mu, mp->nu),mp->ku));
   #if 0
   fprintf(fp, "#define ATL_%sAMM_LASTMFLOP %e\n", cn, mf);
   if (mfGE > 0.0)
      fprintf(fp, "#define ATL_%sAMM_MFLOP_RATIO %e\n", cn, mf/mfGE);
   #endif
   for (kvec=0,mp=b; mp; mp = mp->next)
      if (FLAG_IS_SET(mp->flag, MMF_KVEC))
         kvec = Mmax(kvec, mp->vlen);
   fprintf(fp, "#ifndef  ATL_%sAMM_MAXKVEC\n", cn);
   fprintf(fp, "   #define ATL_%sAMM_MAXKVEC %d\n", cn, kvec);
   fprintf(fp, "#endif\n");
   fprintf(fp, "\n");
   return(mf);
}

void GenSumH(char pre, char *outd, ATL_mmnode_t *gb, ATL_mmnode_t *sb, 
             ATL_mmnode_t *rb)
/*
 * cn:[ge,sq,rk]
 * For [ge,sq,rk] report: ncases, max[nb,mb,kb]
 * -> for maxB, report: perf,time,ratio wt best ge
 */
{
   FILE *fp;
   double mf;
   int i;

   fp = OpenMMGenHeader(outd, 0, pre, NULL, 0, 0, "sum", gb);
   mf = PrintSum(fp, "ge", gb, 0.0);
   if (sb)
      PrintSum(fp, "sq", sb, mf);
   if (rb)
      PrintSum(fp, "rk", rb, mf);
   CloseGenHeader(fp);
}

void GenDegenH_IP(char pre, char *outd, char *cn, ATL_mmnode_t *mb, 
                  ATL_mmnode_t *cpb)
/*
 * Used to generate timing/index file for when one or more dims are degenerate
 * for inner product.  mb should be ordered by the degen dim(s), ivar should
 * have the index of kern.h that corresponds to this kern.
 */
{
   FILE *fp;
   ATL_mmnode_t *mp;
   int i, n, idxMax=0, maxM=0, maxN=0, maxK=0;
   double fcnt, mfMax=0.0;

   fp = OpenMMGenHeader(outd, 0, pre, cn, 0, 0, "degen", mb);
/*
 * Compute max perf & M,N,K
 */
   for (n=0,mp=mb; mp; n++, mp = mp->next)
   {
      maxM = Mmax(maxM, mp->mbB);
      maxN = Mmax(maxN, mp->nbB);
      maxK = Mmax(maxK, mp->kbB);
      if (mp->mflop[0] > mfMax)
      {
         if (mp->ivar > 0)
            (mp->ivar)--;
         mfMax = mp->mflop[0];
         idxMax = n;
      }
   }
   fprintf(fp, "#ifdef NOARRS\n");
   fprintf(fp, "   #define NOPERF 1\n");
   fprintf(fp, "   #define NOTIME 1\n");
   fprintf(fp, "   #define NOKIDX 1\n");
   fprintf(fp, "   #define NONBs  1\n");
   fprintf(fp, "#endif\n");
   fprintf(fp, "#define ATL_%sAMM_NCASES %d\n", cn, n);
   fprintf(fp, "#define ATL_%sAMM_DENOM %le /* (%.2f)*/ \n", cn,
           mfMax, mfMax);
   fprintf(fp, "#define ATL_%sAMM_MAXMFLOPIDX %d\n", cn, idxMax);
   fprintf(fp, "#define ATL_%sAMM_MAXMB %d\n", cn, maxM);
   fprintf(fp, "#define ATL_%sAMM_MAXNB %d\n", cn, maxN);
   fprintf(fp, "#define ATL_%sAMM_MAXKB %d\n\n", cn, maxK);

   fprintf(fp, "#ifndef NOPERF\n");
   fprintf(fp, "static const float ATL_%sAMM_PERF[%d] =\n", cn, n);
   fprintf(fp, "{  /* %% of performance of best kernel */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
      fprintf(fp, "   %f%c  /* CNT=%d, KB=%d, mf=%.0f */\n", mp->mflop[0]/mfMax,
              (mp->next)?',':' ', i, mp->kbB, mp->mflop[0]);
   fprintf(fp, "};\n#endif\n\n");

   fprintf(fp, "#if !defined(NOTIME) && !defined(NOARRS)\n");
   fprintf(fp, "static const float ATL_%sAMM_TIME[%d] =\n", cn, n);
   fprintf(fp, "{  /* actual seconds to compute one block */\n");
   for (i=0,mp=mb; mp; i++,mp = mp->next)
   {
      if (mp->blask == 0)
         fcnt = (2.0*mp->mbB)*mp->nbB*mp->kbB;  /* gemm flop count */
      else
         fcnt = (1.0*mp->mbB)*mp->nbB*mp->kbB;  /* roughly right */
      fprintf(fp, "   %e%c  /* CNT=%d, B=(%d,%d,%d) */\n",
              fcnt / (mp->mflop[0]*1.0e6),
              (mp->next)?',':' ', i, mp->mbB, mp->nbB, mp->kbB);
   }
   fprintf(fp, "};\n#endif\n");
   if (cpb)
   {
      fprintf(fp, "#if !defined(NOCPTIMEA) && !defined(NOARRS)\n");
      fprintf(fp, "static const float ATL_%sAMM_CPTIMEA[%d] =\n", cn, n);
      fprintf(fp, "{  /* actual seconds to coy one A block row-wise */\n");
      for (i=0,mp=mb; mp; i++,mp = mp->next)
      {
         fcnt = ((double)mp->nbB)*mp->kbB;  /* copy flop count */
         if (pre == 'z' || pre == 'c')
            fcnt *= 2.0;
         fprintf(fp, "   %e%c  /* CNT=%d, B=(%d,%d,%d) */\n",
                 fcnt / (mp->mflop[0]*1.0e6),
                 (mp->next)?',':' ', i, mp->mbB, mp->nbB, mp->kbB);
      }
      fprintf(fp, "};\n#endif\n");
      if (mb->mflop[0] > 0.0)
      {
         fprintf(fp, "#if !defined(NOCPTIMEC) && !defined(NOARRS)\n");
         fprintf(fp, "static const float ATL_%sAMM_CPTIMEC[%d] =\n", cn, n);
         fprintf(fp, "{  /* actual seconds to coy one A block row-wise */\n");
         for (i=0,mp=mb; mp; i++,mp = mp->next)
         {
            fcnt = ((double)mp->mbB)*mp->nbB;  /* copy flop count */
            if (pre == 'z' || pre == 'c')
               fcnt *= 2.0;
            fprintf(fp, "   %e%c  /* CNT=%d, B=(%d,%d,%d) */\n",
                    fcnt / (mp->mflop[0]*1.0e6),
                    (mp->next)?',':' ', i, mp->mbB, mp->nbB, mp->kbB);
         }
         fprintf(fp, "};\n#endif\n");
      }
   }

   fprintf(fp, "#define ATL_AMM_NBs ATL_pmnAMM_NBs\n");
   PrintIntArrAtOff(fp, pre, "NBs", mb, GetOffset(&mb->next, mb), 
                    GetOffset(&mb->nbB, mb), 0, 0);
   fprintf(fp, "#undef ATL_AMM_NBs\n");
   fprintf(fp, "#define ATL_AMM_KBs ATL_pmnAMM_KBs\n");
   PrintIntArrAtOff(fp, pre, "KBs", mb, GetOffset(&mb->next, mb), 
                    GetOffset(&mb->kbB, mb), 0, 0);
   fprintf(fp, "#undef ATL_AMM_KBs\n");
   PrintIntArrAtOff(fp, pre, "KIDX", mb, GetOffset(&mb->next, mb), 
                    GetOffset(&mb->ivar, mb), 0, 0);
   fprintf(fp, "#ifdef NOARRS\n");
   fprintf(fp, "   #undef NOPERF\n");
   fprintf(fp, "   #undef NOTIME\n");
   fprintf(fp, "   #undef NOKIDX\n");
   fprintf(fp, "   #undef NONBs\n");
   fprintf(fp, "#endif\n");
   CloseGenHeader(fp);
}

void GenAllHeaders(char pre, char *outd, ATL_mmnode_t **lists)
{
   ATL_mmcp_t *cb;
   ATL_mmnode_t *mmb;
   char *nm="perf";
   char *cn[4]={"ge", "sq", "rk", "ts"};
   double mfMax;
   int i, k, SKSAME;
   char pr;
/*
 * Write degenerate case header files.  Kind of ugly hardwiring names here,
 * but I don't see point in taking these from command line.
 */
   pr=pre;
   DO_TYPE:
   @whiledef nm n m mn
   mmb = ReadMMFileWithPath(pr, "res", "ip@(nm)PERF.sum");
   if (mmb)
   {
      ATL_mmnode_t *cpb;
      cpb = ReadMMFileWithPath(pr, "res", "ip@(nm)PERFcp.sum");
      GenDegenH_IP(pr, outd, "p@(nm)", mmb, cpb);
      KillAllMMNodes(mmb);  /* done with these! */
   }
   @endwhile
   if (pr == pre)
   {
      pr = (pre == 'd') ? 'z' : 'c';
      goto DO_TYPE;
   }
   SKSAME = MMKernsPerfSame(lists[ISYRK], lists[ISYRK+NMMLISTS]);
/*
 * Handle [perf,blk,flag,sum] which require only ordered lists
 */
   for (pr=pre,k=0; k < 2*NMMLISTS; k += NMMLISTS)
   {
      mfMax = GenPerfH(pr, outd, "ge", 0.0, lists[k+IGE], lists[k+IGEK1]);
      if (k < NMMLISTS)  /* ts only in real for now */
         GenPerfH(pr, outd, "ts", mfMax, lists[k+ITRSM], NULL);
      KillAllMMNodes(lists[k+ITRSM]);  /* done with these! */
      lists[k+ITRSM] = NULL;
@skip      if (lists[k+ISYRKT])
@skip      {
      GenPerfH(pr, outd, "sk", mfMax, lists[k+ISYRKT], NULL);
      KillAllMMNodes(lists[k+ISYRKT]);  /* done with these! */
      lists[k+ISYRKT] = NULL;
@skip      }
      GenSyrkH(pr, outd, lists[k+ISYRK], SKSAME);

      GenPerfH(pr, outd, "sq", 0.0, lists[k+ISQ], lists[k+ISQK1]);
      GenPerfH(pr, outd, "rk", 0.0, lists[k+IRKK], NULL);

      GenBlkH(pr, outd, "ge", lists[k+IGE]); 
      GenBlkH(pr, outd, "sq", lists[k+ISQ]); 
      GenBlkH(pr, outd, "rk", lists[k+IRKK]);
      pr = (pre == 'd') ? 'z' : 'c';
   }
   GenSumH(pre, outd, lists[IGE], lists[ISQ], lists[IRKK]);
   GenSumH(pr, outd, lists[IGE+NMMLISTS], lists[ISQ+NMMLISTS], 
           lists[IRKK+NMMLISTS]);
/*
 * Create lists of only the unique kernels for [ge,sq,rk] in real & cplx
 * for use in prototyping.  We combine kern & K1 lists for each.
 * We can now gen [kern].
 */
   for (pr=pre,k=0; k < 2; k++)
   {
      for (i=0; i < 3; i++)
      {
         ATL_mmnode_t *ulst;  /* unordered list of only unique kernels */
         const int h = i+i+k*NMMLISTS, u=k*3+i;
         ulst = AddUniqueMMKernCompList(NULL, lists[h]);
         if (i < 2)
         {
            ulst = AddUniqueMMKernCompList(ulst, lists[h+1]);
            GenKernH(pr, outd, cn[i], lists[h], lists[h+1], ulst);
         }
         else
            GenKernH(pr, outd, cn[i], lists[h], NULL, ulst);
         KillAllMMNodes(ulst);  /* done with these! */
      }
      pr = (pre == 's') ? 'c' : 'z';
   }
/*
 * [cmat2ablk_a[1,n,X]_b[0,1,n,X],ablk2cmat_a?_b?,am2cm_a[1,n,X]]
 * -> have never genned, can we?: am2rm_a[1,n,X],
 */
   GenAllCpyA(pre, outd, 'T', lists[IGE], lists[ISQ], lists[IRKK]);
   GenAllCpyA(pr, outd, 'T', lists[IGE+NMMLISTS], lists[ISQ+NMMLISTS], 
              lists[IRKK+NMMLISTS]);
   GenAllCpyC(pre, outd, 'F', lists[IGE], lists[ISQ], lists[IRKK]);
   GenAllCpyC(pr, outd, 'F', lists[IGE+NMMLISTS], lists[ISQ+NMMLISTS], 
              lists[IRKK+NMMLISTS]);
}

static void AddAlpBetSuf(char *rt, int rl, int ial, int ibe)
/*
 * Add _aXbX suffix to rt, which is presently of length rl
 */
{
   rt[rl] = '_';
   rt[rl+1] = 'a';
   if (ial == -1)
      rt[rl+2] = 'n';
   else if (ial == 2)
      rt[rl+2] = 'X';
   else
      rt[rl+2] = ial+48;
   rt[rl+3] = 'b';
   if (ibe == -1)
      rt[rl+4] = 'n';
   else if (ibe > 1)
      rt[rl+4] = 'X';
   else
      rt[rl+4] = ibe+48;
}

void GenAllKerns(char pre, char *outd, ATL_mmnode_t *rb, 
                 ATL_mmcp_t *cpA, ATL_mmcp_t *cpC)
{
   ATL_mmcp_t *last, *cp;
   ATL_mmnode_t *mp;
   char *sgen;
   int i, len, dlen, mID, mU;
   char pr=pre;
/*
 * join all copy routs into one list temporarily
 */
   last = FindLastCopyNode(cpA);
   last->next = cpC;
/*
 * Get a string of max length for all system calls
 */
   mID=mU=len=i=0;
   for (cp=(!i)?cpA:cpC; cp; cp = cp->next)
   {
      len = Mmax(len, cp->rtlen);
      mID = Mmax(mID, cp->ID);
      mU = Mmax(mU, cp->mu);
      mU = Mmax(mU, cp->nu);
      mU = Mmax(mU, cp->kvec);
   }
   dlen = strlen(outd);
   len += dlen + 1;  /* outd */
   len += 17;  /* " > /dev/null 2>&1" */
   assert(mID == 0);  /* just until we support user copies */
   len += 64 - 2*4;  /* C format string */
   len += 4*NumDecDigits(mU); /* mu,nu,kvec */
   len += 2;                  /* extra for syrk */
   sgen = malloc(len+1);
   assert(sgen);
/*
 * Generate all needed copy routines
 */
   printf("\nGENERATING MMCOPY FILES\n");
   for (cp=cpA; cp; cp = cp->next)
   {
      int flag = cp->flag;
      int k;
      char pr;
      pr = MMCopyGetPre(cp->flag);
      printf("   -> %s\n", cp->rout);
      if (flag & (1<<MMCP_CBLK))
      {
         if (flag & (1<<MMCP_SYRK))
         {
            k = sprintf(sgen, 
"make genall_syblk2C pre=%c vec=NA vlen=%d mu=%d nu=%d cpvlen=1 rt=%s/%s.c",
                        pr, cp->kvec ? cp->kvec:1, cp->mu, cp->nu, outd, cp->rout);
         }
         else if (flag & (1<<MMCP_CBLK))
         {
            k = sprintf(sgen, 
      "make genall_%s pre=%c vec=NA vlen=%d mu=%d nu=%d cpvlen=1 rt=%s/%s.c",
                        (flag&(1<<MMCP_TOBLK)) ? "C2blk":"blk2C", pr, 
                        cp->kvec ? cp->kvec:1, cp->mu, cp->nu, outd, cp->rout);
         }
      }
      else /* generate A/B copy */
      {
         char *targ;
         if (flag & (1<<MMCP_REAL))
            targ = (flag & (1<<MMCP_TOBLK)) ? "A2blk":"blk2A";
         else
            targ = (flag & (1<<MMCP_TOBLK)) ? "cA2blk":"cblk2A";
         k = sprintf(sgen, 
             "make genall_%s pre=%c kmaj=%d vlen=%d UR=%d cpvlen=1 rt=%s/%s.c",
                     targ, pr, cp->kvec, cp->kvec ? cp->kvec:1, 
                     cp->nu, outd, cp->rout);
      }
      assert(k < len);
      k += sprintf(sgen+k, " > /dev/null 2>&1");
      assert(k <= len);
      if ((k=system(sgen)))
      {
         fprintf(stderr, "\n\ncpgenstr='%s' returns %d!\n\n", sgen, k);
         exit(k);
      }
   }
   printf("DONE GENERATING MMCOPY FILES\n");
   last->next = NULL;  /* disconnect A/C lists */
/*
 * Generate/copy all required kernels.  This list has files with compile-time
 * K repeated, but we'll check ID to avoid repeated copies of user-supplied, 
 * and generated kernels need a new generation for each required KB.
 */
   printf("\nGENERATING AMM KERNS:\n");
   for (mp=rb; mp; mp = mp->next)
   {
      const int id=mp->ID;
      if (!id)
      {
         printf("   -> %s\n", mp->rout);
         assert(mp->genstr);
         if ( (i=system(mp->genstr)) )
         {
            fprintf(stderr, "GENSTR RETURNS %d:\n'%s'\n", i, mp->genstr);
            exit(i);
         }
      }
      else /* user-supplied kernel */
      {
         ATL_mmnode_t *p;
         for (p=rb; p != mp && p->ID != id; p = p->next);
         if (p == mp)  /* this is first mention of this ID */
         {
            printf("   %s -> %s\n", mp->genstr, mp->rout);
            i = strlen(mp->genstr) + strlen(mp->rout) + dlen + 16;
            if (i > len)
            {
               free(sgen);
               sgen = malloc(i*sizeof(char));
               assert(sgen);
               len = i;
            }
            sprintf(sgen, "cp AMMCASES/%s %s/%s", mp->genstr, outd, mp->rout);
            
            if ( (i=system(sgen)) )
            {
               fprintf(stderr, "FAILED CP='%s'\n", sgen);
               exit(i);
            }
         }
         else /* they better have same filename! */
         {
            if (strcmp(mp->rout, p->rout))
            {
               printf("rout=(%s,%s)!\n", mp->rout, p->rout);
               exit(1);
            }
         }
      }
   }
   printf("DONE GENERATING AMM KERNS.\n");
   free(sgen);
}

void GenMake(char pre, char *outd, ATL_mmnode_t *mb,
             ATL_mmcp_t *cpA, ATL_mmcp_t *cpC)
/*
 * mb files have already been made at least compile-time unique (same source
 * file might occur multiple times due to need to compile with -DKB)
 */
{
   FILE *fp;
   char *fn;
   ATL_mmcp_t *cp;
   ATL_mmnode_t *mp;
   char *sals[3] = {"1", "N1", "X"};
   char als[3] = {'1', 'n', 'X'};
   char *sbes[4] = {"0", "1", "N1", "X"};
   char bes[4] = {'0', '1', 'n', 'X'};  /* use 1st 3 for mmkerns */
   char ctas[4] = {'N', 'T', 'C', 'H'};
   char dcomp[8] = {'$', '(', 'D', 'M', 'C', ')', '\0'};
   char dflags[12] = {'$','(','D','M','C','F','L','A','G','S',')','\0'};


   fn = malloc(strlen(outd)+11);
   assert(fn);
   sprintf(fn, "%s/%cMake_amm", outd, pre);
   fp = fopen(fn, "w");
   assert(fp);
   free(fn);
   fprintf(fp, "include ../Make.inc\n");
   fprintf(fp, "CDEFS2=$(CDEFS)\n\n");
/*
 * Spew out kernels to be compiled
 */
   fprintf(fp, "objs =");
   for (mp=mb; mp; mp = mp->next)
   {
      int ib;
      for (ib=0; ib < 3; ib++)
         fprintf(fp, " \\\n       %s_b%c.o", mp->auth, bes[ib]);
   }
   for (cp=cpC; cp; cp = cp->next)  /* C copy routs */
   {
      int ib;
      for (ib=0; ib < 4; ib++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
            fprintf(fp, " \\\n       %s_a%cb%c.o", cp->rout, als[ia], bes[ib]);
      }
   }

   for (cp=cpA; cp; cp = cp->next)  /* A/B copy routs */
   {
      const int NTA = (cp->flag & (1<<MMCP_REAL)) ? 2:4;
      int it;
      for (it=0; it < NTA; it++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
            fprintf(fp, " \\\n       %s_%ca%c.o", cp->rout, ctas[it], als[ia]);
      }
   }
   fprintf(fp, "\n");
/*
 * library make targets
 */
   fprintf(fp, "\n\nlib : %clib.grd\nall : %clib.grd\n%clib : %clib.grd\n",
           pre, pre, pre, pre);
   fprintf(fp, "%clib.grd : $(objs)\n", pre);
   fprintf(fp, "\t$(ARCHIVER) $(ARFLAGS) $(ATLASlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(ATLASlib)\n");
   fprintf(fp, "\t touch %clib.grd\n", pre);
   fprintf(fp, "clean : %cclean\n", pre);
   fprintf(fp, "%cclean:\n\t- rm -f $(objs)\n", pre);
   fprintf(fp, "killall : %ckillall\n", pre);
   fprintf(fp, "%ckillall : %cclean\n", pre, pre);
   fprintf(fp, "\t- $(ARCHIVER) d $(ATLASlib) $(objs)\n");
   fprintf(fp, "\t $(RANLIB) $(ATLASlib)\n");
   fprintf(fp, "\t- rm -f ATL_%c*.[S,c]\n\n", pre);
/*
 * Make targets for amm kerns
 */
   fprintf(fp, "#\n#  AMM kernel rules\n#\n");
   fn = (pre == 'd' || pre == 'z') ?  "-DDREAL=1" : "-DSREAL";
   for (mp=mb; mp; mp = mp->next)
   {
      int ib;
      char *comp, *flgs;

      comp = GetMMKernComp(mp, dcomp, dflags, &flgs);
      for (ib=0; ib < 3; ib++)
      {
         char *sp=" ";
         fprintf(fp, "%s_b%c.o : %s\n", mp->auth, bes[ib], mp->rout);
         fprintf(fp, "\t%s $(CDEFS2) %s -DBETA%s=1 \\\n", comp, fn, sbes[ib]);
         if (!FLAG_IS_SET(mp->flag, MMF_KRUNTIME))
            fprintf(fp, "        -DMB=%d -DNB=%d -DKB=%d", 
                    mp->mbB, mp->nbB, mp->kbB);
         else
            sp = "        ";
   @whiledef mtx C B A
         if (FLAG_IS_SET(mp->flag, MMF_MV@(mtx)))
         {
            fprintf(fp, "%s-DATL_MOVE@(mtx)", sp);
            sp = " ";
         }
   @endwhile
         fprintf(fp, " \\\n        %s \\\n", flgs);
         fprintf(fp, 
                 "        -DATL_USERMM=%s_b%c \\\n        -c -o %s_b%c.o \\\n",
                 mp->auth, bes[ib], mp->auth, bes[ib]);
         fprintf(fp, "        %s\n", mp->rout);
      }
   }
/*
 * Make targets for C copy routines
 */
   fprintf(fp, "#\n#  C copy rules\n#\n");
   dflags[3] = dcomp[3] = 'K';
   for (cp=cpC; cp; cp = cp->next)  /* C copy routs */
   {
      char *styp;
      int ib;
      char pr;

      styp = MMCopyGetCompType(cp->flag);
      for (ib=0; ib < 4; ib++)
      {
         int ia;
         for (ia=0; ia < 3; ia++)
         {
            fprintf(fp, "%s_a%cb%c.o : %s.c\n", cp->rout, als[ia], bes[ib], 
                    cp->rout);
            fprintf(fp, "\t%s %s -c $(CDEFS) -D%s=1 -DBETA%s=1 -DALPHA%s=1",
                    dcomp, dflags, styp, sbes[ib], sals[ia]);
            fprintf(fp, 
            " \\\n           -DATL_USERCPMM=%s_a%c_b%c -DATL_MU=%d -DATL_NU=%d",
                    cp->rout, als[ia], bes[ib], cp->mu, cp->nu);
            fprintf(fp, " \\\n           -o %s_a%cb%c.o %s.c\n", 
                    cp->rout, als[ia], bes[ib], cp->rout);
         }
      }
   }
/*
 * Make targets for A/B copy routines
 */
   fprintf(fp, "#\n#  A/B copy rules\n#\n");
   for (cp=cpA; cp; cp = cp->next) 
   {
      char *styp, *cnj[2] = {"", "-DConj_=1"};
      const int flag = cp->flag;
      const int NC = (flag&(1<<MMCP_REAL)) ? 1 : 2;
      int ic;
      char pr;
      styp = MMCopyGetCompType(cp->flag);
      for (ic=0; ic < NC; ic++)
      {
         int it;
         for (it=0; it < 2; it++)
         {
            int ia;
            const int itc = ic*NC+it;
            for (ia=0; ia < 3; ia++)
            {
               fprintf(fp, "%s_%ca%c.o : %s.c\n", cp->rout, ctas[itc], 
                       als[ia], cp->rout);
               fprintf(fp, "\t%s %s -c $(CDEFS) -D%s=1 -DALPHA%s=1",
                       dcomp, dflags, styp, sals[ia]);
               fprintf(fp, " \\\n           -DATL_NU=%d -DTRANS%c_=1 %s", 
                       cp->nu, ctas[it],  cnj[ic]);
               fprintf(fp, " \\\n           -DATL_USERCPMM=%s_%ca%c", cp->rout, 
                       ctas[itc], als[ia]);
               fprintf(fp, " \\\n           -o %s_%ca%c.o %s.c\n", 
                       cp->rout, ctas[itc], als[ia], cp->rout);
            }
         }
      }
   }
   fclose(fp);
}

void GenAllFiles(char pre, char *outd, ATL_mmnode_t **lists)
{
   FILE *fp;
   int i, RCSAME;
   ATL_mmnode_t *rb=NULL, *ib=NULL, *mp;
   ATL_mmcp_t *cpA=NULL, *cpC=NULL, *ncp;
   const char cpr = (pre == 'd') ? 'z' : 'c';
/*
 * First, generate performance files, which require routs separated by
 * various lists
 */
   printf("\nGENERATING HEADER FILES\n");
   GenAllHeaders(pre, outd, lists);
   printf("DONE HEADER GENERATION\n");

/*
 * Generating kernels & Makefile do not care which list kernels came from,
 * or their order, so combine them all into one list for each data type 
 * (2 lists total: real,complex), and remove any redundancies.
 * NOTE: rank-K should be distinguished by flag setting (MMF_MV[A,B,C]),
 * and so doesn't need protection in new naming system.
 * NOTE2: I think we should generate copy routs at this time and then
 *        can pass info to GenAllKerns & GenMake.
 */
   for (i=0; i < ITRSM; i++)
   {
      rb = AddUniqueMMKernCompList(rb, lists[i]);
      KillAllMMNodes(lists[i]);
      ib = AddUniqueMMKernCompList(ib, lists[NMMLISTS+i]);
      KillAllMMNodes(lists[NMMLISTS+i]);
   }
/*
 * Now create lists of copy routines for both real & complex
 */
   GetMMAllUniqueCopyFromMMNodes(pre, 'F', 'T', rb, &cpA, &cpC);
   GetMMAllUniqueCopyFromMMNodes(cpr, 'F', 'T', ib, &cpA, &cpC);
/*
 * SYRK A2blk copy rout same as GEMM, so add it to list; 
 * syblk2C not same, so add w/o checking uniqueness
 */
   cpA = AddMMUniqueACopyFromMMNodes(pre, 'T', lists[ISYRK], cpA);
   cpA = AddMMUniqueACopyFromMMNodes(cpr, 'T', lists[NMMLISTS+ISYRK], cpA);
   cpC = AddMMCKernCopyFromMMNodes(pre, 'F', MMCP_SYRK, lists[ISYRK], cpC);
   cpC = AddMMCKernCopyFromMMNodes(cpr, 'F', MMCP_SYRK, 
                                  lists[NMMLISTS+ISYRK], cpC);
/*
 * Now, kerns are compiled the same for real and complex, so reduce real
 * and complex to one unique list
 */
   rb = AddUniqueMMKernCompList(rb, ib);
   KillAllMMNodes(ib);
/*
 * SYRK never same as GEMM, so just add syrk kerns to list, but don't dup if
 * real/cplx are same kernel other than blocking
 */
   ib = lists[ISYRK];
   if (ib)
   {
      ATL_mmnode_t *p = lists[NMMLISTS+ISYRK];
      assert(p);
      if (!MMKernsPerfSame(lists[ISYRK], p))
      {
         ib->next = lists[NMMLISTS+ISYRK];
         ib->next->next = rb;
      }
      else
      {
         ib->next = rb;
         KillAllMMNodes(p);
      }
      rb = ib;
   }
   GenAllKerns(pre, outd, rb, cpA, cpC);
   GenMake(pre, outd, rb, cpA, cpC);
   KillAllMMNodes(rb);
   KillAllCopyNodes(cpA);
   KillAllCopyNodes(cpC);
}

int main(int nargs, char **args)
{
   char *outd;
   ATL_mmnode_t *lists[2*NMMLISTS];
   int i;
   char pre, cpr;

   outd = GetFlags(nargs, args, &pre, lists);
   cpr = (pre == 'd') ? 'z' : 'c';
/*
 * Prep file for generation.  Free present values, and replace with:
 * ->auth  : kernel name without _b[1,n,0] suffix
 * ->genstr: for ID=0: genstr, else user kernel name (came in ->rout)
 * ->rout  : correct present filename
 * TRSM/SYRKT entries we just set all these to NULL, since not needed.
 * TRSM/SYRKT used to [ts,sk]amm_perf.h, needs perf,NB,IDX
 */
   for (i=0; i < 2*NMMLISTS; i++)
   {
      if (i == ITRSM || i == ITRSM+NMMLISTS ||
          i == ISYRKT || i == ISYRKT+NMMLISTS)
         KillAllMMStrings(lists[i]);
      else if (i == ISYRK || i == ISYRK+NMMLISTS)
         PrepMMForGen((i==ISYRK)?pre:cpr, outd, "syrk", lists[i]);
      else
         PrepMMForGen(pre, outd, "amm", lists[i]);
   }

   GenAllFiles(pre, outd, lists);

   free(outd);
   return(0);
}
@ROUT ATL_syrk_amm
@extract -b @(topd)/cw.inc lang=C -def cwdate 2016
#define ATL_GLOBIDX 1
#include "atlas_misc.h"
#include "atlas_level1.h"
#include "atlas_level2.h"
#include Mstr(Mjoin(ATLAS_PRE,sysinfo.h))
#include Mstr(Mjoin(ATLAS_PRE,amm_sum.h))
#include Mstr(Mjoin(ATLAS_PRE,amm_syrk.h))
/*
 * Service routine, particularly for parallel.  Takes its blocking from ip
 * (assuming that is what is being used below diagonal blocks
 * flag bits, meaning if set (opposite if unset):
 * 0/1: C is upper
 * 1/2: TA == AtlasNoTrans
 * 2/4: use beta=0 syrk kernel (else use beta=1)
 *
 * If (Uplo==Upper && sy2blk) 
 *    (1) flag&1 == 1; (2) wU non-NULL; (3) sy2blk is beta=0.
 * ==> wU can be aliased wt wS if you don't need correct wS on output
 */
#ifdef Conj_
   #define syrkBlk Mjoin(PATL,herkBlk)
   #define syrk_K  Mjoin(PATL,herk_KLoop)
   #define syrk_amm  Mjoin(PATL,herk_amm)
   #define syrk_OP  Mjoin(PATL,herk_OP)
#else
   #define syrkBlk Mjoin(PATL,syrkBlk)
   #define syrk_K  Mjoin(PATL,syrk_KLoop)
   #define syrk_amm  Mjoin(PATL,syrk_amm)
   #define syrk_OP  Mjoin(PATL,syrk_OP)
#endif
void syrkBlk
(
   ipinfo_t *ip,
   int flag,      /* bitvec: 0: set means C is upper, 1: set TA==AtlasNoTrans */
   size_t d,      /* which global diagonal blk of C is being computed */
   size_t k,      /* which K block of A is being computed */
   const TYPE *A, /* if non-NULL, base A ptr to copy */
   cm2am_t sy2blk,/* copy A to syrk storage */
   ablk2cmat_t blk2c, /* if non-NULL sy storage to C storage copy func */
   const SCALAR beta, /* only needed if blk2c non-NULL */
   TYPE *C,       /* if blk2c && non-NULL, which C to write to */
   TYPE *rS,      /* real portion of wS (unused for real routines) */
   TYPE *wS,      /* space to store syrk A; */
   TYPE *wA,      /* if non-NULL, ip-based A workspace */
   TYPE *wAn,     /* next A wrkspc to be prefetched */
   TYPE *wB,      /* if non-NULL ip-based At workspace */
   TYPE *wBn,     /* next B wrkspc to be prefetched */
   TYPE *rC,      /* real portion of wC (unused for real routines) */
   TYPE *wC,      /* if non-NULL: ptr to syrk-storage C wrkspc */
   TYPE *wU       /* reflection space for Upper if non-NULL */
)
{
   ATL_CUINT kb = (k != ip->nfkblks) ? ip->kb : ip->kb0;
   ATL_UINT nb, kbS, nnu;
   size_t nfblks = ip->nfnblks;
   #ifdef TCPLX 
      TYPE *rA, *rB;
   #endif
   if (d == nfblks + ip->npnblks - 1)
   {
      nb = ip->nF;
      #ifdef TCPLX
         if (d < nfblks)
         {
            rA = wA + ip->szA;
            rB = wB + ip->szB;
         }
         else
         {
            rA = wA + ip->pszA;
            rB = wB + ip->pszB;
         }
      #endif
   }
   else if (d < nfblks)
   {
      nb = ip->nb;
      #ifdef TCPLX
         rA = wA + ip->szA;
         rB = wB + ip->szB;
      #endif
   }
   else
   {
      nb = ip->pnb;
      #ifdef TCPLX
         rA = wA + ip->pszA;
         rB = wB + ip->pszB;
      #endif
   }
   nnu = (nb+ATL_SYRKK_NU-1)/ATL_SYRKK_NU;
   kbS = ((kb+ATL_SYRKK_KU-1)/ATL_SYRKK_KU)*ATL_SYRKK_KU;
   if (A)  /* want to copy input array */
   {
      A = IdxA_ip(ip, A, d, k);
      if (wA)  /* want to copy A to gemm storage too! */
      {
         #ifdef TCPLX
            ip->a2blk(kb, nb, ip->alpA, A, ip->lda, rA, wA);
         #else
            ip->a2blk(kb, nb, ip->alpA, A, ip->lda, wA);
         #endif
         if (ip->a2blk == sy2blk)
         {
            wS = wA;
            #ifdef TCPLX
               rS = rA;
            #endif
         }
      }
      if (wB)  /* want to copy At to gemm storage too! */
      {
         #ifdef TCPLX
            ip->b2blk(kb, nb, ip->alpB, A, ip->ldb, rB, wB);
         #else
            ip->b2blk(kb, nb, ip->alpB, A, ip->ldb, wB);
         #endif
         if (ip->b2blk == sy2blk)
         {
            wS = wB;
            #ifdef TCPLX
               rS = rB;
            #endif
         }
      }
      if (wS != wA && wS != wB)
      {
         #ifdef TCPLX
            sy2blk(kb, nb, ip->ONE, A, ip->lda, rS, wS);
         #else
            sy2blk(kb, nb, ATL_rone, A, ip->lda, wS);
         #endif
      }
   }
   if (wC && wS)  /* want to compute SYRK on this block into wC */
   {
      #ifdef TCPLX
         #ifdef Conj_
            TYPE *crA=(flag&2)?rS:wS, *ciA=(flag&2)?wS:rS;
            if (flag&4)
            {
               Mjoin(PATL,amsyrkK_b0)(nnu, nnu, kbS, wS, wS, rC, crA, ciA, wC);
               Mjoin(PATL,amsyrkK_b0)(nnu, nnu, kbS, crA, ciA, wC, rS, rS, rC);
            }
            else
            {
               Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kbS, wS, wS, rC, crA, ciA, wC);
               Mjoin(PATL,amsyrkK_bn)(nnu, nnu, kbS, crA, ciA, wC, rS, rS, rC);
            }
            Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kbS, rS, rS, rC, ciA, crA, wC);
            Mjoin(PATL,amsyrkK_bn)(nnu, nnu, kbS, ciA, crA, wC, wS, wS, rC);
         #else
            if (flag&4)
            {
               Mjoin(PATL,amsyrkK_b0)(nnu, nnu, kbS, wS, wS, rC, rS, wS, wC);
               Mjoin(PATL,amsyrkK_b0)(nnu, nnu, kbS, rS, wS, wC, rS, rS, rC);
            }
            else
            {
               Mjoin(PATL,amsyrkK_bn)(nnu, nnu, kbS, wS, wS, rC, rS, wS, wC);
               Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kbS, rS, wS, wC, rS, rS, rC);
            }
            Mjoin(PATL,amsyrkK_bn)(nnu, nnu, kbS, rS, rS, rC, wS, rS, wC);
            Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kbS, wS, rS, wC, wS, wS, rC);
         #endif
      #else
         if (flag&4)
            Mjoin(PATL,amsyrkK_b0)(nnu, nnu, kbS, wS, wS, wC, wS, wS, wC);
         else
            Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kbS, wS, wS, wC, wS, wS, wC);
      #endif
   }
   if (C)
      C = IdxC_ip(ip, C, d, d);
   if (blk2c)
   {
      const size_t ldc=ip->ldc;
      #ifdef TCPLX
         const TYPE *alp = ip->alpC;
      #else
         TYPE alp = ip->alpC;
      #endif
      if (ip->alpA != ip->alpB)
         alp = (ip->alpA != ip->alpC) ? ip->alpA : ip->alpB;
      if (flag&1)  /* Upper matrix */
      {
         #ifdef TCPLX
            const TYPE zero[2] = {ATL_rzero, ATL_rzero};
            blk2c(nb, nb, alp, rC, wC, zero, wU, nb);
         #else
            blk2c(nb, nb, alp, wC, ATL_rzero, wU, nb);
         #endif
      }
      else if (C)
      {
         #ifdef TCPLX
            blk2c(nb, nb, alp, rC, wC, beta, C, ldc);
            #ifdef Conj_  /* must zero complex part of diagonal! */
               Mjoin(PATLU,zero)(nb, C+1, (ldc+1)SHIFT);
            #endif
         #else
            blk2c(nb, nb, alp, wC, beta, C, ldc);
         #endif
      }
   }
   if ((flag&1) && C && wU)  /* need to reflect from Lower to Upper */
   {
      size_t ldc2=(ip->ldc)SHIFT;
      #ifdef Conj_
         for (k=0; k < nb; k++, C += ldc2, wU += 2)
         {
            Mjoin(PATL,axpbyConj)(k+1, ip->ONE, wU, nb, beta, C, 1);
            C[((k+1)<<1)-1] = ATL_rzero;
         }
      #else
         if (SCALAR_IS_ZERO(beta))
            for (k=0; k < nb; k++, wU += (1 SHIFT), C += ldc2)
               Mjoin(PATL,copy)(k+1, wU, nb, C, 1);
         else
            for (k=0; k < nb; k++, wU += (1 SHIFT), C += ldc2)
            #ifdef TCPLX
               Mjoin(PATL,axpby)(k+1, ip->ONE, wU, nb, beta, C, 1);
            #else
               Mjoin(PATL,axpby)(k+1, ATL_rone, wU, nb, beta, C, 1);
            #endif
      #endif
   }
}

/*
 * This helper function computes one block of C by looping over the K dim.
 * flag bits, meaning if set (opposite if unset):
 * 0/1: C is upper
 * 1/2: TA == AtlasNoTrans
 */
void syrk_K  /* inner-product based syrk/herk loop over K loop */
(
   ipinfo_t *ip,
   int flag,      /* bitvec: 0: set means C is upper, 1: set TA==AtlasNoTrans */
   size_t d,      /* which global diagonal blk of C is being computed */
   const TYPE *A, /* if non-NULL, base A ptr to copy */
   cm2am_t sy2blk,/* copy A to syrk storage */
   ablk2cmat_t blk2c, /* if non-NULL sy storage to C storage copy func */
   const SCALAR beta, /* only needed if blk2c non-NULL */
   TYPE *C,       /* if blk2c non-NULL, which C to write to, else ignored */
   TYPE *rS,      /* real portion of wS (unused in real routines) */
   TYPE *wS,      /* space to store syrk A; */
   TYPE *wA,      /* if non-NULL, ip-based A workspace */
   TYPE *wB,      /* if non-NULL ip-based At workspace */
   TYPE *rC,      /* real portion of wC (unused in real routines) */
   TYPE *wC,      /* if non-NULL: ptr to syrk-storage C wrkspc */
   TYPE *wU       /* NBxNB wrkspc needed for Upper C storage & blk2c != NULL */
)
{
   const size_t nfkblks = ip->nfkblks;
   size_t k;
   ATL_UINT szA, szB;
   if (d < ip->nfnblks)
      szA = szB = ip->szA;
   else
   {
      szA = ip->pszA;
      szB = ip->pszB;
   }
   #ifdef TCPLX
      szA += szA;
      szB += szB;
   #endif
/*
 * For first K block, use beta=0 kernel to init wC
 */
   if (nfkblks)
   {
      TYPE *wAn=(wA)? wA+szA:NULL, *wBn=(wB) ? wB+szB : NULL;
      syrkBlk(ip, flag|4, d, 0, A, sy2blk, NULL, beta, NULL, rS, wS, 
              wA, wAn, wB, wBn, rC, wC, wU);
      wA = wAn;
      wB = wBn;
   }
   else /* this is first & last block! */
   {
      syrkBlk(ip, flag|4, d, 0, A, sy2blk, blk2c, beta, C, rS, wS, 
              wA, wA, wB, wB, rC, wC, wU);
      return;
   }
/*
 * Handle all blocks except first (handled above) & last (handled below)
 */
   for (k=1; k < nfkblks; k++)
   {
      TYPE *wAn=(wA)? wA+szA:NULL, *wBn=(wB) ? wB+szB : NULL;
      syrkBlk(ip, flag, d, k, A, sy2blk, NULL, beta, NULL, rS, wS, 
              wA, wAn, wB, wBn, rC, wC, wU);
      wA = wAn;
      wB = wBn;
   }
/*
 * Last block actually writes to C
 */
   syrkBlk(ip, flag, d, k, A, sy2blk, blk2c, beta, C, rS, wS, 
           wA, wA, wB, wB, rC, wC, wU);
}

int syrk_amm
(
   const enum ATLAS_UPLO  Uplo,
   const enum ATLAS_TRANS TA,
   ATL_CSZT  N,
   ATL_CSZT K,
   #ifdef Conj_
   const TYPE ralpha,
   #else
   const SCALAR alpha,
   #endif
   const TYPE *A,
   ATL_CSZT lda,
   #ifdef Conj_
   const TYPE rbeta,
   #else
   const SCALAR beta,
   #endif
   TYPE *C,
   ATL_CSZT ldc
)
{
   size_t sz, szA, szB, szC, szS, nnblks, extra;
   void *vp;
   TYPE *wA, *wB, *wC, *wS, *wCs, *rC, *rCs, *rS;
   int nb, nbS, flg, idx;
   #ifdef Conj_
      TYPE alpha[2]={ralpha, ATL_rzero}, beta[2]={rbeta, ATL_rzero};
      const enum ATLAS_TRANS TB=(TA==AtlasNoTrans)?AtlasConjTrans:AtlasNoTrans;
   #else
      const enum ATLAS_TRANS TB = (TA==AtlasNoTrans) ? AtlasTrans:AtlasNoTrans;
   #endif
   ipinfo_t ip;
   cm2am_t sy2blk;
   ablk2cmat_t blk2sy, blk2c;

/*
 * Need a special case for outer-product eventually.  Outer product is
 * used in right-looking Cholesky
 */
   if (K <= ATL_sqAMM_LASTKB)
   #ifdef Conj_
      return(syrk_OP(Uplo, TA, N, K, ralpha, A, lda, rbeta, C, ldc));
   #else
      return(syrk_OP(Uplo, TA, N, K, alpha, A, lda, beta, C, ldc));
   #endif
/*
 * Inner-product version calls nothing by SYRK kernels
 */
   if (N < ATL_sqAMM_LASTNB)
   {
      #ifdef Conj_
         Mjoin(PATL,herk_IP)(Uplo, TA, N, K, ralpha, A, lda, rbeta, C, ldc);
      #else
         Mjoin(PATL,syrk_IP)(Uplo, TA, N, K, alpha, A, lda, beta, C, ldc);
      #endif
      return(0);
   }
/*
 * Will eventually need syrk timed for all square blocks to select best case.
 * For now, just pretend syrk time doesn't matter
 */
#if 1
   idx = Mjoin(PATL,GetSyrkIdx)((Uplo == AtlasUpper), N, K, 1.33);
#else
   idx = 0;
#endif
   Mjoin(PATL,sqComputeIPInfo)(&ip, idx, TA, TB, N, N, K, lda, lda, ldc, 
                               alpha, beta);
/*
 * Need space for only one column-panel of At
 */
   szB = ip.nfnblks ? ip.szA : ip.pszA;
   szB *= (ip.nfkblks+1);
/*
 * A needs entire matrix minus one row/col panel
 */
   szA = szB * (ip.nfnblks + ip.npnblks - 1);
   nb = (ip.nfnblks) ? ip.nb : ip.pnb;
   nbS = (nb+ATL_SYRKK_NU-1)/ATL_SYRKK_NU;
   szC = ((nbS+1)*nbS)>>1;  /* only need lower tri blks, not full nnu*nnu */
   nbS *= ATL_SYRKK_NU;
   szC *= ((ATL_SYRKK_NU*ATL_SYRKK_NU+ATL_SYRKK_VLEN-1)/ATL_SYRKK_VLEN)
          * ATL_SYRKK_VLEN;
   extra = (ip.mu<<1)*ip.nu;
   extra = Mmax(extra, (ATL_SYRKK_NU+ATL_SYRKK_NU)*ATL_SYRKK_NU);
   if (Uplo == AtlasUpper)
      extra = Mmax(extra, ip.szC);
   szS = nbS * ip.kb;
   sz = Mmax(ip.szC,szC);
   sz = ATL_MulBySize(sz + szS + szA+szB + extra) + 5*ATL_Cachelen;
   if (sz < ATL_MaxMalloc)
      vp = malloc(sz);
   if (!vp)
      return(1);  /* keep recurring, can't malloc space! */
   wA = ATL_AlignPtr(vp);
   wB = wA + (szA SHIFT);
   wB = ATL_AlignPtr(wB);
   wS = wB + (szB SHIFT);
   wS = ATL_AlignPtr(wS);
   wC = wS + (szS SHIFT);
   wC = ATL_AlignPtr(wC);
   if (!szA)
      wA = NULL;
   if (Uplo == AtlasLower)
      wCs = wC;
   else
   {
      wCs = wC + (szC SHIFT);
      wCs = ATL_AlignPtr(wCs);
   }
   #ifdef TCPLX
      rC = wC + ip.szC;
      rCs = wC + szC;
      rS = wS + szS;
   #else
      rCs = rC = wC;
      rS = wS;
   #endif
/*
 * ============================================================================
 * First, we compute diagonals of C, and in the process we will copy A/A^T
 * for use in computing non-diaginal blocks using inner-product amm.
 * ============================================================================
 */
   sy2blk = IS_COLMAJ(TA) ? Mjoin(PATL,a2blk_syrkT) : Mjoin(PATL,a2blk_syrkN);
      
   if (Uplo == AtlasLower)
   {
      if (SCALAR_IS_ONE(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2sy = Mjoin(PATL,syblk2cmat_an_b1);
         else
            blk2sy = SCALAR_IS_ONE(alpha) ?
                     Mjoin(PATL,syblk2cmat_a1_b1):Mjoin(PATL,syblk2cmat_aX_b1);
      }
      else if (SCALAR_IS_NONE(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2sy = Mjoin(PATL,syblk2cmat_an_bn);
         else
            blk2sy = SCALAR_IS_ONE(alpha) ?
                     Mjoin(PATL,syblk2cmat_a1_bn):Mjoin(PATL,syblk2cmat_aX_bn);
      }
      else if (SCALAR_IS_ZERO(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2sy = Mjoin(PATL,syblk2cmat_an_b0);
         else
            blk2sy = SCALAR_IS_ONE(alpha) ?
                     Mjoin(PATL,syblk2cmat_a1_b0):Mjoin(PATL,syblk2cmat_aX_b0);
      }
      else
      {
         if (SCALAR_IS_NONE(alpha))
            blk2sy = Mjoin(PATL,syblk2cmat_an_bX);
         else
            blk2sy = SCALAR_IS_ONE(alpha) ?
                     Mjoin(PATL,syblk2cmat_a1_bX):Mjoin(PATL,syblk2cmat_aX_bX);
      }
   }
   else
   {
      if (SCALAR_IS_NONE(alpha))
         blk2sy = Mjoin(PATL,syblk2cmat_an_b0);
      else
         blk2sy = SCALAR_IS_ONE(alpha) ?
                  Mjoin(PATL,syblk2cmat_a1_b0):Mjoin(PATL,syblk2cmat_aX_b0);
   }
   nnblks = ip.nfnblks + ip.npnblks;
   flg = (TA == AtlasNoTrans) ? 2 : 0;
/*
 * Upper doesn't need to copy first row panel of A or last col panel of At
 * to GEMM storage.  If C only block, should call syrk_IP instead!
 */
   if (Uplo == AtlasUpper)
   {
      flg |= 1;
      syrk_K(&ip, flg, 0, A, sy2blk, blk2sy, beta, C, rS, wS, wB, NULL, 
             rCs, wC, wCs);
      if (N > nb)
      {
         const size_t incC = nb*((ldc+1)SHIFT);
         size_t i;
/*
 *       Compute all C blks within this rowpan of C, copy rest of At
 */
         blk2c = ip.blk2c;
         Mjoin(PATL,iploopsNK)(&ip, 0, 1, NULL, A, C, 11, wB, wA, rC, wC,
                               beta, blk2c);
/*
 *       Loop over all col-pans of C, excepting first & last;
 *       A already fully copied, B will be copied by syrk_Kloop call.
 */
         for (i=1; i < nnblks-1; i++)
         {
            syrk_K(&ip, flg, i, A, sy2blk, blk2sy, beta, C, rS, wS, wB, NULL, 
                   rCs, wC, wCs);
            wA += szB SHIFT;
            Mjoin(PATL,iploopsNK)(&ip, i, i+1, NULL, NULL, C+i*(nb SHIFT), 11, 
                                  wB, wA, rC, wC, beta, blk2c);
         }
/*
 *       Last colpan is only 1 diag blk, so don't copy A or B for gemm
 */
         syrk_K(&ip, flg, i, A, sy2blk, blk2sy, beta, C, rS, wS, NULL, NULL, 
                rCs, wC, wCs);
      }
   }
/*
 * Lower doesn't need to copy first row panel of A or last col panel of At
 * to GEMM storage.  If C only block, should call syrk_IP instead!
 */
   else
   {
      const size_t incC = (ldc SHIFT) * nb;
      size_t j;
      TYPE *c;
/*
 *    Compute first diag block, copying At to wB for use by all of this colpan
 *    of C's gemm computation
 */
      syrk_K(&ip, flg, 0, A, sy2blk, blk2sy, beta, C, rS, wS, NULL, wB, 
             rCs, wC, wCs);
      if (N > nb)
      {
/*
 *       Compute all C blks within this colpan of C, copying rest of A
 */
         blk2c = ip.blk2c;
         Mjoin(PATL,iploopsMK)(&ip, 1, 0, A, NULL, C, 7, wA, wB, rC, wC, 
                               beta, blk2c);
/* 
 *       Loop over all col-pans of C, excepting first & last;
 *       A already fully copied, B will be copied by syrk_Kloop call.
 */
         c = C + incC;
         for (j=1; j < nnblks-1; j++)
         {
            syrk_K(&ip, flg, j, A, sy2blk, blk2sy, beta, C, rS, wS,
                   NULL, wB, rCs, wC, wCs);
            wA += szB SHIFT;
            Mjoin(PATL,iploopsMK)(&ip, j+1, j, NULL, NULL, c, 7, wA, wB, rC, wC,
                                  beta, blk2c);
            c += incC;
         }
/*
 *       Last colpan is only 1 diag blk, so don't copy A or B for gemm
 */
         syrk_K(&ip, flg, j, A, sy2blk, blk2sy, beta, C, rS, wS, 
                NULL, NULL, rCs, wC, wCs);
      }
   }
   free(vp);
   return(0);
}
@ROUT ATL_syrk_OP
@extract -b @(topd)/cw.inc lang=C -def cwdate 2016
#include "atlas_misc.h"
#include "atlas_level1.h"
#include "atlas_level2.h"
#include Mstr(Mjoin(ATLAS_PRE,sysinfo.h))
#include Mstr(Mjoin(ATLAS_PRE,amm_sum.h))
#include Mstr(Mjoin(ATLAS_PRE,amm_syrk.h))
#ifdef Conj_
   #define syrkBlk Mjoin(PATL,herkBlk_OP)
   #define syrk_OP Mjoin(PATL,herk_OP)
#else
   #define syrkBlk Mjoin(PATL,syrkBlk_OP)
   #define syrk_OP Mjoin(PATL,syrk_OP)
#endif

/*
 * Indexes both A and C from base ptrs according to d (diagonal blk)
 */
void syrkBlk
(
   rkinfo_t *op,
   int flag,      /* bitvec: 0: set means C is upper, 1: set TA==AtlasNoTrans */
   size_t d,      /* which global diagonal blk of C is being computed */
   const TYPE *A, /* if non-NULL, base A ptr to copy */
   cm2am_t sy2blk,/* copy A to syrk storage */
   ablk2cmat_t blk2c, /* if non-NULL sy storage to C storage copy func */
   TYPE *C,       /* if blk2c non-NULL, which C to write to, else ignored */
   TYPE *rS,      /* real ptr (unused for real types) */
   TYPE *wS,      /* space to store syrk A; */
   TYPE *wA,      /* if non-NULL, op-based A workspace */
   TYPE *wAn,     /* next A wrkspc to be prefetched */
   TYPE *wB,      /* if non-NULL op-based At workspace */
   TYPE *wBn,     /* next B wrkspc to be prefetched */
   TYPE *rC,      /* real ptr (unused for real routs) */
   TYPE *wC,      /* if non-NULL: ptr to syrk-storage C wrkspc */
   TYPE *wU       /* NBxNB wrkspc needed for Upper C storage & blk2c != NULL */
)
{
   ATL_CSZT lda = op->lda, nfblks = op->nfnblks;
   ATL_CUINT KB = op->KB, kb = op->kb;
   ATL_UINT nb, kbS, nnu;
   #ifdef TCPLX
      ATL_UINT szC, szA;
      TYPE *rA, *rB;
   #endif
   const SCALAR beta=op->beta;
   if (d == nfblks + op->npnblks - 1)  /* last block is SYRK only */
   {
      nb = op->nF;
      nb = (nb) ? nb : op->nb;
      #ifdef TCPLX
         if (d < nfblks)
         {
            rA = wA + op->szA;
            rB = wB + op->szB;
         }
         else
         {
            rA = wA + op->pszA;
            rB = wB + op->pszB;
         }
      #endif
   }
   else if (d < nfblks)
   {
      nb = op->nb;
      #ifdef TCPLX
         rA = wA + op->szA;
         rB = wB + op->szB;
      #endif
   }
   else
   {
      nb = op->pnb;
      #ifdef TCPLX
         rA = wA + op->pszA;
         rB = wB + op->pszB;
      #endif
   }
   nnu = (nb+ATL_SYRKK_NU-1)/ATL_SYRKK_NU;
   kbS = ((kb+ATL_SYRKK_KU-1)/ATL_SYRKK_KU)*ATL_SYRKK_KU;
   if (A)  /* want to copy input array */
   {
/*
 *    Move A ptr to d'th block
 */
      if (d)
      {
         size_t n = Mmin(d, nfblks);
         A += n*op->incAm;
         n = d - n;  /* # of partial blocks remaining in d */
         A += n*op->pincAm;
      }
      if (wA)  /* want to copy A to gemm storage too! */
      {
         #ifdef TCPLX
            op->a2blk(kb, nb, op->alpA, A, lda, rA, wA);
         #else
            op->a2blk(kb, nb, op->alpA, A, lda, wA);
         #endif
         if (op->a2blk == sy2blk)
         {
            wS = wA;
            #ifdef TCPLX
               rS = rA;
            #endif
         }
      }
      if (wB)  /* want to copy At to gemm storage too! */
      {
         #ifdef TCPLX
            op->b2blk(kb, nb, op->alpB, A, lda, rB, wB);
         #else
            op->b2blk(kb, nb, op->alpB, A, lda, wB);
         #endif
         if (op->b2blk == sy2blk)
         {
            wS = wB;
            #ifdef TCPLX
               rS = rB;
            #endif
         }
      }
      if (wS != wA && wS != wB)
      {
         #ifdef TCPLX
            sy2blk(kb, nb, op->ONE, A, lda, rS, wS);
         #else
            sy2blk(kb, nb, ATL_rone, A, lda, wS);
         #endif
      }
   }
   if (wC)  /* want to compute SYRK on this block into wC */
   {
      #ifdef TCPLX
         #ifdef Conj_
            TYPE *crA=(flag&2)?rS:wS, *ciA=(flag&2)?wS:rS;
            Mjoin(PATL,amsyrkK_b0)(nnu, nnu, kbS, wS, wS, rC, crA, ciA, wC);
            Mjoin(PATL,amsyrkK_b0)(nnu, nnu, kbS, crA, ciA, wC, rS, rS, rC);
            Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kbS, rS, rS, rC, ciA, crA, wC);
            Mjoin(PATL,amsyrkK_bn)(nnu, nnu, kbS, ciA, crA, wC, wS, wS, rC);
         #else
            Mjoin(PATL,amsyrkK_b0)(nnu, nnu, kbS, wS, wS, rC, rS, wS, wC);
            Mjoin(PATL,amsyrkK_b0)(nnu, nnu, kbS, rS, wS, wC, rS, rS, rC);
            Mjoin(PATL,amsyrkK_bn)(nnu, nnu, kbS, rS, rS, rC, wS, rS, wC);
            Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kbS, wS, rS, wC, wS, wS, rC);
         #endif
      #else
         Mjoin(PATL,amsyrkK_b0)(nnu, nnu, kbS, wS, wS, wC, wS, wS, wC);
      #endif
   }
   if (blk2c)
   {
      const size_t ldc=op->ldc;
      int k;
      #ifdef TCPLX
         const TYPE *alp = (op->alpA == op->ONE) ? op->alpB : op->alpA;
      #else
         TYPE alp = (op->alpA == ATL_rone) ? op->alpB : op->alpA;
      #endif
      C += d*op->nb*((ldc+1)SHIFT);
      if (flag&1)  /* Upper matrix */
      {
         #ifdef TCPLX
            const TYPE zero[2] = {ATL_rzero, ATL_rzero};
            blk2c(nb, nb, alp, rC, wC, zero, wU, nb);
            #ifdef Conj_  /* must zero imag part of diagonal for HERK */
            {
               ATL_CINT ldc2=ldc+ldc;
               for (k=0; k < nb; k++, C += ldc2, wU += 2)
               {
                  Mjoin(PATL,axpbyConj)(k+1, op->ONE, wU, nb, beta, C, 1);
                  C[((k+1)<<1)-1] = ATL_rzero;
               }
            }
            #endif
         #else
            blk2c(nb, nb, alp, wC, ATL_rzero, wU, nb);
         #endif
/*
 *       Copy matrix back to original C while applying beta
 */
         #ifndef Conj_
         if (SCALAR_IS_ZERO(beta))
            for (k=0; k < nb; k++, wU += (1 SHIFT), C += (ldc SHIFT))
               Mjoin(PATL,copy)(k+1, wU, nb, C, 1);
         else
            for (k=0; k < nb; k++, wU += (1 SHIFT), C += (ldc SHIFT))
            #ifdef TCPLX
               Mjoin(PATL,axpby)(k+1, op->ONE, wU, nb, beta, C, 1);
            #else
               Mjoin(PATL,axpby)(k+1, ATL_rone, wU, nb, beta, C, 1);
            #endif
         #endif
      }
      else
      {
         #ifdef TCPLX
            blk2c(nb, nb, alp, rC, wC, beta, C, ldc);
            #ifdef Conj_  /* must zero complex part of diagonal! */
               Mjoin(PATLU,zero)(nb, C+1, (ldc+1)SHIFT);
            #endif
         #else
            blk2c(nb, nb, alp, wC, beta, C, ldc);
         #endif
      }
   }
}

int syrk_OP
(
   const enum ATLAS_UPLO  Uplo,
   const enum ATLAS_TRANS TA,
   ATL_CSZT  N,
   ATL_CSZT K,
   #ifdef Conj_
   const TYPE ralpha,
   #else
   const SCALAR alpha,
   #endif
   const TYPE *A,
   ATL_CSZT lda,
   #ifdef Conj_
   const TYPE rbeta,
   #else
   const SCALAR beta,
   #endif
   TYPE *C,
   ATL_CSZT ldc
)
{
   size_t sz, szA, szC, szU, szS, nnblks, szAblk;
   void *vp;
   TYPE *wA, *wB, *wC, *wS, *wU, *rC, *rCs, *rS;
   int nb, nbS, flg, idx, extra;
   #ifdef Conj_
      TYPE alpha[2]={ralpha, ATL_rzero}, beta[2]={rbeta, ATL_rzero};
      const enum ATLAS_TRANS TB=(TA==AtlasNoTrans)?AtlasConjTrans:AtlasNoTrans;
   #else
      const enum ATLAS_TRANS TB = (TA==AtlasNoTrans) ? AtlasTrans:AtlasNoTrans;
   #endif
   rkinfo_t op;
   cm2am_t sy2blk;
   ablk2cmat_t blk2sy, blk2c;

   Mjoin(PATL,GetSyrkOP)(&op, 1, TA, TB, N, K, lda, ldc, alpha, beta);
   nnblks = op.nfnblks + op.npnblks;
   sy2blk = IS_COLMAJ(TA) ? Mjoin(PATL,a2blk_syrkT) : Mjoin(PATL,a2blk_syrkN);
      
   if (Uplo == AtlasLower)
   {
      szU = 0;
      if (SCALAR_IS_ONE(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2sy = Mjoin(PATL,syblk2cmat_an_b1);
         else
            blk2sy = SCALAR_IS_ONE(alpha) ?
                     Mjoin(PATL,syblk2cmat_a1_b1):Mjoin(PATL,syblk2cmat_aX_b1);
      }
      else if (SCALAR_IS_NONE(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2sy = Mjoin(PATL,syblk2cmat_an_bn);
         else
            blk2sy = SCALAR_IS_ONE(alpha) ?
                     Mjoin(PATL,syblk2cmat_a1_bn):Mjoin(PATL,syblk2cmat_aX_bn);
      }
      else if (SCALAR_IS_ZERO(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2sy = Mjoin(PATL,syblk2cmat_an_b0);
         else
            blk2sy = SCALAR_IS_ONE(alpha) ?
                     Mjoin(PATL,syblk2cmat_a1_b0):Mjoin(PATL,syblk2cmat_aX_b0);
      }
      else
      {
         if (SCALAR_IS_NONE(alpha))
            blk2sy = Mjoin(PATL,syblk2cmat_an_bX);
         else
            blk2sy = SCALAR_IS_ONE(alpha) ?
                     Mjoin(PATL,syblk2cmat_a1_bX):Mjoin(PATL,syblk2cmat_aX_bX);
      }
   }
   else
   {
      szU = N*N;
      if (SCALAR_IS_NONE(alpha))
         blk2sy = Mjoin(PATL,syblk2cmat_an_b0);
      else
         blk2sy = SCALAR_IS_ONE(alpha) ?
                  Mjoin(PATL,syblk2cmat_a1_b0):Mjoin(PATL,syblk2cmat_aX_b0);
   }
   extra = (ATL_SYRKK_NU+ATL_SYRKK_NU)*ATL_SYRKK_NU;
   flg = (TA == AtlasNoTrans) ? 2 : 0;
   if (TA == AtlasUpper)
   {
      flg |= 1;
      extra -= Mmin(extra, szU);
   }
   if (nnblks == 1)  /* we've got a 1 block of SYRK only! */
   {
      nbS = (N+ATL_SYRKK_NU-1)/ATL_SYRKK_NU;
      szC = ((nbS+1)*nbS)>>1;  /* only need lower tri blks, not full nnu*nnu */
      nbS *= ATL_SYRKK_NU;
      szC *= ((ATL_SYRKK_NU*ATL_SYRKK_NU+ATL_SYRKK_VLEN-1)/ATL_SYRKK_VLEN)
             * ATL_SYRKK_VLEN;
      #if ATL_SYRKK_KVEC > 1
         szS = ((K+ATL_SYRKK_KVEC-1)/ATL_SYRKK_KVEC)*ATL_SYRKK_KVEC;
         szS *= nbS;
      #else
         szS = nbS * K;
      #endif
      szU = Mmax(op.szC, szU);
      sz = ATL_MulBySize(szU + szC + szS + extra) + 3*ATL_Cachelen;
      vp = malloc(sz);
      if (!vp)
         return(1);
      wS = ATL_AlignPtr(vp);
      wC = wS + (szS SHIFT);
      wC = ATL_AlignPtr(wC);
      wU = wC + (szC SHIFT);
      wU = ATL_AlignPtr(wU);
      #ifdef TCPLX
         rC = wC + szC;
         rS = wS + szS;
      #else
         rC = wC;
         rS = wS;
      #endif
      flg |= (Uplo == AtlasUpper) ? 1 : 0;
      syrkBlk(&op, flg, 0, A, sy2blk, blk2sy, C, rS, wS, 
              NULL, NULL, NULL, NULL, rC, wC, wU);
      free(vp);
      return(0);
   }
/*
 * If we reach here, we have at rank-K SYRK update requiring both SYRK & GEMM
 * Since nnblks > 1, nfnblks > 1 as well.
 */
   nbS = (op.nb+ATL_SYRKK_NU-1)/ATL_SYRKK_NU;
   szC = ((nbS+1)*nbS)>>1;  /* only need lower tri blks, not full nnu*nnu */
   nbS *= ATL_SYRKK_NU;
   szC *= ((ATL_SYRKK_NU*ATL_SYRKK_NU+ATL_SYRKK_VLEN-1)/ATL_SYRKK_VLEN)
          * ATL_SYRKK_VLEN;
   #if ATL_SYRKK_KVEC > 1
      szS = ((K+ATL_SYRKK_KVEC-1)/ATL_SYRKK_KVEC)*ATL_SYRKK_KVEC;
      szS *= nbS;
   #else
      szS = nbS * K;
   #endif
   szU = Mmax(op.szC, szU);
   szAblk = op.szA;
   szA = szAblk * (nnblks-1);
   sz = ATL_MulBySize(szA+szAblk + szS + szC + szU + extra) + 5*ATL_Cachelen;
   vp = malloc(sz);
   if (!vp)
      return(1);
   wA = ATL_AlignPtr(vp);
   wB = wA + (szA SHIFT);
   wB = ATL_AlignPtr(wB);
   wS = wB + (szAblk SHIFT);
   wS = ATL_AlignPtr(wS);
   wC = wS + (szS SHIFT);
   wC = ATL_AlignPtr(wC);
   wU = wC + (szC SHIFT);
   wU = ATL_AlignPtr(wU);
   #ifdef TCPLX
      rC = wC + op.szC;
      rCs = wC + szC;
      rS = wS + szS;
   #else
      rC = wC;
      rCs = wC;
      rS = wS + szS;
   #endif
   if (Uplo == AtlasLower)
   {
      size_t j;
/*
 *    Do first diagonal block, don't copy A blk to GEMM storage since it is
 *    used only for this diagonal (SYRK)
 */
      syrkBlk(&op, flg, 0, A, sy2blk, blk2sy, C, rS, wS, NULL, NULL, wB, wB, 
              rCs, wC, wU);
/*
 *    Do rank-K update on ge blks beneath diag, copying entire A at same time
 */
      Mjoin(PATL,oploopsM)(&op, 1, 0, A, NULL, C, 1, wA, wB, rC, wC);
/*
 *    For remaining column panels of C, syrkBlk copies B, reusues wA
 */
      for (j=1; j < nnblks-1; j++)
      {
         syrkBlk(&op, flg, j, A, sy2blk, blk2sy, C, rS, wS, NULL, NULL, wB, wB, 
                 rCs, wC, wU);
         wA += (szAblk SHIFT);
         Mjoin(PATL,oploopsM)(&op, j+1, j, NULL, NULL, C, 1, wA, wB, rC, wC);
      }
/*
 *    Last col panel is only one diagonal
 */
      syrkBlk(&op, flg, j, A, sy2blk, blk2sy, C, rS, wS, NULL, NULL, NULL, NULL,
              rCs, wC, wU);
   }
   else
   {
      size_t i;
/*
 *    Do first diagonal block, don't copy A^T blk to GEMM storage since it is
 *    used only for this diagonal (SYRK)
 */
      flg |= 1;
      syrkBlk(&op, flg, 0, A, sy2blk, blk2sy, C, rS, wS, wB, wB, NULL, NULL, 
              rCs, wC, wU);
/*
 *    Do rank-K update on ge blks beneath diag, copying entire A^T at same time
 */
      Mjoin(PATL,oploopsN)(&op, 0, 1, NULL, A, C, 2, wB, wA, rC, wC);
/*
 *    For remaining column panels of C, syrkBlk copies A, reuses A^T
 */
      for (i=1; i < nnblks-1; i++)
      {
         syrkBlk(&op, flg, i, A, sy2blk, blk2sy, C, rS, wS, wB, wB, NULL, NULL,
                 rCs, wC, wU);
         wA += (szAblk SHIFT);
         Mjoin(PATL,oploopsN)(&op, i, i+1, NULL, NULL, C, 2, wB, wA, rC, wC);
      }
/*
 *    Last col panel is only one diagonal
 */
      syrkBlk(&op, flg, i, A, sy2blk, blk2sy, C, rS, wS, NULL, NULL, NULL, NULL,
              rCs, wC, wU);
   }
   free(vp);
   return(0);
}
@ROUT ATL_syrk_IP
@extract -b @(topd)/cw.inc lang=C -def cwdate 2015 
#define ATL_GLOBIDX 1
#include "atlas_misc.h"
#include "atlas_level1.h"
#include "atlas_level2.h"
#include Mstr(Mjoin(ATLAS_PRE,sysinfo.h))
#include Mstr(Mjoin(ATLAS_PRE,amm_sum.h))
#include Mstr(Mjoin(ATLAS_PRE,amm_syrk.h))

static INLINE void ATL_syr1
(
   const enum ATLAS_UPLO Uplo,
   const enum ATLAS_TRANS TA,
   ATL_CSZT N,
#ifdef Conj_
   const TYPE ralpha,
#else
   const SCALAR alpha,
#endif
   const TYPE *A,
   ATL_CSZT lda,
#ifdef Conj_
   const TYPE rbeta,
#else
   const SCALAR beta,
#endif
   TYPE *C,
   ATL_CSZT ldc
)
{
/*
 * First, see if we can simply call the Level-2 BLAS
 */
   #ifdef Conj_
      TYPE *c=C+1;
   #endif
   #ifndef TCPLX
      if (beta == 1.0)
      {
         Mjoin(PATL,syr)(Uplo, N, alpha, A, TA==AtlasNoTrans?1:lda, C, ldc);
         return;
      }
   #endif
   {
      size_t k;
      TYPE *X=(TYPE*)A;
      void *vp=NULL;
      #ifdef Conj_
         const TYPE beta[2] = {rbeta, ATL_rzero};
      #endif
/*
 *    Copy A if it's a row so it is contiguous for all N axpby calls
 */
      #ifdef Conj_
      if (TA == AtlasConjTrans)
      #else
      if (TA == AtlasTrans || TA == AtlasConjTrans)
      #endif
      {
         vp = malloc(ATL_MulBySize(N)+ATL_Cachelen);
         ATL_assert(vp);
         X = ATL_AlignPtr(vp);
         #ifdef Conj_
            Mjoin(PATL,copyConj)(N, A, lda, X, 1);
         #else
            Mjoin(PATL,copy)(N, A, lda, X, 1);
         #endif
      }
      #ifdef Conj_
         if (rbeta == 1.0)
         {
            Mjoin(PATL,her)(Uplo, N, ralpha, X, 1, C, ldc);
            if (vp)
               free(vp);
            return;
         }
      #endif  /* NO syr for complex, so cplx SYR has to use axpy-based code */
      #ifdef TCPLX
         if (Uplo == AtlasUpper)
         {
            size_t ldc2 = ldc+ldc;
            #ifndef Conj_
               const register TYPE ra=(*alpha), ia=alpha[1];
            #endif
            for (k=0; k < N; k++, C += ldc2)
            {
               size_t k2=k+k;
               #ifndef Conj_
                  const register TYPE rx=X[k2], ix=X[k2+1];
               #endif
               TYPE scal[2];
               #ifdef Conj_
                  scal[0] = ralpha*X[k2];
                  scal[1] = -ralpha*X[k2+1];
               #else
                  scal[0] = ra*rx - ia*ix;
                  scal[1] = ra*ix + ia*rx;
               #endif
               Mjoin(PATL,axpby)(k+1, scal, X, 1, beta, C, 1);
            }
         }
         else   /* Uplo == AtlasLower */
         {
            size_t ldcp1 = (ldc+1)SHIFT;
            #ifndef Conj_
               const register TYPE ra=(*alpha), ia=alpha[1];
            #endif
            for (k=0; k < N; k++, C += ldcp1, X += 2)
            {
               #ifndef Conj_
                  const register TYPE rx=*X, ix=X[1];
               #endif
               TYPE scal[2];
               #ifdef Conj_
                  scal[0] = ralpha* *X;
                  scal[1] = ralpha * (-X[1]);
               #else
                  scal[0] = ra*rx - ia*ix;
                  scal[1] = ra*ix + ia*rx;
               #endif
               Mjoin(PATL,axpby)(N-k, scal, X, 1, beta, C, 1);
            }
         }
      #else  /* real with beta != 1.0 */
         if (Uplo == AtlasUpper)
         {
            for (k=0; k < N; k++, C += ldc)
               Mjoin(PATL,axpby)(k+1, X[k]*alpha,  X, 1, beta, C, 1);
         }
         else   /* Uplo == AtlasLower */
         {
            for (k=0; k < N; k++, C += (ldc+1), X++)
               Mjoin(PATL,axpby)(N-k, (*X)*alpha,  X, 1, beta, C, 1);
         }
      #endif
      if (vp)
         free(vp);
      @beginskip
         {
            size_t n=N;
            TYPE zero[2] = {ATL_rzero, ATL_rzero;
            else
               vp = NULL;
            if (Uplo == Upper)
            {
               if (SCALAR_IS_ONE(alpha))
               {
                  for (k=0; k < N; k++, B += incB, C += ldc2)
                     Mjoin(PATL,axpby)(M, X+k+k,  X, 1, beta, C, 1);
               }
               else if (SCALAR_IS_NONE(alpha))
               {
                  for (k=0; k < N; k++, B += incB, C += ldc2)
                  {
                     const TYPE scal[2] = {-X[k+k], -X[k+k+1]};
                     Mjoin(PATL,axpby)(M, scal,  X, 1, beta, C, 1);
                  }
               }
               else  /* alpha should be multiplied */
               {
                  const register TYPE ralp=*alpha, ialp=alpha[1];
                  for (k=0; k < N; k++, B += incB, C += ldc2)
                  {
                     TYPE scal[2];
                     const register TYPE rx=X[k+k], ix=X[k+k+1];
                     scal[0] = rx*ralp - ix*ialp;
                     scal[1] = rx*ialp + ix*ralp;
                     Mjoin(PATL,axpby)(M, scal,  X, 1, beta, C, 1);
                  }
               }
            }
            else  /* Uplo == Lower */
            {
            }
         }
         @endskip
   }
   #ifdef Conj_  /* must zero complex part of diagonal for HERK! */
      Mjoin(PATLU,zero)(N, c, (ldc+1)SHIFT);
   #endif
}

#ifdef Conj_
void Mjoin(PATL,herk_IP)
#else
void Mjoin(PATL,syrk_IP)
#endif
(
   const enum ATLAS_UPLO Uplo,
   const enum ATLAS_TRANS TA,
   ATL_CSZT N,
   ATL_CSZT K,
#ifdef Conj_
   const TYPE ralpha,
#else
   const SCALAR alpha,
#endif
   const TYPE *A,
   ATL_CSZT lda,
#ifdef Conj_
   const TYPE rbeta,
#else
   const SCALAR beta,
#endif
   TYPE *C,
   ATL_CSZT ldc
)
/* 
 * C NxN, A NxK
 * SYRK:
 *    C = alpha * A * A^T + beta*C, if TA == AtlasNoTrans
 *    C = alpha * A^T * A + beta*C, if TA == AtlasTrans
 * HERK:
 *    C = alpha * A * A^H + beta*C, if TA == AtlasNoTrans
 *    C = alpha * A^H * A + beta*C, if TA == AtlasTrans
 */
{
   cm2am_t a2blk;
   ablk2cmat_t blk2c;
   void *vp;
   #ifdef TCPLX
      TYPE *rA, *iA, *rC, *iC, *c;
      TYPE one[2] = {ATL_rone, ATL_rzero};
      #ifdef Conj_
         TYPE *crA, *ciA;
         const TYPE alpha[2] = {ralpha, ATL_rzero};
         const TYPE beta[2] = {rbeta, ATL_rzero};
      #endif
   #else
      TYPE *pA, *pC, *c;
      #define one ATL_rone
   #endif
   size_t szA, szC, szE, incAk, nkb, k;
   ATL_CUINT nnu = (N+ATL_SYRKK_NU-1)/ATL_SYRKK_NU, NN=nnu*ATL_SYRKK_NU;
   ATL_UINT kb, kb0, KB0;
/*
 * Handle degenerate cases
 */
   if (!N)                            /* no output! */
      return;
   if (SCALAR_IS_ZERO(alpha) || !K)  /* really scale of C */
   {
      if (SCALAR_IS_ONE(beta))       /* no-op */
         return;
      if (SCALAR_IS_ZERO(beta))      /* explicit zero */
      {
         if (Uplo == AtlasLower)
            Mjoin(PATL,trsetL)(N, N, beta, beta, C, ldc);
         else
            Mjoin(PATL,trsetU)(N, N, beta, beta, C, ldc);
         return;
      }
      Mjoin(PATL,trscal)(Uplo, N, N, beta, C, ldc);
      #ifdef Conj_  /* must zero complex part of diagonal for HERK! */
         Mjoin(PATLU,zero)(N, C+1, (ldc+1)SHIFT);
      #endif
      return;
   }
   if (K == 1)  /* Level-2/1 BLAS */
   {
      #ifdef Conj_
         ATL_syr1(Uplo, TA, N, ralpha, A, lda, rbeta, C, ldc);
      #else
         ATL_syr1(Uplo, TA, N, alpha, A, lda, beta, C, ldc);
      #endif
      return;
   }
   if (N == 1)  /* dot product */
   {
      const size_t incA = (TA==AtlasNoTrans) ? lda : 1;
      #ifdef TCPLX
         TYPE dot[2];
         #ifdef Conj_
            Mjoin(PATL,dotc_sub)(K, A, incA, A, incA, dot);
            *dot   *= ralpha;
            if (rbeta != ATL_rzero)
               *dot   += rbeta * *C;
            *C = *dot;
            C[1] = ATL_rzero;
         #else
            const register TYPE ra=(*alpha), ia=alpha[1];
            register TYPE rd, id, rr;
            Mjoin(PATL,dotu_sub)(K, A, incA, A, incA, dot);
            rr = rd = dot[0];
            id = dot[1];
            rd = rr*ra - id*ia;
            id = rr*ia + id*ra;
            if (!SCALAR_IS_ZERO(beta))
            {
               const register TYPE rb=(*beta), ib=beta[1];
               const register TYPE rc=(*C), ic=C[1];
               rd += rb*rc - ib*ic;
               id += rb*ic + ib*rc;
            }
            C[0] = rd;
            C[1] = id;
         #endif
      #else
         TYPE dot;
         dot = Mjoin(PATL,dot)(K, A, incA, A, incA);
         dot *= alpha;
         if (beta != ATL_rzero)
            dot += beta * *C;
         *C = dot;
      #endif
      return;
   }
/*
 * Choose a KB that is a multiple of KU.  Usually, we like near-square sizes,
 * but for small problems, you want to expand KB to avoid having vector
 * reduction (KVEC) and C store dominate cost.  There's some advantage to
 * containing one or more operands in the L1: on some systems, this results
 * in better max perf, but on all systems it helps to reduce bandwidth demands
 * for parallel operations.  So, don't expand kb beyond L1 if a square problem
 * could fit (since longer than NB KB has only marginal benefit, that might
 * prevent a more substantial in-L1 benefit).  If problem is really tiny,
 * may make sense to contain both C & A in the cache.  We ignore the case
 * where, C/A and the col-major A all fit, as that is super-tiny 
 */
   szC = ((ATL_SYRKK_NU*ATL_SYRKK_NU+ATL_SYRKK_VLEN-1)/ATL_SYRKK_VLEN)
         * ATL_SYRKK_VLEN;
   szC *= ((nnu+1)*nnu)>>1;  /* only need lower tri blks, not full nnu*nnu */
   if (szC < ATL_L1elts)  /* If we can't fit C in L1, no square block can */
   {
      szE = ATL_L1elts - szC;  /* szE = elts in L1 after C stored there */
      kb = (szE>>1) / NN;      /* fit A, Ac & C all in L1 */
      if (kb < N)
         kb = ATL_L1elts / N;  /* fill L1 with just A */
      kb = (kb/ATL_SYRKK_KU)*ATL_SYRKK_KU;
      if (kb < N)              /* if we can't make at least square */
         kb = (ATL_sqAMM_LASTKB/ATL_SYRKK_KU)*ATL_SYRKK_KU;
   }
   else  /* just use kb that worked for out-of-L1 best GEMM case */
      kb = (ATL_sqAMM_LASTKB/ATL_SYRKK_KU)*ATL_SYRKK_KU;
   ATL_assert(kb);
/*
 * Our SYRK C copy is always to Lower, so if output is Upper, will need
 * workspace to put the Lower part, before reflecting it to Upper.
 * Need max of this extra space, or preload distance.
 */
   szE = (Uplo == AtlasLower) ? 0 : N*N;
   szE = Mmax(szE, ATL_SYRKK_NU*ATL_SYRKK_NU*2);
   if (IS_COLMAJ(TA))
   {
      incAk = lda*(kb SHIFT);
      a2blk = Mjoin(PATL,a2blk_syrkT);
   }
   else
   {
      incAk = kb SHIFT;
      a2blk = Mjoin(PATL,a2blk_syrkN);
   }
   if (K > kb)
   {
      nkb = K / kb;
      kb0 = K - nkb*kb;
      if (!kb0)
      {
         kb0 = kb;
         nkb--;
      }
   }
   else
   {
      nkb = 0;
      kb0 = K;
   }
   #if ATL_SYRKK_KVEC > 1
      KB0 = ((kb0+ATL_SYRKK_KVEC-1)/ATL_SYRKK_KVEC)*ATL_SYRKK_KVEC;
   #else
      KB0 = kb0;
   #endif
   szA = nnu*ATL_SYRKK_NU;
   k = (Uplo == AtlasUpper) ? Mmax(kb,N) : kb;
   szA *= k;
   szA = nnu*ATL_SYRKK_NU * kb;
   vp = malloc(ATL_MulBySize(szA + szC + szE) 
               + 2*ATL_Cachelen);
   ATL_assert(vp);
   #ifdef TCPLX
      iA = ATL_AlignPtr(vp);
      rA = iA + szA;
      iC = rA + szA;
      iC = ATL_AlignPtr(iC);
      rC = iC + szC;
      #ifdef Conj_
         crA = (TA == AtlasNoTrans) ? rA : iA;
         ciA = (TA == AtlasNoTrans) ? iA : rA;
      #endif
      c = rC + szC;
   #else
      pA = ATL_AlignPtr(vp);
      pC = pA + (szA SHIFT);
      pC = ATL_AlignPtr(pC);
      c = pC + szC;
   #endif
#if 0
   ipinfo_t ip;
   int i, flg;
   i = Mjoin(PATL,geGetAmmmIndx)(N, N, K);
   Mjoin(PATL,geComputeIPInfo)(&ip, i, TA, TA, N, N, K, lda, lda, ldc, 
         alpha, beta);
   flg = (Uplo == AtlasLower) ? 0 : 1;
   if (TA == AtlasNoTrans)
      flg |= 2;
   if (Uplo == AtlasLower)
   {
      if (SCALAR_IS_ONE(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2c = Mjoin(PATL,syblk2cmat_an_b1);
         else
            blk2c = SCALAR_IS_ONE(alpha) ?
                    Mjoin(PATL,syblk2cmat_a1_b1):Mjoin(PATL,syblk2cmat_aX_b1);
      }
      else if (SCALAR_IS_NONE(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2c = Mjoin(PATL,syblk2cmat_an_bn);
         else
            blk2c = SCALAR_IS_ONE(alpha) ?
                    Mjoin(PATL,syblk2cmat_a1_bn):Mjoin(PATL,syblk2cmat_aX_bn);
      }
      else if (SCALAR_IS_ZERO(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2c = Mjoin(PATL,syblk2cmat_an_b0);
         else
            blk2c = SCALAR_IS_ONE(alpha) ?
                    Mjoin(PATL,syblk2cmat_a1_b0):Mjoin(PATL,syblk2cmat_aX_b0);
      }
      else
      {
         if (SCALAR_IS_NONE(alpha))
            blk2c = Mjoin(PATL,syblk2cmat_an_bX);
         else
            blk2c = SCALAR_IS_ONE(alpha) ?
                    Mjoin(PATL,syblk2cmat_a1_bX):Mjoin(PATL,syblk2cmat_aX_bX);
      }
   }
   else
   {
      if (SCALAR_IS_NONE(alpha))
         blk2c = Mjoin(PATL,syblk2cmat_an_b0);
      else
         blk2c = SCALAR_IS_ONE(alpha) ?
                 Mjoin(PATL,syblk2cmat_a1_b0):Mjoin(PATL,syblk2cmat_aX_b0);
   }
   Mjoin(PATL,syrkBlk)(&ip, flg|4, 0, 0, A, a2blk, K<=ip.kb?blk2c:NULL, beta, C,
                       pA, NULL, NULL, NULL, NULL, pC, pA);
//   A += (kb0 SHIFT) * (IS_COLMAJ(TA) ? lda : 1);
   nkb = K / ip.kb;
   if (nkb * ip.kb == K)
      nkb--;
   for (k=0; k < nkb; k++)
      Mjoin(PATL,syrkBlk)(&ip, flg, 0, k+1, A, a2blk, k == nkb-1 ? blk2c:NULL, 
                          beta, C, pA, NULL, NULL, NULL, NULL, pC, pA);
#else

   #ifdef TCPLX
      a2blk(kb0, N, one, A, lda, rA, iA);
      #ifdef Conj_
         Mjoin(PATL,amsyrkK_b0)(nnu, nnu, KB0, iA, iA, rC, crA, ciA, iC);
         Mjoin(PATL,amsyrkK_b0)(nnu, nnu, KB0, crA, ciA, iC, rA, rA, rC);
         Mjoin(PATL,amsyrkK_b1)(nnu, nnu, KB0, rA, rA, rC, ciA, crA, iC);
         Mjoin(PATL,amsyrkK_bn)(nnu, nnu, KB0, ciA, crA, iC, iA, iA, rC);
      #else
         Mjoin(PATL,amsyrkK_b0)(nnu, nnu, KB0, iA, iA, rC, rA, iA, iC);
         Mjoin(PATL,amsyrkK_b0)(nnu, nnu, KB0, rA, iA, iC, rA, rA, rC);
         Mjoin(PATL,amsyrkK_bn)(nnu, nnu, KB0, rA, rA, rC, iA, rA, iC);
         Mjoin(PATL,amsyrkK_b1)(nnu, nnu, KB0, iA, rA, iC, iA, iA, rC);
      #endif
   #else
      a2blk(kb0, N, ATL_rone, A, lda, pA);
      Mjoin(PATL,amsyrkK_b0)(nnu, nnu, KB0, pA, pA, pC, pA, pA, pC);
   #endif
   A += (kb0 SHIFT) * (IS_COLMAJ(TA) ? lda : 1);
   for (k=0; k < nkb; k++, A += incAk)
   {
      #ifdef TCPLX
         a2blk(kb, N, one, A, lda, rA, iA);
         #ifdef Conj_
            Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kb, iA, iA, rC, crA, ciA, iC);
            Mjoin(PATL,amsyrkK_bn)(nnu, nnu, kb, crA, ciA, iC, rA, rA, rC);
            Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kb, rA, rA, rC, ciA, crA, iC);
            Mjoin(PATL,amsyrkK_bn)(nnu, nnu, kb, ciA, crA, iC, iA, iA, rC);
         #else
            Mjoin(PATL,amsyrkK_bn)(nnu, nnu, kb, iA, iA, rC, rA, iA, iC);
            Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kb, rA, iA, iC, rA, rA, rC);
            Mjoin(PATL,amsyrkK_bn)(nnu, nnu, kb, rA, rA, rC, iA, rA, iC);
            Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kb, iA, rA, iC, iA, iA, rC);
         #endif
      #else
         a2blk(kb, N, ATL_rone, A, lda, pA);
         Mjoin(PATL,amsyrkK_b1)(nnu, nnu, kb, pA, pA, pC, pA, pA, pC);
      #endif
   }
   if (Uplo == AtlasLower)
   {
      if (SCALAR_IS_ONE(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2c = Mjoin(PATL,syblk2cmat_an_b1);
         else
            blk2c = SCALAR_IS_ONE(alpha) ? 
                    Mjoin(PATL,syblk2cmat_a1_b1):Mjoin(PATL,syblk2cmat_aX_b1);
      }
      else if (SCALAR_IS_NONE(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2c = Mjoin(PATL,syblk2cmat_an_bn);
         else
            blk2c = SCALAR_IS_ONE(alpha) ? 
                    Mjoin(PATL,syblk2cmat_a1_bn):Mjoin(PATL,syblk2cmat_aX_bn);
      }
      else if (SCALAR_IS_ZERO(beta))
      {
         if (SCALAR_IS_NONE(alpha))
            blk2c = Mjoin(PATL,syblk2cmat_an_b0);
         else
            blk2c = SCALAR_IS_ONE(alpha) ? 
                    Mjoin(PATL,syblk2cmat_a1_b0):Mjoin(PATL,syblk2cmat_aX_b0);
      }
      else
      {
         if (SCALAR_IS_NONE(alpha))
            blk2c = Mjoin(PATL,syblk2cmat_an_bX);
         else
            blk2c = SCALAR_IS_ONE(alpha) ? 
                    Mjoin(PATL,syblk2cmat_a1_bX):Mjoin(PATL,syblk2cmat_aX_bX);
      }
      #ifdef TCPLX
         blk2c(N, N, alpha, rC, iC, beta, C, ldc);
         #ifdef Conj_  /* must zero complex part of diagonal! */
            Mjoin(PATLU,zero)(N, C+1, (ldc+1)SHIFT);
         #endif
      #else
         blk2c(N, N, alpha, pC, beta, C, ldc);
      #endif
   }
   else /* Upper must use workspace */
   {
      if (SCALAR_IS_NONE(alpha))
         blk2c = Mjoin(PATL,syblk2cmat_an_b0);
      else
         blk2c = SCALAR_IS_ONE(alpha) ? 
                 Mjoin(PATL,syblk2cmat_a1_b0):Mjoin(PATL,syblk2cmat_aX_b0);
      #ifdef TCPLX
         blk2c(N, N, alpha, rC, iC, beta, c, N);
         #ifdef Conj_  /* must zero imag part of diagonal for HERK */
         {
            ATL_CINT ldc2=ldc+ldc;
            for (k=0; k < N; k++, c += 2, C += ldc2)
            {
               Mjoin(PATL,axpbyConj)(k+1, one, c, N, beta, C, 1);
               C[((k+1)<<1)-1] = ATL_rzero;
            }
         }
         #endif
      #else
         blk2c(N, N, alpha, pC, beta, c, N);
      #endif
      #ifndef Conj_
      if (SCALAR_IS_ZERO(beta))
         for (k=0; k < N; k++, c += (1 SHIFT), C += (ldc SHIFT))
            Mjoin(PATL,copy)(k+1, c, N, C, 1);
      else
         for (k=0; k < N; k++, c += (1 SHIFT), C += (ldc SHIFT))
            Mjoin(PATL,axpby)(k+1, one, c, N, beta, C, 1);
      #endif
   }
#endif
   free(vp);
}
#undef one
@ROUT uammsrch
#include "atlas_misc.h"
#include "atlas_mmtesttime.h"
#define CON_NOKVEC 0
#define CON_NOMVEC 1
#define CON_NOCOMPK 2


void PrintUsage(char *name, int ierr, char *flag)
{
   if (ierr > 0)
      fprintf(stderr, "Bad argument #%d: '%s'\n", ierr,
              flag?flag:"OUT-OF_ARGUMENTS");
   else if (ierr < 0)
      fprintf(stderr, "ERROR: %s\n", flag);
   fprintf(stderr, "USAGE: %s [flags]:\n", name);
   fprintf(stderr, "   -T #  : set pruning tolerance for slower kernels:\n");
   fprintf(stderr,
   "      # <= 0.0 : keep all legal kernel sizes regardless of performance\n");
   fprintf(stderr,
   "      # >=0.0 : delete all kerns wt perf*# < maxSmallerPerf\n");
   fprintf(stderr,
   "                maxSmallerPerf= max perf found in smaller-sized kern\n");
   fprintf(stderr, "   -p [s,d]: set precision prefix (d) \n");
   fprintf(stderr, "   -b # nb1 ... nb# : square NBs to force\n");
   fprintf(stderr, "   -B # mb1 nb1 kb1 ... mb# nb# kb#: dims to force\n");
   fprintf(stderr, "   -S B0 Bn Binc : do series [B0,Bn] wt Binc stride\n");
   fprintf(stderr, "   -N maxB : try all blks up to & including maxB\n");
   fprintf(stderr, 
      "   -F # a/b/c1 ... a/b/c#: which matblks should be cache flushed\n");
   fprintf(stderr, "   -v <verb> : set verbosity (1)\n");
   fprintf(stderr, "   -C [kmc] : Constrain kernel choice:\n");
   fprintf(stderr, "      k : don't allow K-vectorized storage\n");
   fprintf(stderr, "      m : don't allow M-vectorized storage\n");
   fprintf(stderr, "      c : don't allow compile-time K kernels\n");
   fprintf(stderr, "   -K <1/0> : do/don't generate K cleanup\n");
   fprintf(stderr, "   -o <outfile> : [res/<pre>UAMMRES.sum]\n");

   exit(ierr ? ierr : -1);
}

char *GetFlags(int nargs, char **args, char *PRE, int *C, int *MVS,
               int *NN, int **MBS, int **NBS, int **KBS, float *TOL,
               int *KCLEAN)
{
   ATL_mmnode_t *mmb=NULL;
   int B0=0, BN, KI;
   int *mbs=NULL, *nbs=NULL, *kbs=NULL;
   int i, k, j, N=0, ALL=0, MV=3, b0, bn, incB;
   char *cs, *fout=NULL;
   static char fnam[32];

   *TOL = 0.0;
   *PRE = 'd';
   *C = 0;
   *KCLEAN = 1;
   for (i=1; i < nargs; i++)
   {
      int n;
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);

      switch(args[i][1])
      {
      case 'o':
         if (++i >= nargs)
             PrintUsage(args[0], i-1, NULL);
         fout = args[i];
         break;
      case 'p':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *PRE = tolower(args[i][0]);
         assert(*PRE == 's' || *PRE == 'd' || *PRE == 'z' || *PRE == 'c');
         break;
      case 'T':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *TOL = atof(args[i]);
         if (*TOL < 0.0)
            *TOL = 0.0;
         break;
      case 'F':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         n = atoi(args[i]);
         for (MV=k=0; k < n; k++)
         {
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
            if (args[i][0] == 'a' || args[i][0] == 'A')
               MV |= 1;
            else if (args[i][0] == 'b' || args[i][0] == 'B')
               MV |= 2;
            else if (args[i][0] == 'c' || args[i][0] == 'C')
               MV |= 4;
            else
               PrintUsage(args[0], -i, "UNKNOWN MATRIX FOR -M");
         }
         break;
      case 'K':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *KCLEAN = atoi(args[i]);
         break;
@beginskip
      case 'v':
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *VERB = atoi(args[i]);
         break;
@endskip
      case 'C':  /* -C <constraint string */
        if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         cs = args[i];
         n = strlen(cs);
         for (k=0; k < n; k++)
         {
            switch(cs[k])
            {
            case 'm':
               *C |= 1<<CON_NOMVEC;
               break;
            case 'k':
               *C |= 1<<CON_NOKVEC;
               break;
            case 'c':
               *C |= 1<<CON_NOCOMPK;
               break;
            default:
               PrintUsage(args[0], -i, "UNKNOWN CONSTRAINT");
            }
         }
         break;
      case 'N': /* <maxNB> */
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         else
         {
            int b0, bn, incB, n, k;
            bn = atoi(args[i]);
            b0 = 4;
            incB = 1;
            n = 1 + (bn-b0)/incB;
            mbs = malloc(n*sizeof(int));
            nbs = malloc(n*sizeof(int));
            kbs = malloc(n*sizeof(int));
            assert(mbs && nbs && kbs);
            for (k=0,n=b0; n <= bn; k++, n += incB)
               mbs[k] = nbs[k] = kbs[k] = n;
            assert(k <= n);
            *NN = k;
         }
         break;
      case 'S':  /* <b0> <bN> <incB> */
         if (i+3 >= nargs)
            PrintUsage(args[0], i-1, NULL);
         else
         {
            int b0, bn, incB, n, k;

            b0 = atoi(args[i+1]);
            bn = atoi(args[i+2]);
            incB = atoi(args[i+3]);
            n = 1 + (bn-b0)/incB;
            mbs = malloc(n*sizeof(int));
            nbs = malloc(n*sizeof(int));
            kbs = malloc(n*sizeof(int));
            assert(mbs && nbs && kbs);
            for (k=0,n=b0; n <= bn; k++, n += incB)
               mbs[k] = nbs[k] = kbs[k] = n;
            assert(k <= n);
            i += 3;
            *NN = k;
         }
         break;
      case 'B':
         if (nbs)
         {
            free(mbs);
            free(nbs);
            free(kbs);
         }
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         *NN = N = atoi(args[i]);
         assert(N > 0);
         nbs = malloc(N*sizeof(int));
         assert(nbs);
         mbs = malloc(N*sizeof(int));
         assert(mbs);
         kbs = malloc(N*sizeof(int));
         assert(kbs);
         for (k=0; k < N; k++)
         {
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           mbs[k] = atoi(args[i]);
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           nbs[k] = atoi(args[i]);
           if (++i >= nargs)
               PrintUsage(args[0], i-1, NULL);
           kbs[k] = atoi(args[i]);
         }
         break;
      case 'b':
         if (nbs)
         {
            free(mbs);
            free(nbs);
            free(kbs);
         }
         if (++i >= nargs)
            PrintUsage(args[0], i-1, NULL);
         N = atoi(args[i]);
         if (N < 0)
         {
            ALL = (N == -2) ? 32 : -1;  /* -2: don't force MB */
            N = 36;
         }
         *NN = N;
         assert(N > 0);
         nbs = malloc(N*sizeof(int));
         assert(nbs);
         mbs = malloc(N*sizeof(int));
         assert(nbs);
         kbs = malloc(N*sizeof(int));
         assert(nbs);
         if (ALL)  /* special case to just try most possible NBs */
         {
            mbs[ 0]=nbs[ 0]=kbs[ 0]=4;
            mbs[ 1]=nbs[ 1]=kbs[ 1]=6;
            mbs[ 2]=nbs[ 2]=kbs[ 2]=8;
            mbs[ 3]=nbs[ 3]=kbs[ 3]=12;
            mbs[ 4]=nbs[ 4]=kbs[ 4]=14;
            mbs[ 5]=nbs[ 5]=kbs[ 5]=16;
            mbs[ 6]=nbs[ 6]=kbs[ 6]=20;
            mbs[ 7]=nbs[ 7]=kbs[ 7]=22;
            mbs[ 8]=nbs[ 8]=kbs[ 8]=24;
            mbs[ 9]=nbs[ 9]=kbs[ 9]=26;
            mbs[10]=nbs[10]=kbs[10]=28;
            mbs[11]=nbs[11]=kbs[11]=32;
            mbs[12]=nbs[12]=kbs[12]=36;
            mbs[13]=nbs[13]=kbs[13]=40;
            mbs[14]=nbs[14]=kbs[14]=44;
            mbs[15]=nbs[15]=kbs[15]=48;
            mbs[16]=nbs[16]=kbs[16]=52;
            mbs[17]=nbs[17]=kbs[17]=56;
            mbs[18]=nbs[18]=kbs[18]=60;
            mbs[19]=nbs[19]=kbs[19]=64;
            mbs[20]=nbs[20]=kbs[20]=72;
            mbs[21]=nbs[21]=kbs[21]=80;
            mbs[22]=nbs[22]=kbs[22]=84;
            mbs[23]=nbs[23]=kbs[23]=88;
            mbs[24]=nbs[24]=kbs[24]=96;
            mbs[25]=nbs[25]=kbs[25]=104;
            mbs[26]=nbs[26]=kbs[26]=112;
            mbs[27]=nbs[27]=kbs[27]=120;
            mbs[28]=nbs[28]=kbs[28]=128;
            mbs[29]=nbs[29]=kbs[29]=132;
            mbs[30]=nbs[30]=kbs[30]=144;
            mbs[31]=nbs[31]=kbs[31]=156;
            mbs[32]=nbs[32]=kbs[32]=168;
            mbs[33]=nbs[33]=kbs[33]=192;
            mbs[34]=nbs[34]=kbs[34]=216;
            mbs[35]=nbs[35]=kbs[35]=240;
            for (k=0; k < ALL; k++)     /* don't force any particular */
               mbs[k] = 0;              /* MB during search */
         }
         else
         {
            for (k=0; k < N; k++)
            {
              if (++i >= nargs)
                  PrintUsage(args[0], i-1, NULL);
               mbs[k] = kbs[k] = nbs[k] = atoi(args[i]);
            }
         }
         break;
      default:
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (!nbs)
      PrintUsage(args[0], -1, "Dimensional flag (-b, -B -N, or -S) required!");
   *MBS = mbs;
   *NBS = nbs;
   *KBS = kbs;
   *MVS = MV;
   if (!fout)
   {
      sprintf(fnam, "res/%cuAMMRES.sum", *PRE);
      fout = fnam;
   }
   return(fout);
}

ATL_mmnode_t *DoSrch(ATL_mmnode_t *mmb, char pre, int flag, int beta, 
                     int cflush, int nB, int *mbs, int *nbs, int *kbs)
// need args for: moves
{
   ATL_mmnode_t *mmB=NULL;
   int ib;
   printf("\nFINDING BEST AMONGST %d KERNELS and %d BLOCK FACTORS:\n", 
          ATL_CountNumberOfMMNodes(mmb), nB);
   for (ib=0; ib < nB; ib++)
   {
      ATL_mmnode_t *mmp;
      const int mb = mbs[ib], nb=nbs[ib], kb=kbs[ib];
      mmp = MMBestWithGenKB(1, 0, flag, mmb, pre, mb, nb, kb, beta, -1, cflush);
      if (mmp)
      {
         mmp->next = mmB;
         mmB = mmp;
         printf("   BEST FOR B=(%d,%d,%d): %d,%s, mf=%.2f\n", 
                mb, nb, kb, mmp->ID, mmp->rout, mmp->mflop[0]);
      }
      else
         printf("   NO VALID KERNEL FOR B=(%d,%d,%d)!\n", mb, nb, kb);
   }
   return(ReverseMMQ(mmB));
}

int main(int nargs, char **args)
{
   ATL_mmnode_t *mmb, *mmB;
   int *mbs, *nbs, *kbs;
   char *fnout;
   int C, MVS, N, KCLEAN;
   float tol;
   char pre, upr;

   fnout = GetFlags(nargs, args, &pre, &C, &MVS, &N, &mbs, &nbs, &kbs, &tol,
                    &KCLEAN);
   if (pre == 'd' || pre == 's')
      upr = pre;
   else
      upr = (pre == 'z') ? 'd' : 's';
/*
 * Get all working user-supplied kerns & best found generated kerns
 * assumes default search already run to produce [WORKING,gAMMRES].sum
 */
   mmb = ReadMMFileWithPath(upr, "res", "WORKING.sum");
   ATL_LastMMNode(mmb)->next = ReadMMFileWithPath(pre, "res", "gAMMRES.sum");
   assert(mmb);
/*
 * Remove kernels that don't meet required constraints
 */
   if (C)
   {
      ATL_mmnode_t *mp=mmb;
      do
      {
         ATL_mmnode_t *nxt = mp->next;
         int kill;
         kill  = (C & (1<<CON_NOKVEC)) && FLAG_IS_SET(mp->flag, MMF_KVEC);
         kill |= (C & (1<<CON_NOMVEC)) && !FLAG_IS_SET(mp->flag, MMF_KVEC);
         kill |= (C & (1<<CON_NOCOMPK)) && !FLAG_IS_SET(mp->flag, MMF_KRUNTIME);
         if (kill)
         {
            mmb = RemoveMMNodeFromQ(mmb, mp);
            KillMMNode(mp);
         }
         mp = nxt;
      }
      while (mp);
      assert(mmb);
   }
   MMApplyMoves2Flags(mmb, MVS);  /* use requested flushing */
   mmB = DoSrch(mmb, pre, 0, 1, -1, N, mbs, nbs, kbs);
   KillAllMMNodes(mmb);
   free(mbs);
   free(nbs);
   free(kbs);
   assert(mmB);
   if (tol > 0.0)
      MMPruneMflopTol(mmB, 0, tol);
   WriteMMFile(fnout, mmB);
   KillAllMMNodes(mmB);
   return(0);
}
